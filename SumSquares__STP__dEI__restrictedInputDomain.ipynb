{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SumSquares__STP__dEI__restrictedInputDomain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaQo_XsusPbm"
      },
      "source": [
        "SumSquares synthetic function:\r\n",
        "\r\n",
        "GP EI: (exact GP EI gradients) vs. STP EI: (exact STP EI gradients)\r\n",
        "\r\n",
        "https://www.sfu.ca/~ssurjano/sumsqu.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhgucjJgsYfm",
        "outputId": "83b85ed3-9931-4666-f488-bc63bb5e9933"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyGPGO\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/87/a113c91ba014708114f7635d5c0f6a5e5c773480c5f0a537b257a02d180d/pyGPGO-0.4.0.dev1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (0.22.2.post1)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (3.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.10.0)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.41.1)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2.8.1)\n",
            "Building wheels for collected packages: pyGPGO\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.4.0.dev1-cp37-none-any.whl size=19866 sha256=923633221dc482ffe89d0625e87fc2273a1989a2fc9bcabb890513cada3c574a\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/27/04/c4fa3bfe194d36e3cd51542132f43415a6813114a5e8301acb\n",
            "Successfully built pyGPGO\n",
            "Installing collected packages: pyGPGO\n",
            "Successfully installed pyGPGO-0.4.0.dev1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E99qMZverfrP"
      },
      "source": [
        "### Import modules:\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import scipy as sp\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import warnings\r\n",
        "import time\r\n",
        "\r\n",
        "from pyGPGO.logger import EventLogger\r\n",
        "from pyGPGO.GPGO import GPGO\r\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\r\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\r\n",
        "from pyGPGO.acquisition import Acquisition\r\n",
        "from pyGPGO.covfunc import squaredExponential\r\n",
        "\r\n",
        "from collections import OrderedDict\r\n",
        "from joblib import Parallel, delayed\r\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\r\n",
        "from scipy.optimize import minimize\r\n",
        "from scipy.spatial.distance import cdist\r\n",
        "from scipy.special import gamma\r\n",
        "from scipy.stats import norm, t\r\n",
        "from matplotlib.pyplot import rc\r\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\r\n",
        "\r\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiJSpz2P9qXK"
      },
      "source": [
        "n_start_AcqFunc = 250 #multi-start iterations to avoid local optima in AcqFunc optimization"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzPUbCs3s9nu"
      },
      "source": [
        "### Inputs:\r\n",
        "\r\n",
        "obj_func = 'SumSquares'\r\n",
        "n_test = n_start_AcqFunc # test points\r\n",
        "df = 3 # nu\r\n",
        "\r\n",
        "util_loser = 'dEI_GP'\r\n",
        "util_winner = 'dEI_STP'\r\n",
        "n_init = 5 # random initialisations"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AMqjmpbtAb1"
      },
      "source": [
        "### Objective function:\r\n",
        "\r\n",
        "if obj_func == 'SumSquares': # 8-D\r\n",
        "            \r\n",
        "    def f_syn_polarity(x1_training, x2_training, x3_training, x4_training, x5_training, x6_training, x7_training, x8_training):\r\n",
        "        return  operator * (  1 * x1_training ** 2\r\n",
        "                            + 2 * x2_training ** 2\r\n",
        "                            + 3 * x3_training ** 2\r\n",
        "                            + 4 * x4_training ** 2\r\n",
        "                            + 5 * x5_training ** 2\r\n",
        "                            + 6 * x6_training ** 2\r\n",
        "                            + 7 * x7_training ** 2\r\n",
        "                            + 8 * x8_training ** 2)\r\n",
        "                            \r\n",
        "# Constraints:\r\n",
        "    lb = -5.12 \r\n",
        "    ub = +5.12\r\n",
        "    \r\n",
        "# Input array dimension(s):\r\n",
        "    dim = 8\r\n",
        "    max_iter = 100\r\n",
        "\r\n",
        "# 8-D inputs' parameter bounds:\r\n",
        "    param = {'x1_training': ('cont', [lb, ub]),\r\n",
        "             'x2_training': ('cont', [lb, ub]),\r\n",
        "             'x3_training': ('cont', [lb, ub]),\r\n",
        "             'x4_training': ('cont', [lb, ub]),\r\n",
        "             'x5_training': ('cont', [lb, ub]),\r\n",
        "             'x6_training': ('cont', [lb, ub]),\r\n",
        "             'x7_training': ('cont', [lb, ub]),\r\n",
        "             'x8_training': ('cont', [lb, ub])\r\n",
        "            }\r\n",
        "\r\n",
        "    \r\n",
        "# True y bounds:\r\n",
        "    y_lb = 0.00000\r\n",
        "    operator = -1 # targets global minimum \r\n",
        "    y_global_orig = y_lb * operator # targets global minimum\r\n",
        "\r\n",
        "# Test data:\r\n",
        "    x1_test = np.linspace(lb, ub, max_iter) \r\n",
        "    x2_test = np.linspace(lb, ub, max_iter)\r\n",
        "    x3_test = np.linspace(lb, ub, max_iter)\r\n",
        "    x4_test = np.linspace(lb, ub, max_iter)\r\n",
        "    x5_test = np.linspace(lb, ub, max_iter)\r\n",
        "    x6_test = np.linspace(lb, ub, max_iter)\r\n",
        "    x7_test = np.linspace(lb, ub, max_iter)\r\n",
        "    x8_test = np.linspace(lb, ub, max_iter)\r\n",
        "    Xstar_d = np.column_stack((x1_test,x2_test,x3_test,x4_test,x5_test,x6_test,x7_test,x8_test))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyQX-59DtC7-"
      },
      "source": [
        "### Cumulative Regret Calculator:\r\n",
        "\r\n",
        "def min_max_array(x):\r\n",
        "    new_list = []\r\n",
        "    for i, num in enumerate(x):\r\n",
        "            new_list.append(np.min(x[0:i+1]))\r\n",
        "    return new_list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE_I_YSntHxl"
      },
      "source": [
        "### Set-seeds:\r\n",
        "\r\n",
        "run_num_1 = 111\r\n",
        "run_num_2 = 113\r\n",
        "run_num_3 = 3333\r\n",
        "run_num_4 = 444\r\n",
        "run_num_5 = 5555\r\n",
        "run_num_6 = 6\r\n",
        "run_num_7 = 777\r\n",
        "run_num_8 = 887\r\n",
        "run_num_9 = 99\r\n",
        "run_num_10 = 1000\r\n",
        "run_num_11 = 1113\r\n",
        "run_num_12 = 1234\r\n",
        "run_num_13 = 2345\r\n",
        "run_num_14 = 88\r\n",
        "run_num_15 = 1556\r\n",
        "run_num_16 = 1666\r\n",
        "run_num_17 = 717\r\n",
        "run_num_18 = 8\r\n",
        "run_num_19 = 1998\r\n",
        "run_num_20 = 2000"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe29v5N5tKjF"
      },
      "source": [
        "### Derivatives - Squared-exponential covariance function:\r\n",
        "\r\n",
        "def l2norm_(X, Xstar):\r\n",
        "    \r\n",
        "    return cdist(X, Xstar)\r\n",
        "\r\n",
        "def kronDelta(X, Xstar):\r\n",
        "\r\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\r\n",
        "\r\n",
        "class squaredExponentialDeriv(squaredExponential):\r\n",
        "    \r\n",
        "    def K(self, X, Xstar):\r\n",
        "        \r\n",
        "        r = (l2norm_(X, Xstar)/self.l)\r\n",
        "        K = self.sigmaf * np.exp(-1/2*r **2) + self.sigman * kronDelta(X, Xstar)\r\n",
        "        return K\r\n",
        "    \r\n",
        "    def dK(self, X, Xstar):\r\n",
        "        \r\n",
        "        r = (l2norm_(X, Xstar)/self.l)\r\n",
        "        dK = self.sigmaf/self.l**2 * np.exp(-1/2 * r **2) * l2norm_(X, Xstar)\r\n",
        "        return dK\r\n",
        "    \r\n",
        "        \r\n",
        "    def d2K(self, X, Xstar):\r\n",
        "        \r\n",
        "        r = (l2norm_(X, Xstar)/self.l)\r\n",
        "        d2K = self.sigmaf/self.l**2 * np.exp(-1/2 * r **2) * (r**2-1)\r\n",
        "        return d2K\r\n",
        "    \r\n",
        "cov_func = squaredExponential()\r\n",
        "d_cov_func = squaredExponentialDeriv()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEBX5l7TtNSN"
      },
      "source": [
        "class Acquisition_new(Acquisition):    \r\n",
        "    def __init__(self, mode, eps=1e-08, **params):\r\n",
        "        \r\n",
        "        self.params = params\r\n",
        "        self.eps = eps\r\n",
        "\r\n",
        "        mode_dict = {\r\n",
        "            'dEI_GP': self.dEI_GP,\r\n",
        "            'dEI_STP': self.dEI_STP\r\n",
        "        }\r\n",
        "\r\n",
        "        self.f = mode_dict[mode]\r\n",
        "    \r\n",
        "    def dEI_GP(self, tau, mean, std, ds, dm, dvdv, d2v, d2m):\r\n",
        "        z = -1 * (tau - mean - self.eps) / (std + self.eps)\r\n",
        "        \r\n",
        "        dsdx = ds / 2 * (std + self.eps)\r\n",
        "        d2sdx = -dsdx**2 / ((std + self.eps)) - dvdv / (std + self.eps) - d2v / (std + self.eps)\r\n",
        "        dmdx = (dm - z * dsdx) / (std + self.eps)\r\n",
        "        d2mdx = (d2m - (z * d2sdx + 2 * dmdx * dsdx)) / (std + self.eps)\r\n",
        "        \r\n",
        "        f = (std + self.eps) * (z * norm.cdf(z) + norm.pdf(z)[0])\r\n",
        "        df = (f / (std + self.eps) * dsdx + (std + self.eps) * norm.cdf(z) * dmdx)\r\n",
        "        d2f = (f / (std + self.eps) * d2sdx + dsdx * dmdx * norm.cdf(z) \\\r\n",
        "            + d2mdx * (std + self.eps) * norm.cdf(z) + dsdx * norm.cdf(z) * dmdx \\\r\n",
        "            + norm.pdf(z)[0] * (std + self.eps) * dmdx)\r\n",
        "            \r\n",
        "        return f, df, d2f\r\n",
        "\r\n",
        "    def dEI_STP(self, tau, mean, std, ds, dm, dvdv, d2v, d2m, nu=3.0):\r\n",
        "    \r\n",
        "        gamma = -1 * (tau - mean - self.eps) / (std + self.eps)\r\n",
        "        dsdx = ds / 2 * (std + self.eps)\r\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\r\n",
        "        f = (std + self.eps) * (gamma * t.cdf(gamma, df=nu) + (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma, df=nu))\r\n",
        "        df = (gamma * t.cdf(gamma, df=nu) + (nu + gamma ** 2)/(nu - 1) * t.pdf(gamma,df=nu)[0]) * dsdx \\\r\n",
        "             + (std + self.eps) * (t.cdf(gamma,df=nu) * dmdx + gamma * t.pdf(gamma, df=nu) * \\\r\n",
        "             (1 - (nu + gamma ** 2)/(nu - 1) + 2/(nu - 1) * dmdx))\r\n",
        "        return f, df\r\n",
        "    \r\n",
        "    def _eval(self, tau, mean, std):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, **self.params)\r\n",
        "    \r\n",
        "    def d_eval(self, tau, mean, std, ds, dm, dvdv, d2v, d2m):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, ds, dm, dvdv, d2v, d2m, **self.params)\r\n",
        "\r\n",
        "    def d_eval_stp(self, tau, mean, std, ds, dm, dvdv, d2v, d2m, nu=3.0):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, ds, dm, dvdv, d2v, d2m, nu=3.0, **self.params)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SdY8rHwtRJ_"
      },
      "source": [
        "### Surrogate derivatives: \r\n",
        "\r\n",
        "from scipy.linalg import cholesky, solve\r\n",
        "\r\n",
        "class dGaussianProcess(GaussianProcess):\r\n",
        "    l = 1\r\n",
        "    sigmaf = 1\r\n",
        "    sigman = 1e-6\r\n",
        "\r\n",
        "    def AcqGrad(self, Xstar, return_std=False):\r\n",
        "        r_X = l2norm_(self.X, self.X)/self.l\r\n",
        "        K = self.sigmaf * np.exp(-1/2*r_X **2) + self.sigman * kronDelta(self.X, self.X)\r\n",
        "        L = cholesky(K).T\r\n",
        "        alpha = solve(L.T, solve(L, self.y))\r\n",
        "        Xstar = np.atleast_2d(Xstar)\r\n",
        "        Kstar = squaredExponentialDeriv.K(self, self.X, Xstar).T\r\n",
        "        dKstar = squaredExponentialDeriv.dK(self, self.X, Xstar).T\r\n",
        "        d2Kstar = squaredExponentialDeriv.d2K(self, self.X, Xstar).T\r\n",
        "        v = solve(self.L, Kstar.T)\r\n",
        "        dv = solve(self.L, dKstar.T)\r\n",
        "        d2v = solve(self.L, d2Kstar.T)\r\n",
        "        \r\n",
        "        ds = -2 * np.dot(dv.T, v)\r\n",
        "        dvdv = np.dot(dv.T, dv)\r\n",
        "        d2s = -2 * (dvdv + d2v)\r\n",
        "        \r\n",
        "        dm = np.dot(dKstar, alpha)\r\n",
        "        d2m = np.dot(d2Kstar, alpha)\r\n",
        "        return ds, dm, dvdv, d2v, d2m\r\n",
        "\r\n",
        "class dtStudentProcess(tStudentProcess):\r\n",
        "    l = 1\r\n",
        "    sigmaf = 1\r\n",
        "    sigman = 1e-6\r\n",
        "    \r\n",
        "    def AcqGrad(self, Xstar, return_std=False):\r\n",
        "        r_X = l2norm_(self.X, self.X)/self.l\r\n",
        "        K = self.sigmaf * np.exp(-1/2*r_X **2) + self.sigman * kronDelta(self.X, self.X)\r\n",
        "        L = cholesky(self.K11).T\r\n",
        "        alpha = solve(L.T, solve(L, self.y))\r\n",
        "        Xstar = np.atleast_2d(Xstar)\r\n",
        "        Kstar = squaredExponentialDeriv.K(self, self.X, Xstar).T\r\n",
        "        dKstar = squaredExponentialDeriv.dK(self, self.X, Xstar).T\r\n",
        "        d2Kstar = squaredExponentialDeriv.d2K(self, self.X, Xstar).T\r\n",
        "        v = solve(L, Kstar.T)\r\n",
        "        dv = solve(L, dKstar.T)\r\n",
        "        d2v = solve(L, d2Kstar.T)\r\n",
        "        \r\n",
        "        ds = -2 * np.dot(dv.T, v)\r\n",
        "        dvdv = np.dot(dv.T, dv)\r\n",
        "        d2s = -2 * (dvdv + d2v)\r\n",
        "        \r\n",
        "        dm = np.dot(dKstar, alpha)\r\n",
        "        d2m = np.dot(d2Kstar, alpha)\r\n",
        "        return ds, dm, dvdv, d2v, d2m"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNv4Z0EqtUi2"
      },
      "source": [
        "class dGPGO(GPGO):  \r\n",
        "    n_start = n_start_AcqFunc\r\n",
        "    eps = 1e-08\r\n",
        "        \r\n",
        "    def func(self, xnew):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2v, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        f  = np.empty((self.n_start,))\r\n",
        "        df = np.empty((self.n_start,))\r\n",
        "        f  = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[0]\r\n",
        "        df = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[1]\r\n",
        "        df_array = np.full((len(xnew),),df)\r\n",
        "        return f, df_array\r\n",
        "        \r\n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start):\r\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\r\n",
        "        start_points_arr = np.array([list(s.values())\r\n",
        "                                     for s in start_points_dict])\r\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\r\n",
        "        f_best = np.empty((n_start,))\r\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func,\r\n",
        "                                                                 x0=start_point,\r\n",
        "                                                                 method=method,\r\n",
        "                                                                 jac = True,\r\n",
        "                                                                 bounds=self.parameter_range) for start_point in\r\n",
        "                                               start_points_arr)\r\n",
        "        x_best = np.array([res.x for res in opt])\r\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\r\n",
        "\r\n",
        "        self.x_best = x_best\r\n",
        "        self.f_best = f_best\r\n",
        "        self.best = x_best[np.argmin(f_best)]\r\n",
        "    \r\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\r\n",
        "        \r\n",
        "        if not resume:\r\n",
        "            self.init_evals = init_evals\r\n",
        "            self._firstRun(self.init_evals)\r\n",
        "            self.logger._printInit(self)\r\n",
        "        for iteration in range(max_iter):\r\n",
        "            self.d_optimizeAcq()\r\n",
        "            self.updateGP()\r\n",
        "            self.logger._printCurrent(self)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7vea4uj-GOi"
      },
      "source": [
        "## dGPGO_stp - BayesOpt derivatives' class: Student's-t\r\n",
        "\r\n",
        "class dGPGO_stp(GPGO):  \r\n",
        "    n_start = 100\r\n",
        "        \r\n",
        "    def func_stp(self, xnew):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2v, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        f  = np.empty((self.n_start,))\r\n",
        "        df = np.empty((self.n_start,))\r\n",
        "        f  = -self.A.d_eval_stp(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m, nu=df)[0]\r\n",
        "        df = -self.A.d_eval_stp(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m, nu=df)[1]\r\n",
        "        df_array = np.full((len(xnew),),df)\r\n",
        "        return f, df_array\r\n",
        "        \r\n",
        "    def d_optimizeAcq_stp(self, method='L-BFGS-B', n_start=n_start):\r\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\r\n",
        "        start_points_arr = np.array([list(s.values())\r\n",
        "                                     for s in start_points_dict])\r\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\r\n",
        "        f_best = np.empty((n_start,))\r\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func_stp,\r\n",
        "                                                                 x0=start_point,\r\n",
        "                                                                 method=method,\r\n",
        "                                                                 jac = True,\r\n",
        "                                                                 bounds=self.parameter_range) for start_point in\r\n",
        "                                               start_points_arr)\r\n",
        "        x_best = np.array([res.x for res in opt])\r\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\r\n",
        "\r\n",
        "        self.x_best = x_best\r\n",
        "        self.f_best = f_best\r\n",
        "        self.best = x_best[np.argmin(f_best)]\r\n",
        "    \r\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\r\n",
        "        \r\n",
        "        if not resume:\r\n",
        "            self.init_evals = init_evals\r\n",
        "            self._firstRun(self.init_evals)\r\n",
        "            self.logger._printInit(self)\r\n",
        "        for iteration in range(max_iter):\r\n",
        "            self.d_optimizeAcq_stp()\r\n",
        "            self.updateGP()\r\n",
        "            self.logger._printCurrent(self)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expMSaSUtcB-"
      },
      "source": [
        "### d2GPGO - BayesOpt class: \r\n",
        "\r\n",
        "class d2GPGO(GPGO):  \r\n",
        "    n_start = 100\r\n",
        "    p = np.full((n_start,1),1)\r\n",
        "    \r\n",
        "    def func(self, xnew):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        f  = np.empty((self.n_start,))\r\n",
        "        df = np.empty((self.n_start,))\r\n",
        "        f  = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[0]\r\n",
        "        df = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[1]\r\n",
        "        df_array = np.full((len(xnew),),df)\r\n",
        "        return f, df_array\r\n",
        "    \r\n",
        "    def hessp_nonzero(self, xnew, p):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        df2 = np.empty((self.n_start,))\r\n",
        "        df2 = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[2]\r\n",
        "        H2 = np.empty((self.n_start,))\r\n",
        "        df2 = np.asarray(df2)\r\n",
        "        p = np.asarray(p)\r\n",
        "        H2 = np.multiply(df2,p)\r\n",
        "        return H2\r\n",
        "    \r\n",
        "    def d_optimizeAcq(self, method='Newton-CG', n_start=n_start):\r\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\r\n",
        "        start_points_arr = np.array([list(s.values())\r\n",
        "                                     for s in start_points_dict])\r\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\r\n",
        "        f_best = np.empty((n_start,))\r\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func,\r\n",
        "                                                                 x0=start_point,\r\n",
        "                                                                 method=method,\r\n",
        "                                                                 jac = True,\r\n",
        "                                                                 hessp = self.hessp_nonzero,\r\n",
        "                                                                 bounds=self.parameter_range) for start_point in\r\n",
        "                                               start_points_arr)\r\n",
        "        \r\n",
        "        x_best = np.array([res.x for res in opt])\r\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\r\n",
        "\r\n",
        "        self.best = x_best[np.argmin(f_best)]     \r\n",
        "    \r\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\r\n",
        "        \r\n",
        "        if not resume:\r\n",
        "            self.init_evals = init_evals\r\n",
        "            self._firstRun(self.init_evals)\r\n",
        "            self.logger._printInit(self)\r\n",
        "        for iteration in range(max_iter):\r\n",
        "            self.d_optimizeAcq()\r\n",
        "            self.updateGP()\r\n",
        "            self.logger._printCurrent(self)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umKPgDuEtcxH",
        "outputId": "0cbfe845-227c-41f4-b978-cada73e072ad"
      },
      "source": [
        "start_lose = time.time()\r\n",
        "start_lose"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1614490221.1665146"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfEuNIqvtdSv",
        "outputId": "fdef4e45-9cf1-46cf-8c07-7b9d3a98a0b0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 1\r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_loser_1 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_1 = dGPGO(surrogate_loser_1, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.1486226  -3.38872572 -0.65475564  2.75724772 -2.09586888 -3.59257132\n",
            " -4.88982196 -0.8169012 ]. \t  -328.0959084909929 \t -201.54672633894333\n",
            "init   \t [-2.67589487 -1.6624006   5.02489564 -2.68568111 -4.28858717  1.73670644\n",
            "  1.24152749 -2.31164385]. \t  -280.8839324859534 \t -201.54672633894333\n",
            "init   \t [-0.34589276 -3.90791423 -4.36267454  4.10392759  3.01017662  3.4874332\n",
            "  3.22772436  5.02737768]. \t  -548.5335043326104 \t -201.54672633894333\n",
            "init   \t [ 0.79128402  3.21297323 -0.80570494 -4.83893289 -0.46964077 -4.04146089\n",
            "  3.24833343  2.024732  ]. \t  -322.64234862459267 \t -201.54672633894333\n",
            "init   \t [ 0.66852251 -2.31191249  5.10437114 -3.70644938  1.18185664 -0.15322828\n",
            " -0.97252315  2.33317475]. \t  -201.54672633894333 \t -201.54672633894333\n",
            "1      \t [-1.8143854  -1.01841357 -1.85378403  4.57955153  4.28757363  3.21376643\n",
            " -4.77105058  4.54013818]. \t  -577.6945507490634 \t -201.54672633894333\n",
            "2      \t [ 0.73477645  4.76179847  2.44940567  3.13414171 -3.48280262  1.90357758\n",
            " -3.83397596  3.09532749]. \t  -365.1147228674192 \t -201.54672633894333\n",
            "3      \t [-3.5467779   3.96685844  3.46147609 -1.56535356  3.7231233  -1.41064385\n",
            " -0.09555    -0.96783139]. \t  \u001b[92m-178.6035640716962\u001b[0m \t -178.6035640716962\n",
            "4      \t [ 4.70386575 -0.61990413 -3.52715656  1.33889179 -0.68273896 -1.23336882\n",
            "  5.01603996 -0.44567422]. \t  -256.559397064366 \t -178.6035640716962\n",
            "5      \t [-0.90304164 -4.48687786 -2.04677476 -0.42286783  3.29703598  4.43106951\n",
            "  2.02351792 -2.70572486]. \t  -313.75120296777686 \t -178.6035640716962\n",
            "6      \t [ 4.54601656 -2.9331311  -0.72674805 -4.70035876 -4.64794837  1.61737369\n",
            "  4.62058541 -2.42925591]. \t  -448.20220732965174 \t -178.6035640716962\n",
            "7      \t [-4.28389253 -3.73571984 -2.80655181  4.05331295 -3.78737786  3.18892028\n",
            "  3.94559298  0.89872328]. \t  -383.7825097969107 \t -178.6035640716962\n",
            "8      \t [ 4.95813127  4.96607931 -2.50561052  4.8892261   1.12715432  3.11191532\n",
            "  2.30920718  2.42021385]. \t  -337.00236425324454 \t -178.6035640716962\n",
            "9      \t [-2.17149059 -3.59638969  4.80494534 -0.21803099 -4.46695367 -3.25794579\n",
            " -3.89312838  4.85422792]. \t  -558.093067666367 \t -178.6035640716962\n",
            "10     \t [-1.92504556  1.47737033 -4.68448457 -4.21674554 -3.773463    4.80149054\n",
            "  1.64440906  2.29176778]. \t  -415.4951538555236 \t -178.6035640716962\n",
            "11     \t [-0.54926905 -3.67610341 -4.87724758 -1.49098033  4.71038006 -2.59407233\n",
            " -4.56647697 -5.11754304]. \t  -614.3805166225843 \t -178.6035640716962\n",
            "12     \t [ 2.15963188 -0.28935896  3.4330065   2.88435574  4.27790585 -3.59554826\n",
            "  4.51075703  4.08577132]. \t  -518.5130170758617 \t -178.6035640716962\n",
            "13     \t [ 4.23570729 -1.25322567 -4.62947164 -1.05331365 -2.46562431  1.1914759\n",
            " -2.57181313  2.46364884]. \t  -223.58655635373117 \t -178.6035640716962\n",
            "14     \t [ 2.7096023   4.01633633  4.42758465  0.27090644  2.56072218  3.20835866\n",
            "  4.91152799 -2.00296156]. \t  -394.21241125830977 \t -178.6035640716962\n",
            "15     \t [ 1.39724163  4.57433139 -4.27303488 -4.52305432 -4.06237888  0.60552741\n",
            "  2.07899585 -3.80950005]. \t  -411.47834480380516 \t -178.6035640716962\n",
            "16     \t [-1.83201609  0.49357821  3.33050886  4.68592079 -1.28128738 -0.32263751\n",
            "  2.7114435  -2.46402514]. \t  -233.81970085263237 \t -178.6035640716962\n",
            "17     \t [-0.64250492  4.02745109 -4.34114381  0.48860422  3.6144917  -0.22614658\n",
            " -0.36824808 -4.38741486]. \t  -310.91918711145547 \t -178.6035640716962\n",
            "18     \t [-2.83735731  0.64370077 -2.81905553 -3.31724895  4.90273561 -4.05767388\n",
            " -4.74791825  4.28473602]. \t  -600.3802641582724 \t -178.6035640716962\n",
            "19     \t [-4.6177753  -5.12       -5.12       -3.77963294 -5.12       -5.12\n",
            " -5.12       -5.12      ]. \t  -891.1127494403648 \t -178.6035640716962\n",
            "20     \t [ 1.9378258  -0.40952615 -4.48307333  3.37434648  1.41469669  3.7276301\n",
            " -5.03852252 -3.00652418]. \t  -453.32794428016115 \t -178.6035640716962\n",
            "21     \t [ 5.07111796  3.61588356  3.4351822   0.47630014  4.47335197  3.31201939\n",
            " -4.06301797  1.22378051]. \t  -381.58348162523873 \t -178.6035640716962\n",
            "22     \t [ 4.17234548 -3.74905414 -3.28714663 -4.64943455  3.46893149 -0.91697168\n",
            "  3.294976   -4.08604531]. \t  -439.18089529704207 \t -178.6035640716962\n",
            "23     \t [-4.06928374 -3.26578657 -0.23424264 -3.38168932 -1.78761698  3.68828215\n",
            " -4.90574398 -0.38207461]. \t  -351.0282334804192 \t -178.6035640716962\n",
            "24     \t [ 4.34737899  1.11821238 -3.5484966  -3.11002767  4.92652316  4.21818856\n",
            " -2.46464939  3.78102538]. \t  -482.867615012529 \t -178.6035640716962\n",
            "25     \t [ 3.52034175  2.20470734  4.9804913   2.53008909 -0.99106825 -3.82779259\n",
            " -3.68515401 -4.95183672]. \t  -506.1866325099793 \t -178.6035640716962\n",
            "26     \t [-4.71325354  0.12246692  4.20094829  3.08876566  4.01784593  3.47738765\n",
            "  2.56283126  2.56049282]. \t  -365.0450428305473 \t -178.6035640716962\n",
            "27     \t [-2.49808257  4.75065964  4.44686159 -4.88354925 -0.93892423  4.94734784\n",
            "  2.87944842  1.54779587]. \t  -434.5672340323659 \t -178.6035640716962\n",
            "28     \t [-4.89988621  4.21603438 -1.20137908  2.95240933 -2.91031254 -0.15904329\n",
            "  3.50721142  4.5311823 ]. \t  -391.61358719881946 \t -178.6035640716962\n",
            "29     \t [-4.18014667  1.74241484 -2.71315089  2.39393234 -3.34192551 -4.95366543\n",
            " -4.4650306   3.54951905]. \t  -511.97616621076304 \t -178.6035640716962\n",
            "30     \t [ 3.49892523 -4.7474275   2.72098332  4.67729941  3.10982505 -1.59525928\n",
            " -2.37362939  4.65839384]. \t  -443.70643578214737 \t -178.6035640716962\n",
            "31     \t [-5.00032705  2.54540284 -3.95784229  1.64796881 -3.92295653 -0.82039946\n",
            " -1.56928399 -3.69252898]. \t  -303.1211727260613 \t -178.6035640716962\n",
            "32     \t [ 5.11656808 -4.93464889  4.34227567  0.98576649 -1.60020465  2.77092347\n",
            "  3.93631358  4.62322016]. \t  -473.6604497374435 \t -178.6035640716962\n",
            "33     \t [ 2.85960226  1.58136403  2.54750539  4.44904883 -4.01792361 -4.30011451\n",
            "  2.3325104   3.77652939]. \t  -455.6703288108725 \t -178.6035640716962\n",
            "34     \t [-3.54459935  1.46610183 -5.01645307 -1.45635243  4.46382659  0.84644066\n",
            "  1.87163321  5.10013455]. \t  -437.3809130991791 \t -178.6035640716962\n",
            "35     \t [-3.51160644  1.10856337  1.12871135 -3.7390973  -3.92134226 -3.78712372\n",
            " -4.91832849 -2.28298046]. \t  -448.4987141336687 \t -178.6035640716962\n",
            "36     \t [ 4.71260685 -2.49237623  4.70617449  4.20653469  3.85063847  2.3875272\n",
            " -2.52132316 -5.07327811]. \t  -530.6000131506784 \t -178.6035640716962\n",
            "37     \t [ 2.93549399  3.90657854 -4.93585962 -4.17749541  3.4097731  -4.83751273\n",
            "  4.28033909 -4.18294895]. \t  -648.8013936318323 \t -178.6035640716962\n",
            "38     \t [ 4.56855361  4.20367402  2.77799543 -2.10763528 -1.93730782 -4.43642414\n",
            " -3.30261693  4.72665452]. \t  -489.07173105620086 \t -178.6035640716962\n",
            "39     \t [ 0.19846559 -5.00044851  0.74470773 -2.72860159 -3.52381154 -4.7474923\n",
            "  4.0222522   3.62534674]. \t  -497.2062333586665 \t -178.6035640716962\n",
            "40     \t [-1.38858521 -3.79328489 -1.9414471   1.17654329 -3.64858264 -5.07094967\n",
            "  3.02573596 -4.00943782]. \t  -461.08909598755315 \t -178.6035640716962\n",
            "41     \t [-3.94618998 -5.09977543  2.8350304  -3.05255108  2.49290155 -1.73084766\n",
            "  2.75878975 -3.18852749]. \t  -312.63019828576853 \t -178.6035640716962\n",
            "42     \t [ 4.28955641  1.62393721  2.62907685 -4.54514822 -3.36256723  4.01124725\n",
            " -1.89065269  1.8597176 ]. \t  -332.8095508882435 \t -178.6035640716962\n",
            "43     \t [-0.83279837 -3.58557033  1.65479721  3.35596166  4.91761397 -4.56161818\n",
            " -0.42980325 -4.89714434]. \t  -518.5852545005152 \t -178.6035640716962\n",
            "44     \t [-1.41733079 -3.40864428 -3.62978511  3.60345237  2.82708193 -4.98170245\n",
            " -0.11553571  3.64503984]. \t  -411.96211342431735 \t -178.6035640716962\n",
            "45     \t [ 3.68806589  0.29580031 -2.19194252 -4.0516204   0.3010597  -4.84995289\n",
            " -3.64586132 -2.82393441]. \t  -392.28159388543196 \t -178.6035640716962\n",
            "46     \t [ 0.35116245  3.8033669   3.27706938 -4.26440167  1.2857908   2.93571608\n",
            " -4.10115539 -4.72062457]. \t  -490.0001145922474 \t -178.6035640716962\n",
            "47     \t [ 0.72680912 -3.07683771  4.38815288  3.73295233 -4.75761292  4.78597016\n",
            " -4.35491819  4.78988401]. \t  -699.8780650728008 \t -178.6035640716962\n",
            "48     \t [ 0.13427484  4.58581167 -3.18088403  4.90150377 -1.97735851  2.73120737\n",
            "  3.93778666 -4.88157839]. \t  -532.018696550027 \t -178.6035640716962\n",
            "49     \t [-4.25120525 -4.33823768  3.11744765  4.83632822 -2.07364259  4.08534982\n",
            " -1.50597231 -2.14310463]. \t  -352.68839521256666 \t -178.6035640716962\n",
            "50     \t [-3.10079482  4.13865676  4.49257427  4.24417958  2.9946261  -5.10855223\n",
            " -0.56397688  4.40120627]. \t  -535.0879847234389 \t -178.6035640716962\n",
            "51     \t [ 4.89193555  2.9922182  -4.4090565   4.35654599 -3.14151355 -4.80922228\n",
            " -2.82633321  4.88653197]. \t  -611.1350065409885 \t -178.6035640716962\n",
            "52     \t [-5.116761   -3.4078763   4.70720691  1.68481497  3.37414999 -4.02799518\n",
            "  1.66036894  2.49068206]. \t  -350.4349456414508 \t -178.6035640716962\n",
            "53     \t [-4.00640676  4.29859192 -3.65006298  4.81681688  4.59271114 -4.32264932\n",
            "  5.02264788 -0.0077478 ]. \t  -579.9490422624966 \t -178.6035640716962\n",
            "54     \t [-4.75240757 -3.46651478 -4.16468996 -4.98850156 -3.00145315  2.39926035\n",
            "  3.05701124 -4.36268176]. \t  -495.4568131158855 \t -178.6035640716962\n",
            "55     \t [ 3.20948721  1.96142984  3.35512418 -2.77770081 -2.2567875  -2.72112168\n",
            "  4.80561782 -4.88575929]. \t  -505.14364186131274 \t -178.6035640716962\n",
            "56     \t [-4.44119934e+00  3.04367392e-04 -3.62044560e+00 -1.97100678e+00\n",
            "  5.09749507e+00  4.18575338e+00 -4.21634254e+00 -4.21908595e+00]. \t  -576.4803706937469 \t -178.6035640716962\n",
            "57     \t [ 3.56056097 -4.44071809 -1.92416096  4.5107665  -4.95588368  4.21496174\n",
            "  0.35656126 -1.70094388]. \t  -398.0477547919105 \t -178.6035640716962\n",
            "58     \t [ 0.05087862 -4.63262675  0.33468986 -0.37208618  4.43577072 -0.27981907\n",
            " -5.09650944  1.05332295]. \t  -333.3617692962063 \t -178.6035640716962\n",
            "59     \t [-4.20870321  5.00949523  1.03039795  1.54033222 -4.96287694  3.59014249\n",
            "  1.84870613 -1.7221088 ]. \t  -328.71366723065853 \t -178.6035640716962\n",
            "60     \t [-5.08081323 -5.00831854 -4.90907437 -4.03653195  1.31763745  1.93052368\n",
            " -1.72084209  4.48152714]. \t  -425.89670536930737 \t -178.6035640716962\n",
            "61     \t [-2.94630156  1.85204064 -4.48177937  4.37779427 -4.41801324  4.03286316\n",
            " -2.50716564  3.27228062]. \t  -477.30200921170746 \t -178.6035640716962\n",
            "62     \t [ 4.3689575   2.55954    -0.04175663  4.80091338  4.53786046 -2.940185\n",
            "  1.81799721 -3.2895046 ]. \t  -388.922123600972 \t -178.6035640716962\n",
            "63     \t [ 1.33916895 -4.77790072 -4.93183509 -5.12       -5.12       -2.10968421\n",
            " -0.23332327 -3.72876564]. \t  -494.6638645271121 \t -178.6035640716962\n",
            "64     \t [-2.2885106  -4.67712229  4.87497832 -1.68992639  1.39745979  0.80964265\n",
            " -4.22030748 -4.72678449]. \t  -448.8223685697748 \t -178.6035640716962\n",
            "65     \t [-5.11055397  3.631714   -4.03296505 -2.29371128  1.80389207  4.17381884\n",
            "  4.04026145 -1.38891296]. \t  -372.8286591368994 \t -178.6035640716962\n",
            "66     \t [ 3.04268536 -5.00534717  5.07241896  4.49395668 -4.02561866  0.81209006\n",
            " -3.08483143 -4.47221424]. \t  -528.9396900978516 \t -178.6035640716962\n",
            "67     \t [-4.66570291 -4.31556099  2.18051378 -4.47874819  0.05598302  4.86168445\n",
            "  1.95509287  3.25786486]. \t  -407.0152888715192 \t -178.6035640716962\n",
            "68     \t [ 1.37223287  4.95820864 -4.81528016  3.43028316  3.39085129 -1.6402152\n",
            " -4.22357095  1.92000498]. \t  -395.67124028208036 \t -178.6035640716962\n",
            "69     \t [-3.83097923 -4.7518301   4.81915116  1.24160059 -4.99047192 -4.87429373\n",
            " -2.03764122 -3.62714484]. \t  -537.0649183600898 \t -178.6035640716962\n",
            "70     \t [ 5.06129809  2.27866397  3.54546799 -3.95068559  4.64638981 -4.23106984\n",
            "  0.95893603 -0.91302245]. \t  -364.6062449412112 \t -178.6035640716962\n",
            "71     \t [-3.20445527  4.41189001  0.20716407 -3.93343932 -2.58444563  2.53802105\n",
            " -4.20626839  4.22901457]. \t  -450.1860823877116 \t -178.6035640716962\n",
            "72     \t [ 3.02492529  4.90843552 -4.24231339 -3.17702213  3.53836559  2.7130223\n",
            "  4.23784998  4.05318127]. \t  -515.6061281830977 \t -178.6035640716962\n",
            "73     \t [ 4.57208879  2.73644531 -0.24566955  4.9034039  -4.24131199  2.20580032\n",
            " -4.63963904 -3.8880297 ]. \t  -522.9897219624268 \t -178.6035640716962\n",
            "74     \t [-1.15658486  3.66035293  3.70892326  4.82043448  1.40931522  4.09437184\n",
            " -4.85968452 -3.31276901]. \t  -525.9741205638004 \t -178.6035640716962\n",
            "75     \t [ 3.84632847 -5.05248846  3.94826548  0.36598291 -0.03446007 -3.45069702\n",
            "  2.70219193 -4.83560437]. \t  -422.778939476137 \t -178.6035640716962\n",
            "76     \t [-4.77083464 -5.05914554 -5.01383676  2.0723645  -1.06459966  0.20687424\n",
            " -4.09418749 -4.34951055]. \t  -441.15140429941516 \t -178.6035640716962\n",
            "77     \t [ 4.30412742 -4.61623693  2.46223679 -3.30428667  4.97611899  3.06559302\n",
            "  2.20357931  4.29797528]. \t  -484.9729001273622 \t -178.6035640716962\n",
            "78     \t [-3.85278565  0.56308074 -1.81020507  4.654868    1.79699693  4.82559072\n",
            "  1.14697003 -1.85039183]. \t  -304.44411438595876 \t -178.6035640716962\n",
            "79     \t [ 5.11077465 -3.74174269 -1.15481817 -1.12097858  4.04048535  4.26432903\n",
            " -3.15785625 -5.09715995]. \t  -531.5358123413586 \t -178.6035640716962\n",
            "80     \t [ 1.01657741 -4.84006104  4.80662852  4.15648053 -4.43489169  4.35995235\n",
            "  4.89739863 -4.71934194]. \t  -744.767694637913 \t -178.6035640716962\n",
            "81     \t [-1.41300679  3.63408947  4.60404256 -1.77317678 -4.97538877 -2.46082105\n",
            "  1.78860756  3.61396973]. \t  -391.5643932015539 \t -178.6035640716962\n",
            "82     \t [-3.19543964  4.5692405   4.53625101 -0.76515767  4.30732802  4.5923212\n",
            " -3.17058534  4.27376166]. \t  -551.8317841031061 \t -178.6035640716962\n",
            "83     \t [ 4.64539093  4.10040387  0.67526913  4.06356214 -3.94020298 -3.31861195\n",
            "  3.38154254 -5.08222306]. \t  -553.0052439005033 \t -178.6035640716962\n",
            "84     \t [ 2.30830736 -5.01434541  4.21668411 -2.65624817 -4.62285088  2.28946276\n",
            " -4.69694087 -1.21247914]. \t  -441.6727047768591 \t -178.6035640716962\n",
            "85     \t [-3.67731504 -3.04531645 -4.48100564 -4.31398812  3.45849246 -3.44589359\n",
            "  4.73951721  0.35476119]. \t  -456.0497132950756 \t -178.6035640716962\n",
            "86     \t [ 3.51856878 -2.86245972  3.47495537 -3.39508718  2.04822444  4.42507835\n",
            "  3.10402858 -4.60605682]. \t  -486.7351457963999 \t -178.6035640716962\n",
            "87     \t [ 5.09284279 -4.25958418 -4.98065014 -3.44895771 -1.91043409 -4.54127354\n",
            "  4.8443878   4.74911329]. \t  -670.9240799985643 \t -178.6035640716962\n",
            "88     \t [-4.38605568  2.71456403 -4.94148169 -4.51823576 -2.58987641 -4.01666373\n",
            " -0.5418209   3.00044118]. \t  -393.3027336129907 \t -178.6035640716962\n",
            "89     \t [ 4.87461019  5.10418234  4.5542836  -2.31746233 -4.32425886  3.93096793\n",
            "  4.34327107  4.96251876]. \t  -674.846093936041 \t -178.6035640716962\n",
            "90     \t [-4.82213779 -1.43632134 -3.01387076  2.49227512  2.54331968 -1.36796155\n",
            "  4.93091166 -3.89251817]. \t  -414.45614036868307 \t -178.6035640716962\n",
            "91     \t [-3.50092552 -3.56371935 -0.64864517  0.40088294 -4.02236227  1.83781066\n",
            " -1.34563209  4.65117183]. \t  -326.46627494834104 \t -178.6035640716962\n",
            "92     \t [-4.42744353  4.96920143  3.58906869 -3.82776924 -2.65633257 -0.05572861\n",
            "  2.06635206 -4.40819512]. \t  -386.88499078009846 \t -178.6035640716962\n",
            "93     \t [-5.11971688  3.97085911  0.06406568  4.29879087  1.36125853 -2.2747117\n",
            " -2.3306557  -3.01272566]. \t  -282.6244926818938 \t -178.6035640716962\n",
            "94     \t [ 5.10445822  5.03694086 -3.83870615 -2.71947569  1.02793789  0.24332367\n",
            " -2.51261392 -0.77658436]. \t  -205.2420143608214 \t -178.6035640716962\n",
            "95     \t [-0.0408155  -4.89736627  4.70520283  3.50796092  3.61607695  2.20036275\n",
            "  3.96498487 -5.04763415]. \t  -571.9162775689066 \t -178.6035640716962\n",
            "96     \t [ 4.24977257 -2.70573376 -4.61390983  3.1100096   0.89577822  4.98180319\n",
            "  4.39987763 -5.11389164]. \t  -632.9055226242197 \t -178.6035640716962\n",
            "97     \t [ 4.69354154 -4.12489815  3.61995903 -1.20863372 -4.07588019 -5.10394983\n",
            " -1.86524354  4.24310558]. \t  -508.9657075217095 \t -178.6035640716962\n",
            "98     \t [ 3.68560779  1.52635715  4.57627363  4.94619402 -1.32564003  2.71459309\n",
            "  4.08863979  3.91059024]. \t  -471.29067612044463 \t -178.6035640716962\n",
            "99     \t [ 0.13366929 -4.98732101  2.48558377  4.87395579 -4.86882914  0.45525966\n",
            "  2.73524812  3.79284561]. \t  -450.5483220186158 \t -178.6035640716962\n",
            "100    \t [-5.11894699 -4.63836431  1.44214954 -4.3262629   0.67535932 -3.97661072\n",
            " -1.96594995  2.08875689]. \t  -309.45715882810106 \t -178.6035640716962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j6UBhkdtdVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8abe9f8-50bf-43fd-eda6-da8ac12ca7df"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 2\r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_loser_2 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_2 = dGPGO(surrogate_loser_2, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.60433145 -4.36322715  4.04410125 -0.65030607 -3.81258     0.77678463\n",
            "  3.48642222 -0.66436556]. \t  -266.73879363027606 \t -205.20381448253355\n",
            "init   \t [ 2.00612414  1.89069411  2.05463926  2.86406925  1.46175353  4.72090796\n",
            " -4.00931957  3.03212891]. \t  -387.12857956211883 \t -205.20381448253355\n",
            "init   \t [ 3.40562005 -2.39607436  3.44765838  0.32897952  0.17313346 -4.11046182\n",
            "  4.2892185   1.70658296]. \t  -312.7789728136913 \t -205.20381448253355\n",
            "init   \t [-3.33025814 -2.89083891 -0.32895713 -0.65647368  3.98698988 -2.84058346\n",
            "  0.91155831 -2.28145592]. \t  -205.20381448253355 \t -205.20381448253355\n",
            "init   \t [ 0.26339516 -2.46418319  0.29643398 -1.92367877  0.45222142 -2.6413414\n",
            " -4.15500263 -3.17986428]. \t  -271.9028038542476 \t -205.20381448253355\n",
            "1      \t [-3.58107824  4.03913561 -2.04029852 -2.32586783 -5.05364741  1.00365777\n",
            "  3.01415303  1.00987973]. \t  -285.07587324909576 \t -205.20381448253355\n",
            "2      \t [-4.60448096  2.80813531  4.99563621  0.03781622  4.39034062  3.92653567\n",
            "  0.21104926  2.43029119]. \t  -348.29121948523493 \t -205.20381448253355\n",
            "3      \t [-2.10140792  2.67807242  1.68628494  4.56034289 -1.8500807  -3.14762825\n",
            " -4.13600895 -2.97135732]. \t  -377.41471871614783 \t -205.20381448253355\n",
            "4      \t [ 1.0793017  -0.36269218 -3.70580843 -3.98481813 -0.83044235 -0.83705955\n",
            "  3.56686091 -3.98529023]. \t  -329.9121011113058 \t -205.20381448253355\n",
            "5      \t [ 3.31386882  4.20874624  2.80639656  4.70516753  0.77583565 -1.58822836\n",
            "  2.17294614 -1.95275945]. \t  -240.29324869898412 \t -205.20381448253355\n",
            "6      \t [ 4.95105294e+00  4.19026678e+00  4.72038052e+00 -3.21008855e+00\n",
            " -4.04784285e+00 -3.82553410e+00  1.05024894e+00 -4.81361638e-03]. \t  -345.1490179673393 \t -205.20381448253355\n",
            "7      \t [ 2.33545738 -4.97304683 -4.30376547  2.72277784  1.61017345 -2.10463381\n",
            "  1.33501868  4.40780283]. \t  -347.5839427484643 \t -205.20381448253355\n",
            "8      \t [-2.34986063  1.8091521   3.7986963   3.9519721  -3.28891208 -2.7619696\n",
            "  5.03032181  1.33988379]. \t  -409.1773629633698 \t -205.20381448253355\n",
            "9      \t [-3.22273268e+00  2.37005141e+00 -4.16522439e+00  6.51493680e-01\n",
            " -3.89879744e+00 -2.57010452e-03 -4.59403457e+00  3.66840666e+00]. \t  -406.76223418427173 \t -205.20381448253355\n",
            "10     \t [-2.61774008 -4.98801546 -4.77330403  0.84989543 -2.31165075  3.71622484\n",
            " -2.20166958 -4.92897108]. \t  -465.7258412436761 \t -205.20381448253355\n",
            "11     \t [-5.12       -3.43039073 -5.12       -4.89541015 -5.12       -5.12\n",
            " -1.87831075 -5.12      ]. \t  -747.0228821526194 \t -205.20381448253355\n",
            "12     \t [-2.74383482 -4.76027162  1.56539778 -4.87420914 -4.82820318  2.10326527\n",
            "  3.89508325 -4.56467333]. \t  -571.2238045852524 \t -205.20381448253355\n",
            "13     \t [-0.35945995 -4.31149655 -3.88015628  2.80347209  2.46317906  4.17909046\n",
            "  3.79086206 -1.0943501 ]. \t  -359.2121790938139 \t -205.20381448253355\n",
            "14     \t [-4.05057391  1.19906134  3.80677173 -4.20000697 -4.82457075 -4.60601283\n",
            " -4.89577116  0.38034293]. \t  -545.9292653945729 \t -205.20381448253355\n",
            "15     \t [ 4.00042221  4.15917878 -4.70357692  4.66649121  2.92576875  4.34557436\n",
            "  3.36154581 -0.58452661]. \t  -442.01439791400554 \t -205.20381448253355\n",
            "16     \t [-3.39620382 -4.92915808  4.72708377 -2.1033081   2.09920674  3.26277488\n",
            " -4.5062692  -4.33858475]. \t  -523.4983023419858 \t -205.20381448253355\n",
            "17     \t [ 1.98515247 -1.1162395  -2.96726016 -3.22734207 -5.04243962  0.87905021\n",
            "  5.10220265  4.71029511]. \t  -565.9993633594706 \t -205.20381448253355\n",
            "18     \t [-1.28941789 -2.74865336  4.12940631  3.5732032  -4.87864481  3.37777225\n",
            " -2.22426517 -2.22784091]. \t  -380.79954058960857 \t -205.20381448253355\n",
            "19     \t [ 3.17368219  3.42580892  0.41376376  3.82604179 -3.20112617  1.84845424\n",
            "  2.07407295  4.87122735]. \t  -384.29261628418 \t -205.20381448253355\n",
            "20     \t [ 1.77264381  3.40420581  4.06924414 -3.9926708  -3.76638096  4.72642494\n",
            " -1.6555747   2.69280524]. \t  -421.9202016332203 \t -205.20381448253355\n",
            "21     \t [-3.13128023 -3.80195953 -1.82995089  1.06242989 -1.24072416  3.61857374\n",
            " -1.40095991  5.10594269]. \t  -361.84136302467107 \t -205.20381448253355\n",
            "22     \t [ 2.71831835  2.67512725 -4.86121531 -3.79827197 -2.84846596 -0.93125416\n",
            " -4.32262479 -4.92646952]. \t  -521.0321972445549 \t -205.20381448253355\n",
            "23     \t [-4.06338518  4.72613409 -4.95656976 -4.43895757  4.19095298 -0.63936677\n",
            " -4.12108722  4.04667178]. \t  -553.8650266915038 \t -205.20381448253355\n",
            "24     \t [ 4.76009479  4.0149267   1.48402281 -2.07349993  4.13480995  5.0475682\n",
            "  5.01421097 -0.02580223]. \t  -493.0547964266358 \t -205.20381448253355\n",
            "25     \t [ 2.27363383 -0.89577868 -3.54680665 -1.84567889  2.87796295 -4.72404239\n",
            " -4.05541075  3.7379042 ]. \t  -460.35261367757926 \t -205.20381448253355\n",
            "26     \t [ 2.83314974 -3.19221916  1.85999456 -4.0034306   4.72378396  4.96489271\n",
            "  0.83894983  3.61788868]. \t  -472.00726685636505 \t -205.20381448253355\n",
            "27     \t [-3.0112922   1.59168628 -4.9661564   2.23883566  4.69468012  2.62841085\n",
            " -4.26505663 -4.73727671]. \t  -566.6931294890983 \t -205.20381448253355\n",
            "28     \t [-1.65516454 -0.40272635  4.0227448  -4.57250632  4.03751885 -2.77520498\n",
            "  4.14272249  3.88730923]. \t  -503.9854295947243 \t -205.20381448253355\n",
            "29     \t [-5.02533033  3.44944246  2.78118279 -2.91610821  1.87181413  0.85076349\n",
            " -0.28051198 -4.56371099]. \t  -295.30263807348786 \t -205.20381448253355\n",
            "30     \t [ 4.41932741 -0.20513988 -1.98251394 -5.10549001  5.00406475 -2.11768139\n",
            "  5.03191053  2.88918385]. \t  -531.8005158122904 \t -205.20381448253355\n",
            "31     \t [ 5.04076916  0.40952426 -4.70537138  1.927475   -5.07048048  4.49987135\n",
            "  4.37503007 -2.91891915]. \t  -559.2158162968242 \t -205.20381448253355\n",
            "32     \t [ 5.10569294  0.47148334 -4.07810266  1.38449582 -4.56139638 -3.47793813\n",
            " -5.10472494  3.58300957]. \t  -545.7919560018566 \t -205.20381448253355\n",
            "33     \t [ 4.62633951 -0.8008661  -1.83903656 -4.51376061 -1.95654027  1.49919124\n",
            " -3.59515761  1.92319954]. \t  -267.0194710085083 \t -205.20381448253355\n",
            "34     \t [ 3.65938321  4.7131228  -1.45326883  4.09968362  2.05891247 -2.60588818\n",
            " -4.74209317  2.08320302]. \t  -385.4532664657366 \t -205.20381448253355\n",
            "35     \t [ 2.16181213 -3.4514385   2.13807284  3.63737917 -1.72780553 -2.02956057\n",
            " -4.85921337  4.91008962]. \t  -492.93124146713467 \t -205.20381448253355\n",
            "36     \t [-3.5307784   4.70926616 -4.51000288  3.73276765  4.01398265 -2.09382881\n",
            "  1.68903504  2.71772964]. \t  -359.49867564858533 \t -205.20381448253355\n",
            "37     \t [-4.43965999 -4.44144977  0.32768465 -2.94604459 -3.90736056 -2.77507687\n",
            "  0.58510467  1.72800053]. \t  -243.0303411869632 \t -205.20381448253355\n",
            "38     \t [-1.51942612  4.7435367  -4.04175857 -5.00329791  2.34995023  4.67975545\n",
            " -1.83047509 -4.21304987]. \t  -520.9151175840888 \t -205.20381448253355\n",
            "39     \t [ 3.82832248 -0.54790786 -2.83848643 -1.79004786  4.58905072  5.04901325\n",
            " -4.51055539 -1.91953824]. \t  -482.3894870178258 \t -205.20381448253355\n",
            "40     \t [-4.57024609  1.740183   -3.37122051 -1.9649861   5.09488946  3.63558555\n",
            "  3.29879462  2.9033142 ]. \t  -429.1862627601474 \t -205.20381448253355\n",
            "41     \t [-0.45217569  4.92834826 -1.70794599 -2.10481222  5.08563179 -4.87289645\n",
            " -3.16501689 -4.65969324]. \t  -590.8660969826783 \t -205.20381448253355\n",
            "42     \t [ 1.65012337  2.63229413 -4.23668583  4.41671876 -4.17441048 -3.87788147\n",
            "  0.79343623 -3.7126064 ]. \t  -440.4896506595188 \t -205.20381448253355\n",
            "43     \t [-2.03990967 -2.37808422  1.83496803  4.78460755  3.94000459  0.69592214\n",
            "  1.68880674  3.51211123]. \t  -316.31090701968634 \t -205.20381448253355\n",
            "44     \t [-5.04812331 -2.11376174 -4.96100723  4.20478529  3.02978249 -5.06748408\n",
            " -3.62085827 -3.84424889]. \t  -588.9497593205815 \t -205.20381448253355\n",
            "45     \t [ 1.07478063  4.22677161  3.11106884 -3.22558246  4.46408112 -0.95141406\n",
            " -4.44050673  3.6509712 ]. \t  -457.27478572008846 \t -205.20381448253355\n",
            "46     \t [-3.88848965 -3.73497948  4.15016171 -3.14285281  3.868979   -0.46727879\n",
            " -3.34382558  4.16497727]. \t  -427.4016787229124 \t -205.20381448253355\n",
            "47     \t [-4.16015188 -3.50926668  2.3517009   3.15617493  4.74264754  5.1060005\n",
            " -4.71787613  4.68869369]. \t  -698.9442708396496 \t -205.20381448253355\n",
            "48     \t [ 2.66839396  5.01583393 -2.35761539 -1.37029358 -3.23083501 -4.93076305\n",
            "  2.77707835  2.75795647]. \t  -394.525135506849 \t -205.20381448253355\n",
            "49     \t [ 4.79222054  3.37275172  4.53249427 -4.42405919  3.24235076 -4.24621873\n",
            "  5.0536739  -2.70329731]. \t  -583.6223014617374 \t -205.20381448253355\n",
            "50     \t [ 3.36948159 -3.02137115  4.85322141  5.01311203 -4.51652643 -4.59341315\n",
            " -1.09534574 -4.71977194]. \t  -615.9973907484066 \t -205.20381448253355\n",
            "51     \t [-4.44028917 -3.42764893  4.66777121 -1.49350413 -0.47409231  4.49053307\n",
            "  3.99986492  1.67960966]. \t  -374.1744905144789 \t -205.20381448253355\n",
            "52     \t [-3.68872506  2.61743966 -2.5130144   1.49224406  1.4226413   4.70715536\n",
            "  3.24086789 -5.10308763]. \t  -480.07957673172336 \t -205.20381448253355\n",
            "53     \t [ 1.84941564  5.01038629 -2.84016568 -0.03383008  4.98729348 -2.36013214\n",
            "  4.86952141 -3.28560477]. \t  -487.96656503063355 \t -205.20381448253355\n",
            "54     \t [-4.32260683 -2.99108047 -4.17611218 -2.24123784  1.418179   -4.18077514\n",
            "  2.70254212  4.88218875]. \t  -465.7320974384571 \t -205.20381448253355\n",
            "55     \t [-3.80526209  4.89911735  2.70137742  5.06767009  4.02690318 -4.97774365\n",
            "  3.29449828 -3.3702309 ]. \t  -583.691181613033 \t -205.20381448253355\n",
            "56     \t [ 4.53352193 -3.91068307 -2.33427793  2.31844024 -4.63309735 -3.99640386\n",
            "  4.39449856 -2.34619655]. \t  -471.36077311657 \t -205.20381448253355\n",
            "57     \t [ 3.38609615 -2.88457345  3.31985771  2.47749963  4.77479943  1.04182905\n",
            "  2.86353077 -3.9983938 ]. \t  -391.525436257035 \t -205.20381448253355\n",
            "58     \t [ 4.37849071  4.44126115  4.2156092   0.44479182  3.86033837  0.24395199\n",
            " -3.94040689 -3.00175771]. \t  -368.3664006413996 \t -205.20381448253355\n",
            "59     \t [ 3.1444391   4.49979543 -0.87278189  1.76149835 -4.93221172  1.82603751\n",
            " -4.19850134  0.06105907]. \t  -330.14232599197277 \t -205.20381448253355\n",
            "60     \t [-4.82183569 -4.83358444 -3.22001796  4.81166664 -2.9735258  -2.99233584\n",
            "  0.48455932  1.71644855]. \t  -316.83813710437283 \t -205.20381448253355\n",
            "61     \t [ 3.20802435 -4.37622959 -1.67534178  5.10164565  1.66575766  0.20664911\n",
            " -2.82997798 -4.91994956]. \t  -424.9602777514018 \t -205.20381448253355\n",
            "62     \t [-1.08241013  4.06648448  0.85472488  3.97388722 -4.83826172  2.76619079\n",
            "  3.55132261 -4.30672048]. \t  -499.2237135982564 \t -205.20381448253355\n",
            "63     \t [ 0.1005769  -3.47689389 -5.01666767 -4.8476402  -4.90267213  4.05874708\n",
            "  0.05580106 -0.7125732 ]. \t  -416.7924415541221 \t -205.20381448253355\n",
            "64     \t [ 0.2370887   0.97399353 -5.12       -5.12       -5.12       -5.12\n",
            " -1.8379977   0.86444462]. \t  -503.4385026809674 \t -205.20381448253355\n",
            "65     \t [-2.85246369 -3.0521596   4.35859245 -4.20583547  4.25999384  3.16225751\n",
            "  4.37957814 -4.89783638]. \t  -631.428413188213 \t -205.20381448253355\n",
            "66     \t [-5.10793054 -4.72419363  0.54818852  2.43034055 -3.64631032 -3.4799733\n",
            " -2.17291989 -4.73845719]. \t  -447.06877578133225 \t -205.20381448253355\n",
            "67     \t [-2.71576481  1.64184641  2.16729266  3.6764636   4.87984431 -4.33652913\n",
            " -5.03811107  3.09529531]. \t  -567.1457872537084 \t -205.20381448253355\n",
            "68     \t [-1.820107    5.06893676  2.92557486 -4.7379063  -2.06928067 -3.38397148\n",
            "  4.35402782 -1.58367839]. \t  -413.0534144970227 \t -205.20381448253355\n",
            "69     \t [ 3.69308976 -4.62494601  4.72140238 -4.69469061 -1.12791401 -3.81940651\n",
            " -1.61156672  4.14679823]. \t  -461.09022635050167 \t -205.20381448253355\n",
            "70     \t [-5.07696954 -2.93736587 -4.57843213 -4.46220768  2.83240764 -1.68862341\n",
            " -4.6926524   1.31966602]. \t  -410.86358010979745 \t -205.20381448253355\n",
            "71     \t [ 4.88213042 -4.40273088  4.65929709 -3.25733207  0.83066957  2.59232312\n",
            " -4.71716218 -2.57396202]. \t  -422.70574465918975 \t -205.20381448253355\n",
            "72     \t [ 2.07543348  0.8506837   1.84584722 -2.69958227 -4.62404397  2.71760848\n",
            " -1.90155612 -4.58718478]. \t  -389.99799511466017 \t -205.20381448253355\n",
            "73     \t [-0.87456373 -5.11610213 -5.06824434 -2.46817669  3.82777825  4.22531169\n",
            " -4.48353083  4.37422509]. \t  -628.706836721851 \t -205.20381448253355\n",
            "74     \t [ 3.28956713  4.87454615 -4.59756689 -4.43709769  3.98896543  4.28842628\n",
            " -1.29889148  2.88552981]. \t  -468.8307776460498 \t -205.20381448253355\n",
            "75     \t [ 2.54608794  4.53871199  3.13018641  3.80253337 -4.70561221 -3.21855553\n",
            " -4.52250213  3.83885104]. \t  -568.8475444686522 \t -205.20381448253355\n",
            "76     \t [-2.56039145  3.46733859  4.91462549  2.14268527  2.32562956  4.95929711\n",
            " -4.8521194  -5.00356491]. \t  -661.122774713394 \t -205.20381448253355\n",
            "77     \t [ 4.19921635 -4.13576005 -5.08235854 -2.30929278  3.68556396  0.5655553\n",
            "  1.10322577 -0.30824678]. \t  -229.7807815323248 \t -205.20381448253355\n",
            "78     \t [ 4.30470265 -3.48479048  3.41867735  4.80142573 -0.30128821  3.15577951\n",
            "  0.28525138  2.20252777]. \t  -269.6809604559236 \t -205.20381448253355\n",
            "79     \t [ 0.33019399 -2.24894995  4.66459501 -4.88496649  0.38314758 -4.96060883\n",
            "  4.82739116 -3.35137946]. \t  -572.3112517481062 \t -205.20381448253355\n",
            "80     \t [ 3.8028368   0.90465333  5.10559894 -5.01418619  0.08429727  4.15561277\n",
            "  4.62625877  4.25163785]. \t  -592.9455590715716 \t -205.20381448253355\n",
            "81     \t [-4.777756   -1.02531315  4.56662448  3.61436189 -4.00635664 -4.77797107\n",
            " -1.2409007   4.4264625 ]. \t  -524.5020283677778 \t -205.20381448253355\n",
            "82     \t [-4.45449551  4.19139595 -5.07073419  3.08527364 -2.82669437  2.99991511\n",
            " -4.85503943 -4.36455414]. \t  -581.5332867760093 \t -205.20381448253355\n",
            "83     \t [-4.68815223 -4.07505125  1.86904991  3.94603702  0.65634513  2.6236039\n",
            "  4.29276958 -3.06202669]. \t  -375.4126156768334 \t -205.20381448253355\n",
            "84     \t [-4.17597231  0.07399827  4.25402625 -0.13438906 -2.33530115  4.20426749\n",
            " -4.00830319  4.31338312]. \t  -466.4431564811076 \t -205.20381448253355\n",
            "85     \t [-1.13007063 -4.65178386 -4.26892404  4.44514632  2.59937426  4.95272199\n",
            " -5.10405702  0.29289924]. \t  -542.2702560995635 \t -205.20381448253355\n",
            "86     \t [-1.15336559  5.05506058  1.86314739 -4.85191339 -1.32629675 -3.46227419\n",
            " -0.66268263  5.10296237]. \t  -449.13094430807206 \t -205.20381448253355\n",
            "87     \t [ 4.94144731 -3.63731067 -3.55704099  2.5708142  -4.27535511  4.53713701\n",
            " -4.18205914  3.69462789]. \t  -561.8084364995563 \t -205.20381448253355\n",
            "88     \t [ 4.36661442 -1.41410614 -2.37964451  4.26676938  2.80432637 -3.39693116\n",
            "  4.63302479 -1.54869915]. \t  -390.87438444523934 \t -205.20381448253355\n",
            "89     \t [ 4.69700199 -3.02381797  3.88605617 -4.32558823 -2.90451682 -4.30152308\n",
            " -1.26468256 -2.99691285]. \t  -396.7434712243486 \t -205.20381448253355\n",
            "90     \t [ 3.55615483  4.63603033  0.27819476 -4.68466769  0.52380261  1.13302734\n",
            " -0.45612107 -2.2104675 ]. \t  \u001b[92m-193.26842335836582\u001b[0m \t -193.26842335836582\n",
            "91     \t [4.10345471 2.71040448 3.90663338 0.57369875 3.52191583 0.54793306\n",
            " 1.28964667 4.16628857]. \t  -292.95964254113215 \t -193.26842335836582\n",
            "92     \t [-3.08050046  1.00401555 -4.87370323 -5.12        0.6349139  -5.12\n",
            " -4.28038962 -5.12      ]. \t  -684.8914524658223 \t -193.26842335836582\n",
            "93     \t [ 5.02179851 -4.08200011 -4.74063667  2.38259331 -3.50230389 -4.81361105\n",
            " -4.86650747 -3.37287357]. \t  -605.8180656163602 \t -193.26842335836582\n",
            "94     \t [ 4.5303776   4.65445707 -4.41916792  0.63533956  5.02543227 -0.98432673\n",
            "  2.09189457  4.15125045]. \t  -424.63746786503214 \t -193.26842335836582\n",
            "95     \t [-4.91522103  0.2662331  -4.30387437  4.63449328 -2.58970302  4.48432274\n",
            "  4.44237356  1.38523953]. \t  -473.46687315495 \t -193.26842335836582\n",
            "96     \t [ 4.26397637 -3.09213529  1.89182087  4.77004596  4.89146921 -4.51242135\n",
            " -4.83769487  0.62679372]. \t  -547.8244461446143 \t -193.26842335836582\n",
            "97     \t [ 0.12639672 -4.7535464   4.29546638  1.05414722  4.87167725 -4.71475792\n",
            "  0.00876931  4.24515102]. \t  -501.21722811283337 \t -193.26842335836582\n",
            "98     \t [-2.33645724 -4.00316033 -4.59329485 -4.53947544  1.39972388  4.88492764\n",
            "  1.73340836 -4.01055787]. \t  -485.91281029790207 \t -193.26842335836582\n",
            "99     \t [ 0.95765638 -3.55164261  2.06717215  3.88104496 -4.76770042 -1.58483748\n",
            "  1.94413515  4.891949  ]. \t  -445.8471240639599 \t -193.26842335836582\n",
            "100    \t [-0.19204005 -4.93371752 -1.52163738  3.86646956 -4.63571274  4.40078885\n",
            "  2.5602573   0.37834623]. \t  -386.1449117099215 \t -193.26842335836582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWnL1rwztdYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "938d33ea-650b-44ce-d762-a4689c8d3c92"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 3\r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_loser_3 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_3 = dGPGO(surrogate_loser_3, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.57613422e+00 -4.00126694e+00 -1.42118102e-01 -1.72873986e-03\n",
            "  1.60880639e+00 -2.70454056e+00  1.15501968e+00 -3.89475939e+00]. \t  -226.23757295607857 \t -200.83819991364615\n",
            "init   \t [ 2.17295152 -1.30498005  0.25362711 -2.42394027  1.24550372 -0.52121845\n",
            " -2.87678861  3.56542093]. \t  -200.83819991364615 \t -200.83819991364615\n",
            "init   \t [ 4.51432417  5.05385819 -3.54862621  1.12022459 -2.14496207 -2.14068561\n",
            "  3.26002484  1.12353371]. \t  -249.2524227715819 \t -200.83819991364615\n",
            "init   \t [ 1.1383917   3.70078893 -1.31804167 -3.13683123 -0.37390212 -2.85955193\n",
            " -3.88879197  1.70639   ]. \t  -252.1724482635516 \t -200.83819991364615\n",
            "init   \t [ 2.32018826 -0.4223289  -1.35717313 -2.05342954 -2.49788598  2.26036994\n",
            " -4.91879441  2.94613072]. \t  -328.7841092566316 \t -200.83819991364615\n",
            "1      \t [-3.55865421  4.31406842 -3.85626065 -3.59130616  2.02875186  3.68832922\n",
            " -3.19072393 -3.1190355 ]. \t  -397.3824499112952 \t -200.83819991364615\n",
            "2      \t [ 1.61474467 -2.07662329  1.28272464 -4.59017283  4.08130204  3.35896166\n",
            "  3.43878606 -2.59421678]. \t  -388.0443276485657 \t -200.83819991364615\n",
            "3      \t [-3.5553363  -2.51308271 -2.98117052 -0.24939697 -2.0899883   0.42425475\n",
            " -2.2295405  -2.63903951]. \t  \u001b[92m-165.6149144600416\u001b[0m \t -165.6149144600416\n",
            "4      \t [ 0.16800741  4.43349801  1.98132744 -3.84107635  0.97602154 -4.70843947\n",
            "  3.98726329  4.25714016]. \t  -504.18580326144445 \t -165.6149144600416\n",
            "5      \t [-4.99583186 -0.17514218 -1.89337007  0.86461806  0.6602039   2.79787651\n",
            "  4.87752486 -3.50544022]. \t  -352.7491483820859 \t -165.6149144600416\n",
            "6      \t [-0.85454523  1.90921614  2.65947013  4.05894716 -4.79502561  0.71319089\n",
            " -4.45606246 -3.76644578]. \t  -465.6365719436497 \t -165.6149144600416\n",
            "7      \t [-3.29853345  2.00623056 -2.03050638 -2.82838086  4.16457577  4.25733991\n",
            "  3.15621368  4.25224594]. \t  -473.15073965838565 \t -165.6149144600416\n",
            "8      \t [-3.69790866  3.91048608 -1.95059034  4.94006827  3.95991808 -1.64178344\n",
            " -3.07477592  4.08531902]. \t  -447.56569153718317 \t -165.6149144600416\n",
            "9      \t [ 3.48363279 -4.77781707 -2.57716541 -4.63400729 -3.56865426  3.70754444\n",
            "  1.88975794 -2.34405226]. \t  -378.7189324711516 \t -165.6149144600416\n",
            "10     \t [ 1.1031735  -4.19883417  5.02658808  4.39804141  0.44308548 -5.04226789\n",
            " -0.45318247  2.84156246]. \t  -409.21009964433546 \t -165.6149144600416\n",
            "11     \t [ 4.92864448  2.02027643  0.45674349  4.39030744  3.79716567 -3.29947963\n",
            " -4.91267816 -4.3503863 ]. \t  -567.9390760654609 \t -165.6149144600416\n",
            "12     \t [ 2.05296226 -0.05004244 -5.07803325 -3.36613229  2.85810006 -1.64192996\n",
            "  3.82055175  2.16789855]. \t  -323.69618053459465 \t -165.6149144600416\n",
            "13     \t [-5.12       -5.12       -5.12       -5.12       -4.81069891 -5.12\n",
            " -4.84804668 -5.12      ]. \t  -909.3846161522091 \t -165.6149144600416\n",
            "14     \t [ 2.97780262 -0.39346246  1.90010274  2.96225562  3.11651999  3.49034808\n",
            "  4.49646808  1.75514882]. \t  -342.93855631708135 \t -165.6149144600416\n",
            "15     \t [-1.13037769 -0.08290228  2.43403225  3.96112439 -3.85020688 -4.51945585\n",
            "  3.67312703 -1.94919222]. \t  -403.33825428051796 \t -165.6149144600416\n",
            "16     \t [ 3.53136129 -3.78883587 -4.82888144  4.39438933  4.55010586  4.94452443\n",
            " -2.19098578 -2.04648888]. \t  -505.6930978235834 \t -165.6149144600416\n",
            "17     \t [-3.58364227  4.6350722   4.93340123  3.05909439  3.62045623 -4.1262635\n",
            "  3.03388363  2.04441228]. \t  -431.8207986956495 \t -165.6149144600416\n",
            "18     \t [ 4.32867925 -2.48201178 -3.96885691  3.68052988 -0.33972975 -2.67451474\n",
            " -0.12052241  2.20086011]. \t  -214.8461226417243 \t -165.6149144600416\n",
            "19     \t [ 3.34358602 -2.49797282 -0.19168509 -4.55364232  4.62525955  1.29160328\n",
            " -4.66359344 -4.45479365]. \t  -534.6919487688178 \t -165.6149144600416\n",
            "20     \t [-2.63042317 -4.08007274 -1.71321857  4.94443504 -0.10361633  0.98970497\n",
            " -4.79064079  3.77069421]. \t  -427.1357485116609 \t -165.6149144600416\n",
            "21     \t [-4.24674033 -2.51746553 -4.9018085  -2.9409886   0.99191976 -4.32331428\n",
            " -4.39718023  4.39391235]. \t  -544.254790781821 \t -165.6149144600416\n",
            "22     \t [ 2.99353594  3.99083914  4.03543583 -1.72880278 -3.15032815 -3.89359782\n",
            " -2.70714492 -4.66200809]. \t  -467.38256671628403 \t -165.6149144600416\n",
            "23     \t [-3.02973341  0.73977026  3.94972792  2.27951195  3.41645874 -2.4192243\n",
            " -1.60445245 -4.06933467]. \t  -321.8321348771259 \t -165.6149144600416\n",
            "24     \t [ 3.00632812  0.02171602  3.86664579  4.78360119 -4.01932428  4.60487711\n",
            "  2.3459114  -2.43737356]. \t  -439.4767809678742 \t -165.6149144600416\n",
            "25     \t [ 3.14948666  2.56698501  3.11243386  4.36758631  4.43605767  1.28845414\n",
            " -4.31363559  4.90350181]. \t  -559.4235908290552 \t -165.6149144600416\n",
            "26     \t [-4.031317    4.73374386  2.34687521  4.46465774 -2.15159996  3.54014599\n",
            "  2.76746115  4.69538213]. \t  -485.6518324241008 \t -165.6149144600416\n",
            "27     \t [ 2.88872717 -4.40914625  4.47493629  5.0224009  -0.29186588 -1.12464564\n",
            " -3.81799438 -4.95966476]. \t  -515.0397527334343 \t -165.6149144600416\n",
            "28     \t [-4.92564809 -2.09757831  1.92267124 -4.98223983 -1.49506402  1.46552054\n",
            "  2.64896263  3.94907986]. \t  -341.38598801189954 \t -165.6149144600416\n",
            "29     \t [ 1.90605704  0.76386745  5.01884806 -3.18399255 -2.98357142  1.19953494\n",
            "  1.12503714  0.05526961]. \t  -182.9439767091382 \t -165.6149144600416\n",
            "30     \t [-0.69404662 -0.96891864 -4.12410031  5.04611574 -1.8394591   2.72722187\n",
            "  4.91656901  5.03472585]. \t  -588.7778079012201 \t -165.6149144600416\n",
            "31     \t [-4.17644533  3.24873341 -4.17747225  0.30164602  2.29251636 -3.95622078\n",
            " -4.18085204 -4.60371101]. \t  -503.3671777354435 \t -165.6149144600416\n",
            "32     \t [-4.94151531 -3.15576797  2.20062317  2.28976708  4.38231657 -3.18032351\n",
            "  4.72422864  3.78170681]. \t  -507.1857201430117 \t -165.6149144600416\n",
            "33     \t [-3.55028654  3.67277985 -2.53310403 -2.41026927 -2.71663822 -4.49801299\n",
            "  3.31786564 -4.36421295]. \t  -469.7924037164481 \t -165.6149144600416\n",
            "34     \t [-0.99523326  4.57301701  1.64025597  3.13242291  4.97756553  4.81504752\n",
            "  3.4615533  -3.69545857]. \t  -546.2517303604358 \t -165.6149144600416\n",
            "35     \t [ 2.68457784  3.30276331 -4.23908102  4.09956665 -4.54024951  4.33665699\n",
            " -1.71198155  3.67054731]. \t  -494.3670570278788 \t -165.6149144600416\n",
            "36     \t [-4.87917131  3.89610413  4.74492988 -3.79911642  3.84599038  4.2467039\n",
            "  1.60781127 -4.04502532]. \t  -510.6002007614677 \t -165.6149144600416\n",
            "37     \t [ 4.41425462 -3.63192689 -0.67828279 -2.13706813 -3.99088409 -4.65069894\n",
            "  3.9495238   5.08958641]. \t  -591.3479424071611 \t -165.6149144600416\n",
            "38     \t [-1.3319591  -4.46609804  4.3228492   4.69954022 -4.72707002  0.97812151\n",
            "  4.2261878   4.59690529]. \t  -597.6132010849167 \t -165.6149144600416\n",
            "39     \t [ 4.66194442  4.16529656  3.36567233  3.94592082 -4.65698133 -0.71144314\n",
            " -3.96154872  3.17353416]. \t  -454.599445650608 \t -165.6149144600416\n",
            "40     \t [-4.95488466 -4.55741242 -4.91109712 -2.1252972   0.80110553  3.46981454\n",
            " -0.36434769  4.519742  ]. \t  -396.3153905975478 \t -165.6149144600416\n",
            "41     \t [ 3.71918161  4.21934514 -1.53518931  1.98334018  3.5918785  -3.90469685\n",
            "  5.06134933 -4.96004254]. \t  -604.3679060542768 \t -165.6149144600416\n",
            "42     \t [-3.99099689  3.01021382  3.63866031 -3.77721951 -4.64925369  4.09388695\n",
            " -3.83683348 -4.1970832 ]. \t  -583.4502847375934 \t -165.6149144600416\n",
            "43     \t [-4.12544837  5.08412044 -4.26201647 -1.37893367 -3.69236395  1.62943046\n",
            " -3.29209868  4.46618292]. \t  -450.35380514877863 \t -165.6149144600416\n",
            "44     \t [ 1.96275455 -4.6324552   4.47998593  1.59017621 -1.79777771  5.02986485\n",
            " -2.49555549  2.25328451]. \t  -369.26732623377575 \t -165.6149144600416\n",
            "45     \t [-1.96721046 -4.41867388  3.41979989 -3.65373615 -4.6123689  -2.86302341\n",
            "  4.65786482 -1.71983031]. \t  -462.48713553606797 \t -165.6149144600416\n",
            "46     \t [-1.03675744  4.68144449  0.8528998  -1.8921516   3.77161869  4.53650027\n",
            " -4.88550376  3.11847673]. \t  -500.89072714847566 \t -165.6149144600416\n",
            "47     \t [-5.0483826  -4.35425836 -0.88121373 -4.56125872  4.03374884 -4.67471046\n",
            " -0.51284743 -2.36443401]. \t  -407.9938642331148 \t -165.6149144600416\n",
            "48     \t [ 4.9789063  -2.1235961   0.41078697 -0.62579769 -3.89706573  3.77240055\n",
            "  4.36765051  4.54054743]. \t  -495.6703642853077 \t -165.6149144600416\n",
            "49     \t [ 1.50557294 -4.2794977   1.99767154 -4.90794662 -4.51864128 -2.54635977\n",
            " -4.42315655 -2.07185031]. \t  -459.5037765363599 \t -165.6149144600416\n",
            "50     \t [ 5.04147769 -1.78697239 -1.32860303  4.28851798 -4.88679281 -5.09553574\n",
            " -3.3114969  -3.31996518]. \t  -550.7942008285715 \t -165.6149144600416\n",
            "51     \t [-1.47998092 -4.15883223  4.85249255  1.88283239  0.88909716  4.19050888\n",
            "  0.84429073 -4.98931261]. \t  -435.0527650969827 \t -165.6149144600416\n",
            "52     \t [-4.97421906 -0.85648591  4.25896552 -0.47011627  4.3686422   4.69681493\n",
            " -5.00963231 -2.40909019]. \t  -531.4006225352056 \t -165.6149144600416\n",
            "53     \t [-3.54673805  2.06728473 -3.81297971 -4.83820017 -3.788281    4.48723515\n",
            "  4.8911578   0.8224492 ]. \t  -523.8182440769525 \t -165.6149144600416\n",
            "54     \t [ 4.46531086  4.83294392 -3.36937247 -4.42519204  4.88574428  5.01152055\n",
            "  0.96979715  2.28421934]. \t  -497.41033088296564 \t -165.6149144600416\n",
            "55     \t [ 4.34457417  4.61702411 -1.85499373  0.52439663 -5.08340819  4.35856684\n",
            "  3.36422128 -3.66354742]. \t  -502.7184755643889 \t -165.6149144600416\n",
            "56     \t [ 4.77176329 -4.29936615  4.90405609 -1.6697823   3.28360609 -4.35365338\n",
            " -4.0765625  -0.28308008]. \t  -427.6465520399117 \t -165.6149144600416\n",
            "57     \t [-2.90773754  1.26518453 -3.62006142 -4.18007324 -4.9322785  -4.20928722\n",
            "  4.50561161  3.25022131]. \t  -575.4236149346191 \t -165.6149144600416\n",
            "58     \t [ 2.51322501  1.9581762  -4.9597527  -4.99844048 -2.50488669 -0.89137049\n",
            "  0.14459634 -3.49294192]. \t  -321.611314983077 \t -165.6149144600416\n",
            "59     \t [-1.24232018  2.09841867  4.96602357 -3.35216259  4.45676059 -2.81719908\n",
            "  4.41325125 -3.60542495]. \t  -516.5456847327612 \t -165.6149144600416\n",
            "60     \t [-4.92817098  2.21078551  4.71659487 -0.53303935 -2.4597139  -2.86713936\n",
            " -4.26006985  4.49398829]. \t  -470.11604300232807 \t -165.6149144600416\n",
            "61     \t [-4.78236536  4.29451938  4.15099296 -3.87697169  4.99372898 -2.66546176\n",
            " -3.53091469 -0.45875287]. \t  -427.84258487125794 \t -165.6149144600416\n",
            "62     \t [-3.9108347  -3.83265284 -4.83821904  3.026387   -5.03437244 -1.43163238\n",
            "  4.82136358 -2.5690875 ]. \t  -506.07671595336 \t -165.6149144600416\n",
            "63     \t [ 5.08384265  1.8726926  -2.30657908  4.93208369  4.8513518  -4.06389485\n",
            "  4.22884152  3.88805787]. \t  -609.0093059293391 \t -165.6149144600416\n",
            "64     \t [-5.09016046  0.96403342 -3.25397902  4.15021595  3.18635166  3.55677407\n",
            " -4.77840043 -0.94738262]. \t  -422.1108425170692 \t -165.6149144600416\n",
            "65     \t [ 4.47280976  3.50057154  5.01362074  2.91406407  1.72915963  3.89601157\n",
            " -3.50524873 -3.60669899]. \t  -449.98728923236666 \t -165.6149144600416\n",
            "66     \t [-5.09722005  3.92552686 -2.68075681  4.92793409 -0.41795657 -3.49457334\n",
            "  4.8449486   4.99495702]. \t  -613.5558323074906 \t -165.6149144600416\n",
            "67     \t [ 3.67751966 -0.37519853 -2.60989024  3.24005886 -2.56528732  4.51222152\n",
            " -2.93118562 -4.20208253]. \t  -432.69948379437574 \t -165.6149144600416\n",
            "68     \t [-3.75126853  3.52881083 -4.77893937  3.63389032 -4.4222119   2.84015228\n",
            "  2.08208046 -0.40248944]. \t  -338.13242327945835 \t -165.6149144600416\n",
            "69     \t [ 4.88704416  4.72680515  1.09302443 -3.95184806  2.33142824  2.05278167\n",
            " -5.08980273 -4.43580748]. \t  -525.8361044788596 \t -165.6149144600416\n",
            "70     \t [ 4.75020844  2.38537111  2.70645962 -4.37269825  2.15285028  3.13243601\n",
            "  2.74998334  5.0632273 ]. \t  -472.47497989037333 \t -165.6149144600416\n",
            "71     \t [ 5.03930603  2.80194249  4.8834581   0.88400214 -3.23721565 -2.31670457\n",
            "  4.59354103  4.63873408]. \t  -520.2144081899424 \t -165.6149144600416\n",
            "72     \t [-4.4390866  -4.72131909  4.66162941 -0.59318343 -4.56119753  3.25507445\n",
            " -4.57199531  0.12954487]. \t  -444.9389458226059 \t -165.6149144600416\n",
            "73     \t [-0.12063523 -4.69021229 -2.88610585 -0.29097971 -4.7879143  -3.51602815\n",
            " -1.16437768  2.38247372]. \t  -313.033449428373 \t -165.6149144600416\n",
            "74     \t [-1.59409257 -3.75216083 -3.99548533  3.71190855  4.60611715 -3.78966652\n",
            " -4.48396171 -3.21495295]. \t  -549.3831009491103 \t -165.6149144600416\n",
            "75     \t [ 1.98801674  3.82025468  4.22760207 -0.34831578  4.69712482 -5.06519566\n",
            " -4.64682073  4.60202249]. \t  -672.0756942531416 \t -165.6149144600416\n",
            "76     \t [ 4.58998869  3.31811055 -4.38742089 -4.19599107 -3.87143644  2.30985043\n",
            "  1.44139322  4.26543201]. \t  -438.3085989125789 \t -165.6149144600416\n",
            "77     \t [ 2.2063623   3.53425288 -3.2532456   4.79636906  4.15274694  3.41667844\n",
            "  1.04814473  4.81613386]. \t  -503.14146661337656 \t -165.6149144600416\n",
            "78     \t [-5.12        0.03479205 -1.06546065 -5.12       -5.12       -5.12\n",
            " -5.12        0.34910778]. \t  -607.3142500823373 \t -165.6149144600416\n",
            "79     \t [-4.27748432 -0.94938718 -0.13659505  5.0348937  -2.34161379 -4.8530344\n",
            " -3.9055406  -1.10907426]. \t  -406.89666712115735 \t -165.6149144600416\n",
            "80     \t [-2.02205068 -1.62346134  4.00588647  2.23208234  4.40349156  2.21673169\n",
            " -0.00783817  4.92018734]. \t  -397.5335513407766 \t -165.6149144600416\n",
            "81     \t [ 4.26338672  2.57335483 -4.94632075  0.22565791 -4.39057838 -2.32664834\n",
            " -4.76031295 -1.24269519]. \t  -404.86676315486346 \t -165.6149144600416\n",
            "82     \t [ 4.7204559   1.00911129  4.92105632  0.73338349  4.32158967 -3.21458855\n",
            "  3.0373618   2.00719069]. \t  -351.3127529134782 \t -165.6149144600416\n",
            "83     \t [-4.90706675 -2.21688423  4.17314472 -5.03864563  2.93672548 -2.76668083\n",
            " -4.90958683  3.84490801]. \t  -563.749425509587 \t -165.6149144600416\n",
            "84     \t [-4.67296149  1.34741134 -2.25810548 -1.10093894  3.41619499 -3.66950071\n",
            "  1.39563734  1.82984245]. \t  -225.17755715694943 \t -165.6149144600416\n",
            "85     \t [-2.07223155 -2.53699654  4.63102996 -3.73058305 -0.76715238 -5.1067947\n",
            "  3.28327891  4.52525613]. \t  -535.8768751113289 \t -165.6149144600416\n",
            "86     \t [ 1.76867618 -5.12       -3.74075223 -3.21374523 -5.12       -5.12\n",
            " -0.28866445 -5.12      ]. \t  -637.5062207021906 \t -165.6149144600416\n",
            "87     \t [ 0.45808553 -0.48758756 -5.09556988 -1.64903818  4.62588738  2.84332173\n",
            " -4.90243115 -0.0495337 ]. \t  -413.21461814510985 \t -165.6149144600416\n",
            "88     \t [ 4.44490271 -1.77443053 -4.53953354  3.19262259 -5.08748307  1.96906582\n",
            "  4.88875002  0.22213943]. \t  -449.0174634326367 \t -165.6149144600416\n",
            "89     \t [-2.54579889  1.61691184 -3.78875499  3.98651805  5.10508405  0.13004974\n",
            "  5.00629468  1.6062125 ]. \t  -444.83434480572805 \t -165.6149144600416\n",
            "90     \t [-2.31340285  4.35542242  3.74381205 -4.76285802 -2.08659593  4.47695757\n",
            " -1.54339928  2.65444546]. \t  -391.1504160503256 \t -165.6149144600416\n",
            "91     \t [-2.01033793  3.9884939   3.75088164 -4.96137682 -2.53003927  4.6296153\n",
            "  4.41065071 -2.41475418]. \t  -519.9567055998066 \t -165.6149144600416\n",
            "92     \t [ 1.59886628 -2.73366291 -4.54576404  0.17159108  5.09620569  4.9027707\n",
            "  4.04082488 -4.95799001]. \t  -664.6425906762959 \t -165.6149144600416\n",
            "93     \t [ 2.28218018 -2.08016562  4.98518464  0.06076062 -5.11912625 -4.10216019\n",
            " -4.77152726  4.19535195]. \t  -620.6071971060567 \t -165.6149144600416\n",
            "94     \t [-3.34113688 -4.30964653 -1.12825647 -3.8736219  -5.00379611  0.61158191\n",
            " -4.75109609  4.25348968]. \t  -542.3298426871994 \t -165.6149144600416\n",
            "95     \t [ 0.85648405  3.73037645 -2.4121026  -4.54126286  4.66624228 -2.03014517\n",
            "  0.12993294 -3.08215142]. \t  -338.2254304290095 \t -165.6149144600416\n",
            "96     \t [ 4.10536235 -2.46491047  4.27593762 -1.96821445 -4.78476044 -5.02441499\n",
            "  1.53943102 -0.43372814]. \t  -383.38400123824306 \t -165.6149144600416\n",
            "97     \t [-5.04978285 -1.94000921 -2.77796168  2.65938095  4.65492609 -4.45313076\n",
            "  2.49973763 -4.98040857]. \t  -553.9685192141608 \t -165.6149144600416\n",
            "98     \t [-3.81555206 -3.34517769  1.75825915 -1.02303398 -0.97013503 -5.12\n",
            " -5.12       -5.12      ]. \t  -605.6078948975702 \t -165.6149144600416\n",
            "99     \t [ 3.15541014 -3.77158908  2.40531833 -5.03761839  4.27693924 -3.58593346\n",
            "  2.3533155   1.84480358]. \t  -391.8810644588522 \t -165.6149144600416\n",
            "100    \t [ 2.99214261 -4.12008532 -3.78842699 -5.11970551  4.36066714 -5.03349041\n",
            " -3.71366618  2.16256168]. \t  -571.8510424121014 \t -165.6149144600416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zciLjgNltda2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb02535-48b9-49e6-c3e5-03f7d79d9437"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 4\r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_loser_4 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_4 = dGPGO(surrogate_loser_4, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.47505713  3.29006044  1.45620137  1.71235961 -4.71920737 -4.44751474\n",
            " -2.28863345 -1.88046844]. \t  -346.80639555492485 \t -165.62625697677552\n",
            "init   \t [-3.1376137  -3.10176889  3.57585195  3.50574682 -1.56298519  2.45496116\n",
            " -0.06749038 -0.27635987]. \t  -165.62625697677552 \t -165.62625697677552\n",
            "init   \t [-3.7790926  -1.54671161  4.27823555  2.60935971 -4.15202172  0.36061924\n",
            "  2.14992129  0.60475125]. \t  -223.4687278056974 \t -165.62625697677552\n",
            "init   \t [-0.25707746  4.70597666  2.91673192  2.51031751  4.76862861  1.58260827\n",
            "  2.63690453 -2.92386101]. \t  -340.87882459564884 \t -165.62625697677552\n",
            "init   \t [-4.10230933 -4.5220156  -2.28380738  4.65096756 -4.15019246  2.30585903\n",
            " -2.53997873  4.26674294]. \t  -468.7231264209916 \t -165.62625697677552\n",
            "1      \t [-5.01918393  0.79364164 -1.36560668  2.11685063 -4.95451332 -1.5583133\n",
            " -2.89797694 -3.01695924]. \t  -318.88110310996603 \t -165.62625697677552\n",
            "2      \t [ 3.54516043 -1.42323946 -4.61942583 -1.93849124 -1.92826544 -0.09386274\n",
            " -3.70385749 -3.87289928]. \t  -330.33627399869533 \t -165.62625697677552\n",
            "3      \t [-2.34545924 -2.03518697  2.56446338 -4.74275426  3.67939613 -3.77571172\n",
            " -1.69528942 -0.5983289 ]. \t  -299.6972370092073 \t -165.62625697677552\n",
            "4      \t [-1.01140414 -4.19690605  1.82013476  1.45813409  4.3944177   0.17426992\n",
            "  2.61182883  3.92706365]. \t  -322.55720555713225 \t -165.62625697677552\n",
            "5      \t [ 3.49032464  4.50549384 -3.44357038  0.25746208  4.54250808 -0.61800521\n",
            "  1.3142628   3.58580495]. \t  -309.03945825584924 \t -165.62625697677552\n",
            "6      \t [-4.73452544 -1.51784525  0.21632425 -3.96512521 -0.50894267  2.32715874\n",
            "  3.31555728  4.95803156]. \t  -397.44887630623725 \t -165.62625697677552\n",
            "7      \t [ 5.05721107 -0.73504045  1.81893561 -3.61959059  4.43392939  2.50894246\n",
            "  3.01984378 -2.07442034]. \t  -323.31663332385546 \t -165.62625697677552\n",
            "8      \t [-2.45939082  3.09116909 -3.71993571 -1.17328657  4.13862467 -4.03748134\n",
            " -4.57108429  4.50515008]. \t  -564.2627302489559 \t -165.62625697677552\n",
            "9      \t [-3.43492556 -3.48806407  0.28606616 -3.69657405  0.95021213  4.44753644\n",
            " -4.89535155 -0.75776699]. \t  -386.57898774726226 \t -165.62625697677552\n",
            "10     \t [ 3.70504083 -0.13991164  1.26491221  3.14015639 -1.35427699 -3.67670235\n",
            "  2.38213063  4.93532467]. \t  -382.86924845962477 \t -165.62625697677552\n",
            "11     \t [-3.73604379  2.96763984  4.34030965 -1.39384588 -0.76286163  4.9629884\n",
            " -3.82243764  2.49926289]. \t  -398.80292371344024 \t -165.62625697677552\n",
            "12     \t [ 2.26491442 -2.34540858  5.01457694  4.19403389  2.55896403 -2.31585649\n",
            " -0.4986284  -2.79403495]. \t  -291.0434415735902 \t -165.62625697677552\n",
            "13     \t [ 1.50021988 -3.47491017 -3.29191989 -4.26138418 -0.85682774  0.45035284\n",
            " -2.43760353  4.84067645]. \t  -365.48669059964334 \t -165.62625697677552\n",
            "14     \t [ 5.09691867  5.07559595 -2.88853554 -5.00232913  0.37578615  3.62083152\n",
            "  4.64360644 -0.43733557]. \t  -434.4662944881213 \t -165.62625697677552\n",
            "15     \t [-3.6158695  -4.79150953  0.82115895 -2.73957691 -3.68183712  3.989516\n",
            "  3.75239705 -4.48652105]. \t  -513.9070769159513 \t -165.62625697677552\n",
            "16     \t [-2.53393613 -4.25205142 -0.11288972 -4.2943875  -3.98835532 -4.89155879\n",
            " -2.50192308 -3.70427783]. \t  -493.07570630767134 \t -165.62625697677552\n",
            "17     \t [ 3.54165343 -0.58420498 -2.588283   -2.19884608 -3.71708536 -2.03375769\n",
            "  4.45423903  0.29959193]. \t  -286.1636230308406 \t -165.62625697677552\n",
            "18     \t [ 4.1688311  -0.08902562 -4.08985813  0.65959919 -3.8314677   5.05567496\n",
            "  3.74942437 -4.81908603]. \t  -580.2719293163149 \t -165.62625697677552\n",
            "19     \t [-3.66319505  3.30234239  4.80066624 -0.05187924 -4.36030968 -5.07227254\n",
            "  3.63959906 -4.81198466]. \t  -631.7774182772243 \t -165.62625697677552\n",
            "20     \t [-3.70882206  0.5842027   4.53118503  3.6495549   4.09461325 -3.80595201\n",
            " -3.31073523  2.34402518]. \t  -420.7331828989557 \t -165.62625697677552\n",
            "21     \t [ 4.73328863  3.40840836  3.54358644 -4.93191994 -0.98263771 -0.06106715\n",
            " -3.02498656 -1.06113311]. \t  -258.5169614271728 \t -165.62625697677552\n",
            "22     \t [ 4.34232439  3.15549294 -4.77312578 -0.81397856 -2.91364198  2.37455478\n",
            " -3.52491898  3.77936766]. \t  -387.2904323875654 \t -165.62625697677552\n",
            "23     \t [ 2.00618998  4.96347294 -4.30338854  4.24862896  2.37251093  0.82079581\n",
            " -4.61570579 -1.74294898]. \t  -386.6802001722146 \t -165.62625697677552\n",
            "24     \t [-1.63187867  2.43718436 -1.17596281 -4.26478997 -3.39363039  4.47161846\n",
            " -0.92358154 -4.65775401]. \t  -448.529427612134 \t -165.62625697677552\n",
            "25     \t [-3.63567322 -0.12313914 -4.71053878  4.37095835 -2.97486154  3.48557213\n",
            "  4.07020148 -0.47275424]. \t  -391.1351181981359 \t -165.62625697677552\n",
            "26     \t [-4.9615414   4.94629939  5.01731945 -4.15975243  3.95092943 -3.74835771\n",
            "  2.60281201 -1.02427437]. \t  -436.44913883346106 \t -165.62625697677552\n",
            "27     \t [ 4.19230208  2.06176265  4.38990758 -0.43661639 -1.25587382  4.53345984\n",
            " -0.11451758  3.80684021]. \t  -331.88123117587526 \t -165.62625697677552\n",
            "28     \t [ 2.35663103 -3.34995305 -3.36991925  4.40284361  3.22664151 -0.05902715\n",
            "  3.15070992 -2.40611726]. \t  -307.4882708064932 \t -165.62625697677552\n",
            "29     \t [ 1.08864835  3.47241036  4.53949122  2.94787777 -3.90444286  4.55438279\n",
            " -5.10183095 -4.37252254]. \t  -657.7114640943697 \t -165.62625697677552\n",
            "30     \t [-1.41898482  4.92583961 -4.94642521 -4.79569849  2.73572569  0.79717265\n",
            " -4.07146886 -1.81565499]. \t  -399.58228872329 \t -165.62625697677552\n",
            "31     \t [-4.04672308  1.36694416 -2.55425896 -0.63388063  4.83042003  4.1956964\n",
            " -0.22885207  1.4164824 ]. \t  -279.998965486268 \t -165.62625697677552\n",
            "32     \t [-3.68725976  2.3662998  -4.86958037 -4.35218697  4.98986055 -4.46874284\n",
            "  4.2295472   3.06949586]. \t  -616.6086412305444 \t -165.62625697677552\n",
            "33     \t [ 2.05553216 -4.92358126 -2.65708516  4.46171082  4.52229288 -4.64651414\n",
            " -4.67762688 -2.38860822]. \t  -584.117448518153 \t -165.62625697677552\n",
            "34     \t [ 3.49213566  2.24070924  4.07326683 -3.06354887  0.0315269  -4.48337375\n",
            "  4.1922037  -2.4999187 ]. \t  -403.17996393395447 \t -165.62625697677552\n",
            "35     \t [-3.07036989  4.84669453 -3.31937617  1.16486375 -1.93352885 -4.80392985\n",
            "  3.20152566 -0.86741465]. \t  -329.817223817093 \t -165.62625697677552\n",
            "36     \t [-4.4693135   4.24575924  4.34788956 -2.89311773 -3.41521267 -4.62574296\n",
            " -4.51234823 -0.19691766]. \t  -475.7632517638615 \t -165.62625697677552\n",
            "37     \t [-4.16577721 -4.82950388 -4.13682216 -1.42047958  4.0108296  -1.53265204\n",
            " -2.07065768 -3.57638182]. \t  -350.27817931919253 \t -165.62625697677552\n",
            "38     \t [ 2.01288193  3.90602575  0.74177315  4.80515031 -4.9293886   3.4677554\n",
            "  3.71663735  4.51148837]. \t  -581.7426243210931 \t -165.62625697677552\n",
            "39     \t [ 4.71135264 -4.81028362  4.99344759 -3.43226543 -4.20836564 -2.57255652\n",
            "  4.93035028 -4.0707644 ]. \t  -621.387289667498 \t -165.62625697677552\n",
            "40     \t [-3.86408081  1.27074799 -1.68289142 -5.02524457 -1.14862427 -2.80662577\n",
            "  2.98352762 -5.01609701]. \t  -445.1288949476939 \t -165.62625697677552\n",
            "41     \t [ 4.99349296 -4.72145956  4.89385346 -4.52431866 -2.53866717  1.02481825\n",
            " -2.81884111 -4.3718911 ]. \t  -470.300755947742 \t -165.62625697677552\n",
            "42     \t [ 3.09246127 -2.91584899 -2.67933395 -3.4061245   4.709839    4.00411078\n",
            "  4.81478763  5.11656374]. \t  -673.3302856958901 \t -165.62625697677552\n",
            "43     \t [-1.39388747 -3.62837202  4.96442223 -3.42199624 -4.85960481 -4.64392792\n",
            " -2.8779756   4.02146774]. \t  -583.8818078333904 \t -165.62625697677552\n",
            "44     \t [ 4.22878517 -3.07960587  4.66638752 -3.51627598  3.21379107 -4.17001454\n",
            "  0.78820669  5.11385107]. \t  -521.1699369701614 \t -165.62625697677552\n",
            "45     \t [-4.97826534 -1.74405833 -4.10950109  4.18549814 -1.58781355 -4.48704652\n",
            "  3.15913296  3.37776899]. \t  -446.14689358970065 \t -165.62625697677552\n",
            "46     \t [-1.59895184  3.91870139  1.76888148 -4.75108055 -3.20395753 -4.6596455\n",
            "  4.99097192  4.5598154 ]. \t  -655.2514123995427 \t -165.62625697677552\n",
            "47     \t [-3.24050441  4.63779314  3.53340366 -3.52871269 -5.0009759   4.23517642\n",
            "  4.65287417  1.380623  ]. \t  -540.2439371266017 \t -165.62625697677552\n",
            "48     \t [-0.08268464 -3.01794114 -3.86106004  4.11054815  4.67280777  1.96810106\n",
            " -4.43742264  3.74185167]. \t  -512.7954144565903 \t -165.62625697677552\n",
            "49     \t [ 3.0771607  -3.11848983 -3.80064725 -1.50142848  3.2375712  -4.6539392\n",
            "  4.88586619  4.51069208]. \t  -593.5075838503064 \t -165.62625697677552\n",
            "50     \t [ 4.62613876 -3.94198209  1.34494833  5.09015594 -3.61727211  4.30527645\n",
            " -0.45825317 -1.1142595 ]. \t  -349.58329887537025 \t -165.62625697677552\n",
            "51     \t [ 2.29144752  1.50604255  2.19446091 -1.28749084  5.05792847  0.07649388\n",
            " -4.2660425  -5.0743926 ]. \t  -492.2023890626025 \t -165.62625697677552\n",
            "52     \t [ 2.89924106  0.94427124 -4.36314016  3.40613346 -0.22078198 -4.88266217\n",
            " -4.05091569  2.49358912]. \t  -421.60623380014516 \t -165.62625697677552\n",
            "53     \t [ 1.7919446   1.45105706  2.52006068  4.88967291 -5.03337778  4.91207056\n",
            " -4.50667879  5.06207845]. \t  -740.7231852385021 \t -165.62625697677552\n",
            "54     \t [ 1.23905907  4.82622565  4.73916637 -3.70947578  4.02377106 -2.1582398\n",
            " -0.09775774  4.25478178]. \t  -424.3340127885607 \t -165.62625697677552\n",
            "55     \t [-4.83589962 -3.363515   -4.16259109  1.7545687   1.0357585  -2.75844215\n",
            "  5.00556226 -4.54046398]. \t  -501.64200749100223 \t -165.62625697677552\n",
            "56     \t [ 4.42800168  4.06193053 -3.86452486 -4.27510735  0.90075845 -4.31692437\n",
            " -3.06199143  0.70816652]. \t  -356.0299708689756 \t -165.62625697677552\n",
            "57     \t [-1.18451018  4.40017574  3.3940554   4.34125962  3.89509741 -5.04960053\n",
            " -5.04181338 -4.68555665]. \t  -732.4955507858289 \t -165.62625697677552\n",
            "58     \t [ 4.82994584  4.52287158  4.55497273  4.43016223  3.17448385 -4.73547746\n",
            "  2.72390375 -0.57508113]. \t  -444.5083178224643 \t -165.62625697677552\n",
            "59     \t [-4.22491123  1.26222638 -3.60199002 -3.84293935 -4.30125447  4.74547749\n",
            " -4.40856938  4.72930298]. \t  -661.6321644973 \t -165.62625697677552\n",
            "60     \t [ 0.95932012 -3.03416377  2.95373278  3.98510846 -3.1865968  -3.89115261\n",
            " -4.90876334  4.93048586]. \t  -613.79820121912 \t -165.62625697677552\n",
            "61     \t [ 5.10499047 -4.23322368  2.29312869  4.96980923 -4.1653669  -3.61533284\n",
            " -3.53823373 -3.92138915]. \t  -552.2998503690442 \t -165.62625697677552\n",
            "62     \t [ 4.56507774 -4.90386904 -0.56535324 -4.99475918  4.80670382 -0.82323109\n",
            " -4.22133815 -2.26976494]. \t  -455.22594640899257 \t -165.62625697677552\n",
            "63     \t [-1.05039069  0.68355127 -4.19564669  4.94812646 -2.68387265  4.10117563\n",
            " -4.58439506 -4.52620049]. \t  -600.7263656076404 \t -165.62625697677552\n",
            "64     \t [-4.96733132  4.63576615 -4.56332158  4.73083269  0.22445431 -0.38725406\n",
            " -2.05384748  1.4246682 ]. \t  -266.56701440459847 \t -165.62625697677552\n",
            "65     \t [ 1.18373656 -5.10983457  4.74603199  2.41431814  2.42733262  4.68569219\n",
            "  4.25854693 -3.88811873]. \t  -553.592516093492 \t -165.62625697677552\n",
            "66     \t [ 4.47791536  2.33363091  3.56191685  3.83686828 -2.43158037  2.20750038\n",
            "  4.082594   -3.16059452]. \t  -383.280521167169 \t -165.62625697677552\n",
            "67     \t [ 2.05262862 -3.63780147 -4.6952681   1.11199706  3.77424821  4.7857118\n",
            " -1.9888943  -5.01629588]. \t  -539.4019321487931 \t -165.62625697677552\n",
            "68     \t [-1.30113567 -4.80931659 -2.48450831 -4.82460956  3.3205888  -2.4391623\n",
            "  4.9785216  -1.73999304]. \t  -448.1267537540673 \t -165.62625697677552\n",
            "69     \t [-4.88087915  1.1348718   1.82573471 -4.29701784  3.92875696  4.89982762\n",
            "  5.0468847  -1.02696219]. \t  -518.2162676065285 \t -165.62625697677552\n",
            "70     \t [-2.02867082  4.08071587 -4.19298989 -4.74597024 -2.65372822 -0.77433828\n",
            "  0.35035512  2.5668459 ]. \t  -272.63820608378415 \t -165.62625697677552\n",
            "71     \t [-3.91579297  2.983796   -4.1054409  -4.80459465 -3.99445447 -4.47904137\n",
            " -4.69632305 -2.95513959]. \t  -600.4401192910566 \t -165.62625697677552\n",
            "72     \t [ 4.69489593 -1.36998931  1.97807735 -4.16627125  4.48251888  3.13258266\n",
            " -3.90097938  3.37902142]. \t  -464.1745134021964 \t -165.62625697677552\n",
            "73     \t [ 5.01208483 -4.94297882  2.60079822 -2.40418821 -4.84431371 -2.51615655\n",
            "  0.97737934  3.2090241 ]. \t  -361.7927287704697 \t -165.62625697677552\n",
            "74     \t [ 3.49708795  2.56561464 -3.40831629  4.63568724 -2.97108589 -2.77066645\n",
            "  3.99595497 -4.83555673]. \t  -535.2334020439778 \t -165.62625697677552\n",
            "75     \t [ 1.27667045  4.51829971  3.16142655  0.08068238 -1.54597296 -1.23122179\n",
            " -4.82622213  4.90827207]. \t  -449.2914667990942 \t -165.62625697677552\n",
            "76     \t [ 0.38047663  2.34909616 -0.16102969  4.95862712  4.61788186  3.75450469\n",
            "  5.08709422  4.00058336]. \t  -610.0000187721168 \t -165.62625697677552\n",
            "77     \t [-4.19849007 -4.52931035  2.04156674  2.02705829  5.08419325  1.95949096\n",
            " -1.98386407 -4.21306865]. \t  -409.4287987774777 \t -165.62625697677552\n",
            "78     \t [ 0.81470437  4.60126009  3.94436945  4.15484833  3.44911906  4.7720427\n",
            " -3.81123847  0.39985389]. \t  -457.8064379580194 \t -165.62625697677552\n",
            "79     \t [-3.99796553  1.19294355  4.112126    4.86905843  1.40104702 -4.58743096\n",
            "  4.7195217  -0.44413327]. \t  -457.96664883491206 \t -165.62625697677552\n",
            "80     \t [ 4.71788565 -5.04772256  4.00380159  3.02051147  2.48574484  4.76713036\n",
            "  0.6127438   2.8755163 ]. \t  -393.82745583456915 \t -165.62625697677552\n",
            "81     \t [-5.08615385  4.63044117  1.20331427 -2.34535867  4.96059725  4.29494385\n",
            " -4.53610601 -4.78847972]. \t  -656.2846458615176 \t -165.62625697677552\n",
            "82     \t [ 4.40820115 -4.83454729  2.69618153  1.56182296  4.80461299 -2.21910501\n",
            " -4.61839976  3.1169096 ]. \t  -469.73969124148704 \t -165.62625697677552\n",
            "83     \t [-4.89984049 -3.3592679   1.20540119 -2.48056532 -2.12529646 -5.00105269\n",
            "  4.02330022 -0.91132527]. \t  -368.14990763888454 \t -165.62625697677552\n",
            "84     \t [ 0.9851916  -3.50173032 -0.34879664  3.99440008 -3.40094434 -3.00899245\n",
            "  2.35411478 -1.33505802]. \t  -254.8890978479035 \t -165.62625697677552\n",
            "85     \t [ 3.92752576  4.46615573 -2.19292504  4.27013742  4.499913   -3.53676154\n",
            "  1.18881018 -5.10905806]. \t  -537.6924677348178 \t -165.62625697677552\n",
            "86     \t [ 0.10245101 -4.28066737  3.08871985 -1.24222938 -4.66169489  4.03906074\n",
            " -3.47393428  4.33587404]. \t  -512.8688597969028 \t -165.62625697677552\n",
            "87     \t [ 4.95478892  4.28139428 -2.81219477 -1.24291975 -5.10523269 -4.66815474\n",
            "  1.16554188  4.97414781]. \t  -559.6289261368829 \t -165.62625697677552\n",
            "88     \t [ 4.47536446  5.11655944 -2.07770197  1.00071495 -2.42358955  3.97584781\n",
            " -3.68402746 -4.83979936]. \t  -495.9503035134253 \t -165.62625697677552\n",
            "89     \t [ 3.34323705  3.10091551 -1.64017058 -5.09266497 -1.5500836  -5.02756571\n",
            "  0.56145356 -4.68510546]. \t  -483.70062578352247 \t -165.62625697677552\n",
            "90     \t [-4.30843857  0.87990698 -3.77357284  5.0833708   3.01509568 -2.28850899\n",
            " -3.32270491 -4.58609264]. \t  -488.6114980330026 \t -165.62625697677552\n",
            "91     \t [-2.01795314  4.79275112  4.89633545  3.76447858 -0.13933403  2.92000972\n",
            "  4.29001857  1.54108449]. \t  -377.7057171179371 \t -165.62625697677552\n",
            "92     \t [-4.61999878 -4.75082259 -4.19683092 -3.85593038 -4.18302783 -4.75011851\n",
            "  4.02019717  4.85575336]. \t  -703.4289712256426 \t -165.62625697677552\n",
            "93     \t [-2.26607318 -4.85402882 -2.70232422 -2.18559123  4.81889032 -4.1529624\n",
            " -4.4440031   4.75887961]. \t  -632.2839104327916 \t -165.62625697677552\n",
            "94     \t [ 0.3336282   5.08510966  1.51290283 -1.5106927  -4.90295856  0.18402841\n",
            "  4.24181941 -4.60623651]. \t  -483.9121368685097 \t -165.62625697677552\n",
            "95     \t [-5.12       -5.12       -5.12       -5.12        0.23096563 -5.12\n",
            " -5.12       -0.50350562]. \t  -605.2260688704608 \t -165.62625697677552\n",
            "96     \t [-3.98972493  4.67987075  1.97133185  3.95128986 -4.43573025 -0.77084049\n",
            " -1.65911367  3.45976185]. \t  -350.8014073927576 \t -165.62625697677552\n",
            "97     \t [-1.65837132  3.78613275 -3.48886382  0.30086509 -3.21731461  4.99493286\n",
            "  1.11896345  3.6612319 ]. \t  -385.75158829960986 \t -165.62625697677552\n",
            "98     \t [ 3.35017179 -0.47869756  1.75112949 -4.18923282 -3.80705211  5.03410863\n",
            "  3.31814723 -1.63813514]. \t  -414.14033215249276 \t -165.62625697677552\n",
            "99     \t [-1.39163114  4.57134583 -4.99147532  2.43382887 -0.79641025  3.29697123\n",
            "  1.82460388 -4.99240697]. \t  -433.2583485848504 \t -165.62625697677552\n",
            "100    \t [ 2.58338169 -4.10755125 -2.06996104  4.00117821  0.45206168  4.20633099\n",
            "  3.88926949  3.07815599]. \t  -406.1761358815405 \t -165.62625697677552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH76hlE2tddm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3ec54bd-8799-45a2-9146-c3475785f5af"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 5\r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_loser_5 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_5 = dGPGO(surrogate_loser_5, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.58729753  0.42762882  0.61873954 -1.20782752 -3.90047561  3.54303094\n",
            "  2.45495411  4.42734146]. \t  -358.07993275421416 \t -191.0582179343833\n",
            "init   \t [ 3.67951879  2.13099137  1.85311997 -0.93591243  2.81174646  4.9610363\n",
            "  4.76656492  2.68257959]. \t  -440.2387279623039 \t -191.0582179343833\n",
            "init   \t [ 2.28457508 -3.1898747  -0.24613755 -2.16324482  3.55437597  3.73325571\n",
            " -1.2826718  -0.39471791]. \t  -204.02442667207546 \t -191.0582179343833\n",
            "init   \t [3.75520732 3.06877821 2.55257243 0.39811528 0.98991542 2.6976486\n",
            " 2.32004232 2.54212732]. \t  -191.0582179343833 \t -191.0582179343833\n",
            "init   \t [ 0.5992029   3.04558915 -1.51609106  4.46525397  4.55980658  3.872474\n",
            " -1.66783187  4.83819235]. \t  -506.2318322394824 \t -191.0582179343833\n",
            "1      \t [ 2.93499453 -4.66586726 -4.44927383  4.16377803  3.1780443  -4.4736638\n",
            " -0.65762836  1.31319723]. \t  -368.2961856386949 \t -191.0582179343833\n",
            "2      \t [-1.17343893 -3.84389035 -2.84342415 -4.04422171 -0.2015563  -2.63778573\n",
            " -0.25088104  0.97245514]. \t  \u001b[92m-170.5625917535914\u001b[0m \t -170.5625917535914\n",
            "3      \t [ 0.16471768 -1.55288    -2.70880353  3.24811743  0.36701741  0.77219384\n",
            "  3.43195549 -4.86663863]. \t  -345.23673182195546 \t -170.5625917535914\n",
            "4      \t [ 2.34262684  4.33520792 -4.50777938  1.15587138  2.36170739 -3.38944867\n",
            " -4.71681112 -2.20304355]. \t  -400.7641750492331 \t -170.5625917535914\n",
            "5      \t [-2.96489911e-03  3.20621581e+00 -1.53267486e+00  4.29738075e-01\n",
            " -3.51692901e+00 -4.59367930e+00  1.11305274e+00 -3.84765614e+00]. \t  -343.9087769128066 \t -170.5625917535914\n",
            "6      \t [-3.13469556 -1.06340474  4.75679604  2.55261997 -2.57791231 -4.37003313\n",
            " -1.9998041   1.17662843]. \t  -292.91422388884996 \t -170.5625917535914\n",
            "7      \t [ 3.76780927 -3.61837208  5.08490111  0.53948569  4.58846195 -3.56537275\n",
            " -1.34823879  4.60669661]. \t  -483.1531336259286 \t -170.5625917535914\n",
            "8      \t [ 3.86560629  3.94064489 -4.92423919 -3.11858659  0.21275663  3.08598528\n",
            " -1.38104352  1.29235925]. \t  -241.72566601926175 \t -170.5625917535914\n",
            "9      \t [-4.43514584  1.63284787  3.20130493 -4.29445809  0.36932758  3.1096296\n",
            " -3.18039699 -4.01024866]. \t  -387.67946478997555 \t -170.5625917535914\n",
            "10     \t [ 0.57918812 -1.27301857 -1.60583996  4.57224101 -5.11405873 -3.54223127\n",
            " -5.08018675 -2.93794031]. \t  -550.6967548948048 \t -170.5625917535914\n",
            "11     \t [-2.04288174  1.92724755  1.78611519 -4.91665611  2.74814586 -4.17521066\n",
            " -3.44121405  3.49951913]. \t  -441.089168643814 \t -170.5625917535914\n",
            "12     \t [-2.64712335 -1.67801236  2.40426663  3.46096282  3.58546381  0.85947678\n",
            " -2.39545945 -4.84681336]. \t  -374.70359695355705 \t -170.5625917535914\n",
            "13     \t [-3.74071788 -0.11736652  1.49774963  4.01633387 -4.20438289  4.02088889\n",
            " -3.30855977 -1.34051979]. \t  -361.6654163044921 \t -170.5625917535914\n",
            "14     \t [-3.7996221   4.99523501 -3.02007887  2.72005147  1.40991291  2.20712428\n",
            " -2.93451843 -2.05935467]. \t  -254.67420279006052 \t -170.5625917535914\n",
            "15     \t [-4.41447036 -4.87046567 -4.94564978 -4.61081931 -5.12       -5.12\n",
            " -5.12       -5.06425315]. \t  -902.3798741157899 \t -170.5625917535914\n",
            "16     \t [ 3.24460129  0.2192569   3.65340883 -0.85275618 -2.04937054  0.23809855\n",
            " -0.77352082 -4.89089436]. \t  -270.4694114501725 \t -170.5625917535914\n",
            "17     \t [ 2.64862787 -4.1477411   4.40164116  4.99954793  1.05188356 -1.04422038\n",
            "  2.7234174  -2.05109203]. \t  -297.17751148012564 \t -170.5625917535914\n",
            "18     \t [-2.63373184 -4.0324312   3.718451   -3.96088722 -4.81332415  2.6882799\n",
            "  1.54897652 -2.7717451 ]. \t  -381.15009481702805 \t -170.5625917535914\n",
            "19     \t [-3.18245826 -2.56965169  4.62714329 -0.90638767  4.22702225  1.8001303\n",
            "  4.2636719   1.04823791]. \t  -335.6758878253862 \t -170.5625917535914\n",
            "20     \t [-0.06256051  3.73969012  1.78719432  3.98674821  4.80049678 -4.83960568\n",
            "  3.15189846  3.37634255]. \t  -517.6266189272541 \t -170.5625917535914\n",
            "21     \t [-4.97243297  1.44414082 -2.19799861 -2.92655015  4.0023898  -3.33904197\n",
            " -0.23976703 -2.67385464]. \t  -282.2377865990213 \t -170.5625917535914\n",
            "22     \t [-4.89757019  4.36872835  1.74423362 -1.32501662 -1.50627094  2.30136911\n",
            "  3.92078043 -0.88931707]. \t  -235.36427012393375 \t -170.5625917535914\n",
            "23     \t [ 4.23166752 -1.94797354 -4.82168404  3.44132259 -5.00051887  2.26104707\n",
            " -4.60717952  3.57032796]. \t  -548.8735313774636 \t -170.5625917535914\n",
            "24     \t [-4.68969889  4.90087992 -2.36252947 -3.18017888 -4.843878   -0.07787627\n",
            " -1.88053165  5.09961213]. \t  -477.3846150251172 \t -170.5625917535914\n",
            "25     \t [ 1.44288672  2.5205166   2.6189566  -4.48262537  2.9027562   3.66776694\n",
            "  4.67679015 -5.07786133]. \t  -597.9694742386596 \t -170.5625917535914\n",
            "26     \t [-4.16883871  0.65631436  5.03502845 -0.85718494  1.75124238  3.10457269\n",
            " -4.21989664  4.78289738]. \t  -478.06034355183635 \t -170.5625917535914\n",
            "27     \t [ 4.97444514  1.09641338 -4.04663537 -5.0342975   4.8418141  -3.87068655\n",
            "  2.806562   -3.84436198]. \t  -558.1313172795503 \t -170.5625917535914\n",
            "28     \t [ 4.65224675  4.86421848 -1.4739816   4.23482187 -0.95789412 -3.34526563\n",
            " -3.12354182  4.13261482]. \t  -423.8736279594338 \t -170.5625917535914\n",
            "29     \t [-0.61525911 -4.86184133 -3.75673943 -2.12980373 -3.23610045  2.3791203\n",
            " -3.99687278 -4.49968519]. \t  -468.26236496878676 \t -170.5625917535914\n",
            "30     \t [-4.88371024 -1.49593119 -1.96774734  3.30157222  0.43627315  4.10256581\n",
            "  2.18983697  2.77529846]. \t  -280.6677539427682 \t -170.5625917535914\n",
            "31     \t [-1.31491736  0.46459246 -4.30519314 -5.10207524  3.22276782  1.87079803\n",
            "  4.70858376  3.95454408]. \t  -515.122602854345 \t -170.5625917535914\n",
            "32     \t [ 5.0535868  -4.90543654 -0.50252182 -1.82441814 -4.24317193 -4.03924552\n",
            "  4.44938429 -2.39047586]. \t  -459.9466551401748 \t -170.5625917535914\n",
            "33     \t [-2.94129254  0.22570811  4.60219389 -3.10056298  0.39127115 -3.10544165\n",
            "  4.39758485 -4.35278389]. \t  -456.32078013067337 \t -170.5625917535914\n",
            "34     \t [ 3.19652878  1.07663641  0.97026642 -2.59314768 -2.15337128 -0.00643437\n",
            " -4.76513874  4.83020436]. \t  -411.0361100802038 \t -170.5625917535914\n",
            "35     \t [ 4.9030994   1.84976432 -4.38068057 -5.0828358   4.51341454 -2.89180329\n",
            " -4.99665389  2.61626981]. \t  -573.3501099464734 \t -170.5625917535914\n",
            "36     \t [-1.79614281 -0.33328993 -4.91788117  5.00840199 -3.50231672 -3.4409085\n",
            " -4.46533257  5.03995755]. \t  -651.4952820107997 \t -170.5625917535914\n",
            "37     \t [ 2.0399069   1.24986676 -3.12019755 -0.89445331 -3.84210142 -4.46277331\n",
            "  4.03255723  4.6592869 ]. \t  -520.5016892048434 \t -170.5625917535914\n",
            "38     \t [-4.77683813 -3.51218304  0.94640865  2.31477979  4.76610895 -3.48310409\n",
            " -1.3977521   3.81853545]. \t  -388.305669467196 \t -170.5625917535914\n",
            "39     \t [ 3.02474753 -2.60098448 -1.91309042 -2.35161702  1.11895624 -4.43694146\n",
            " -4.36973581 -4.97891563]. \t  -512.1374498905877 \t -170.5625917535914\n",
            "40     \t [ 1.53873518  4.98226448 -4.99524276  3.94777254 -3.31516802  3.69271777\n",
            "  2.95543128 -2.638963  ]. \t  -442.8343133517079 \t -170.5625917535914\n",
            "41     \t [-4.36173021 -3.9309503  -3.31583767 -0.74139981 -4.6813144   1.39031546\n",
            " -2.35795557  4.62656667]. \t  -416.444483467822 \t -170.5625917535914\n",
            "42     \t [ 4.45394191 -4.92701426  2.14518884 -2.05022034  3.75560991 -1.39485025\n",
            "  4.87738782 -4.09585909]. \t  -481.9352068018284 \t -170.5625917535914\n",
            "43     \t [-5.10700847  0.96517124 -0.21274176  3.88360771 -0.76431721 -3.34265975\n",
            "  5.02597597  1.24399995]. \t  -347.5745363512074 \t -170.5625917535914\n",
            "44     \t [-4.20538464  3.91632159 -3.94594242 -4.35681082 -4.20373099  1.99575367\n",
            " -3.80210463 -5.07311632]. \t  -590.338034456558 \t -170.5625917535914\n",
            "45     \t [-4.69179692 -5.04904811  1.65949004  3.1738175  -1.02337289 -4.1405256\n",
            "  4.04569007 -4.34860737]. \t  -495.509442533153 \t -170.5625917535914\n",
            "46     \t [ 2.93597698  4.85788184  3.66938222 -2.11554857 -3.81328182 -2.92012164\n",
            "  5.02373446  0.34598913]. \t  -415.60455045967035 \t -170.5625917535914\n",
            "47     \t [ 2.91981188  3.71357624  3.132862    4.90846218  0.24163651  4.55591584\n",
            " -3.68650793 -4.25381423]. \t  -526.645099898332 \t -170.5625917535914\n",
            "48     \t [ 3.78827701 -3.63713832  3.97542108  4.78553922 -4.98964864  1.60783723\n",
            " -3.55323818  4.05640353]. \t  -539.8336529451656 \t -170.5625917535914\n",
            "49     \t [-2.38624939 -2.77083377 -4.74815005  3.31290152 -4.91626722 -0.48806421\n",
            "  3.37551153  0.17605847]. \t  -334.86945478783844 \t -170.5625917535914\n",
            "50     \t [-3.99911125  0.81146823 -3.88384085 -3.60817374 -3.12447775  0.66749154\n",
            "  4.25113883 -4.75531536]. \t  -473.5327206522214 \t -170.5625917535914\n",
            "51     \t [ 0.8107498  -2.03772529  4.44593675  3.16737622 -2.47688946 -4.22843324\n",
            "  4.53913323  4.96992725]. \t  -588.1704347259567 \t -170.5625917535914\n",
            "52     \t [-4.08199087 -4.55796547 -4.70417445 -3.18313824  3.00276246  4.23616163\n",
            "  3.13932793 -2.75826221]. \t  -447.73504242956585 \t -170.5625917535914\n",
            "53     \t [ 3.5159025   4.9976916   3.97136927  2.8047874   4.31940127 -2.05593425\n",
            " -3.76280598  1.22811029]. \t  -370.92239560646937 \t -170.5625917535914\n",
            "54     \t [-4.29008475  1.6782253  -3.08190662 -2.07693659  0.96963056  4.89921859\n",
            " -4.15129885  3.31863813]. \t  -427.2416360759374 \t -170.5625917535914\n",
            "55     \t [ 4.98862196  1.60593042 -4.12687206 -1.14586082 -3.73879442  1.61146293\n",
            " -4.78482336 -4.97962559]. \t  -530.498487060293 \t -170.5625917535914\n",
            "56     \t [ 4.84776332 -0.3047525  -4.18307494 -3.64349938 -2.30087818  1.69571577\n",
            "  4.2947325  -3.26106498]. \t  -387.19361889923385 \t -170.5625917535914\n",
            "57     \t [-1.8046752  -3.33824688  4.96235012 -4.65027917  4.58081336 -1.37964766\n",
            " -3.70082485 -2.52555545]. \t  -449.15977495094336 \t -170.5625917535914\n",
            "58     \t [-0.6603844   2.71157113 -4.00293208 -4.57764109  4.3432387   3.93860384\n",
            " -3.50102062 -3.32507644]. \t  -508.6742286514814 \t -170.5625917535914\n",
            "59     \t [ 4.57458738 -1.4329981  -3.55488994  4.67360462  2.85785941  4.27231259\n",
            "  4.10541577  4.98866446]. \t  -617.7438509418171 \t -170.5625917535914\n",
            "60     \t [-4.6551142  -3.70556473  0.71827027 -4.03583377  4.31848637 -5.11202057\n",
            "  4.97753654  2.95046675]. \t  -608.9483324477758 \t -170.5625917535914\n",
            "61     \t [ 0.67983339  1.87325392  4.93780311  4.37169356 -2.56952269  3.95115095\n",
            "  4.0447975  -3.16895424]. \t  -478.6155236184386 \t -170.5625917535914\n",
            "62     \t [-3.35528432  4.26227619  4.76565631 -3.5380039  -5.05074636 -4.32077508\n",
            " -0.8839173   4.99358826]. \t  -610.3175922708701 \t -170.5625917535914\n",
            "63     \t [ 4.41092411 -1.37001466 -3.64669073  3.58358101  4.93558607  1.31844994\n",
            " -2.03965701 -2.92049128]. \t  -344.0588735313062 \t -170.5625917535914\n",
            "64     \t [ 4.11476895 -1.08959796  2.3174951  -4.99530746 -0.94561179 -4.84649871\n",
            "  2.95538242  1.72920505]. \t  -365.69391270308824 \t -170.5625917535914\n",
            "65     \t [ 4.46375389  3.20625835  3.54340736  4.92362013 -1.25993898 -3.62067344\n",
            "  3.16194907 -2.35988652]. \t  -376.2514884309388 \t -170.5625917535914\n",
            "66     \t [-4.13076498  3.73110975 -3.28921475  3.89373217  2.42932348  4.65657044\n",
            "  4.58200166 -4.35812467]. \t  -596.5261135250646 \t -170.5625917535914\n",
            "67     \t [-3.16519875 -0.45541548  5.01384748 -3.22710526 -4.99135736  3.64775943\n",
            " -4.65720196  0.93947113]. \t  -490.79881614040494 \t -170.5625917535914\n",
            "68     \t [-5.07107444  4.33201087  3.67840217  5.11205341  4.41737346 -3.12154522\n",
            " -3.9680809  -0.45272278]. \t  -476.26225476315636 \t -170.5625917535914\n",
            "69     \t [ 2.99190675  2.70358298 -4.62100084 -0.87561194  4.91566986 -2.86413461\n",
            "  1.99643276  3.78579643]. \t  -403.294855421847 \t -170.5625917535914\n",
            "70     \t [-2.47804407 -4.76348533  4.57609367 -4.12379796 -1.40823495 -0.82065257\n",
            "  1.56743384  4.06837517]. \t  -345.9348321282109 \t -170.5625917535914\n",
            "71     \t [-3.01401651 -4.61678598 -4.41845702  0.32038761  4.8586541   1.5214467\n",
            "  0.64856524  4.25954136]. \t  -390.7079984911159 \t -170.5625917535914\n",
            "72     \t [ 4.54094172  3.33215067 -4.54246433  2.26833849  2.174782   -4.55915527\n",
            "  4.48741208 -3.94624197]. \t  -539.2144327600191 \t -170.5625917535914\n",
            "73     \t [-4.36760348 -4.12199628 -4.2345425   2.75475087  1.14412786 -4.27189065\n",
            " -2.56266441 -2.70567645]. \t  -357.78199022171316 \t -170.5625917535914\n",
            "74     \t [-4.68198722  4.66168341  4.16684538  1.90220801  4.35872784  2.12365146\n",
            "  4.21486522  3.09065961]. \t  -454.76992289128657 \t -170.5625917535914\n",
            "75     \t [ 2.17445034 -3.91375764  3.92937917  4.89894542  3.36176419  3.39568961\n",
            " -1.33712272  4.19740308]. \t  -456.8343200735353 \t -170.5625917535914\n",
            "76     \t [ 3.95450225 -4.7685027  -2.16690115  2.49580181 -3.83594711  2.5272977\n",
            "  3.06179207  2.85165995]. \t  -342.6913760136247 \t -170.5625917535914\n",
            "77     \t [ 2.15972132  1.16619461  1.61922762  1.94215122  4.62301379 -2.73103838\n",
            "  1.58151031 -3.1246916 ]. \t  -277.56842667116587 \t -170.5625917535914\n",
            "78     \t [ 3.83229011  4.50436931 -1.68077225  3.78317468 -4.00415629  4.46902667\n",
            " -1.7275095   4.10886533]. \t  -476.9415143192159 \t -170.5625917535914\n",
            "79     \t [-3.08221666  2.32046364  5.07071134 -4.87238014 -4.01137275 -4.8510413\n",
            " -5.05512339 -3.23593565]. \t  -676.6671666351632 \t -170.5625917535914\n",
            "80     \t [ 4.54326727 -4.23750775  1.01132584  3.61773392 -5.00669297  2.78578666\n",
            "  1.62542025 -4.79068484]. \t  -485.9722990102056 \t -170.5625917535914\n",
            "81     \t [ 3.60946327 -5.0731789   3.55797784 -2.22807956 -2.62265546  1.88593949\n",
            " -4.92551429 -0.70240705]. \t  -351.8415437991673 \t -170.5625917535914\n",
            "82     \t [-2.85403882  1.98311751 -4.88033746 -3.91103078 -4.98259299 -3.68793624\n",
            "  1.5712635   0.49311118]. \t  -373.61253433913197 \t -170.5625917535914\n",
            "83     \t [ 1.0046888   0.61435767  3.91158371 -3.55284239  5.04459097 -2.50993556\n",
            "  4.48869253  3.74596029]. \t  -516.4909098149207 \t -170.5625917535914\n",
            "84     \t [-0.97253451 -5.12        0.51870732 -5.12        0.37021578 -5.12\n",
            "  0.77384319 -5.12      ]. \t  -530.9181267913498 \t -170.5625917535914\n",
            "85     \t [-3.29033539  4.76637268  4.04473326  3.73074711 -4.21091207 -1.46232616\n",
            " -3.34734746 -4.18924738]. \t  -481.3372040782275 \t -170.5625917535914\n",
            "86     \t [ 0.47220287  4.74355946  5.01235824  0.7558429  -3.00214236  2.30610591\n",
            " -3.04598549  2.94935401]. \t  -334.39083404249567 \t -170.5625917535914\n",
            "87     \t [-3.21139451  3.76982124 -0.60894695 -2.83099632  1.43649844 -4.19681085\n",
            "  4.18170701  3.24254183]. \t  -394.42307058184207 \t -170.5625917535914\n",
            "88     \t [-4.68169581  4.27793282 -3.18796188  3.0126791   3.4380351  -4.20747467\n",
            " -1.51799104  5.07827657]. \t  -513.0726447508399 \t -170.5625917535914\n",
            "89     \t [ 4.65521554  4.37538615  1.65987945  4.10358111  4.56884127  4.43100799\n",
            "  4.04975609 -3.37531218]. \t  -563.7022235023243 \t -170.5625917535914\n",
            "90     \t [ 3.22163377 -4.96327034 -2.63213369 -0.89234801  4.75291816 -0.55195739\n",
            "  4.37707793  2.2067151 ]. \t  -371.4640600407514 \t -170.5625917535914\n",
            "91     \t [ 1.82163861 -4.93697285 -4.92067656  5.09471084 -3.55865637  4.77718608\n",
            " -3.65313972 -3.43903984]. \t  -616.8124428938056 \t -170.5625917535914\n",
            "92     \t [-3.75775216  5.05670623 -5.00239738  2.27216321 -4.18178609 -4.87312331\n",
            " -2.66266951 -0.47362308]. \t  -442.32797034329906 \t -170.5625917535914\n",
            "93     \t [-4.50973303 -5.11504091  4.59971485  1.37165236 -4.43658334 -2.95698278\n",
            " -2.96985574 -4.86774757]. \t  -545.8417044788937 \t -170.5625917535914\n",
            "94     \t [ 1.38625679 -1.27492439  4.33402626  1.50471878 -4.67224589 -5.05776115\n",
            "  4.55163702 -3.04071332]. \t  -552.205029868409 \t -170.5625917535914\n",
            "95     \t [ 4.82039877 -5.00677241 -4.62533035 -3.249361   -0.68630139  2.37389573\n",
            " -4.44535344  4.75200538]. \t  -534.9341595501454 \t -170.5625917535914\n",
            "96     \t [ 1.25639828 -1.85343011  0.69049117  4.26032312 -0.20958425 -4.70430847\n",
            " -2.02694597  4.74114916]. \t  -424.0709587766619 \t -170.5625917535914\n",
            "97     \t [-0.70799245 -5.10100457  4.98767784  3.31856414 -3.58423963  4.58895018\n",
            "  5.02979499  2.67644853]. \t  -596.2075396820351 \t -170.5625917535914\n",
            "98     \t [-3.43330284  4.09279919 -0.88268012  4.4505207  -4.39314273  1.38207241\n",
            "  2.53169366  3.93989437]. \t  -403.8632000262604 \t -170.5625917535914\n",
            "99     \t [ 4.27125903  5.05211766  4.8480031  -4.67881799 -0.73361327 -3.95109953\n",
            " -3.93326426 -3.29711488]. \t  -518.9859663086402 \t -170.5625917535914\n",
            "100    \t [-3.05748815 -2.00328985  1.05440773 -4.13067601  5.11364434  4.46040992\n",
            "  0.65034147  4.88433567]. \t  -532.892657926842 \t -170.5625917535914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_Amb8TtdgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e257b7-a695-4dfc-ae28-e8ca66c50724"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 6\r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_loser_6 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_6 = dGPGO(surrogate_loser_6, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.02288795 -1.72052679  3.28938622 -4.69302655 -4.0175956   0.97333314\n",
            "  0.30532979 -0.83141193]. \t  -235.23441702954543 \t -201.94095626044867\n",
            "init   \t [-1.68542362  1.25459899 -0.6334318   2.41543277  0.18469286  0.80751207\n",
            "  1.48843618  5.01989654]. \t  -251.71565703551553 \t -201.94095626044867\n",
            "init   \t [ 3.27534794 -0.88882243  3.85298079  3.31529659 -4.56218104  2.2388453\n",
            "  3.09422656  2.42080403]. \t  -348.8531157616155 \t -201.94095626044867\n",
            "init   \t [ 2.14150913  0.41919339 -3.84180045  4.68630831 -0.9906555  -2.89842012\n",
            "  2.22490467  5.06068417]. \t  -431.90936813726233 \t -201.94095626044867\n",
            "init   \t [-2.50251207  1.75420858  1.01382055  2.22548117  4.47845923 -1.51746797\n",
            " -2.52278684 -0.99868151]. \t  -201.94095626044867 \t -201.94095626044867\n",
            "1      \t [ 2.52426974  2.29448261 -0.96145617  5.01124965 -0.50688737 -1.29220163\n",
            "  2.14659693 -4.27562441]. \t  -309.93117061486333 \t -201.94095626044867\n",
            "2      \t [-2.1732107  -4.071104   -1.05955676  0.563544   -2.4916715  -4.43837041\n",
            "  3.16725126 -3.45000541]. \t  -357.18651782929135 \t -201.94095626044867\n",
            "3      \t [ 0.45041751  3.04462334 -4.19217931  4.07489457 -5.03627391  4.82675639\n",
            " -0.2109413  -1.32181192]. \t  -418.7792092236846 \t -201.94095626044867\n",
            "4      \t [ 1.13973531  0.02174566 -4.62097322  2.28023966 -4.53238513 -1.3679228\n",
            " -4.92490741  2.61866956]. \t  -424.7403788210404 \t -201.94095626044867\n",
            "5      \t [-4.09131316  0.92385945  3.58336907 -1.58465775 -1.76392005 -1.00200185\n",
            "  3.29877381 -0.03674573]. \t  \u001b[92m-164.77731695731757\u001b[0m \t -164.77731695731757\n",
            "6      \t [-0.36675946  1.75512676 -4.97484639 -2.33012056  1.71913733 -4.05086626\n",
            " -2.23443154  0.20696239]. \t  -250.78631759071766 \t -164.77731695731757\n",
            "7      \t [-4.09980816 -2.43417915  2.31668169 -2.56361355 -3.28974468  4.50139526\n",
            " -4.54042416 -3.56396318]. \t  -492.6586685976233 \t -164.77731695731757\n",
            "8      \t [ 1.29040313 -2.6311265   1.32394803 -4.64369555  3.72243003 -4.69094677\n",
            " -4.55281376 -2.0883067 ]. \t  -488.3222489970762 \t -164.77731695731757\n",
            "9      \t [ 4.94251725 -4.98573359  0.21587065  4.12642972  4.11603157 -4.32322334\n",
            " -2.98601239 -3.47119565]. \t  -498.0506683117082 \t -164.77731695731757\n",
            "10     \t [ 1.53642786  3.01514227  4.7331146  -4.42892316  1.0647551   4.81474145\n",
            "  3.12109734  4.72628662]. \t  -557.8612899465525 \t -164.77731695731757\n",
            "11     \t [ 3.96580616  2.52455738  2.0656669  -1.16255556  3.51379228 -3.23829501\n",
            " -1.5787945   2.99633296]. \t  -260.60672211274664 \t -164.77731695731757\n",
            "12     \t [ 2.02100411 -5.01594556 -1.3855721   0.62551375  2.62736825  3.94402312\n",
            "  2.80181189 -0.11408451]. \t  -244.63077846579424 \t -164.77731695731757\n",
            "13     \t [ 4.61355455  5.01149033  4.92708657  1.56485643  0.07889719  1.75870422\n",
            " -3.75184781 -3.49806805]. \t  -369.15434656076263 \t -164.77731695731757\n",
            "14     \t [-4.72521673  4.01200939 -4.38670087  0.72894853  3.9132738   3.9186637\n",
            "  0.29224917 -0.34697818]. \t  -284.6401375353442 \t -164.77731695731757\n",
            "15     \t [ 0.31503705 -4.27728734  3.14979058 -4.82271222  3.39361475 -4.76696735\n",
            "  4.1525441   3.58866611]. \t  -577.1479018428682 \t -164.77731695731757\n",
            "16     \t [-4.70316117 -4.81303537  4.87284899  2.86873913 -1.93295945  0.95053279\n",
            "  0.56045546  4.8668206 ]. \t  -388.3920237547741 \t -164.77731695731757\n",
            "17     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -164.77731695731757\n",
            "18     \t [ 3.0621335  -3.83722124 -4.57291373 -2.98991527 -3.49840827 -2.93790622\n",
            "  3.22473093  4.94452732]. \t  -518.6792794160901 \t -164.77731695731757\n",
            "19     \t [ 1.37420932  4.44983787 -1.44114859 -0.50031095 -4.73574972 -3.02909364\n",
            " -3.19701011 -4.48583637]. \t  -448.4395532196568 \t -164.77731695731757\n",
            "20     \t [-4.74811932 -4.52423685  3.24890576 -1.26214877 -0.21969924 -4.29073589\n",
            " -4.86606152 -4.80637369]. \t  -562.78385275587 \t -164.77731695731757\n",
            "21     \t [-4.80158625 -3.68595799 -4.49577738 -1.33744718  4.58488467  2.9409182\n",
            " -2.54652381 -3.49962922]. \t  -418.3914636274104 \t -164.77731695731757\n",
            "22     \t [ 4.56858159 -0.46890403 -1.73938087 -5.10381081 -3.04288541  4.7104021\n",
            "  3.80023754  4.66228705]. \t  -588.9946440415033 \t -164.77731695731757\n",
            "23     \t [-0.47478383 -3.91317548 -4.45893212 -3.71223433  2.18038364  3.53001812\n",
            " -4.85261294  4.61274091]. \t  -579.2107935342232 \t -164.77731695731757\n",
            "24     \t [-1.3123044  -1.06276225 -2.99383547 -3.63941589  4.84964678 -1.97189335\n",
            "  4.36577852 -4.9872492 ]. \t  -557.1785559146126 \t -164.77731695731757\n",
            "25     \t [-4.76582696 -3.72587711  5.02102407  1.46067925  4.39617027 -2.55285987\n",
            "  2.80741902 -0.34428639]. \t  -326.49741294817176 \t -164.77731695731757\n",
            "26     \t [-0.25087833 -4.08478393  0.94952612  5.04897473 -4.37250306  2.61554368\n",
            "  4.18845154 -5.04607657]. \t  -601.2525641427246 \t -164.77731695731757\n",
            "27     \t [ 3.32191507 -3.58946269  3.78704996 -4.83714074  2.35063048  5.07625521\n",
            " -3.31692995  3.51169979]. \t  -531.3285422178127 \t -164.77731695731757\n",
            "28     \t [ 1.48464095  3.71070133  4.70741056 -4.94508457  4.26863427  2.67142277\n",
            "  1.96098864 -4.4416771 ]. \t  -512.7088446718955 \t -164.77731695731757\n",
            "29     \t [ 3.28494987  1.20672309 -4.72801175  3.48291648  3.74395917  4.92076252\n",
            " -4.00503747  2.33361496]. \t  -500.50629167013386 \t -164.77731695731757\n",
            "30     \t [-1.18850877 -1.05962212  1.07237734 -4.89956999 -4.18277073 -4.7849305\n",
            " -4.99745433  4.38705186]. \t  -656.7741294875693 \t -164.77731695731757\n",
            "31     \t [ 5.02686492 -5.09193218 -4.8303958  -2.07741361  2.70325395 -4.78013666\n",
            " -2.91499643  2.24977672]. \t  -437.99421697748124 \t -164.77731695731757\n",
            "32     \t [ 4.32658983 -4.29818579 -0.68082755 -5.0198795   0.26120002 -4.99672828\n",
            "  4.21941159 -4.49706032]. \t  -594.4128608696217 \t -164.77731695731757\n",
            "33     \t [ 4.38558278  2.99563846 -4.71044041 -4.53949001  3.91853084  2.97066705\n",
            " -0.12067873  2.6687154 ]. \t  -372.9755359377102 \t -164.77731695731757\n",
            "34     \t [ 3.95921476  3.78974623 -3.88386858  4.86035848  4.97629056  2.08739476\n",
            "  4.87012373  4.27359275]. \t  -646.2415136288151 \t -164.77731695731757\n",
            "35     \t [ 4.43075817 -4.59120006 -2.00390977  1.05067564 -1.51513376  5.05061691\n",
            " -4.49581418 -1.38679661]. \t  -399.65508732820285 \t -164.77731695731757\n",
            "36     \t [ 1.84867142  0.29931834 -4.37002632 -3.99397652 -1.2940945   3.18229895\n",
            "  0.67430744 -3.67171015]. \t  -304.8655927864166 \t -164.77731695731757\n",
            "37     \t [-5.10828365  5.05147192  2.29367149 -4.87814879  0.12862564 -3.14033673\n",
            " -4.98189492  3.19578919]. \t  -502.789927011225 \t -164.77731695731757\n",
            "38     \t [-2.12975785  5.11142181 -4.23320432 -4.73005131 -2.56911904  1.48031785\n",
            "  0.45428452  5.07324308]. \t  -453.5396246959348 \t -164.77731695731757\n",
            "39     \t [-4.80404916 -1.71913086 -3.11028913  4.48196197  2.61329168  0.75291798\n",
            "  3.74390034 -2.29757719]. \t  -316.2595333688694 \t -164.77731695731757\n",
            "40     \t [-4.66785309  4.52681451 -3.08262597  2.41647685 -4.28834933 -0.72389205\n",
            "  4.98317578 -4.50138702]. \t  -545.6561260198213 \t -164.77731695731757\n",
            "41     \t [-1.14577803  5.11808203  0.98196399 -4.78325047 -4.26321619  2.7508076\n",
            "  4.78700729 -2.94159828]. \t  -514.0218260936645 \t -164.77731695731757\n",
            "42     \t [-4.12609413  4.58755389 -3.36498297 -2.95696137  4.93378209 -2.9160946\n",
            "  4.14810934  4.32859829]. \t  -571.1342256158591 \t -164.77731695731757\n",
            "43     \t [ 5.04450135  4.37337376 -3.63543418 -3.59941166 -4.25998444 -2.41329929\n",
            "  4.83806738 -4.1434245 ]. \t  -582.0454145109604 \t -164.77731695731757\n",
            "44     \t [-2.13408115 -3.63969293  4.65435468  2.46090398  3.53777371  3.7588719\n",
            " -4.48627744 -5.05927127]. \t  -613.2728022695852 \t -164.77731695731757\n",
            "45     \t [ 4.60128397  1.89132279  2.64282265 -1.83611109 -2.58266513 -4.94756114\n",
            "  4.66649328  0.78118728]. \t  -400.3008769330892 \t -164.77731695731757\n",
            "46     \t [ 5.08584458 -1.38529228  3.32266535  4.54750677 -4.59590878 -2.13686158\n",
            " -4.37334088  3.48826769]. \t  -509.7792877708723 \t -164.77731695731757\n",
            "47     \t [-4.47283955  4.71353005  3.85198869  3.13930862 -4.025476   -1.90650231\n",
            " -3.33199908 -2.82171847]. \t  -392.618587052664 \t -164.77731695731757\n",
            "48     \t [-4.21118263 -1.40540477  3.73480251 -3.92055982  4.76599501  0.78233481\n",
            " -3.73640363  1.78791681]. \t  -365.55777647040816 \t -164.77731695731757\n",
            "49     \t [ 3.48852012 -2.5101336   4.82638717  1.65768636  4.96745779 -0.07654104\n",
            "  3.44493893 -3.43505227]. \t  -406.5282870326812 \t -164.77731695731757\n",
            "50     \t [-0.61576101  4.36328377  5.06106294  4.88474657  3.13673506  4.61268433\n",
            "  0.590607    1.10223796]. \t  -399.75954180243696 \t -164.77731695731757\n",
            "51     \t [-2.26059625 -4.38928305  0.05269601  4.6878816   1.02626655 -0.78604708\n",
            " -4.83300892  2.28773245]. \t  -345.9040929057934 \t -164.77731695731757\n",
            "52     \t [ 4.06423984  4.74846442  1.19701709 -4.93512717 -2.32138     1.77032442\n",
            " -4.94740091  1.52989586]. \t  -399.14474276879787 \t -164.77731695731757\n",
            "53     \t [-3.72213007 -4.86577659 -5.09394073  1.43329188 -4.11159646  4.56752318\n",
            "  4.62788341 -0.09216994]. \t  -506.95664634541043 \t -164.77731695731757\n",
            "54     \t [-3.674521    3.48926876  3.72410548  5.1117599   0.99019762 -3.57711338\n",
            "  5.03208606 -1.98055099]. \t  -474.2901254628675 \t -164.77731695731757\n",
            "55     \t [-2.12090376  2.33891593  4.92474178  4.98811739 -1.75450193 -1.02182278\n",
            " -4.51349594  4.8098808 ]. \t  -537.0610544614326 \t -164.77731695731757\n",
            "56     \t [ 5.02715399 -2.77568685  0.72666253 -2.60146951  4.34259481  3.23495476\n",
            " -2.24759114 -3.68774458]. \t  -370.57342674357756 \t -164.77731695731757\n",
            "57     \t [-4.91209741  0.52113487 -0.53496452 -4.51510576  3.7422428   4.39208233\n",
            "  4.3552975   4.91258562]. \t  -618.6876682105092 \t -164.77731695731757\n",
            "58     \t [ 4.39921449  4.42879376  4.92622824  4.71731248  1.87260332 -1.7438891\n",
            "  3.90133528  2.9162708 ]. \t  -430.75695193304756 \t -164.77731695731757\n",
            "59     \t [ 0.70127303 -3.76012076 -2.236577    4.96127098 -4.14501168 -3.28851258\n",
            " -3.66507698 -3.80638238]. \t  -502.961867402069 \t -164.77731695731757\n",
            "60     \t [ 4.54999576 -2.85932663  5.08591057  1.91906308 -3.8298999  -2.67360764\n",
            "  1.38081045 -5.10224247]. \t  -467.2238524033479 \t -164.77731695731757\n",
            "61     \t [-0.76958747 -4.32656779 -1.98211412  4.58132046  5.10634124  0.21352224\n",
            "  3.41172719  5.04403432]. \t  -549.4355501999553 \t -164.77731695731757\n",
            "62     \t [ 4.57863143  4.88090881 -1.42429533  5.10231232 -4.11167057  3.60160511\n",
            " -4.29811952  4.93026772]. \t  -664.9662915663754 \t -164.77731695731757\n",
            "63     \t [ 0.06814496  1.41507323  2.84042003  0.73157262 -2.0247006   5.10557721\n",
            "  1.13308205 -3.19566692]. \t  -297.93825551386294 \t -164.77731695731757\n",
            "64     \t [ 4.33125458  3.39448302  4.04872279 -3.94142837 -1.01620288 -3.19773961\n",
            " -0.93375045 -4.18444768]. \t  -365.81731659935895 \t -164.77731695731757\n",
            "65     \t [-4.50628757 -3.60240404  0.02547933  0.98285289  0.03057927 -4.569045\n",
            "  4.17112549  5.06464476]. \t  -502.3819403609468 \t -164.77731695731757\n",
            "66     \t [-3.22241016  4.387044   -4.28676743  4.56079728 -0.66577086 -2.96341213\n",
            " -2.57015492 -4.78231992]. \t  -471.32051718861777 \t -164.77731695731757\n",
            "67     \t [ 4.69081604  4.38259879 -4.47774263  0.18879334 -2.22333705  1.54113902\n",
            "  0.56645757  2.19757558]. \t  -200.55882995149457 \t -164.77731695731757\n",
            "68     \t [-3.13987731 -4.02171869  3.02062262 -4.84994764 -4.75507788  0.53491042\n",
            "  2.01664614  4.2329092 ]. \t  -450.2465206404489 \t -164.77731695731757\n",
            "69     \t [ 4.49166257 -2.59677196 -0.71946391  4.90532044  3.95603296 -1.46414331\n",
            " -3.46798448  4.90270152]. \t  -499.05659099512377 \t -164.77731695731757\n",
            "70     \t [ 5.03701549 -2.12170286 -3.04755621 -4.13363444 -3.57025602 -3.90390314\n",
            " -4.67196816 -2.73072142]. \t  -498.2074220358934 \t -164.77731695731757\n",
            "71     \t [ 3.99210286e+00 -2.03607804e+00 -4.37636292e+00  2.13002277e+00\n",
            "  4.36836550e+00 -3.24100427e+00  3.93992511e+00 -1.54390142e-03]. \t  -366.93258342016946 \t -164.77731695731757\n",
            "72     \t [-4.56660937  4.61184174  3.5617901   2.1830261  -4.57131176  4.76213432\n",
            "  4.63344733  3.41519756]. \t  -604.6559768118517 \t -164.77731695731757\n",
            "73     \t [ 3.76989209 -3.20440863 -4.51149648 -5.01976077  4.71392754  1.09343188\n",
            "  3.94347109  4.99216772]. \t  -623.1111316240895 \t -164.77731695731757\n",
            "74     \t [ 0.34156989 -3.50860479  5.0579587   2.88332466 -4.87390095  3.20755587\n",
            " -4.18009029  1.36208166]. \t  -452.3996240758148 \t -164.77731695731757\n",
            "75     \t [-2.67215195  3.12196812 -1.70834009 -4.75781378  3.3721822   0.17024068\n",
            " -2.87639085 -4.95151899]. \t  -437.02385921851914 \t -164.77731695731757\n",
            "76     \t [-4.56461353  4.56773838  4.8215984  -1.80008782  4.22542264 -4.73318172\n",
            "  2.01263406 -4.37974922]. \t  -550.7703965020847 \t -164.77731695731757\n",
            "77     \t [-2.56329076  1.7143444   1.77397986 -2.98579189 -2.36599191  3.16801897\n",
            " -4.4408021   3.5463691 ]. \t  -384.41582701193596 \t -164.77731695731757\n",
            "78     \t [-1.10745416 -4.3517425   2.47486627 -4.63096435  4.10263452  4.80400395\n",
            "  3.16963913 -2.76799025]. \t  -497.5092118802942 \t -164.77731695731757\n",
            "79     \t [ 2.09530463 -3.87001154  4.71515754  3.18451906  1.03315694 -4.79455116\n",
            " -1.3334075   4.66382263]. \t  -471.3262107144629 \t -164.77731695731757\n",
            "80     \t [-5.12        0.0369175  -4.74827911 -5.12       -4.30543282 -0.03263695\n",
            " -5.12       -1.54770507]. \t  -494.06726692281364 \t -164.77731695731757\n",
            "81     \t [ 2.25173095  4.48113767  1.16911109 -4.18035982  3.44176235 -1.87390548\n",
            "  4.85209595  0.79868741]. \t  -369.4344061896381 \t -164.77731695731757\n",
            "82     \t [-4.81214748  4.01955934 -4.61293662  1.7282114  -1.10258139 -4.79134117\n",
            "  0.17064422  4.55326595]. \t  -441.1367016919699 \t -164.77731695731757\n",
            "83     \t [ 2.9025531   2.58002391 -4.85572936  3.94467787  4.84767866 -2.40743437\n",
            " -3.29760852 -1.02441633]. \t  -391.50348540263235 \t -164.77731695731757\n",
            "84     \t [-1.37872375  5.11431344 -3.90318826  4.09504008  2.90663993  3.72833559\n",
            " -4.04777362 -4.67013918]. \t  -581.8139270024135 \t -164.77731695731757\n",
            "85     \t [ 3.03752022 -4.85355795  4.5615821   2.28558221  4.07741417  2.60555604\n",
            " -2.24873237  3.58234329]. \t  -401.58333026065696 \t -164.77731695731757\n",
            "86     \t [-2.82633902  4.54813943 -1.27954177  4.08092777 -0.72003928  4.56061263\n",
            " -4.49235327  2.57057406]. \t  -442.4057854399488 \t -164.77731695731757\n",
            "87     \t [-2.50652849 -2.50810539 -3.90120215 -4.79781822  1.86139931 -4.04685569\n",
            "  1.21818573  4.9830088 ]. \t  -481.21537555182726 \t -164.77731695731757\n",
            "88     \t [ 2.26170167 -3.61669544 -0.94682333 -5.04574197 -5.06560097  3.90824584\n",
            " -3.7313643   3.71820125]. \t  -563.813337445652 \t -164.77731695731757\n",
            "89     \t [ 4.8788081  -3.70828294 -4.97998389 -5.07402372  4.50915858 -4.30114861\n",
            " -4.54289016 -4.7263046 ]. \t  -764.5195093139696 \t -164.77731695731757\n",
            "90     \t [ 0.81059087 -4.38885446  1.16345233 -1.98624411 -0.71480473 -1.00260754\n",
            " -1.69561105  3.48753838]. \t  -185.03780077924452 \t -164.77731695731757\n",
            "91     \t [-1.78912289 -4.81026107  4.12287438 -3.69302167  0.66383933 -2.09124922\n",
            "  2.46035985 -3.1852997 ]. \t  -307.0121203238552 \t -164.77731695731757\n",
            "92     \t [-4.52882805  1.20606675 -1.0191466  -4.89478489 -3.65871258 -4.62164276\n",
            "  4.48954507  3.25916646]. \t  -543.5289456956048 \t -164.77731695731757\n",
            "93     \t [ 4.56011396  4.69536472 -3.88059314 -3.39949212  5.03493021 -3.62919924\n",
            " -0.40003162 -4.64069524]. \t  -535.4784648050868 \t -164.77731695731757\n",
            "94     \t [3.80014521 2.91481813 1.9742217  0.39544311 4.44403315 5.06662711\n",
            " 4.51648144 1.16898681]. \t  -450.24547658409523 \t -164.77731695731757\n",
            "95     \t [ 4.99784959  4.86717394 -3.82181738  0.19789293  2.89170236  2.31179275\n",
            "  4.53506883 -4.68178066]. \t  -509.5293090006045 \t -164.77731695731757\n",
            "96     \t [-5.035184   -2.53669951 -1.62951499  2.00973233 -2.6072178   5.02153324\n",
            " -3.83811911  4.15821172]. \t  -489.07142557807543 \t -164.77731695731757\n",
            "97     \t [-0.38865628  4.72429546 -0.19672913 -4.47013422  5.05195445  1.34486774\n",
            " -3.46037912  3.1326292 ]. \t  -425.62322149178203 \t -164.77731695731757\n",
            "98     \t [ 4.97449129 -3.83567986 -4.68207321  2.43186988 -2.69823452 -2.60951\n",
            "  2.72939654 -4.47484415]. \t  -433.19251837598927 \t -164.77731695731757\n",
            "99     \t [-2.52782771 -4.23166649  4.07196494 -4.72154985 -4.84994484  4.4192319\n",
            "  4.54262629 -2.00113492]. \t  -592.3907350443759 \t -164.77731695731757\n",
            "100    \t [ 3.19657758  2.46818271  4.61758776  1.91065018  4.58488365  4.92733759\n",
            " -4.33807273  4.51361956]. \t  -646.4625882335883 \t -164.77731695731757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNmoDTuUtdi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40637c66-bf20-4bde-dbbe-a2e54caa76e7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 7\r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_loser_7 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_7 = dGPGO(surrogate_loser_7, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.55672335 -2.02386832 -4.48474711 -0.4110301   3.43299466  4.37244977\n",
            "  2.3243672   2.74940131]. \t  -353.7866241526368 \t -217.44194749723354\n",
            "init   \t [-2.36334012  1.47485995 -4.16385785 -4.30401653  0.91764484 -1.60419289\n",
            "  5.00609176  1.29508563]. \t  -344.5427966394509 \t -217.44194749723354\n",
            "init   \t [ 1.86141982  0.53510977 -2.36687301 -1.29782388 -2.83721627 -3.21082777\n",
            " -1.11976352 -3.14201697]. \t  -217.44194749723354 \t -217.44194749723354\n",
            "init   \t [ 1.13572794  3.9199585   1.25274956 -2.52806201 -3.27751366  3.23998177\n",
            " -2.8121946   0.17261711]. \t  -234.58737464459995 \t -217.44194749723354\n",
            "init   \t [ 0.18939719  1.02783934  0.33403374 -4.98370509  0.24675597  4.05385947\n",
            "  2.76378925 -3.86199863]. \t  -373.52986721661773 \t -217.44194749723354\n",
            "1      \t [-2.09026361  1.14712145  2.31565437 -0.3737859   2.75569016 -3.15769824\n",
            "  0.59255523  0.51996833]. \t  \u001b[92m-126.06288515837247\u001b[0m \t -126.06288515837247\n",
            "2      \t [ 2.75085748  2.31805411 -0.85031656  3.12431177 -2.44115014  0.01810138\n",
            "  3.95854974  4.53429735]. \t  -363.496045642814 \t -126.06288515837247\n",
            "3      \t [ 0.3197009  -4.24821941  1.44362319  4.43538764 -3.73778765 -4.45035073\n",
            "  0.60134187  0.88561962]. \t  -318.6346160644668 \t -126.06288515837247\n",
            "4      \t [ 2.99171241 -4.16669349  0.06626421 -3.90805164  4.99638945  3.30615025\n",
            " -0.90933644  4.39696134]. \t  -455.6353713631223 \t -126.06288515837247\n",
            "5      \t [ 3.80241898 -4.76561259  3.75477373 -2.31697124  1.95612299 -4.8590656\n",
            "  3.87732368 -4.51857722]. \t  -553.0199071382995 \t -126.06288515837247\n",
            "6      \t [-3.87174622  0.11711937  0.60621965 -2.77389796  3.6777981  -0.61714207\n",
            " -4.44111449 -5.11053133]. \t  -463.8193086344131 \t -126.06288515837247\n",
            "7      \t [-1.62934979 -2.77766743  3.88355824  2.63054964  3.5967524   4.63514942\n",
            " -1.80595721  4.03176121]. \t  -437.4728509815538 \t -126.06288515837247\n",
            "8      \t [-4.87299908 -3.60438804  4.14373037 -3.66711479 -4.11526938 -3.23954251\n",
            " -2.15930292 -5.0851064 ]. \t  -542.1813791428053 \t -126.06288515837247\n",
            "9      \t [ 0.46738539  2.1646163   0.18847445  4.77376931 -2.41808188 -1.00777632\n",
            " -4.68197947  1.61777929]. \t  -310.56511723466554 \t -126.06288515837247\n",
            "10     \t [ 4.58684088 -3.86154213 -5.10238691  3.28477999 -4.2350354   4.4322743\n",
            "  4.27338411 -0.40158936]. \t  -508.7951306576851 \t -126.06288515837247\n",
            "11     \t [ 2.18807677 -3.85838637 -0.14390746 -2.54364233 -3.68109291 -3.85783141\n",
            "  4.56739657  4.76093171]. \t  -544.9135139030769 \t -126.06288515837247\n",
            "12     \t [ 3.65910848 -3.77322784 -4.39092579 -4.04329935  4.92496582 -4.83510266\n",
            "  1.41512293 -1.67248293]. \t  -463.03868968879215 \t -126.06288515837247\n",
            "13     \t [ 3.70463372 -1.6169365   3.99069216 -4.79873113  3.21012622 -3.59582379\n",
            " -3.62529352 -1.33583421]. \t  -394.22057211255174 \t -126.06288515837247\n",
            "14     \t [-4.5894154   4.92798365  2.37548828 -2.76315117 -4.38889546 -2.95023546\n",
            "  4.23062684 -1.37722754]. \t  -406.09845273916767 \t -126.06288515837247\n",
            "15     \t [ 3.03724509 -4.71790039  2.51302555  0.03615994 -4.39481833  2.54450993\n",
            " -1.26899952  0.71522446]. \t  -223.47736072165253 \t -126.06288515837247\n",
            "16     \t [ 1.84266697 -3.35314984 -3.54865233 -4.62317696 -1.38585737 -0.64246734\n",
            " -4.39848531  4.64968205]. \t  -469.6191559661819 \t -126.06288515837247\n",
            "17     \t [-2.50399261  3.09944983 -1.78206992  3.66530073 -0.72521701  0.0927845\n",
            "  4.28994614 -2.16487185]. \t  -257.7483735095152 \t -126.06288515837247\n",
            "18     \t [-2.86542444 -4.683581    0.54115179 -0.39180876 -1.41324475  3.35805496\n",
            " -1.52857118 -4.68463338]. \t  -323.1426418602525 \t -126.06288515837247\n",
            "19     \t [ 2.48184377  4.66551143 -4.9596751  -3.43903238 -4.35518841 -3.3123188\n",
            " -0.54239038  3.58194976]. \t  -436.1657379088569 \t -126.06288515837247\n",
            "20     \t [ 3.50969778 -0.85729815 -3.40613827  5.10070628  3.57291431  0.80937832\n",
            "  1.54976903 -3.34444673]. \t  -326.7162735361845 \t -126.06288515837247\n",
            "21     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -126.06288515837247\n",
            "22     \t [ 3.43654162  2.37720797  5.01669256 -4.95385484 -2.54870646 -3.72425019\n",
            "  1.11165097  2.40658989]. \t  -367.4599120709033 \t -126.06288515837247\n",
            "23     \t [ 1.98387325  1.67275942  4.48981292  4.53543431 -2.80345593  3.62397376\n",
            "  3.75908479 -2.01170598]. \t  -401.674576242779 \t -126.06288515837247\n",
            "24     \t [-0.84293283  3.48913065 -2.68496808 -3.25305769  4.07373554  2.87426449\n",
            " -3.67591306  3.5888769 ]. \t  -419.18694060168053 \t -126.06288515837247\n",
            "25     \t [-4.9925136  -0.04399427 -3.91692885  4.96109248  3.34448879 -1.57934636\n",
            " -2.13194442  0.43900937]. \t  -273.6579910101781 \t -126.06288515837247\n",
            "26     \t [ 2.4707812  -1.48111345  4.44872515  5.07739461  2.90692425 -4.55416511\n",
            " -3.25498266  4.39629928]. \t  -568.4628902261106 \t -126.06288515837247\n",
            "27     \t [-4.91554525  2.89709073 -4.92224896 -1.57136991  0.23902827  4.44092204\n",
            " -4.78237799 -2.25757831]. \t  -442.9989299504249 \t -126.06288515837247\n",
            "28     \t [-3.29513168  4.69703011  4.31837646 -3.82056116  3.60718111  5.05741155\n",
            " -1.5779542  -0.14830569]. \t  -405.44273268819427 \t -126.06288515837247\n",
            "29     \t [-4.76621345 -0.65412886 -4.87480111 -1.43615909 -2.03929788 -4.66702248\n",
            " -3.59241771  4.65398803]. \t  -518.2091927885375 \t -126.06288515837247\n",
            "30     \t [-4.59632758 -3.1197202  -2.35021669  0.46448236 -1.29341086 -4.19166308\n",
            "  3.00681779 -4.53166588]. \t  -399.38449837167275 \t -126.06288515837247\n",
            "31     \t [-3.32995226  2.3566786   4.51740145  3.1274462   4.94979517  3.07521084\n",
            "  1.11387665 -3.93306882]. \t  -434.2220593166157 \t -126.06288515837247\n",
            "32     \t [-4.65600681 -2.33230214  1.9198081   1.94038757 -4.8061165   4.93417478\n",
            " -1.02135168  3.57858206]. \t  -429.99744638214315 \t -126.06288515837247\n",
            "33     \t [ 4.69117852 -4.95966635  4.00120457 -2.61337472 -4.96747111 -3.62216146\n",
            " -4.17873666 -3.67319295]. \t  -578.8223800965548 \t -126.06288515837247\n",
            "34     \t [-4.65891214 -1.8539564   5.08351102 -4.96897638  2.98653259 -4.29999065\n",
            " -4.40106778  2.62358603]. \t  -551.0567434148775 \t -126.06288515837247\n",
            "35     \t [ 3.65070719 -1.61137318  4.39408057  4.62918309  5.09582941 -4.19235121\n",
            " -2.16394287 -4.89988938]. \t  -622.3039941887954 \t -126.06288515837247\n",
            "36     \t [ 3.12270749 -1.10643081 -3.09023247 -4.9150458  -0.38132969  4.85016166\n",
            " -5.02656311 -3.00336982]. \t  -528.376660783285 \t -126.06288515837247\n",
            "37     \t [ 2.82721129  2.83495095 -1.20407627 -2.90812872  4.81537988  4.70444454\n",
            "  5.1014436   3.21891957]. \t  -576.0401084594043 \t -126.06288515837247\n",
            "38     \t [ 4.13421669 -0.00512137 -4.94498531 -3.64718248 -1.98202397  4.88916549\n",
            "  1.48393019  3.71772539]. \t  -432.7101283505503 \t -126.06288515837247\n",
            "39     \t [-3.30183886 -4.06733792  4.98570845 -1.68785371  5.00930643  2.19400339\n",
            "  4.84033579 -1.15056899]. \t  -458.895967565413 \t -126.06288515837247\n",
            "40     \t [ 4.65419152  2.96497799 -4.29522873 -3.98879643  4.01893485 -3.59218847\n",
            " -4.23207094 -4.14766832]. \t  -579.412931213512 \t -126.06288515837247\n",
            "41     \t [ 4.47727712 -2.98415741  2.8484701   3.42727006  3.58423302 -1.73137264\n",
            "  4.98872412  3.46172515]. \t  -461.4819128187171 \t -126.06288515837247\n",
            "42     \t [ 3.49235565  4.59385774  2.11856193  3.31953353  1.84560596  4.37365149\n",
            " -1.34058314  4.01241719]. \t  -385.12607787647903 \t -126.06288515837247\n",
            "43     \t [-1.780762    3.21783638  4.35245659  2.66410558 -4.61218223 -4.19432433\n",
            " -0.78076841 -4.36106615]. \t  -477.43516808029506 \t -126.06288515837247\n",
            "44     \t [-4.065784    1.20726911  2.66026032  4.90416463  4.55847381 -4.54819465\n",
            "  4.82761247 -4.95406689]. \t  -724.3778646935331 \t -126.06288515837247\n",
            "45     \t [ 3.90318603  5.07097627 -0.10464568  0.63693993  3.33421053 -3.13703861\n",
            "  2.97208012 -4.25888474]. \t  -389.88856577581714 \t -126.06288515837247\n",
            "46     \t [ 4.59042452  2.59148526 -4.76062565  4.30692082 -3.96183129 -4.60073579\n",
            "  3.21473751 -1.50255692]. \t  -472.57686026549163 \t -126.06288515837247\n",
            "47     \t [ 4.98919915  5.10956884 -5.09231092 -0.42393897 -0.11551188  3.21894168\n",
            " -0.64974996 -4.06072598]. \t  -352.72870098398147 \t -126.06288515837247\n",
            "48     \t [ 4.55688248  1.45390653 -1.03818276 -1.39634278  4.31766067 -4.17598525\n",
            " -0.2851115   4.53929015]. \t  -399.27977497564814 \t -126.06288515837247\n",
            "49     \t [-4.78423195  4.95905843 -1.66277428 -2.03075737  0.45024421  3.54255237\n",
            "  3.04618687  4.5330511 ]. \t  -402.51861562727595 \t -126.06288515837247\n",
            "50     \t [-3.8874185  -2.44978105 -4.94060571  0.88957022 -3.7487915   0.30518537\n",
            "  4.87566276  4.42803405]. \t  -497.59948507637023 \t -126.06288515837247\n",
            "51     \t [-5.09296222  4.96799341 -4.52982563  3.03126267 -4.41572932 -2.87263242\n",
            " -4.80293809 -4.79659212]. \t  -666.1536519160758 \t -126.06288515837247\n",
            "52     \t [ 0.21333477 -4.73149471 -4.65711115  4.63789876 -2.0291509   2.00698314\n",
            " -3.95285832 -1.22073445]. \t  -361.9783860461043 \t -126.06288515837247\n",
            "53     \t [-1.9410221   0.21852535  4.12099768 -4.56116732 -2.98588166  5.04643513\n",
            "  4.42520396  4.9653252 ]. \t  -669.7170658576059 \t -126.06288515837247\n",
            "54     \t [ 0.21132943 -5.10511174  4.51228662  4.83588805  1.41358262  1.69116063\n",
            "  0.87885281 -2.68200595]. \t  -296.89758474715273 \t -126.06288515837247\n",
            "55     \t [-1.51377082  4.89936992 -2.22819918  3.82817464  5.04829218  2.79478747\n",
            " -4.84967274 -2.46540537]. \t  -511.3658134198294 \t -126.06288515837247\n",
            "56     \t [-4.21897914 -4.9173616  -4.00305383 -4.57367384 -2.96322354  1.99627995\n",
            "  1.02030834  0.42090534]. \t  -274.4267293311488 \t -126.06288515837247\n",
            "57     \t [ 4.15002035  1.95299292 -4.29935879  4.81983136 -4.61776232  3.07831746\n",
            " -4.18384218 -3.27403162]. \t  -544.9884736173814 \t -126.06288515837247\n",
            "58     \t [ 2.92868122 -1.09771224  4.06113147 -3.15913434  4.30646556  5.06695085\n",
            " -4.91937638 -0.85739819]. \t  -522.4410781781945 \t -126.06288515837247\n",
            "59     \t [-2.86875847 -3.13273465  3.22986442 -1.03989463 -4.9467127  -0.31051717\n",
            "  5.01843137  0.27389569]. \t  -363.30050649793765 \t -126.06288515837247\n",
            "60     \t [ 2.33153758 -1.55717918 -3.56607654  3.65990967  4.80507923  1.37613077\n",
            " -0.46146438  4.80986581]. \t  -415.39160854073805 \t -126.06288515837247\n",
            "61     \t [-3.81949502  4.42035831 -4.84371314  0.34579591 -4.3421587   5.05168267\n",
            "  1.3665522  -2.93232746]. \t  -453.7799539899686 \t -126.06288515837247\n",
            "62     \t [ 2.60951563 -4.32394621 -3.80127125 -4.05921208 -3.67342125  4.82319883\n",
            "  4.15400133 -3.89178641]. \t  -602.4680955160921 \t -126.06288515837247\n",
            "63     \t [-4.47876487 -4.96344251 -2.44493728 -4.45738918  0.13136297  4.77609192\n",
            " -4.86132036  4.62884175]. \t  -640.5263486535432 \t -126.06288515837247\n",
            "64     \t [ 1.33934797  3.35747308  4.68510374  4.20538712 -3.30070613 -4.99037399\n",
            "  4.99296417  0.78696891]. \t  -544.2895174786909 \t -126.06288515837247\n",
            "65     \t [-2.02214105 -4.02564771  3.57057198  1.55142368  4.76549851 -3.40204489\n",
            " -4.87366691 -1.3837977 ]. \t  -448.956257274611 \t -126.06288515837247\n",
            "66     \t [-3.04623207  4.52202737  4.30068507 -1.80477247 -3.86190095 -3.27446762\n",
            " -3.46901151  2.27460177]. \t  -383.22649901159787 \t -126.06288515837247\n",
            "67     \t [-4.62653169  1.48564364  4.67192103  3.98812018 -1.25397528  3.08672166\n",
            " -3.7300208  -4.32496147]. \t  -466.98311163273183 \t -126.06288515837247\n",
            "68     \t [-4.22782405 -3.86891848  4.04034044 -1.081632   -4.12876997 -1.92296927\n",
            " -2.96917765  4.76147554]. \t  -451.97019874920056 \t -126.06288515837247\n",
            "69     \t [-4.16271264  3.34180653  3.03449541  5.00894337  5.08251494 -1.9322614\n",
            " -0.79575239  4.94075921]. \t  -518.9290211815734 \t -126.06288515837247\n",
            "70     \t [ 4.27488555 -4.37630749 -3.10725494  3.04132314  4.78323047 -3.2012495\n",
            " -4.64583011 -2.53620746]. \t  -500.97187338004613 \t -126.06288515837247\n",
            "71     \t [ 4.78986392  4.24036657 -3.47661256  5.00696868  3.98791566 -3.6694881\n",
            "  3.58510011  4.47082557]. \t  -605.6287232414135 \t -126.06288515837247\n",
            "72     \t [-3.67687556 -4.87562151 -4.3588536  -3.84573594  4.743902   -3.4655177\n",
            " -0.17593116  3.05093843]. \t  -436.4847110478042 \t -126.06288515837247\n",
            "73     \t [ 1.30662715 -2.90787154  4.51713971  4.51151038 -3.68401654  3.06292146\n",
            "  4.74784002  4.56856917]. \t  -610.1645698126301 \t -126.06288515837247\n",
            "74     \t [ 2.86825292 -4.53439682 -2.40124625  4.62111583 -1.36833296 -1.87564634\n",
            " -3.537974    5.08206356]. \t  -476.77493195227044 \t -126.06288515837247\n",
            "75     \t [-2.67808046  4.21166453 -2.51840833  2.79223596  4.93559453 -4.89335419\n",
            " -0.48652248 -3.97160481]. \t  -486.1778644746092 \t -126.06288515837247\n",
            "76     \t [-1.12235943 -4.73997626  4.73307374 -4.38385113  2.48524489 -5.01922093\n",
            "  5.07363928  3.38849048]. \t  -644.358337742447 \t -126.06288515837247\n",
            "77     \t [-3.78807237 -4.24635998 -2.44984338  0.30909451  4.11007227  2.006032\n",
            "  5.11138163 -5.09499145]. \t  -567.9635086664478 \t -126.06288515837247\n",
            "78     \t [ 5.08877951 -3.34715522  3.22950498  0.85640496 -4.45058261 -1.4546155\n",
            "  4.04398904 -3.22470736]. \t  -391.92609521088815 \t -126.06288515837247\n",
            "79     \t [-1.03177339  4.65296111 -4.64498302  3.38824998 -2.23998182  3.78818925\n",
            " -0.89103366  4.75437208]. \t  -452.59308128993393 \t -126.06288515837247\n",
            "80     \t [ 4.50300717 -1.37760092  4.69743853 -5.07792934 -2.45850812  2.55355818\n",
            "  4.75528184  0.38284992]. \t  -422.2186914083558 \t -126.06288515837247\n",
            "81     \t [ 3.20480929  3.3823284   4.88155553 -4.61373431  4.02454506  0.71536562\n",
            "  3.3028888   0.28603592]. \t  -350.85938005809885 \t -126.06288515837247\n",
            "82     \t [-3.91452618 -4.16884238  4.28349512  3.20233929 -0.17494882 -4.72364108\n",
            "  5.02491138  2.92999368]. \t  -525.6036979195742 \t -126.06288515837247\n",
            "83     \t [-3.51881716  3.94282401  2.07219909  3.81830004 -2.79291345 -3.5660105\n",
            "  1.34800352  4.7205906 ]. \t  -420.9654974046708 \t -126.06288515837247\n",
            "84     \t [-1.52849504 -5.12       -1.96973121 -5.12       -5.12       -5.12\n",
            "  0.83143643 -2.27735981]. \t  -505.95056754022005 \t -126.06288515837247\n",
            "85     \t [ 4.18968297 -4.99942498 -4.35214793 -0.18405964  2.66485755  3.80327547\n",
            "  2.73488485 -1.2653633 ]. \t  -311.9641053143754 \t -126.06288515837247\n",
            "86     \t [ 4.76185354  0.12175905  2.0807318   0.22008519 -4.16994702 -4.04494669\n",
            " -3.72082423  4.9549801 ]. \t  -514.3251904500883 \t -126.06288515837247\n",
            "87     \t [ 0.7208291   3.34579002  5.09850784 -2.06934781  3.13668952  0.32632027\n",
            " -3.01173659  4.6904147 ]. \t  -407.34820110392843 \t -126.06288515837247\n",
            "88     \t [-2.84986281  3.78981458 -2.83082885  3.47552879  4.75490856 -4.60867961\n",
            "  4.53221657  3.13290947]. \t  -571.9983114767854 \t -126.06288515837247\n",
            "89     \t [-2.14367027  4.7017305  -4.25665275 -1.21138091  3.39494905  2.70296224\n",
            "  1.47980811 -2.44303715]. \t  -273.5756074542297 \t -126.06288515837247\n",
            "90     \t [-0.78361085  4.54534188 -2.78972516 -4.92274513 -0.76805186 -3.07562192\n",
            "  4.92575081 -5.03567555]. \t  -594.6272822665569 \t -126.06288515837247\n",
            "91     \t [ 2.93788574  1.78682512  4.52781582  1.1774453  -0.00639281  3.72267093\n",
            " -2.79369627 -4.61513795]. \t  -390.24455484064515 \t -126.06288515837247\n",
            "92     \t [ 3.59241536  5.03326922  3.38086681 -4.0128877  -4.93650218 -4.64194681\n",
            "  0.73229589 -4.68993144]. \t  -593.1256449843719 \t -126.06288515837247\n",
            "93     \t [-3.29854367 -4.3411339  -1.31607687 -5.11357998  2.52638824 -1.56475802\n",
            "  0.40255217 -3.92806505]. \t  -329.5381450351533 \t -126.06288515837247\n",
            "94     \t [-4.90308625  0.41950708 -4.65058619  5.00329717  2.80633317  4.31601731\n",
            "  1.13819925 -3.75760538]. \t  -462.5788439633349 \t -126.06288515837247\n",
            "95     \t [-4.70532271  2.31378937 -4.87202588 -4.97958658 -3.53818867  2.54817121\n",
            " -2.54998583  3.70129485]. \t  -459.90895996296365 \t -126.06288515837247\n",
            "96     \t [ 4.94426616  3.24622917  4.1812172   1.55380944 -0.80270773 -4.2786256\n",
            " -3.32407581 -4.76591838]. \t  -479.7465065568298 \t -126.06288515837247\n",
            "97     \t [-3.48699102  2.04363098 -5.12       -1.34472934  1.76201523 -5.12\n",
            " -5.12       -4.37138234]. \t  -615.5709065163586 \t -126.06288515837247\n",
            "98     \t [-3.92941469  4.32504803 -4.81650143 -0.87210949 -4.38215511 -3.0210166\n",
            "  1.24209859 -1.36174031]. \t  -301.9007594772047 \t -126.06288515837247\n",
            "99     \t [-0.8982652  -4.64122505 -2.97075063  2.08253987  5.09925702  2.55800324\n",
            " -4.62780396 -0.38757107]. \t  -408.10285900453965 \t -126.06288515837247\n",
            "100    \t [-1.61693608  4.57551691  5.02363779 -3.72816625  5.07604642 -4.43971945\n",
            "  4.68170426 -4.73426912]. \t  -755.6257013921371 \t -126.06288515837247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_21yVprtdlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a51fafc-7358-4895-bfd4-97b2f21c9be0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 8\r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_loser_8 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_8 = dGPGO(surrogate_loser_8, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.99872128 -4.68771825  1.02085207 -2.04932398  3.03730465 -1.37015168\n",
            "  3.89742944 -2.07010168]. \t  -277.86676122742784 \t -180.51916289603517\n",
            "init   \t [-1.74998258  0.70366122  2.49781681 -4.56854645  1.04524157 -0.72377777\n",
            " -3.01595019  0.49815264]. \t  -180.51916289603517 \t -180.51916289603517\n",
            "init   \t [-1.18004907 -0.43124987 -2.23607519  0.87291919  1.19692315  0.82388062\n",
            "  4.34999751 -2.6686217 ]. \t  -220.47800037058124 \t -180.51916289603517\n",
            "init   \t [ 3.35954485  4.67643031  4.19598825  2.82329052 -0.36849066 -1.29661262\n",
            "  4.62746655  4.05379841]. \t  -431.85390329456686 \t -180.51916289603517\n",
            "init   \t [-0.2416498   4.43676172  4.77427222  3.16353515  1.62974284 -3.16385107\n",
            "  1.99781252 -1.93490553]. \t  -279.0706376092465 \t -180.51916289603517\n",
            "1      \t [-0.80689796  0.12979216 -3.32388196  5.07613741 -3.43250948 -2.05510194\n",
            " -3.97044354  3.43910665]. \t  -426.1198945095334 \t -180.51916289603517\n",
            "2      \t [-2.47747564  2.99675238 -3.50374538 -1.80117914 -3.5161839  -4.45826655\n",
            "  3.67687843  2.14617347]. \t  -386.46373501095024 \t -180.51916289603517\n",
            "3      \t [ 0.67811681 -1.3781688  -2.58692023  3.85333047  3.25130113  4.04155624\n",
            " -2.06044078  1.40198962]. \t  -280.03000154622777 \t -180.51916289603517\n",
            "4      \t [ 4.42454388  2.4188757  -3.21525657 -3.20344997 -1.04051026  5.10245349\n",
            " -0.18691581  2.84253024]. \t  -329.8483850739637 \t -180.51916289603517\n",
            "5      \t [-3.07302883 -2.35748372 -4.76094872 -3.54574189  0.41804042  1.01804191\n",
            " -4.13688486 -2.82255427]. \t  -329.47146503033844 \t -180.51916289603517\n",
            "6      \t [ 4.36422087  1.90391934  0.09991155  1.48583163 -5.11736914  0.78996386\n",
            " -3.71360948 -0.80410969]. \t  -271.54756978806927 \t -180.51916289603517\n",
            "7      \t [ 3.91575324  4.44584808 -4.68483153 -1.3300073   3.96829654 -2.30847028\n",
            "  3.63052491  2.20115262]. \t  -369.5195285564901 \t -180.51916289603517\n",
            "8      \t [ 2.83791722 -1.84109194 -0.18336038  5.05505168 -2.27716459 -4.66250782\n",
            "  2.86358311 -0.56762536]. \t  -333.48768015256735 \t -180.51916289603517\n",
            "9      \t [-4.34829873  4.8056149   2.63278856  2.70249436 -3.33886902  3.32420497\n",
            " -1.98131952 -3.03250746]. \t  -338.1946658605332 \t -180.51916289603517\n",
            "10     \t [-4.86997064  3.74258529 -3.20639472 -0.45958993 -4.35843637  4.8523993\n",
            " -4.34311529  4.90084006]. \t  -643.8572272382727 \t -180.51916289603517\n",
            "11     \t [-5.00411946  0.44264128  3.47943139  1.31201606  1.59913651  3.50610765\n",
            " -1.3911044   4.64701043]. \t  -341.4847277527873 \t -180.51916289603517\n",
            "12     \t [ 0.00548086 -4.23465739  4.71059857  4.19732566  0.82693307 -0.63428372\n",
            " -1.78653781 -2.22242468]. \t  -240.5924435082622 \t -180.51916289603517\n",
            "13     \t [-0.57223471 -3.8222528   1.07901006 -2.63093396 -2.58877446  4.422961\n",
            "  0.11753285  3.42507695]. \t  -305.5569122434089 \t -180.51916289603517\n",
            "14     \t [ 4.03761438  2.56133194  5.1197742   2.35660972  4.75332242 -2.77386776\n",
            " -3.83140306  4.55349137]. \t  -558.0421125100511 \t -180.51916289603517\n",
            "15     \t [ 5.07002423 -3.07341682  2.03370618 -2.97540296 -1.19482646  4.04468259\n",
            " -1.72924441 -3.91197777]. \t  -341.07226021043425 \t -180.51916289603517\n",
            "16     \t [-1.41671202  2.55666195 -2.3853693   1.08516009  4.30765662 -3.68324439\n",
            " -4.13221178 -2.44338018]. \t  -378.32469967994336 \t -180.51916289603517\n",
            "17     \t [-1.86728783 -0.80945079  1.84517462 -2.62059911 -5.04656418 -1.09871244\n",
            "  1.57935526 -4.31856167]. \t  -343.7237567008143 \t -180.51916289603517\n",
            "18     \t [ 3.66966602 -0.99814995  2.15291433 -4.92866581  2.78887625  0.68641935\n",
            "  3.51008714  1.89619243]. \t  -283.2566926789915 \t -180.51916289603517\n",
            "19     \t [ 3.97405564 -4.75710002 -2.01610248  5.07982104  3.97698667 -2.99383872\n",
            "  4.55425869  4.69086357]. \t  -630.5485044279746 \t -180.51916289603517\n",
            "20     \t [ 4.89167444 -4.35507446  3.93944184 -4.28192575 -5.07746683 -3.77769739\n",
            " -1.03928419  1.60291329]. \t  -424.40374657480845 \t -180.51916289603517\n",
            "21     \t [ 5.01960078  4.66343278  2.47908295 -0.1380686   2.4412476   0.91037699\n",
            " -4.27646892 -4.63889164]. \t  -422.1484084919773 \t -180.51916289603517\n",
            "22     \t [ 1.46921301 -1.90240606 -3.84335063 -5.06810438 -3.31266033 -4.81007936\n",
            " -0.85475063  4.40766578]. \t  -510.6777487454212 \t -180.51916289603517\n",
            "23     \t [-5.07574257  0.9567305   2.26465    -4.88807507  3.91342817 -4.93868051\n",
            "  4.90344371  2.79780682]. \t  -592.3989559199782 \t -180.51916289603517\n",
            "24     \t [ 4.42185871 -4.04838897 -3.40680335 -0.43441359 -2.34356268  3.1813517\n",
            " -4.88664142  5.0991389 ]. \t  -551.257541467041 \t -180.51916289603517\n",
            "25     \t [ 3.02005946 -0.28946757  4.46799786  0.86269113 -2.46440069  4.94345878\n",
            "  5.04534233 -2.35245246]. \t  -471.60797757980407 \t -180.51916289603517\n",
            "26     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -180.51916289603517\n",
            "27     \t [ 4.79720828 -4.22946252 -4.0281915  -0.80296819 -3.82216182 -3.2698492\n",
            "  0.43511803 -3.92789985]. \t  -371.99648514497284 \t -180.51916289603517\n",
            "28     \t [-2.45652141  4.69621567 -4.35725831  5.04561852 -4.30274899  4.941271\n",
            "  4.0771041   0.94008965]. \t  -571.428338267913 \t -180.51916289603517\n",
            "29     \t [ 3.87333974 -4.16740068 -3.883898    1.18395794 -3.03775313  5.0025232\n",
            "  3.33771536 -4.93527906]. \t  -569.7276263414255 \t -180.51916289603517\n",
            "30     \t [ 4.08890417  4.94345227  0.8273562  -3.77103829 -2.75423202 -3.62028656\n",
            "  0.93923661  1.48437471]. \t  -264.900974636553 \t -180.51916289603517\n",
            "31     \t [ 2.63656256 -5.08585994 -2.03710373 -2.5078634   2.50053278 -3.18902679\n",
            " -3.85469637 -0.41079712]. \t  -293.93378992559553 \t -180.51916289603517\n",
            "32     \t [-2.8617014  -2.65212229 -0.44945493  4.64340813 -0.81896431 -0.53157431\n",
            "  4.37606182  4.14663878]. \t  -385.76309067404435 \t -180.51916289603517\n",
            "33     \t [-3.67364611  3.58284625 -2.05438179 -5.02332146 -3.28970817  3.72997149\n",
            "  2.76318082  3.28523873]. \t  -430.1412870166693 \t -180.51916289603517\n",
            "34     \t [ 3.88985138  3.15756992 -4.96071759 -4.74637069  3.58417391 -3.86575799\n",
            " -2.0904379  -4.99028775]. \t  -582.7190459077771 \t -180.51916289603517\n",
            "35     \t [-0.87522108  5.07922594 -1.29272057  4.93410574 -4.0126065  -4.3584217\n",
            " -4.3870108  -3.14365793]. \t  -563.0198818743911 \t -180.51916289603517\n",
            "36     \t [-4.10480064 -3.92466462 -4.45138043  0.78043132  3.84921301 -4.08494889\n",
            " -4.33965454  2.76404217]. \t  -476.6867208590488 \t -180.51916289603517\n",
            "37     \t [-4.02738225  1.92634882  4.84539184 -2.5866606   0.14153928  3.54521975\n",
            "  5.00865971 -4.31977319]. \t  -521.2400592606305 \t -180.51916289603517\n",
            "38     \t [ 4.74248688  4.41156993 -4.50417805  3.37436951 -3.61370696 -4.09590624\n",
            "  3.44967939 -3.98960231]. \t  -544.4139241090639 \t -180.51916289603517\n",
            "39     \t [ 4.48023166  4.86333126 -4.30722253  4.65419032  0.0661146  -4.69857936\n",
            "  0.06780351  4.85563852]. \t  -530.8106334453986 \t -180.51916289603517\n",
            "40     \t [-4.25294219  4.52639591  4.18726302  4.8264791  -0.02761229 -3.19252306\n",
            " -2.70449292  4.53849168]. \t  -481.9834142207267 \t -180.51916289603517\n",
            "41     \t [ 4.29894557 -3.1371144  -4.2468848  -4.38761864  4.8244412   2.05386982\n",
            "  0.91278778 -3.63419963]. \t  -422.4547657402016 \t -180.51916289603517\n",
            "42     \t [-5.0417793  -4.83906763  3.40145714  4.66843181  0.21828891 -3.69802087\n",
            " -3.84373455  4.54335417]. \t  -544.9864482112325 \t -180.51916289603517\n",
            "43     \t [-5.12       -1.72424602 -5.12       -2.41134048 -0.75856483 -4.58494294\n",
            "  1.70247613 -4.83572411]. \t  -470.4320104878843 \t -180.51916289603517\n",
            "44     \t [-2.53091057  4.59401986  4.93133433 -3.88337755 -4.93149815 -5.10021546\n",
            "  3.44199404  4.33344787]. \t  -692.7251862242503 \t -180.51916289603517\n",
            "45     \t [-2.91672448  4.04522193 -5.01281992  0.80993504  4.77106101  4.84356204\n",
            "  4.03856252  2.35564681]. \t  -532.3821531215153 \t -180.51916289603517\n",
            "46     \t [ 3.20405848 -2.95918097  4.9198676   3.23456556  4.31471242 -2.87814545\n",
            "  4.74362933 -3.70096053]. \t  -552.1214922769788 \t -180.51916289603517\n",
            "47     \t [-3.20403481 -5.11301229 -3.89350589  3.67293555 -2.24733544  4.55634521\n",
            " -4.28801809 -4.38970784]. \t  -594.6718611860366 \t -180.51916289603517\n",
            "48     \t [-1.33421434 -4.29727091  4.82187183 -2.6334693   3.22263362  4.87272422\n",
            "  0.98684594 -4.3639148 ]. \t  -489.75974725087883 \t -180.51916289603517\n",
            "49     \t [ 4.69746669  4.59969471 -4.06289378 -1.99653753  3.89209236 -0.66418485\n",
            " -4.91913236  2.07088867]. \t  -411.9289870185117 \t -180.51916289603517\n",
            "50     \t [ 4.61551064 -3.58884404  3.15499749  4.27739454 -3.93798212 -5.0649973\n",
            " -4.13043317  3.97675662]. \t  -627.5127799367586 \t -180.51916289603517\n",
            "51     \t [ 3.65691747 -4.96121519 -1.44086027 -2.87224888  4.8053054   5.01246607\n",
            " -0.95906364  4.5712296 ]. \t  -541.6392857541672 \t -180.51916289603517\n",
            "52     \t [-4.41779186 -5.02354276 -1.9267254   1.65496306 -1.53905592  3.11515467\n",
            " -4.90148497  4.87031203]. \t  -520.0812675473336 \t -180.51916289603517\n",
            "53     \t [-2.15961732  4.73973166 -4.8427031  -1.9939927  -4.70679312 -1.64738883\n",
            " -0.90701478 -4.73970313]. \t  -448.3832707161231 \t -180.51916289603517\n",
            "54     \t [ 0.41053538  4.78871453  4.01407292  0.43179899  4.33826345  4.72002531\n",
            "  1.48475191 -1.19115042]. \t  -349.67287340916636 \t -180.51916289603517\n",
            "55     \t [3.40852894 0.84640147 4.19082071 4.98261933 4.59525337 4.58397842\n",
            " 3.23434812 3.5568389 ]. \t  -571.1405710588766 \t -180.51916289603517\n",
            "56     \t [-3.26090619 -4.56978756  2.31122861 -2.02490321 -3.83858586 -4.24870128\n",
            "  4.38919359  4.57717492]. \t  -569.2675579045233 \t -180.51916289603517\n",
            "57     \t [-4.98279035 -0.94658226  0.71207746  4.91634023  3.19920625 -4.49243244\n",
            "  1.45021648 -2.92869979]. \t  -380.42945674746494 \t -180.51916289603517\n",
            "58     \t [-3.7002203  -3.53639538  2.96920475  4.18786206  3.73296785  4.13661773\n",
            "  3.5985261  -1.09529143]. \t  -407.8930191954427 \t -180.51916289603517\n",
            "59     \t [ 0.66768193  4.81327348 -2.98950175 -3.18512968  4.85446779  3.58431762\n",
            " -0.89507706 -3.35771093]. \t  -404.8877753906416 \t -180.51916289603517\n",
            "60     \t [ 3.60735668  3.98944168  4.24373512 -4.68386298 -4.76123928  3.6361193\n",
            " -0.89065409  2.26770074]. \t  -425.99422986699096 \t -180.51916289603517\n",
            "61     \t [ 1.80389593  4.28207573 -4.68145142 -3.72429221 -4.00528234  2.26810585\n",
            "  5.00729371 -4.05898658]. \t  -579.5469244072606 \t -180.51916289603517\n",
            "62     \t [-4.46664434  4.24054045 -3.31205249 -2.49158715 -0.79215676 -4.1930179\n",
            " -4.6436345   4.53861346]. \t  -538.0178220607838 \t -180.51916289603517\n",
            "63     \t [ 5.073687   -0.10875756  3.2241455  -5.05723637 -1.90530492 -4.21611253\n",
            "  3.0490301  -4.24304549]. \t  -493.1619936929178 \t -180.51916289603517\n",
            "64     \t [-2.8733783  -0.36654651 -4.46389974 -4.91875701  3.21633001 -1.09005506\n",
            "  0.37128799  5.02186364]. \t  -426.6520131600044 \t -180.51916289603517\n",
            "65     \t [-4.21033787  0.99864495  1.24715702 -0.5525815   3.95452187  5.0304965\n",
            " -4.38781839 -4.64712157]. \t  -563.1722650356618 \t -180.51916289603517\n",
            "66     \t [-3.871599    4.96183133 -4.13832787 -3.89763196  4.25588026 -2.79717908\n",
            "  2.60763155 -0.61508813]. \t  -364.5049434145085 \t -180.51916289603517\n",
            "67     \t [-2.87582586  2.56800254 -1.90396267  1.93041505  4.38661324 -2.83320784\n",
            "  3.65768789  4.61281542]. \t  -455.4904508538041 \t -180.51916289603517\n",
            "68     \t [-4.66209293 -5.12       -4.86197377  1.6470031  -5.12       -5.12\n",
            " -5.12        1.36461084]. \t  -642.6872560610368 \t -180.51916289603517\n",
            "69     \t [-4.87216964 -0.81424955  4.1851601  -4.08526562 -4.44297948  3.92313186\n",
            " -5.05470158  3.61490862]. \t  -618.8050034970271 \t -180.51916289603517\n",
            "70     \t [ 2.16970197 -3.90771259 -4.49166884  4.62797911  4.68388094 -4.98876578\n",
            "  4.31800882 -4.77940886]. \t  -753.7248720360345 \t -180.51916289603517\n",
            "71     \t [-4.75040175 -4.78498299 -0.69751648  3.58924281 -4.27229849  3.52354718\n",
            "  3.41244318 -2.37585398]. \t  -413.7745018753404 \t -180.51916289603517\n",
            "72     \t [ 2.91594066 -4.12190301 -3.39118197  1.06416192 -4.96826525  3.07985091\n",
            "  3.86361122  3.3150941 ]. \t  -454.2554072656625 \t -180.51916289603517\n",
            "73     \t [ 3.07146796 -3.29339482  4.99516458 -4.97031689  4.44484219  4.73137693\n",
            " -4.79831945  2.79339377]. \t  -661.4881752822587 \t -180.51916289603517\n",
            "74     \t [-2.67027406  0.24169695  4.02183328  4.96571973 -3.60509935  4.25820567\n",
            "  4.85022786  2.01633401]. \t  -525.3815116034853 \t -180.51916289603517\n",
            "75     \t [ 0.70828226 -3.78050201  4.72533157  4.42378306  2.5019428   3.971857\n",
            " -5.01685353  4.28400585]. \t  -623.3076173360197 \t -180.51916289603517\n",
            "76     \t [-1.95868951 -4.87930124  4.50039175 -1.27101221 -4.18822026 -1.34491002\n",
            " -4.89327681 -3.84299519]. \t  -502.99073525514166 \t -180.51916289603517\n",
            "77     \t [ 3.27922664 -4.97055446  4.7165529  -0.15251545  4.32784927 -1.70024567\n",
            " -2.71999352  2.58205102]. \t  -343.117669905067 \t -180.51916289603517\n",
            "78     \t [-4.38379774 -1.32270302 -0.59706414 -4.22944     5.10161609  4.98451408\n",
            "  2.42834244  0.12194633]. \t  -415.9404908724171 \t -180.51916289603517\n",
            "79     \t [ 5.06948689  0.89913792 -4.6196479   2.05843386  4.80673524  1.73973804\n",
            " -2.85670658 -3.80731894]. \t  -415.06311190911237 \t -180.51916289603517\n",
            "80     \t [-4.81503647 -0.63204076  4.93006022  4.62501007  0.13265812 -4.985711\n",
            " -5.08181077 -2.05674957]. \t  -546.3101123920505 \t -180.51916289603517\n",
            "81     \t [ 4.26524678  3.90234042 -1.99139426  4.5744624   0.16434933  2.76673171\n",
            " -2.56241491  4.26334723]. \t  -381.68333731343245 \t -180.51916289603517\n",
            "82     \t [-2.39100646 -2.45716768 -1.10729874  4.49738707 -4.51522765 -3.57554661\n",
            " -1.93274184 -3.22678279]. \t  -390.46561094535434 \t -180.51916289603517\n",
            "83     \t [ 5.00610762  4.44688661 -0.96698398  3.66189603 -4.5750887   4.2827217\n",
            "  4.66793841 -2.88538502]. \t  -554.8923500088598 \t -180.51916289603517\n",
            "84     \t [ 4.9084746  -4.36651305  0.39848413  2.22735887  3.37675488  4.23744326\n",
            "  4.92507312 -2.47951763]. \t  -466.2732730260141 \t -180.51916289603517\n",
            "85     \t [-3.01563797  5.02772589  5.07875667  0.54723638  2.36115048 -0.76855511\n",
            " -4.55357877 -3.43714743]. \t  -409.30594319348694 \t -180.51916289603517\n",
            "86     \t [-2.38238632  2.6354261  -0.03374852 -3.92243918 -3.72543517  4.82208105\n",
            " -3.23015383 -2.81295288]. \t  -426.36025707661673 \t -180.51916289603517\n",
            "87     \t [ 3.97204529  4.16769084  4.94683209 -4.67719334  3.82367013 -4.10337232\n",
            " -2.90233526  0.32752427]. \t  -445.3857108035907 \t -180.51916289603517\n",
            "88     \t [ 4.93125488 -5.08451271  2.23542936  4.58727356 -2.26390486  1.47797484\n",
            "  1.61866377  3.16417927]. \t  -312.35509565968437 \t -180.51916289603517\n",
            "89     \t [ 0.9878966   4.6736112  -4.81039061  3.56570166 -0.02278086  1.74648717\n",
            " -0.30346196 -4.27143342]. \t  -329.84738094551597 \t -180.51916289603517\n",
            "90     \t [ 1.63281423  4.23232303  2.57898496 -4.55500346  4.75379062  3.55235912\n",
            "  0.17709591  4.1471406 ]. \t  -467.954815150169 \t -180.51916289603517\n",
            "91     \t [-3.48603366 -3.94337236  3.96486088  4.94272779 -2.53739025 -2.74963249\n",
            "  4.67288529 -2.07772495]. \t  -453.0765453672152 \t -180.51916289603517\n",
            "92     \t [-4.83317842 -3.43113959  3.89323771  4.74085088 -1.98270081  3.82154706\n",
            " -4.71430785 -2.00365641]. \t  -477.25046526519696 \t -180.51916289603517\n",
            "93     \t [-1.40894043  1.46383468  3.30197162 -0.65706864 -3.55951    -3.47432765\n",
            " -4.79883473  4.90098316]. \t  -529.8418069966219 \t -180.51916289603517\n",
            "94     \t [ 3.54590851  3.00395829  1.87559367  4.57103718 -1.25281449  5.0786582\n",
            " -2.21361287 -3.62699126]. \t  -426.89751018465296 \t -180.51916289603517\n",
            "95     \t [-5.10417084 -4.78876116 -4.66471104 -1.04707016 -4.88517546  1.02658504\n",
            "  2.48866573  3.53205072]. \t  -410.3862536397909 \t -180.51916289603517\n",
            "96     \t [ 4.52160448 -5.11309196  0.688394   -3.87756003  3.85860037 -5.05677358\n",
            "  4.95959878 -4.04195978]. \t  -665.0484614557234 \t -180.51916289603517\n",
            "97     \t [ 4.97249523  1.29958396 -3.19757959  1.46867798 -5.04818421 -4.19164966\n",
            "  3.88949674  4.76670775]. \t  -587.9148479074973 \t -180.51916289603517\n",
            "98     \t [-4.60992847 -1.23219726 -4.69831546 -2.05616496 -4.61742776  2.25973389\n",
            "  2.19772287 -3.8972303 ]. \t  -399.9805344059411 \t -180.51916289603517\n",
            "99     \t [-3.08645235  4.4468406  -4.893456   -3.38305854  2.71217414  4.62214867\n",
            " -4.66198909  1.55878858]. \t  -503.2356092947565 \t -180.51916289603517\n",
            "100    \t [-4.80945496  4.14509577 -4.52127268  4.3672397   2.96209179 -1.0399465\n",
            " -3.65458383  3.43232919]. \t  -433.2091667782506 \t -180.51916289603517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkq32q1utdoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a7edca-4b7f-4841-8c3d-95f6ef98cc47"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 9\r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_loser_9 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_9 = dGPGO(surrogate_loser_9, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.76413244 -0.12207719  3.33307058 -4.79798899  3.15443162  0.67192238\n",
            " -2.07234561 -4.64183582]. \t  -383.4493461208245 \t -276.8057458851627\n",
            "init   \t [ 5.02402457 -5.05010449  2.76268061  2.52689511 -1.25502529 -0.05993009\n",
            "  4.39243154 -1.07055059]. \t  -276.8057458851627 \t -276.8057458851627\n",
            "init   \t [ 4.85331248  0.25000669 -4.16140192  3.20827815 -2.95232732  0.55650083\n",
            " -2.12716425  3.23729777]. \t  -277.7575521997104 \t -276.8057458851627\n",
            "init   \t [ 3.35915588 -2.85104771  1.48310734 -4.14534019 -0.90456843 -4.12809972\n",
            " -3.64532737 -2.94711116]. \t  -371.7161372605202 \t -276.8057458851627\n",
            "init   \t [-0.23904098 -4.32523431 -2.71315168 -5.05289725  4.08211648  0.53488053\n",
            " -3.40432253  4.3917126 ]. \t  -482.1410604064339 \t -276.8057458851627\n",
            "1      \t [-0.3457215  -2.41570642  0.505635   -1.25610202 -3.03382172  4.25433599\n",
            "  4.49717681  3.45593439]. \t  -410.6056418678222 \t -276.8057458851627\n",
            "2      \t [-1.35161709  4.3664537   3.4113556  -0.0757769   0.37398872 -4.76755028\n",
            "  1.94154011  3.49268818]. \t  -335.948278022135 \t -276.8057458851627\n",
            "3      \t [ 0.81711508  0.33401963  5.0650915   3.97129991  1.53230457  1.60569378\n",
            " -0.18323784  2.41800804]. \t  \u001b[92m-215.1596001270892\u001b[0m \t -215.1596001270892\n",
            "4      \t [-1.3419182  -4.98099454  2.81282579  3.21247481 -4.59772652  0.1103174\n",
            "  0.69095709 -4.7923155 ]. \t  -409.27802251836886 \t -215.1596001270892\n",
            "5      \t [-3.52610438  2.60047911 -2.01214225  0.72809513 -4.0107663  -1.51047699\n",
            "  3.81781734  0.44716805]. \t  -237.97528955990038 \t -215.1596001270892\n",
            "6      \t [ 4.12518634  3.19557651  1.66287169  3.82650865 -0.71435422  0.77049356\n",
            " -0.28518656 -4.91973347]. \t  -304.61769228244486 \t -215.1596001270892\n",
            "7      \t [-2.23790816 -0.46011833 -2.39554865  2.53065697  4.38763037 -0.14848842\n",
            "  0.84515017  3.58226126]. \t  -252.3140210243721 \t -215.1596001270892\n",
            "8      \t [ 0.7956411   1.76197212  5.05433518 -1.20533783 -2.57597512  4.1866622\n",
            "  5.01793143 -2.64606205]. \t  -459.9100931774228 \t -215.1596001270892\n",
            "9      \t [-4.86249768  0.46857535 -4.90416126 -5.00670057  4.21126596  4.49766511\n",
            " -2.28241394 -4.645285  ]. \t  -615.6466340589916 \t -215.1596001270892\n",
            "10     \t [ 3.42804641  4.24233712 -0.34390994 -3.32234534 -3.80280091  2.71517718\n",
            " -0.64780622  1.05682285]. \t  -220.66525022977282 \t -215.1596001270892\n",
            "11     \t [-3.7820612  -3.27616661 -3.99861302  4.16631422 -2.5278151  -3.04856967\n",
            "  4.81156379 -4.92976666]. \t  -597.3606624524207 \t -215.1596001270892\n",
            "12     \t [ 4.86537819 -4.56124212 -2.87810914  1.37232581  2.33728351 -3.6658278\n",
            " -0.87311764  1.85615356]. \t  -238.50843437027828 \t -215.1596001270892\n",
            "13     \t [-4.01741287  4.69215646 -4.87405369  3.88468691 -0.32433668  3.75379162\n",
            " -2.5003732  -0.34545711]. \t  -321.59410669786985 \t -215.1596001270892\n",
            "14     \t [ 3.02623357 -0.71461655 -4.3767601  -1.05086848 -3.41362989 -3.5739232\n",
            "  3.23816667 -2.70184432]. \t  -338.7665012562862 \t -215.1596001270892\n",
            "15     \t [-0.33361407 -1.17981279 -4.15972585 -0.08067727  4.33211474 -2.27479101\n",
            " -3.38603215 -4.65938743]. \t  -433.65096892136313 \t -215.1596001270892\n",
            "16     \t [-1.42452928  4.93633171 -3.16346043  2.56519148  5.06202491  0.27091926\n",
            "  1.93251969 -4.35163063]. \t  -413.30410475391915 \t -215.1596001270892\n",
            "17     \t [ 2.80256913 -1.47692834 -4.43161086 -2.74455277  4.42278224  1.12432781\n",
            "  4.22242405 -1.97869899]. \t  -362.7785759140599 \t -215.1596001270892\n",
            "18     \t [-3.28036773  0.43588521  4.36740483  3.1884057   4.67699512 -2.90577958\n",
            " -3.99721127 -2.1427701 ]. \t  -417.63554461807126 \t -215.1596001270892\n",
            "19     \t [-2.07972875 -0.35682558 -0.92728781  0.5197243  -4.70000537 -3.89554146\n",
            " -3.61371954  3.22850779]. \t  -384.54055694393685 \t -215.1596001270892\n",
            "20     \t [-4.92597471 -4.35804261  2.93577725 -0.90622571  3.6984092   2.24465228\n",
            "  4.39178596 -0.06177478]. \t  -325.05859422412584 \t -215.1596001270892\n",
            "21     \t [-4.75131045  4.49013326 -0.84395903 -2.78796759  1.65499738 -1.31700467\n",
            " -4.75332119  4.66422201]. \t  -452.425659674541 \t -215.1596001270892\n",
            "22     \t [-4.69739057  4.63977616 -3.46955173 -4.87083258  2.04906211 -4.84545567\n",
            " -5.05156713 -2.6866391 ]. \t  -594.370403320813 \t -215.1596001270892\n",
            "23     \t [-3.5753902  -1.84660188  4.41344412 -4.0087312  -3.94613081 -5.03089032\n",
            "  3.62321194 -0.52165871]. \t  -466.1080245743258 \t -215.1596001270892\n",
            "24     \t [ 3.85901116  3.75906354 -4.87059442 -4.94569808  4.37391411  4.40165693\n",
            " -1.4786638   2.23749993]. \t  -479.42037223824235 \t -215.1596001270892\n",
            "25     \t [-3.73875982 -1.39409943  3.99171915 -4.19380959 -3.24473476  3.02857305\n",
            " -3.76385929 -2.16780508]. \t  -380.4555070822014 \t -215.1596001270892\n",
            "26     \t [4.45199177 4.1369171  1.62419417 1.87963566 4.70791789 1.93669766\n",
            " 4.54951253 2.93701543]. \t  -423.31670616303126 \t -215.1596001270892\n",
            "27     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -215.1596001270892\n",
            "28     \t [-4.8674541   1.06661946  2.83419957  3.03796376  2.13799797 -2.80165628\n",
            "  4.70106602 -3.32550575]. \t  -400.1053244590762 \t -215.1596001270892\n",
            "29     \t [ 3.28543029 -4.49132334  1.28066734  4.25786842  0.44003471  1.79758317\n",
            " -5.07415009 -4.70770804]. \t  -506.46122208216616 \t -215.1596001270892\n",
            "30     \t [-4.26034594 -4.54161102 -1.57372269 -3.59934132  3.18179096 -3.85134594\n",
            "  3.06904802 -3.138039  ]. \t  -402.9817121682645 \t -215.1596001270892\n",
            "31     \t [ 2.0172223  -5.0394335  -4.26095239 -4.34374605 -5.08975548  4.34460561\n",
            " -1.14285371 -1.31456971]. \t  -450.5498226375551 \t -215.1596001270892\n",
            "32     \t [ 4.90713701 -3.66603338 -4.82484168 -1.08290572  2.1488922   4.67507251\n",
            " -3.51950639  1.27009031]. \t  -379.3276437098469 \t -215.1596001270892\n",
            "33     \t [-3.12508401 -2.04760938 -4.70465607  4.13969736  3.10905954  3.31772538\n",
            "  5.10565609 -2.27811146]. \t  -491.4687706202922 \t -215.1596001270892\n",
            "34     \t [-2.49258448  2.93631603  3.99584623  4.59617874 -0.91825304  5.00035657\n",
            " -3.26024731 -5.00235163]. \t  -584.6866796610559 \t -215.1596001270892\n",
            "35     \t [-1.02243468 -4.04852373  0.99012479  3.36615209  4.68444422  5.11172453\n",
            " -4.22056359  3.11995063]. \t  -551.1547113026895 \t -215.1596001270892\n",
            "36     \t [ 4.51438495  4.87825066 -2.93459083  4.02808873  4.36673971 -1.52213476\n",
            " -2.30875102  4.02392158]. \t  -434.80311714594416 \t -215.1596001270892\n",
            "37     \t [-1.57211395 -4.45816047  5.00649835 -2.10853491  3.27778731 -4.97136605\n",
            " -1.9687608   4.96428168]. \t  -561.4918922129687 \t -215.1596001270892\n",
            "38     \t [-5.09930328  3.59705329  2.23228703 -2.75377166  5.0565122   2.90516767\n",
            " -4.98698563 -1.53729463]. \t  -468.6407795396418 \t -215.1596001270892\n",
            "39     \t [-0.78519843  0.19677557  4.33682233 -4.58813415  5.01107277  4.61998335\n",
            "  1.28127317  2.6641793 ]. \t  -463.21612714384605 \t -215.1596001270892\n",
            "40     \t [-3.56367772  3.54793394 -4.2707231  -3.958517    4.59656994 -4.73804816\n",
            "  3.26097049  4.04705179]. \t  -601.0755276272299 \t -215.1596001270892\n",
            "41     \t [ 2.25577224 -1.34509628  4.64260525  1.09656894 -4.96662213 -3.19682176\n",
            "  3.07788113  5.11430625]. \t  -538.3954670290433 \t -215.1596001270892\n",
            "42     \t [ 4.56104879  3.48086988 -2.6269377  -2.10245306 -4.39256299 -2.86269512\n",
            " -3.96435058 -4.83968509]. \t  -526.4558482759198 \t -215.1596001270892\n",
            "43     \t [ 1.57370641 -3.87150413  0.69770889 -2.46067035 -4.30052346  2.39213276\n",
            " -4.60901949  5.09673766]. \t  -541.4552352727112 \t -215.1596001270892\n",
            "44     \t [ 2.4974563   4.6755272  -4.79730736 -2.85379405 -2.72739091 -3.42359153\n",
            " -2.96918766  4.90651475]. \t  -513.4002359936112 \t -215.1596001270892\n",
            "45     \t [ 3.8383228   3.61846804  4.29749789 -4.59989905  2.90389495 -3.27344196\n",
            " -4.64014192  1.51828248]. \t  -456.5745289522447 \t -215.1596001270892\n",
            "46     \t [-3.04038756  4.89335566  4.94298576  1.82967356 -0.60201394  3.22764382\n",
            "  4.34615525  4.7454665 ]. \t  -520.5212502165056 \t -215.1596001270892\n",
            "47     \t [ 4.67306872  2.55027165 -4.79229956 -2.32620922  1.5118172  -4.02341425\n",
            "  4.19394171  3.43686725]. \t  -451.5643559635667 \t -215.1596001270892\n",
            "48     \t [-4.89373734 -3.89184973 -0.40658987  3.98546596 -3.58437213 -4.75043867\n",
            "  4.72605469  3.68508725]. \t  -582.900073640577 \t -215.1596001270892\n",
            "49     \t [-2.85656868  3.72704096 -4.4639954  -3.30661774 -1.80717412  5.10210825\n",
            "  4.25782577 -3.82991725]. \t  -556.2264355669847 \t -215.1596001270892\n",
            "50     \t [-3.69973577 -0.60678157 -4.8547538  -2.48508746 -0.9470253   4.80724949\n",
            " -1.58607815  4.21795871]. \t  -412.9140378136958 \t -215.1596001270892\n",
            "51     \t [ 2.33184869 -2.5059905   2.1990503   4.94428135  4.82257505 -3.81727069\n",
            "  2.82528507 -0.45075332]. \t  -391.5051963408349 \t -215.1596001270892\n",
            "52     \t [-0.56495249  3.19365704  0.46261138 -4.56380634  3.00678332 -4.88577363\n",
            "  4.98006496 -4.49711875]. \t  -628.5017814361045 \t -215.1596001270892\n",
            "53     \t [ 1.46345351  3.91895517  3.19382071  5.00123145 -3.89327321 -1.40282975\n",
            " -4.92452889  3.97404902]. \t  -547.2057392854344 \t -215.1596001270892\n",
            "54     \t [-3.39931707  3.02573163  0.845798    4.01348117 -3.76296675 -3.93777845\n",
            " -3.14306843 -3.68163213]. \t  -437.86737089836254 \t -215.1596001270892\n",
            "55     \t [ 3.5228626  -2.60142355  4.6820963  -0.49957507 -3.51825176  3.34320903\n",
            " -1.78300048 -1.75790857]. \t  -268.6380806258051 \t -215.1596001270892\n",
            "56     \t [-4.37848061  4.77091957  2.18434887 -4.53741654 -4.49405832  0.7868325\n",
            "  0.60688752  4.84916744]. \t  -456.7521944596438 \t -215.1596001270892\n",
            "57     \t [ 4.94183279 -0.88209961  2.92294621 -3.84577913  0.54462445  1.44678763\n",
            " -0.74206089  4.73047205]. \t  -307.6845755233761 \t -215.1596001270892\n",
            "58     \t [-5.05338991  3.15555397  5.07223684 -3.01386577  4.13554004  2.29126639\n",
            "  4.64902811 -4.42956067]. \t  -584.2432643422442 \t -215.1596001270892\n",
            "59     \t [-5.10772308 -2.88386558 -4.70534939 -4.19234191 -2.81828784 -3.19495019\n",
            "  3.99193808  4.47001513]. \t  -551.8032992770267 \t -215.1596001270892\n",
            "60     \t [-2.56595724 -5.10333876 -3.68760868  4.09598259 -4.70016203  1.04762091\n",
            " -2.24935117 -0.20988791]. \t  -319.38809786768337 \t -215.1596001270892\n",
            "61     \t [-4.51350178 -0.02404704  3.01924404  2.62439881 -3.20170102  4.35550597\n",
            " -3.02280083  4.72820563]. \t  -483.1559778521982 \t -215.1596001270892\n",
            "62     \t [ 4.1899942   0.7253606   2.80634496 -4.34901279  2.22306145 -4.1779043\n",
            "  4.69156468  4.19406013]. \t  -542.1266059049262 \t -215.1596001270892\n",
            "63     \t [ 4.7947939   4.02236964 -3.40360985 -1.21186691  0.78013997  4.47437299\n",
            "  2.4124652  -3.2285247 ]. \t  -343.26719505082986 \t -215.1596001270892\n",
            "64     \t [ 4.89893004 -4.57965195 -4.84623626  3.48572519 -3.33202218  4.79146837\n",
            "  2.38821125 -4.56065756]. \t  -584.5876015211396 \t -215.1596001270892\n",
            "65     \t [-4.8524869  -3.7845035  -4.72050887  4.8374618   4.84940729  3.37791892\n",
            " -3.38784089 -1.57994562]. \t  -499.00318067739823 \t -215.1596001270892\n",
            "66     \t [ 4.87848648 -1.88213044  2.16743842 -0.09695157  4.58727693  4.45309438\n",
            "  2.46536385 -4.4160374 ]. \t  -467.7684954652906 \t -215.1596001270892\n",
            "67     \t [ 2.79781725 -2.45312844 -3.134766    4.99003133 -4.03158928 -4.0603559\n",
            " -1.99425154 -3.76388243]. \t  -470.30664725462003 \t -215.1596001270892\n",
            "68     \t [ 3.87194979 -4.18981782 -4.31922326 -3.4298232  -4.35450372 -2.34721459\n",
            " -1.42813198  3.48940789]. \t  -392.67263661558206 \t -215.1596001270892\n",
            "69     \t [-3.73083426 -3.51410455  0.9269929  -3.10726087 -4.87924577  4.22888285\n",
            "  4.30702923 -4.55212125]. \t  -601.7790799718272 \t -215.1596001270892\n",
            "70     \t [ 3.66392114  3.19346291 -4.61290324  1.8655768  -4.41898693  4.65857344\n",
            " -3.80540963 -2.89296212]. \t  -507.75176712056947 \t -215.1596001270892\n",
            "71     \t [-5.12       -5.12       -5.12       -0.2234052  -0.95680478 -3.59841602\n",
            " -5.12        0.0333311 ]. \t  -423.2646914375373 \t -215.1596001270892\n",
            "72     \t [ 3.65765988  4.03263269 -2.88746488  5.11753129 -4.03475285 -3.99650779\n",
            "  2.40623545  4.66850563]. \t  -567.7895369618374 \t -215.1596001270892\n",
            "73     \t [-1.19483931 -0.13035155 -5.12       -2.85899923 -5.12        1.74764059\n",
            " -5.12       -4.44760659]. \t  -603.9482511053623 \t -215.1596001270892\n",
            "74     \t [ 4.44205324  2.85101361  3.48912565 -2.31596088 -3.48582793 -2.00389065\n",
            "  2.28624752 -3.13470202]. \t  -294.012882955622 \t -215.1596001270892\n",
            "75     \t [-5.0403143  -4.99662653  3.89567791 -4.81494994  4.17763514  4.00802964\n",
            " -3.89703299  3.31266016]. \t  -591.3480008927907 \t -215.1596001270892\n",
            "76     \t [ 0.95002493  3.04088039 -2.46823937  2.17900753  5.11279382  4.97361775\n",
            " -4.76088836 -3.71923086]. \t  -605.1137424514488 \t -215.1596001270892\n",
            "77     \t [ 4.57045242  1.40206853  4.05252613  4.63194447 -0.22265301 -4.95625465\n",
            " -4.08268568 -1.24004819]. \t  -436.52381543478776 \t -215.1596001270892\n",
            "78     \t [-4.36904034 -4.15354976  2.39321873 -1.21048547 -4.72495976 -3.95045638\n",
            " -4.07786396 -3.33261237]. \t  -487.1521731393375 \t -215.1596001270892\n",
            "79     \t [ 4.93757155 -1.11936227 -4.56256271  5.02405675  4.20117445 -2.86467978\n",
            "  1.55470051 -4.10342043]. \t  -479.4128816524046 \t -215.1596001270892\n",
            "80     \t [-4.99306037 -4.87494749 -3.06268231  3.08537043  0.51210351  4.40696832\n",
            "  3.50646822  4.73791522]. \t  -522.1684191351305 \t -215.1596001270892\n",
            "81     \t [-1.82679457 -3.84027518  3.92363807  4.5592633  -0.50302006 -3.48841857\n",
            " -3.21262829  4.60845637]. \t  -478.59429492255543 \t -215.1596001270892\n",
            "82     \t [-2.15215873  3.21169292  0.40568234 -5.08485653 -4.81801765 -2.43361691\n",
            " -4.37924567 -2.23884087]. \t  -455.123761854174 \t -215.1596001270892\n",
            "83     \t [ 2.19587939  3.58470404 -2.45574836  2.94534773  0.20133369 -4.93950652\n",
            "  2.96887674 -5.0932835 ]. \t  -499.14140814285986 \t -215.1596001270892\n",
            "84     \t [ 1.7497044  -3.89554297  3.74915659  4.09867445  4.48993041  2.06222303\n",
            "  4.84978164  4.00633318]. \t  -562.1393062083291 \t -215.1596001270892\n",
            "85     \t [ 4.87477376  5.02090478  5.03614496 -0.07894825  3.07030107 -4.73926569\n",
            "  2.49337535 -2.42304225]. \t  -422.68068188766756 \t -215.1596001270892\n",
            "86     \t [ 4.07098763  0.36432648 -4.74851592  4.95454497 -0.6951275   2.60101774\n",
            "  4.68052319  1.92902737]. \t  -408.80170636890534 \t -215.1596001270892\n",
            "87     \t [ 1.74810329 -2.2068237   4.39789079 -0.72047757  2.42018271 -4.79045599\n",
            "  5.0480237  -4.63006465]. \t  -589.7517143957527 \t -215.1596001270892\n",
            "88     \t [-4.89178872 -4.2323776   3.45311062  3.33021271  1.44143927  2.83271883\n",
            " -4.5916795  -4.18835309]. \t  -486.34639203373854 \t -215.1596001270892\n",
            "89     \t [ 1.7709844  -3.35727584 -4.8725343   1.91194668 -4.75539056 -4.39976293\n",
            "  4.48669934  5.11005926]. \t  -690.5570418396853 \t -215.1596001270892\n",
            "90     \t [ 3.12258894  3.37546345 -4.98439733  4.49881654  1.36909273 -1.79101024\n",
            " -4.84428191 -4.30143564]. \t  -528.9347600118692 \t -215.1596001270892\n",
            "91     \t [ 3.29814024  0.5288641  -0.02499639  0.3745965   1.2371399   0.07758806\n",
            " -4.7198202   0.06190709]. \t  \u001b[92m-175.65656232870992\u001b[0m \t -175.65656232870992\n",
            "92     \t [ 0.23426021  4.81502299  4.51883988 -4.2539441  -0.86185419  4.96913008\n",
            " -4.82854    -0.62447836]. \t  -498.25853521017336 \t -175.65656232870992\n",
            "93     \t [-1.77353994 -4.21190593  2.19562439  4.46618985  3.61917921  3.78965259\n",
            "  2.8105315  -4.90802128]. \t  -532.5395387096512 \t -175.65656232870992\n",
            "94     \t [-5.11201931  4.68262126  4.25785347 -1.36957272 -3.03453211  2.06394368\n",
            "  0.18847429 -1.9472486 ]. \t  -234.06147311268296 \t -175.65656232870992\n",
            "95     \t [-2.80607267 -4.95079501 -2.35036346 -0.52846899  2.86476804  3.80809491\n",
            " -0.36033694 -4.32478495]. \t  -353.16754754838024 \t -175.65656232870992\n",
            "96     \t [ 1.11656045 -3.44406136 -4.98962471 -0.56713301  2.72062732  3.74184399\n",
            "  4.83959111  4.80234853]. \t  -570.4147983062993 \t -175.65656232870992\n",
            "97     \t [ 3.87583449  5.06280899  2.42621924 -1.72948564  4.03682519  4.72462872\n",
            " -5.06042594  4.51282841]. \t  -653.5030889197344 \t -175.65656232870992\n",
            "98     \t [-1.35997698 -3.61518917 -4.98452172  4.88787293  4.41797871 -4.40046808\n",
            " -3.79559382  3.87962007]. \t  -633.1250382269823 \t -175.65656232870992\n",
            "99     \t [-4.67593671  3.33085226 -4.66700709  3.24107965  2.68704998 -3.32730995\n",
            "  4.59686298  0.72463536]. \t  -406.06074551437223 \t -175.65656232870992\n",
            "100    \t [-1.48460938  4.35975709  0.80449963 -3.699248    0.89030009  5.03509595\n",
            "  4.86139161  2.10569476]. \t  -453.8782510624534 \t -175.65656232870992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Aur-aRtdq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac38903-c289-4d7c-f8bd-ce06bbeb2fa5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 10\r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_loser_10 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_10 = dGPGO(surrogate_loser_10, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.57275736 -3.9423289   4.61089653 -0.18236005  3.81413924 -2.94571335\n",
            " -4.70313344 -1.05272872]. \t  -385.9754059539706 \t -352.16802530271787\n",
            "init   \t [-2.7327263   3.49942502 -2.99947679  2.48288802 -1.10434173 -3.25369324\n",
            "  2.49384361 -4.40747949]. \t  -352.16802530271787 \t -352.16802530271787\n",
            "init   \t [ 3.94585297  4.63507865  4.41490877 -0.86598704 -4.82322781  4.93596144\n",
            " -1.64211012  2.11647687]. \t  -437.2230551014739 \t -352.16802530271787\n",
            "init   \t [-1.41437883 -4.7605156   3.63579651  1.61027592  2.72059386  0.55385332\n",
            "  3.94335167  4.13898358]. \t  -382.1028014270721 \t -352.16802530271787\n",
            "init   \t [-5.01328179 -4.35653902 -2.61499689 -3.75495933  2.02675303 -1.04238199\n",
            "  3.92317124 -3.26648309]. \t  -360.16156644546146 \t -352.16802530271787\n",
            "1      \t [-0.69120848 -4.9342136   1.9603237  -0.31036772 -3.80700478  4.00729141\n",
            "  4.28240511 -4.37124102]. \t  -511.13628956580146 \t -352.16802530271787\n",
            "2      \t [-3.86842882  1.46678813  4.99960309 -2.4831348   2.4968462   3.15039041\n",
            "  5.02108701 -1.33889878]. \t  -400.46096949127036 \t -352.16802530271787\n",
            "3      \t [ 5.08639972  0.59547281 -4.35771525 -0.91677037 -3.63032957  1.36330471\n",
            "  0.06774278 -0.91962543]. \t  \u001b[92m-170.7574293822782\u001b[0m \t -170.7574293822782\n",
            "4      \t [-2.83991747  4.95529941  0.81210737 -5.05728904 -2.46957144  3.87928032\n",
            "  0.68677571  3.8274095 ]. \t  -402.7393046428011 \t -170.7574293822782\n",
            "5      \t [-4.78297483  0.9384769  -3.4383774   1.8608363   1.81977827  2.42169935\n",
            " -0.95936305  2.02437623]. \t  \u001b[92m-164.9296567609566\u001b[0m \t -164.9296567609566\n",
            "6      \t [ 0.12341074  4.54186746  3.11452712  2.81407137  1.9287183   1.45984277\n",
            " -4.13199064  3.21849354]. \t  -335.81882752614865 \t -164.9296567609566\n",
            "7      \t [-4.20538034  4.05601237 -1.05842507 -1.02069306  0.01430092 -4.79109053\n",
            " -3.54033371  4.116951  ]. \t  -419.1760821638135 \t -164.9296567609566\n",
            "8      \t [-0.91570811  5.08597627 -1.60534636 -2.0596013   1.48205846  0.4870594\n",
            " -2.64369806 -2.85935751]. \t  -204.00929831470415 \t -164.9296567609566\n",
            "9      \t [ 0.44337387 -2.12434014  1.33594503 -3.46985162 -2.48584606  1.69932882\n",
            " -4.18127858 -4.91228807]. \t  -426.38564089718784 \t -164.9296567609566\n",
            "10     \t [-0.65116081 -1.60635209 -4.70549384 -3.22611311 -0.03412151 -2.98445577\n",
            " -3.93598434  0.31416276]. \t  -276.3220583911353 \t -164.9296567609566\n",
            "11     \t [ 1.42052082  1.29703507 -3.81453734 -3.5177973   1.73163558  2.21093581\n",
            "  2.05625557  4.63066838]. \t  -343.9984138154799 \t -164.9296567609566\n",
            "12     \t [-1.60941423 -2.82491091 -0.98142108 -0.01883512 -3.65427762 -4.17298134\n",
            "  3.47763998  4.68649525]. \t  -453.0565633245601 \t -164.9296567609566\n",
            "13     \t [ 2.99380686 -1.50053952 -2.7035087  -4.29804816  4.31467208  1.10011192\n",
            "  4.62027106 -2.66535793]. \t  -415.89071625609967 \t -164.9296567609566\n",
            "14     \t [ 2.02806307 -4.78319908  0.68412069  4.6111561  -3.13484279  4.8311571\n",
            " -3.01463496 -1.11576249]. \t  -399.07837772597856 \t -164.9296567609566\n",
            "15     \t [-1.99262461 -2.08960012  3.25436987 -1.79854657 -4.70001473 -3.87339678\n",
            " -3.54777849  2.39136055]. \t  -391.74113438840425 \t -164.9296567609566\n",
            "16     \t [ 1.74285833 -3.58288483 -1.67449356  3.94202292  4.67125838  4.57693891\n",
            " -1.66537555 -5.03651194]. \t  -556.4210907963367 \t -164.9296567609566\n",
            "17     \t [ 1.91504342  4.39092188  0.28741722  4.53015261  0.58630604 -1.11371379\n",
            "  4.72409298  1.56795205]. \t  -309.61283245614425 \t -164.9296567609566\n",
            "18     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -164.9296567609566\n",
            "19     \t [-3.28986647  3.10911714 -3.26390187  2.60047567 -4.52223851  3.7419\n",
            "  4.49561109  2.67039795]. \t  -473.95143567504294 \t -164.9296567609566\n",
            "20     \t [-2.69188145  4.27423623  4.45650448  1.33998599 -4.74747398 -2.22928774\n",
            " -3.25792358 -2.97792105]. \t  -398.30142386704057 \t -164.9296567609566\n",
            "21     \t [-0.74999857  4.56913275  2.81802739 -4.87014588  4.24577422 -0.87689028\n",
            "  0.52922959  3.68742668]. \t  -366.49768909696553 \t -164.9296567609566\n",
            "22     \t [ 3.23194654 -3.74126463 -0.34501769  4.88418946  1.41302239 -1.10846456\n",
            " -1.45233236  3.10603409]. \t  -243.51772956650711 \t -164.9296567609566\n",
            "23     \t [-4.74432089 -2.60738194  1.1748746   2.46250407  1.42620077 -4.88127701\n",
            "  1.00603728 -0.81798933]. \t  -230.0712224150592 \t -164.9296567609566\n",
            "24     \t [ 3.77755537 -4.19561354 -2.55604946  2.78570997 -2.02274327 -5.08893234\n",
            "  4.60915514 -3.56419073]. \t  -526.2958250274548 \t -164.9296567609566\n",
            "25     \t [ 4.9712413  -1.16638858  4.43599367  2.39421648 -2.72681507  1.41182924\n",
            "  3.65407669  0.96408155]. \t  -259.4361086548463 \t -164.9296567609566\n",
            "26     \t [ 3.73939414  0.20456631  1.08307937 -2.3238558  -1.12109962 -4.54351089\n",
            "  0.21174279 -4.48071971]. \t  -330.2610760317743 \t -164.9296567609566\n",
            "27     \t [ 3.19225917 -5.00474448  3.51592727  3.11211588  4.34287793 -3.89939365\n",
            "  2.653807   -3.6056679 ]. \t  -474.9518860303458 \t -164.9296567609566\n",
            "28     \t [-4.56000519 -4.79898054 -0.89750564  1.61955305 -4.79183665  2.75269966\n",
            " -4.22367396  4.36725213]. \t  -517.4941394071767 \t -164.9296567609566\n",
            "29     \t [ 1.78467075 -3.74457715 -4.63029271  2.95238565  4.30881267  3.67790078\n",
            "  3.5189734   3.70886495]. \t  -501.1326298439502 \t -164.9296567609566\n",
            "30     \t [ 3.00004406  1.99933581  3.67365671 -4.21466616  0.23611045  3.85742467\n",
            "  1.92087046 -4.53796333]. \t  -408.666040188667 \t -164.9296567609566\n",
            "31     \t [ 3.7886124   1.74411675  2.56836952  3.03186856  0.56925454  3.61086139\n",
            " -4.58568272 -5.04040046]. \t  -507.2906136391273 \t -164.9296567609566\n",
            "32     \t [-3.96380958 -3.52805202 -4.9443913   4.08614082 -1.96712467  4.72790195\n",
            " -0.78515986 -4.10835311]. \t  -473.54338444402185 \t -164.9296567609566\n",
            "33     \t [ 1.95501753  5.04494152 -4.2516212   4.56701904  1.3606753  -4.47485635\n",
            " -1.65925342  4.20316154]. \t  -482.39207469922826 \t -164.9296567609566\n",
            "34     \t [ 5.01830868  1.61380025  1.25435128  2.69172909 -4.34279457 -1.37050802\n",
            " -2.22509129  4.78957914]. \t  -387.8407799399921 \t -164.9296567609566\n",
            "35     \t [ 0.40343795 -4.91016615 -2.20275049  3.06424478 -3.61668931 -3.85600857\n",
            " -4.9946751  -3.52733295]. \t  -529.276036626093 \t -164.9296567609566\n",
            "36     \t [-2.06285692  4.02920248 -2.7925518  -3.06083195 -4.76765896  4.7805904\n",
            "  3.03606969 -3.66136967]. \t  -520.1403135585301 \t -164.9296567609566\n",
            "37     \t [ 4.01139259 -0.96217271  3.01491578 -3.5676155   0.66311124 -3.65098409\n",
            "  4.60728893  2.55431008]. \t  -379.0859663500136 \t -164.9296567609566\n",
            "38     \t [ 0.50571972  4.3670331  -0.12078505  4.05226057  1.02718992 -4.9311036\n",
            " -4.77285042 -4.32381862]. \t  -564.318998041207 \t -164.9296567609566\n",
            "39     \t [ 4.58718608 -0.91988951  4.86713593  5.06075614 -4.32873737 -4.34145707\n",
            "  1.29430588 -4.09500938]. \t  -548.9054589497778 \t -164.9296567609566\n",
            "40     \t [-4.66830995 -3.21814131  2.66487204 -0.99010415  3.3318051   4.33986223\n",
            " -3.40501789 -0.71749223]. \t  -321.52027825766896 \t -164.9296567609566\n",
            "41     \t [ 4.14013026  0.48979685 -5.08780122  1.66391074  4.24270768  2.08662326\n",
            " -4.72017725  4.84453893]. \t  -566.1958339774443 \t -164.9296567609566\n",
            "42     \t [-4.97288499  4.09407438 -4.16220019 -0.98144936  0.65027037 -3.62468336\n",
            "  4.47057278  4.90484816]. \t  -527.3838428514438 \t -164.9296567609566\n",
            "43     \t [ 4.8602786  -4.29786527 -2.87190641 -4.31566735 -4.47827253 -4.03284941\n",
            " -0.09682835  3.48748381]. \t  -455.0329255526204 \t -164.9296567609566\n",
            "44     \t [-3.64698256  0.56690283  4.79185484  3.60573525 -0.34742397  3.0579379\n",
            "  1.06892692 -5.09536704]. \t  -407.2439420821917 \t -164.9296567609566\n",
            "45     \t [-0.78922005  4.77614772  3.37828843 -4.84461839 -4.69614351 -4.7867719\n",
            "  1.78774744  1.42368443]. \t  -460.701086057514 \t -164.9296567609566\n",
            "46     \t [-3.79382008 -3.51279097 -4.51236892 -4.13047788 -3.64617855  3.56900135\n",
            " -4.92058571 -1.13026336]. \t  -491.0051039211172 \t -164.9296567609566\n",
            "47     \t [-1.93433162  4.87134992 -4.60131636  4.08599251 -4.6663398   0.55488158\n",
            " -3.52156616  0.01652506]. \t  -379.03259385746844 \t -164.9296567609566\n",
            "48     \t [ 4.70159964 -3.70014541  5.065524   -4.34484637  1.8215861   4.93289159\n",
            "  2.77427167  3.71495239]. \t  -528.8510009808648 \t -164.9296567609566\n",
            "49     \t [ 4.18525776 -3.8182224  -1.05323788 -5.06156923  4.37743139  0.84148478\n",
            " -5.09233623  1.19187424]. \t  -445.4257291124625 \t -164.9296567609566\n",
            "50     \t [ 2.24429408  4.56257702 -4.54984175 -1.70256298 -4.02449888  4.77606897\n",
            " -4.13870299  4.08685305]. \t  -591.7380815505364 \t -164.9296567609566\n",
            "51     \t [ 0.12002096 -4.65765328 -1.74889937 -3.61881159  3.90790034 -4.44213519\n",
            "  1.28290065  1.62134139]. \t  -332.26564709434564 \t -164.9296567609566\n",
            "52     \t [-2.83535768 -1.52017641  3.75679825  1.59801881 -4.92813529 -4.54141413\n",
            "  4.78296137 -4.51357878]. \t  -633.5118062770609 \t -164.9296567609566\n",
            "53     \t [-2.19250156  4.4192478   4.39757247 -2.56358594 -1.05084538  4.88244658\n",
            " -4.25104821 -4.91103012]. \t  -596.1670859393462 \t -164.9296567609566\n",
            "54     \t [ 2.54177346  4.68327837 -2.22650556  1.97892932  4.00503065  4.07986562\n",
            "  3.39229957 -4.96196872]. \t  -538.4595471317298 \t -164.9296567609566\n",
            "55     \t [-4.04952141  0.6314348   4.54533072 -3.6380375   2.11583549 -2.13978734\n",
            " -2.51249727 -3.61511616]. \t  -330.71435971675083 \t -164.9296567609566\n",
            "56     \t [-1.67747922 -4.60329892  1.84726459  4.73676407  3.31202317  4.21433318\n",
            " -4.22328151  4.54043983]. \t  -596.3681629941359 \t -164.9296567609566\n",
            "57     \t [-4.99418608 -4.93518269 -4.53590799  3.82462307  2.45854959 -1.7302887\n",
            " -4.2726901  -4.23844027]. \t  -513.580197488156 \t -164.9296567609566\n",
            "58     \t [-4.49443427 -4.84973788 -0.45062436 -3.85281247  0.50226704  3.86113561\n",
            "  1.7740285   5.00113037]. \t  -440.0579463090262 \t -164.9296567609566\n",
            "59     \t [ 0.74570396 -4.48131008  0.17974843  1.37462165 -5.05250997  3.59365916\n",
            "  3.25941567  4.00352951]. \t  -456.0937456626276 \t -164.9296567609566\n",
            "60     \t [ 3.51664278  5.00398539 -4.3648564   0.13761564  1.36181689 -5.11229729\n",
            "  3.21019339 -0.69541746]. \t  -361.77064456647315 \t -164.9296567609566\n",
            "61     \t [ 4.73262381  3.95897614  1.1625609  -3.21011372  2.00248015  2.77219621\n",
            " -3.19674337  1.02699326]. \t  -245.15063943073943 \t -164.9296567609566\n",
            "62     \t [-4.73443386  3.76342656  4.95573347  2.95964527 -1.10430115  0.3591647\n",
            "  3.77861038  3.54658025]. \t  -366.90003325777525 \t -164.9296567609566\n",
            "63     \t [ 5.10131314  4.10417407 -1.7819537   3.6125857  -4.39207839 -2.58577794\n",
            "  5.04711469 -4.55113482]. \t  -602.0265047890817 \t -164.9296567609566\n",
            "64     \t [ 4.71510634 -3.74424238 -4.26015977 -3.98239918  2.2535702   3.68676972\n",
            " -2.07354688 -4.3918734 ]. \t  -459.50793731857175 \t -164.9296567609566\n",
            "65     \t [-1.39370591 -4.75275483  0.06105716 -4.98927847  3.32611169 -4.2360773\n",
            " -4.86941385 -4.46489937]. \t  -635.144705835031 \t -164.9296567609566\n",
            "66     \t [ 4.05386776 -0.73057196 -4.61742528  4.0138486  -4.72746849  4.97456477\n",
            "  3.63417102 -4.44446144]. \t  -656.6059376812042 \t -164.9296567609566\n",
            "67     \t [-1.27069071 -1.63297419  4.60226039 -4.6357832  -4.08505429  0.53041154\n",
            "  4.67431281  1.16039505]. \t  -405.2951061421491 \t -164.9296567609566\n",
            "68     \t [ 5.08872416  4.90081005 -4.50424174 -4.70202633  2.2433538  -5.08306735\n",
            " -4.40224188 -3.81702369]. \t  -655.6358959961112 \t -164.9296567609566\n",
            "69     \t [-4.91733131  2.50486023 -2.27758841 -1.4776716   3.60315304  3.89016787\n",
            "  2.0138935  -4.6296553 ]. \t  -416.59910749902076 \t -164.9296567609566\n",
            "70     \t [ 4.11248591  4.71319727  2.00601901 -5.04774536 -4.66146735  1.36287264\n",
            "  4.64715555  0.49544858]. \t  -448.25932423144013 \t -164.9296567609566\n",
            "71     \t [-4.55792062  4.44149134  2.85712451  2.325759    4.77044567 -4.8440629\n",
            "  3.65058167  5.04923737]. \t  -658.1754733618596 \t -164.9296567609566\n",
            "72     \t [-0.12073686 -2.58615889  3.04277198 -4.68580671 -4.31333432  4.64958135\n",
            " -2.00366813  3.22680236]. \t  -463.1302701578304 \t -164.9296567609566\n",
            "73     \t [-0.7776191   4.59899902  4.17257247 -0.26311106  0.92335314 -4.86137502\n",
            "  3.60700084 -4.04755804]. \t  -463.6099698647851 \t -164.9296567609566\n",
            "74     \t [-4.92608198 -1.58101527  5.05852303 -0.69382425  3.1092836  -1.56917232\n",
            " -3.11696062  4.5508084 ]. \t  -404.7560304563507 \t -164.9296567609566\n",
            "75     \t [-2.51768383  1.36664952 -4.29659027  1.5117285  -3.23172711 -5.12\n",
            " -5.12       -5.12      ]. \t  -677.3202504788655 \t -164.9296567609566\n",
            "76     \t [ 5.10393082 -0.44440164  1.10414524 -1.60415468  1.31277324 -3.70785204\n",
            " -4.15484407  4.14025501]. \t  -389.47441975435015 \t -164.9296567609566\n",
            "77     \t [-5.12       -5.12        1.39184025 -2.87397273 -5.12       -5.12\n",
            "  0.15903238 -5.12      ]. \t  -615.7443740226106 \t -164.9296567609566\n",
            "78     \t [-0.1301514  -2.94864323 -4.81891753 -3.73145216 -2.66973257  3.21189364\n",
            "  4.94701531  0.79248819]. \t  -416.636720251597 \t -164.9296567609566\n",
            "79     \t [1.57345734 2.37757458 4.98090192 1.5484961  4.39892363 5.03075243\n",
            " 4.31323313 3.64115111]. \t  -582.696179613979 \t -164.9296567609566\n",
            "80     \t [-0.21733048 -2.47376619 -4.76833984  4.9652401   3.41200917 -0.18195604\n",
            "  2.50749215 -2.41372938]. \t  -328.14091770427007 \t -164.9296567609566\n",
            "81     \t [ 1.10509591 -3.53540926 -2.99204416 -5.00520915 -1.16229069  2.39711203\n",
            " -4.76807561  4.90126339]. \t  -545.8372865401344 \t -164.9296567609566\n",
            "82     \t [-4.35061169 -4.80734966 -5.07560401  4.41783998  1.58470777 -2.27432094\n",
            " -0.72113279  4.39839469]. \t  -422.5024946036061 \t -164.9296567609566\n",
            "83     \t [-5.09382952  5.11570076 -1.68074362  4.68393664  0.89349071  4.52196354\n",
            "  4.54490528 -2.08250374]. \t  -480.48791154508234 \t -164.9296567609566\n",
            "84     \t [ 4.55696825 -2.06920744  3.66961325  2.22440303  4.44845546  4.95054624\n",
            "  3.1538199  -4.60266415]. \t  -574.6126844674598 \t -164.9296567609566\n",
            "85     \t [-4.575967   -3.37800052  4.71944532  4.91242903 -3.0692675  -1.27375191\n",
            " -4.90935327 -4.61616513]. \t  -603.1293465657444 \t -164.9296567609566\n",
            "86     \t [-4.86497556  3.66455743  1.89174512 -4.78939837  2.72948255 -4.93757678\n",
            "  4.858316    0.86853342]. \t  -507.80119998281685 \t -164.9296567609566\n",
            "87     \t [ 1.36028945  2.83575425  3.74323117 -3.42619918 -0.90654452 -3.50740705\n",
            " -4.7852403  -0.7437341 ]. \t  -349.5594301932032 \t -164.9296567609566\n",
            "88     \t [ 4.43044843 -1.54021288 -4.32512478  0.43155879  4.66187314 -3.13514155\n",
            " -4.39875683 -4.3983716 ]. \t  -539.0872638836513 \t -164.9296567609566\n",
            "89     \t [-3.00721135 -3.92100198 -2.43377887  4.91445965 -4.08012234 -3.28503946\n",
            "  1.87796921 -4.60153656]. \t  -496.23571155323145 \t -164.9296567609566\n",
            "90     \t [ 1.26090574  4.51186256  2.05067098  2.6415075  -4.39393056  4.04852659\n",
            "  3.47830052 -3.49274851]. \t  -459.99058549261247 \t -164.9296567609566\n",
            "91     \t [-0.40471885 -3.36212816 -4.54524323 -1.6547675  -4.9890206  -4.25542541\n",
            "  1.13492281 -1.89991074]. \t  -366.69947905759636 \t -164.9296567609566\n",
            "92     \t [ 4.66116267 -4.97941518  4.07509121 -3.86547238 -4.42242397 -2.52943742\n",
            " -4.47672536 -0.87822785]. \t  -463.5374545884846 \t -164.9296567609566\n",
            "93     \t [ 0.86230613 -3.21595501 -4.76973083  4.18408254 -4.92454978  0.26849213\n",
            " -2.03161193  4.33771934]. \t  -460.812571118098 \t -164.9296567609566\n",
            "94     \t [-4.58115359 -0.65224914  4.47159564  2.8868637  -4.57559879  4.94849607\n",
            " -0.06073123  3.17498758]. \t  -447.4356451477212 \t -164.9296567609566\n",
            "95     \t [ 4.04476912  0.56396418  4.10318437 -3.58218461  4.89654373 -4.09472281\n",
            "  4.90047942 -4.71229518]. \t  -685.0627490485396 \t -164.9296567609566\n",
            "96     \t [-0.0138998   2.07633557 -4.86896933 -3.78495926  4.95007692 -1.95644341\n",
            " -3.56381831  4.81998321]. \t  -557.2926294819166 \t -164.9296567609566\n",
            "97     \t [ 4.27194214  3.54929062 -4.7321856   5.01530692 -4.98294837 -4.29138231\n",
            "  3.19864322  4.28335751]. \t  -664.2794596548159 \t -164.9296567609566\n",
            "98     \t [-3.91621882  3.25071184 -2.6618189  -4.82444735 -4.96688485 -2.4819023\n",
            " -1.76635195 -0.42176429]. \t  -334.39986799938714 \t -164.9296567609566\n",
            "99     \t [ 1.98568367 -2.37888949  3.37160058  0.97417584  4.96292241 -4.49372534\n",
            " -0.01235119  5.07386095]. \t  -503.4283014785846 \t -164.9296567609566\n",
            "100    \t [-4.11023395  2.235725   -4.71188101 -1.04161491  3.51292698 -3.67805363\n",
            " -2.64240959 -4.54763912]. \t  -455.032492123029 \t -164.9296567609566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMu7U9NNtdtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e59b24-c0ac-4cab-fc28-a7703af02015"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 11\r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_loser_11 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_11 = dGPGO(surrogate_loser_11, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.92580518  3.28957798  1.4939506  -0.78143474 -3.04833558 -0.08287467\n",
            " -3.70116269 -0.4861846 ]. \t  -199.328627991057 \t -199.328627991057\n",
            "init   \t [-3.95535741 -5.09005324  0.23988403 -3.17469533 -3.66878933 -1.68072836\n",
            "  0.85700801  4.66360642]. \t  -371.33373135563875 \t -199.328627991057\n",
            "init   \t [ 4.97602467 -3.51277821  1.50799121 -0.08432225  3.26374507  1.8591538\n",
            "  1.97393801 -3.23583363]. \t  -241.32944618066992 \t -199.328627991057\n",
            "init   \t [ 3.9633366   0.66475842  1.73406641 -4.83201623 -0.61553705  4.24424807\n",
            " -3.088857    4.67305641]. \t  -470.469518894517 \t -199.328627991057\n",
            "init   \t [-2.63594969  1.40305335 -1.97175977  1.69687477 -1.50561156  4.86926807\n",
            " -1.76401693  2.83643699]. \t  -273.80464224498314 \t -199.328627991057\n",
            "1      \t [ 2.27211609  2.02425273 -1.2017534   4.16140797 -1.81853031 -4.31745003\n",
            "  2.0394904   3.25603062]. \t  -329.2676500747198 \t -199.328627991057\n",
            "2      \t [ 0.91195965  4.40131628  0.25601848  2.01131675  4.61880194 -3.48112843\n",
            "  3.42075462 -3.42959209]. \t  -411.3369948951634 \t -199.328627991057\n",
            "3      \t [ 3.4506638  -2.28972411 -4.72154565 -2.03612565 -4.39132286 -1.00741573\n",
            "  4.50346009  0.21594287]. \t  -350.70398565509174 \t -199.328627991057\n",
            "4      \t [-3.38138851 -5.02243145  1.53786308  2.1320223   4.42505211 -2.72288588\n",
            " -1.18446707 -2.93627121]. \t  -308.3448893098524 \t -199.328627991057\n",
            "5      \t [-0.10747918  2.37788089 -4.82420832  1.36302762  4.46107597 -2.00232408\n",
            " -4.31877147  4.4681394 ]. \t  -502.4089925694798 \t -199.328627991057\n",
            "6      \t [-4.68089968 -1.55369369 -3.77643376  4.20342398  1.64474619  2.87231187\n",
            "  1.06318932 -2.79587634]. \t  -273.6731982115635 \t -199.328627991057\n",
            "7      \t [ 3.11322085 -4.48047435 -3.83272114  3.76752102 -3.36685429  4.28679607\n",
            "  1.56134023 -1.11226498]. \t  -344.58737025711645 \t -199.328627991057\n",
            "8      \t [-3.33910255  0.1879076   4.14514181 -4.35915362  1.98010538  4.94389058\n",
            " -5.04313587 -0.54675167]. \t  -485.45615371360304 \t -199.328627991057\n",
            "9      \t [-2.72335001  1.80846448  4.68225647 -0.71121565 -2.78382979 -3.6860239\n",
            " -3.2612813  -2.13435768]. \t  -312.9163374954662 \t -199.328627991057\n",
            "10     \t [-4.32661955  1.33169156  4.91442928  3.31861383 -4.59670139  4.74890091\n",
            "  0.53763197 -3.66295502]. \t  -489.09600808544707 \t -199.328627991057\n",
            "11     \t [ 2.73014082 -4.33539565  1.53521602  0.37490252  1.11809835 -3.89108725\n",
            "  4.53185729  2.81630051]. \t  -356.9884333775324 \t -199.328627991057\n",
            "12     \t [ 0.39771306  4.39811339  4.38376536 -2.10001545  1.35799499 -1.02498673\n",
            "  2.76745678  2.56230497]. \t  -235.79674648457183 \t -199.328627991057\n",
            "13     \t [ 0.20475016 -3.14437524  0.86111427  4.63800503 -4.54627501  1.16215327\n",
            " -4.2603917  -4.77747914]. \t  -529.1827311637971 \t -199.328627991057\n",
            "14     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -199.328627991057\n",
            "15     \t [ 4.70162927  5.06830333  2.62406035  0.94371355 -4.15332766  4.33644674\n",
            "  4.84130568 -4.04657921]. \t  -591.8455608576407 \t -199.328627991057\n",
            "16     \t [-0.75501182  2.48474844 -4.39096584  0.49099478 -2.94496989 -4.60948524\n",
            " -4.45246272 -2.49695418]. \t  -431.2216140122552 \t -199.328627991057\n",
            "17     \t [ 3.10906224 -2.32268673  3.77447827 -4.93681369 -3.81599142  0.17154071\n",
            "  2.32171698  0.81884469]. \t  -276.76674256138216 \t -199.328627991057\n",
            "18     \t [-4.42150285 -3.71026662 -4.12703005 -2.00737679 -4.72365545  2.40941386\n",
            "  2.81646552 -3.88113933]. \t  -436.7267622590048 \t -199.328627991057\n",
            "19     \t [-2.16676392  3.17464234 -4.59474313 -2.12477327  4.16809712  1.99095939\n",
            " -1.374751   -1.63825799]. \t  -251.594593003222 \t -199.328627991057\n",
            "20     \t [ 0.58068745  1.49492322  3.40703585  4.96159875  3.90126186 -0.96404033\n",
            " -4.61008247  1.43700838]. \t  -385.0657478697283 \t -199.328627991057\n",
            "21     \t [ 0.33111923 -2.63411052 -2.52915776 -5.10677829  1.00390686 -1.68168367\n",
            " -2.58888188  1.2018014 ]. \t  -217.9716542711628 \t -199.328627991057\n",
            "22     \t [ 4.17109659  3.09124011 -4.27464474  4.46764442  4.36249458  2.26920503\n",
            "  4.06423703  4.81605764]. \t  -598.4007185191645 \t -199.328627991057\n",
            "23     \t [ 5.09827643 -4.84625138  1.17712716  5.11277683 -1.29107671 -2.6608193\n",
            " -4.2980034   0.98988251]. \t  -369.64648347859026 \t -199.328627991057\n",
            "24     \t [-1.12886035 -4.27177426 -4.61840712 -4.12460173  5.08834478  4.99098554\n",
            " -0.44925863  3.16854203]. \t  -530.4548324657435 \t -199.328627991057\n",
            "25     \t [-1.50892764 -4.76916303 -3.51952957 -3.14992723  3.65441859  3.28455813\n",
            "  3.67218108 -5.02737727]. \t  -552.710510242246 \t -199.328627991057\n",
            "26     \t [ 1.37503239  4.95494644 -4.01076459 -4.49289161 -2.63853009  2.56794199\n",
            "  4.06042182 -0.85967241]. \t  -375.6933328819776 \t -199.328627991057\n",
            "27     \t [-5.05392985  2.11875326  4.50970929  4.62875134 -1.47122248  0.08459035\n",
            "  4.47105378  3.29299213]. \t  -418.7822687603419 \t -199.328627991057\n",
            "28     \t [ 2.6755183  -1.98647734 -1.74041653  4.79612643  4.03395413  4.7603749\n",
            " -1.94362367  2.01321538]. \t  -392.34799147758844 \t -199.328627991057\n",
            "29     \t [ 4.70754776 -4.53131077  3.32266977 -2.69963304 -3.55508263  4.97079414\n",
            " -1.81424267 -4.63570823]. \t  -531.9035279327605 \t -199.328627991057\n",
            "30     \t [-4.48063227  2.25979029 -4.94838719 -2.28817635 -4.16850886 -4.01986049\n",
            "  3.81549318 -4.75776111]. \t  -591.5262249988972 \t -199.328627991057\n",
            "31     \t [-3.73022874 -5.08821378 -3.55211942  4.72320692  2.43630643  3.44280007\n",
            "  3.51794071  4.80476935]. \t  -564.8948321306123 \t -199.328627991057\n",
            "32     \t [ 5.02765887  3.52536108 -3.73223507  4.14542379  2.28002402 -0.93210256\n",
            " -4.22900598 -4.07770956]. \t  -450.0791861534374 \t -199.328627991057\n",
            "33     \t [ 4.00582262  2.77306602 -3.41056683 -3.90677883  3.37979767 -3.90067082\n",
            " -1.67388254 -3.50379771]. \t  -393.6065120823698 \t -199.328627991057\n",
            "34     \t [-5.03700585  1.5746022  -0.27688172  0.53862893  2.27847491 -4.71823776\n",
            "  4.04099057  4.35829649]. \t  -457.51371152380773 \t -199.328627991057\n",
            "35     \t [-4.66805003  4.42539114  0.66936174 -1.67535896 -4.08558839  3.71451126\n",
            "  4.30202257  4.72022216]. \t  -547.5718019602925 \t -199.328627991057\n",
            "36     \t [-3.54870486  4.13637987  0.75240891 -4.978745    2.24861199  4.30183147\n",
            "  4.99689592 -1.48949542]. \t  -476.5099063361178 \t -199.328627991057\n",
            "37     \t [-3.8356487  -4.97812246  2.19809002 -4.052489   -1.16616292 -3.26998652\n",
            "  1.33616451 -4.58812768]. \t  -396.32230009024636 \t -199.328627991057\n",
            "38     \t [-4.29853795 -1.9859553   2.57301425 -1.49928897  3.11935808  4.30179609\n",
            "  3.10554289  4.68744847]. \t  -458.1909753391132 \t -199.328627991057\n",
            "39     \t [-4.88543937  3.14589007 -4.56851771 -1.44153714 -4.03278711 -1.97009944\n",
            " -1.35118475  3.62691797]. \t  -337.2077293017051 \t -199.328627991057\n",
            "40     \t [ 4.87969869 -0.50753287  4.6302514   5.02477134  1.84698656  4.43931\n",
            " -4.34477522 -5.11022416]. \t  -665.9938968721807 \t -199.328627991057\n",
            "41     \t [ 3.79245062  3.99604341 -2.67350106 -5.07589004 -4.86809403 -3.37731489\n",
            " -2.83953983  5.10783848]. \t  -622.9111189794868 \t -199.328627991057\n",
            "42     \t [-3.66166961 -5.12       -4.7638621  -0.38390239  0.13536143 -0.19013504\n",
            " -5.12       -5.12      ]. \t  -528.0338164312703 \t -199.328627991057\n",
            "43     \t [ 5.09277052  3.88384573  5.10662016  1.13952775 -3.36595953 -4.20474107\n",
            "  2.94153392 -1.4007135 ]. \t  -378.52347112819325 \t -199.328627991057\n",
            "44     \t [-1.62853868  2.39223911  0.72334824  4.23987302 -4.26769663 -3.26874532\n",
            "  3.57204591 -3.67028793]. \t  -439.83258513714236 \t -199.328627991057\n",
            "45     \t [ 3.43886988  3.11265643  2.77516174  0.33253253 -2.9192395   5.02823799\n",
            "  4.39631649  4.91305537]. \t  -577.4569208308797 \t -199.328627991057\n",
            "46     \t [ 4.58999125  4.26374237  4.50392723 -0.88947155  4.16012254  0.54234553\n",
            " -4.97420636 -4.15419618]. \t  -521.0035368216272 \t -199.328627991057\n",
            "47     \t [-4.43996599 -3.82300484  4.70161496  2.11441558  1.59419962 -2.87225212\n",
            " -4.42196114  3.84351206]. \t  -450.405810209528 \t -199.328627991057\n",
            "48     \t [ 3.51589433 -3.49046669  3.78808846 -0.90335169  0.95174465 -4.99007236\n",
            " -4.34771931 -3.37277514]. \t  -460.29881026977415 \t -199.328627991057\n",
            "49     \t [-3.72102409 -2.43409768 -0.5408895   4.49491355 -4.46229696 -4.96290126\n",
            " -1.91898951  2.51049655]. \t  -430.93155180392847 \t -199.328627991057\n",
            "50     \t [-4.4498693  -0.35226651  3.21354475  4.28681883  2.69880241  0.84466025\n",
            "  4.6632058  -5.05807284]. \t  -522.126995905093 \t -199.328627991057\n",
            "51     \t [ 1.96451356  2.92953139 -4.17235828 -3.97053073 -4.40617782  3.24065859\n",
            " -4.63858778 -4.0733433 ]. \t  -579.7455043985258 \t -199.328627991057\n",
            "52     \t [-0.81385562 -1.84741528 -2.62982529 -3.15578413  4.37637084 -4.61422331\n",
            "  3.4449655  -4.0293236 ]. \t  -504.53963429129305 \t -199.328627991057\n",
            "53     \t [ 1.50055121 -5.02160583  2.81586618  4.57959069 -2.19397967 -4.38841475\n",
            "  1.74223415 -5.04236194]. \t  -524.630422651405 \t -199.328627991057\n",
            "54     \t [ 4.57889984  3.58902784 -4.76539099 -4.35821057  5.11871192  3.37767021\n",
            "  1.60358364  4.91653745]. \t  -601.6684984443574 \t -199.328627991057\n",
            "55     \t [ 2.99099976  4.97517336  3.78692968 -0.20493246 -0.27760963 -5.07985153\n",
            " -4.74438667  5.04107006]. \t  -617.7194956986906 \t -199.328627991057\n",
            "56     \t [ 0.29830474 -5.02138477  4.73660924  3.48400607 -4.64182109  0.70025609\n",
            " -2.32215111  4.45609003]. \t  -473.65246445512275 \t -199.328627991057\n",
            "57     \t [ 4.7591291  -4.29164018 -3.83274924  0.59784185  0.82451988  0.84716985\n",
            "  1.26814036  4.12264968]. \t  -259.91774927222707 \t -199.328627991057\n",
            "58     \t [-4.85131095 -3.20227627 -3.9708861   3.27122643 -5.03216794  0.83345155\n",
            "  3.75128008  2.38224303]. \t  -408.8386531919021 \t -199.328627991057\n",
            "59     \t [ 4.86049252 -2.88407583  4.72868963  4.5177395  -3.53501586  2.22565107\n",
            "  4.4558937  -3.91951126]. \t  -543.0698630399314 \t -199.328627991057\n",
            "60     \t [-2.44141255  4.82450578  4.95731789 -0.60232352  0.16393643  3.3598048\n",
            " -3.31583265  4.70452306]. \t  -449.57601062211813 \t -199.328627991057\n",
            "61     \t [ 3.96327713 -2.82099552 -4.9729425  -5.05055313  4.18105902  4.08161107\n",
            " -3.52304931 -2.19567528]. \t  -520.6610366823375 \t -199.328627991057\n",
            "62     \t [-2.41749475  2.70418783 -0.43855343  3.10096574  2.08239818  4.29418081\n",
            "  5.07493653  1.92989579]. \t  -401.91317708628105 \t -199.328627991057\n",
            "63     \t [ 4.26298322 -3.40775042 -4.73429139 -4.31178329 -4.09909803  4.47546595\n",
            " -3.12858469  3.30331435]. \t  -543.0081741816593 \t -199.328627991057\n",
            "64     \t [ 4.57026954  4.81315873 -1.67973714  1.78761816  2.48731997  4.81501442\n",
            " -0.32498515 -1.28481887]. \t  -272.45259286750763 \t -199.328627991057\n",
            "65     \t [-4.01111897 -1.89071159 -4.86689568  4.40511224  1.08873669 -4.97631715\n",
            "  4.82651859 -4.56674285]. \t  -656.335959152263 \t -199.328627991057\n",
            "66     \t [-2.69275217  2.62419831 -4.8342971  -4.39079418  2.73816442  2.60017717\n",
            "  4.73974265  4.65360586]. \t  -576.8090799549441 \t -199.328627991057\n",
            "67     \t [-3.6535286   3.06781182  2.45828933 -3.35539503 -3.49148733  3.81331162\n",
            " -3.3884564  -5.10810189]. \t  -532.6490603637776 \t -199.328627991057\n",
            "68     \t [-4.69786975  2.44662546  0.81801081 -2.93530213  2.68848079 -4.23691038\n",
            " -3.8870037   3.55618147]. \t  -421.2944517612834 \t -199.328627991057\n",
            "69     \t [-4.95529932  1.91863573  4.49417651 -4.96938841 -4.11310343 -4.91466597\n",
            "  1.08274455  3.18573443]. \t  -510.1987991035748 \t -199.328627991057\n",
            "70     \t [-4.78246302  4.12529791 -4.87301644  4.4478481   2.18747371 -0.78692443\n",
            "  0.30146455  4.7885161 ]. \t  -418.996360511293 \t -199.328627991057\n",
            "71     \t [-2.39611438 -1.74783099  4.58869734 -3.67783363  4.54242949 -4.96471987\n",
            "  2.3124593   0.68050637]. \t  -421.32143764565916 \t -199.328627991057\n",
            "72     \t [-4.03665559 -4.5874477   1.03994962  2.65818817  4.19031283  5.00161327\n",
            " -4.72002259  2.66857244]. \t  -540.7032276432004 \t -199.328627991057\n",
            "73     \t [ 3.85804169  3.78920071 -2.57437615 -2.80814037 -0.46187426 -4.88532472\n",
            "  4.46131827  4.88028893]. \t  -569.1517265105911 \t -199.328627991057\n",
            "74     \t [ 1.88827201 -4.68853263 -4.98573467  0.14870837 -4.80591589 -2.15451787\n",
            " -2.89120441 -2.75011915]. \t  -384.5458597220634 \t -199.328627991057\n",
            "75     \t [-4.66755778  2.06407444 -4.76595753  5.01315948 -4.5118081   3.98359934\n",
            " -3.052588   -3.399693  ]. \t  -553.6648259263906 \t -199.328627991057\n",
            "76     \t [-3.43083088  4.62732346 -3.25576651  4.65134526  3.97814331 -2.50399822\n",
            " -4.4466323  -3.5606772 ]. \t  -529.5182554193748 \t -199.328627991057\n",
            "77     \t [-3.55714183  3.97059924  4.21900669 -3.784008    0.5806806  -4.29785714\n",
            "  3.49525968 -4.02044395]. \t  -482.2045370588263 \t -199.328627991057\n",
            "78     \t [-1.2479536  -4.57073799  4.58994582 -2.84926314  1.00278578  4.95981268\n",
            "  2.35297867 -3.14152654]. \t  -409.35210936722615 \t -199.328627991057\n",
            "79     \t [ 4.2141017  -4.44374139  2.82893223 -1.59712967  2.20519773  4.25929854\n",
            "  1.55103357  5.0397645 ]. \t  -444.6621686604658 \t -199.328627991057\n",
            "80     \t [ 4.56025907 -3.24055407 -2.21281461  4.40861983  4.85757005 -4.63956528\n",
            "  1.14885107  0.5003506 ]. \t  -392.60685208467424 \t -199.328627991057\n",
            "81     \t [-2.6950374  -5.12        0.47850569 -1.48633337 -5.12       -0.52580466\n",
            " -5.12       -0.69141162]. \t  -389.27170069134337 \t -199.328627991057\n",
            "82     \t [ 1.62504885 -4.54464298  4.27566977 -2.93690301  0.58785046  0.2062236\n",
            " -4.45520045  4.15187038]. \t  -412.12290474753365 \t -199.328627991057\n",
            "83     \t [ 5.09517807  3.07308404 -4.7486721   4.05115988 -1.81849747  3.39199317\n",
            " -5.10224056  3.07658263]. \t  -521.6670444137867 \t -199.328627991057\n",
            "84     \t [ 3.2394747   2.30387982 -1.10780594 -4.9327917  -2.39703395 -4.56813511\n",
            "  2.41004417 -2.28551908]. \t  -358.5043380527987 \t -199.328627991057\n",
            "85     \t [ 3.20362232  2.61662464  0.61462298 -3.75327432  5.09026598  1.77085406\n",
            "  4.97081257 -4.27676526]. \t  -549.0963968154904 \t -199.328627991057\n",
            "86     \t [ 0.13845161 -1.42596392  1.8237473  -1.36513556 -5.01053714  0.53186998\n",
            "  4.36450109 -4.90943348]. \t  -474.90556917373976 \t -199.328627991057\n",
            "87     \t [ 4.02500314  4.91881731 -3.34469545  4.92060891 -1.16335306 -1.44533235\n",
            "  4.72999713 -4.49713758]. \t  -532.7056552247319 \t -199.328627991057\n",
            "88     \t [4.11080767 0.61624851 4.6075762  3.78110595 2.84568461 1.36559695\n",
            " 4.52078895 1.47510646]. \t  -350.6835644588938 \t -199.328627991057\n",
            "89     \t [ 4.12302356 -4.9075763  -2.54303137 -1.01909761 -3.72559156 -3.34306725\n",
            " -5.11276942  3.81818157]. \t  -524.7909156390481 \t -199.328627991057\n",
            "90     \t [ 2.85865196 -3.89969748 -2.9383378   3.99986476  4.77243265  1.82793487\n",
            " -4.37956574 -4.7299834 ]. \t  -575.6590896707996 \t -199.328627991057\n",
            "91     \t [ 5.05563461  0.34005688  2.29926957  0.5784583   3.17729095 -2.08261724\n",
            " -1.10186321  4.57561165]. \t  -295.477246393463 \t -199.328627991057\n",
            "92     \t [-4.58013801 -1.5039288  -2.26387171 -4.88754123  3.52293467 -4.74853\n",
            " -4.35727361 -3.75868024]. \t  -579.6976666117833 \t -199.328627991057\n",
            "93     \t [ 0.54882716  4.78111125 -3.83013317 -2.84173357  4.25576181  5.10526517\n",
            " -5.02556086  4.06306554]. \t  -678.1326042947521 \t -199.328627991057\n",
            "94     \t [ 4.64322397  2.17636967  4.42403321 -3.34882601  1.23081745  4.95892234\n",
            "  0.26706273 -1.1816803 ]. \t  -301.3976779121561 \t -199.328627991057\n",
            "95     \t [ 4.68734838 -4.33523693 -4.20076679 -2.95927829 -3.46982376  4.58766121\n",
            "  5.06890834  4.78903152]. \t  -697.342033003091 \t -199.328627991057\n",
            "96     \t [-1.8355062  -2.17414224  4.89962266  4.91542205 -3.15531936  4.97186678\n",
            "  3.71094177  3.69560541]. \t  -585.2418483579252 \t -199.328627991057\n",
            "97     \t [-1.11226165  2.15142168 -4.40432107  1.3952024  -4.64222232  3.24407368\n",
            "  4.40044056 -2.77549023]. \t  -444.5439804803216 \t -199.328627991057\n",
            "98     \t [-5.07116582  4.79806526  4.57435633  3.47890328  1.76679648  2.74329837\n",
            " -2.21495669 -3.83623858]. \t  -395.7828708321092 \t -199.328627991057\n",
            "99     \t [ 2.89411371  4.48566312  3.71667277  5.11826466  4.13674145 -5.10938603\n",
            " -2.8072336  -4.97227298]. \t  -689.9957579098605 \t -199.328627991057\n",
            "100    \t [ 1.72015807  1.68362142 -4.49200517  1.24536005 -3.30419123  3.03205972\n",
            "  5.00044417  4.9625242 ]. \t  -557.1591038649103 \t -199.328627991057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEjKllHqtdwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae140506-51e2-45b0-9337-5ac3e87d16ce"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 12\r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_loser_12 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_12 = dGPGO(surrogate_loser_12, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.15884083  1.25039382 -0.63766795  2.9220719   2.86695228 -2.32865172\n",
            " -2.28900603  3.0911711 ]. \t  -235.23146270653385 \t -119.61569010596395\n",
            "init   \t [ 4.69134698  3.84955018 -1.45595116  0.01019009  1.87866046  2.17806876\n",
            " -1.32863227  0.62664895]. \t  -119.61569010596395 \t -119.61569010596395\n",
            "init   \t [ 0.03157161 -4.97901108  2.79374461  3.91824579 -1.38356752  1.18165687\n",
            " -4.34809609 -1.34324218]. \t  -299.1328730459762 \t -119.61569010596395\n",
            "init   \t [ 4.43535464  1.55011219 -1.0526456   2.95659666 -1.87559811  0.6973302\n",
            "  3.77986447 -0.65358414]. \t  -186.70407348837227 \t -119.61569010596395\n",
            "init   \t [ 3.09399185 -3.64782772  2.09163234  2.0949126  -2.87956884  4.35064452\n",
            " -0.59247866  4.19139542]. \t  -364.893303476081 \t -119.61569010596395\n",
            "1      \t [-1.20506929 -4.56833346 -0.4951203   4.93572855 -3.85082675 -3.89753961\n",
            "  2.44247609  0.89398921]. \t  -354.81541396698753 \t -119.61569010596395\n",
            "2      \t [-2.38467024  3.09418413  4.09227155 -4.07974036 -0.4732923  -1.0852054\n",
            "  1.75762856  0.55084604]. \t  -173.89009841197802 \t -119.61569010596395\n",
            "3      \t [ 2.1739345  -2.49536672  4.13333698 -1.34769672 -1.32567707 -4.38533973\n",
            " -0.8338263   0.10596233]. \t  -204.82928530268254 \t -119.61569010596395\n",
            "4      \t [-4.28283748 -4.03035474  0.77209587 -4.45030519  4.58851259  3.16061079\n",
            "  2.08538216  3.90087255]. \t  -449.2246638075243 \t -119.61569010596395\n",
            "5      \t [-4.99777619  3.54079835 -4.03410463 -2.99367945  5.08636374  3.52706711\n",
            " -4.2657072  -5.00335179]. \t  -666.361473147168 \t -119.61569010596395\n",
            "6      \t [-4.53464654 -1.56248049 -0.41370416 -5.09190083 -3.88745964  5.07348747\n",
            "  3.98846791 -0.94528333]. \t  -478.1759603715879 \t -119.61569010596395\n",
            "7      \t [ 2.41797118 -4.07927895  5.00574416 -4.24357528  4.15780498 -0.50754755\n",
            "  4.66423605  3.35380286]. \t  -516.5837390836538 \t -119.61569010596395\n",
            "8      \t [-4.65113843 -4.83090942 -4.48180969  2.31592624 -3.86434763  3.05934343\n",
            "  0.93189694 -3.5509208 ]. \t  -387.7971101154641 \t -119.61569010596395\n",
            "9      \t [-3.3457227   2.99220584  4.07970672  5.04320906  3.9459153   2.27190385\n",
            " -1.71752197 -2.65150847]. \t  -366.481973301136 \t -119.61569010596395\n",
            "10     \t [-0.04881348  1.29047429 -3.30598216  4.56425483  1.87189603  1.96088007\n",
            " -2.11009969 -4.7629117 ]. \t  -372.6918189092081 \t -119.61569010596395\n",
            "11     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -119.61569010596395\n",
            "12     \t [-3.89115394  3.15385761 -2.35969335 -1.87583412 -4.04283193 -4.7513417\n",
            "  3.66066312  2.07645382]. \t  -411.2845897200651 \t -119.61569010596395\n",
            "13     \t [ 4.84174076 -1.19773913 -3.75090117  4.48049533  3.71926069 -2.9171414\n",
            " -2.01470603  1.29478388]. \t  -310.86653309339977 \t -119.61569010596395\n",
            "14     \t [ 1.8834428  -4.6809482   3.67236598 -1.12200019 -4.11002182  3.92939418\n",
            "  3.01146371 -4.32536341]. \t  -483.1190353889024 \t -119.61569010596395\n",
            "15     \t [ 4.60941179  2.39162672  0.46579179  4.74370039 -4.11531291 -4.28910187\n",
            " -3.76293416  4.82577056]. \t  -603.8276708088412 \t -119.61569010596395\n",
            "16     \t [-1.4481891  -0.42387069  2.361129   -3.06945072 -2.19770974  3.64165384\n",
            " -4.48783581 -3.2006355 ]. \t  -383.5242147972915 \t -119.61569010596395\n",
            "17     \t [ 4.86812743 -3.61332722 -3.22371878 -4.74041688 -1.86285629 -4.8707853\n",
            "  0.26677496  4.22036275]. \t  -473.5625696622485 \t -119.61569010596395\n",
            "18     \t [ 2.21465442 -1.54112163 -4.17252666 -1.82794977 -5.08650831 -0.85583905\n",
            " -3.69827473 -1.18580599]. \t  -315.9976794000959 \t -119.61569010596395\n",
            "19     \t [ 0.12386132 -1.71798756 -3.84469438 -3.69630312  3.28894266 -4.59050742\n",
            "  2.14167417 -0.72608498]. \t  -321.76119790737573 \t -119.61569010596395\n",
            "20     \t [-2.66960533 -0.27199601  3.61557266  0.07247849  4.28190583 -4.87567018\n",
            " -1.32953305 -5.00146254]. \t  -493.31003866766764 \t -119.61569010596395\n",
            "21     \t [ 3.60983689 -0.64498271 -4.81986754 -4.29906179 -3.91759121  4.41165747\n",
            "  4.55521982 -1.42885215]. \t  -512.5811009368408 \t -119.61569010596395\n",
            "22     \t [-3.20270292 -3.10286729 -4.17958828  3.23529211  1.66462091  4.55757442\n",
            " -2.96006343  3.08691997]. \t  -399.8383603757665 \t -119.61569010596395\n",
            "23     \t [ 0.00892258  3.45698498  3.43566616  2.6471631  -5.02308915 -3.83375341\n",
            "  1.80228951 -1.00409922]. \t  -332.4894344224326 \t -119.61569010596395\n",
            "24     \t [ 0.11130335  4.96719695 -5.10605507 -5.08875359  3.33974552  3.5274559\n",
            "  4.23351711 -2.89351758]. \t  -554.020920438892 \t -119.61569010596395\n",
            "25     \t [-4.57145227  4.48070001  1.96326245  3.29566182 -2.96404956  3.51332028\n",
            "  2.87913871  4.95573705]. \t  -488.5494475969441 \t -119.61569010596395\n",
            "26     \t [-4.49259941 -2.63914006  3.12745705  1.45982917  4.49580082 -2.91222262\n",
            "  5.11619372  2.46272128]. \t  -455.67634289578046 \t -119.61569010596395\n",
            "27     \t [-5.06512487  3.07177887 -3.24550166 -3.17001906  4.07067904 -2.78306348\n",
            "  5.09402638  3.46370695]. \t  -523.2697202123925 \t -119.61569010596395\n",
            "28     \t [ 3.45116782  4.2883336  -1.06827961  1.08873399  5.0482606  -4.51058891\n",
            "  4.35722921  0.96994416]. \t  -446.77680784324997 \t -119.61569010596395\n",
            "29     \t [ 3.63530343 -3.46557873  3.61802128 -3.36749831  3.83014402  1.62343264\n",
            " -3.95296799 -3.58858177]. \t  -423.43457792204293 \t -119.61569010596395\n",
            "30     \t [ 4.01934274  4.05770044  4.31710837  1.5774679  -4.35556493  5.07412149\n",
            "  3.58722918  4.13308112]. \t  -591.0222272976584 \t -119.61569010596395\n",
            "31     \t [-2.25591213  4.96561887  0.0795036  -1.15454996 -4.41063091  4.84978558\n",
            " -4.34250862  3.7355073 ]. \t  -541.7794187817939 \t -119.61569010596395\n",
            "32     \t [ 0.12727565 -2.79689264  1.320464    4.54198801  4.87337276  4.71576159\n",
            "  4.49149952  1.50626835]. \t  -514.9558968982748 \t -119.61569010596395\n",
            "33     \t [-5.02751618  5.06491973  2.48064034 -3.42349431  4.74146408 -4.03937258\n",
            " -3.09039151  4.51412148]. \t  -582.1032982837494 \t -119.61569010596395\n",
            "34     \t [ 4.90962147  3.6406731   2.26649059  4.77802827  4.12003519 -3.1547146\n",
            " -3.56596834 -4.88897631]. \t  -582.1589605949364 \t -119.61569010596395\n",
            "35     \t [-4.51222064  2.33705836 -3.9204912   4.61050437 -2.67519101 -0.6533826\n",
            "  4.50473942 -3.81968648]. \t  -459.5350415752135 \t -119.61569010596395\n",
            "36     \t [-3.35706119 -4.51837979 -4.82198262 -4.46867791 -4.70974965 -2.79849575\n",
            "  2.66466126 -1.51186134]. \t  -427.6191642521146 \t -119.61569010596395\n",
            "37     \t [ 3.84228276  4.43963589  3.00532598 -4.69185779 -4.82136851  2.026124\n",
            "  0.90323042 -2.91310454]. \t  -383.793184410653 \t -119.61569010596395\n",
            "38     \t [ 4.0849197   4.51858529  2.23105834 -3.98594242  2.08804225 -2.13970217\n",
            " -4.23085577 -3.89163271]. \t  -431.7345860806727 \t -119.61569010596395\n",
            "39     \t [-2.58586098  3.937282   -4.69349589 -4.37725799  1.26492357 -3.04887726\n",
            " -4.71377433 -1.02492612]. \t  -408.1348576606018 \t -119.61569010596395\n",
            "40     \t [-4.79679262 -1.19101782 -0.51873672 -2.8827882   3.7406016   3.05765609\n",
            "  3.9684925  -4.92961487]. \t  -490.6028176618996 \t -119.61569010596395\n",
            "41     \t [-4.80601553  2.20230062 -2.91346795  2.62611651 -4.66656923 -1.78269697\n",
            " -3.65609417 -1.06728291]. \t  -316.48318660748 \t -119.61569010596395\n",
            "42     \t [-4.58233729 -2.90182292  4.18639     1.96485379 -4.12704142 -4.49972084\n",
            " -1.87098357 -3.40777068]. \t  -429.91369741773246 \t -119.61569010596395\n",
            "43     \t [ 1.85553758  0.70934102  4.57936536  1.53530059  4.62761911  2.88316442\n",
            " -1.29195595  5.04286473]. \t  -448.86774655317276 \t -119.61569010596395\n",
            "44     \t [-1.32771388 -0.2500952   4.93199565  5.10576033 -2.89496113  4.94507599\n",
            "  3.49541808 -1.29531971]. \t  -466.7119336269132 \t -119.61569010596395\n",
            "45     \t [ 1.49138855  4.95353482  2.70965969 -4.3719624  -4.30373962 -4.79730833\n",
            " -1.6265383   4.89221536]. \t  -590.4676764687233 \t -119.61569010596395\n",
            "46     \t [-4.69146875 -2.55212666  1.61423304 -3.04996153 -2.78637926 -2.63244311\n",
            " -4.19224647  5.03851802]. \t  -486.57879804898437 \t -119.61569010596395\n",
            "47     \t [-1.58766871  3.93152255 -4.80561093  0.0477454  -2.59576839  5.01392316\n",
            "  0.63058118 -3.11782905]. \t  -367.80215136278736 \t -119.61569010596395\n",
            "48     \t [ 4.83577951 -4.14582824 -4.2095003   4.87111583 -3.66027066  3.02391713\n",
            " -4.87528283  2.65473701]. \t  -550.4433660626951 \t -119.61569010596395\n",
            "49     \t [-2.45727121 -3.57800376 -3.59498248 -4.5356804   4.49369616 -3.25401084\n",
            " -3.77456599  4.73843533]. \t  -596.5553265616473 \t -119.61569010596395\n",
            "50     \t [-4.16286711 -3.69571401 -4.56928156  4.38057808  1.42459829 -4.83612759\n",
            " -4.27769809 -4.85059119]. \t  -650.8318927255907 \t -119.61569010596395\n",
            "51     \t [ 3.72565307  5.07908191  4.20306074  0.93294167  3.46961807 -3.53360348\n",
            " -4.77765217  4.17653564]. \t  -556.3920068901169 \t -119.61569010596395\n",
            "52     \t [ 1.96215566 -5.01921275 -4.27992667 -1.49164408  3.82112879  4.06734282\n",
            " -2.78202234 -4.85994376]. \t  -533.4831303333021 \t -119.61569010596395\n",
            "53     \t [ 3.32885076 -4.6174408   0.66677819 -2.88698938  3.92340624  5.08250655\n",
            "  4.64415165 -2.58280436]. \t  -524.69623444286 \t -119.61569010596395\n",
            "54     \t [-4.43426871  3.39581796  4.80950651 -0.12177342  4.85921831  4.6801906\n",
            "  4.04913208  3.46789064]. \t  -572.6428073892683 \t -119.61569010596395\n",
            "55     \t [-1.3144322   2.96648225 -4.58685033  4.27089243  4.58276043  5.03228427\n",
            "  3.66179339  4.67473979]. \t  -681.0458697561622 \t -119.61569010596395\n",
            "56     \t [ 4.05203906 -4.21109401 -2.13644382 -2.70952507  3.03805882  1.79218409\n",
            " -1.97175147  4.85028713]. \t  -375.7823862622354 \t -119.61569010596395\n",
            "57     \t [ 4.63331836 -1.95437578  3.84273577  3.54908259  4.84142131 -2.93418267\n",
            "  3.23686355 -3.18612378]. \t  -447.19605855873607 \t -119.61569010596395\n",
            "58     \t [ 4.37699147  3.24575379 -4.61856717  1.35844937  4.20572821  5.0261401\n",
            "  2.90341528 -4.03502739]. \t  -540.8764815845917 \t -119.61569010596395\n",
            "59     \t [-2.13666398 -1.89056294 -3.77183433  3.62257442  4.71095701 -2.48780523\n",
            "  4.01273599 -3.8256525 ]. \t  -484.7860904299998 \t -119.61569010596395\n",
            "60     \t [ 4.38496674 -4.75994312 -2.71438515 -3.53401599 -2.61001885 -4.72547717\n",
            "  4.68406694 -4.09403551]. \t  -592.3169811999504 \t -119.61569010596395\n",
            "61     \t [ 4.3602157   5.07200701  4.7338835   3.01006059 -3.03877778  4.75462603\n",
            "  1.61440406 -4.33555198]. \t  -524.362664535086 \t -119.61569010596395\n",
            "62     \t [ 3.41765089  2.85348111  2.54975684  5.04341102  4.83071143  5.00798745\n",
            "  5.02443586 -4.95777922]. \t  -789.7225877312676 \t -119.61569010596395\n",
            "63     \t [-2.69954804 -4.46287853 -4.23069558  0.36349683 -3.72794826  0.11450906\n",
            "  5.02891815  4.53679254]. \t  -512.6036856291286 \t -119.61569010596395\n",
            "64     \t [ 2.25407296  2.09863361  1.2056268  -4.22691632  3.24260324 -2.15333643\n",
            "  4.6968155  -5.05592858]. \t  -529.0306323308363 \t -119.61569010596395\n",
            "65     \t [ 4.42766808 -1.8731146   3.3837943  -4.21691074  5.02717513 -4.61806203\n",
            " -4.2682243   4.14513372]. \t  -651.4035669577154 \t -119.61569010596395\n",
            "66     \t [-4.87653697 -3.4591322   4.67985395 -2.97801734 -5.0026146   0.06395157\n",
            "  3.10169794  4.10619321]. \t  -476.27484728999866 \t -119.61569010596395\n",
            "67     \t [ 1.52254561 -4.65782919 -1.54703882 -4.85066697 -4.56810949  5.03981034\n",
            " -4.3682913   4.80009625]. \t  -721.6421841155051 \t -119.61569010596395\n",
            "68     \t [-5.0236938   3.56177448 -2.85075031 -4.31615219  1.6758355   1.89854621\n",
            " -1.51048651  4.25120001]. \t  -345.728573452506 \t -119.61569010596395\n",
            "69     \t [ 4.39877122  4.6709328  -3.30451996 -5.01338339 -3.04256108 -4.41372026\n",
            "  1.41831267 -2.98195489]. \t  -444.66918738750456 \t -119.61569010596395\n",
            "70     \t [ 4.4099775  -3.89112291 -0.66338834  1.58127051  0.51280406 -2.11500171\n",
            "  4.21486326  4.1931665 ]. \t  -354.2223966934372 \t -119.61569010596395\n",
            "71     \t [ 3.78164131e+00 -2.75879113e+00  5.04971616e+00 -4.80148366e+00\n",
            " -2.90394801e-03  2.13616263e+00 -4.78734226e+00  4.85636375e+00]. \t  -574.722408090049 \t -119.61569010596395\n",
            "72     \t [-1.1888317   2.47677283  5.02956862 -4.91262096  4.77116956  3.48648636\n",
            " -0.84774462 -4.55836486]. \t  -544.1212239869448 \t -119.61569010596395\n",
            "73     \t [-4.81380688  4.40095768  4.6372785   2.66916271  0.60511201 -3.68965254\n",
            "  4.14124048  4.95759338]. \t  -555.1033510349539 \t -119.61569010596395\n",
            "74     \t [-4.69774019 -2.79686205 -2.33534836 -1.71876288  0.90641727  0.45175075\n",
            " -5.00093654 -4.91022451]. \t  -439.1722125515285 \t -119.61569010596395\n",
            "75     \t [ 2.76049122  2.60794099 -3.21360673 -3.88550279  2.63956389  2.43575859\n",
            "  4.1644981   5.08500529]. \t  -511.28690505606653 \t -119.61569010596395\n",
            "76     \t [-0.09492567 -5.10410069  0.36971532  4.23057259  1.92946279 -4.9032992\n",
            " -5.11414683  1.48635148]. \t  -487.73734709015173 \t -119.61569010596395\n",
            "77     \t [ 2.03954544 -3.32999415  1.43916871 -4.95919099 -0.21625796  4.76329818\n",
            "  2.32801955  4.10051141]. \t  -439.7445594302609 \t -119.61569010596395\n",
            "78     \t [ 2.57636467  5.02342908 -2.37756192 -2.93847746  0.50045822  5.0847148\n",
            " -4.54187401 -4.50530948]. \t  -571.7654198546909 \t -119.61569010596395\n",
            "79     \t [ 4.43072458 -4.01521381 -4.64425104  3.56849406 -0.40054708  4.97867613\n",
            "  4.03903062  3.18834337]. \t  -512.5651391022285 \t -119.61569010596395\n",
            "80     \t [-3.76847142 -5.11580824  4.95702718 -1.12872395  3.87507869 -1.06959931\n",
            " -4.92375007  2.7875099 ]. \t  -459.16711663123397 \t -119.61569010596395\n",
            "81     \t [ 4.66432852  4.46011058  4.42153771  3.77185029 -4.05541712 -2.3542377\n",
            " -4.62271594 -3.19432935]. \t  -523.8016287658669 \t -119.61569010596395\n",
            "82     \t [-4.78187785  5.06164818 -5.10414907  4.19615545 -3.8777821   5.05398983\n",
            " -0.34790846  3.43521957]. \t  -546.3908150278638 \t -119.61569010596395\n",
            "83     \t [-2.16941915 -2.81639958  4.05388077  4.80758435  1.70841054 -0.24562682\n",
            "  4.49803877 -4.96894947]. \t  -516.4293779313089 \t -119.61569010596395\n",
            "84     \t [-1.13659813  4.91724279 -4.52887486  2.75497127  0.94257282 -0.85037824\n",
            "  3.90979948  1.51057142]. \t  -275.5834065859605 \t -119.61569010596395\n",
            "85     \t [ 3.5497139   1.06943833  4.30708745  4.89389749  2.28373713  3.65243496\n",
            " -4.20007608 -2.49406868]. \t  -445.7082689052508 \t -119.61569010596395\n",
            "86     \t [-1.55161774  3.88797074  0.65349205 -3.9343768  -4.68901362 -4.35292164\n",
            " -2.22296652 -3.93622571]. \t  -478.0024378752458 \t -119.61569010596395\n",
            "87     \t [ 2.19850184  0.71295528  1.54234669 -2.66137892 -3.3907862  -0.67471188\n",
            "  4.53051191  4.07030304]. \t  -377.75454525282913 \t -119.61569010596395\n",
            "88     \t [-2.89644519  1.55077603  3.20210184  4.29002644 -4.52623113 -1.31857381\n",
            " -4.62565324  4.90192683]. \t  -572.4503138056587 \t -119.61569010596395\n",
            "89     \t [ 3.00701408 -4.78789918 -0.08136961  2.82742854 -2.22148223 -3.7171299\n",
            " -2.65996436 -5.02917869]. \t  -446.333586191535 \t -119.61569010596395\n",
            "90     \t [-2.51330132  4.36437832  1.8484944  -4.51742992 -4.20544175  4.65840367\n",
            "  4.68480609  3.06610622]. \t  -583.7647324287566 \t -119.61569010596395\n",
            "91     \t [-3.93651304 -4.69518481 -4.67837002  0.82149603 -3.66608794 -3.94261408\n",
            " -4.72196834 -0.54928533]. \t  -446.9053650288446 \t -119.61569010596395\n",
            "92     \t [ 1.87613561  1.11711224 -3.73754997  2.8108412  -3.91126923 -2.82719412\n",
            "  2.89826458  4.94342964]. \t  -458.27474726177013 \t -119.61569010596395\n",
            "93     \t [-0.52458594  4.00859365  4.73128611  3.86102982  1.08881308  0.12677837\n",
            "  4.84113317 -2.06757064]. \t  -363.4770316563106 \t -119.61569010596395\n",
            "94     \t [ 1.05071607  4.72319436 -1.05967067  4.07827081  2.16967499  3.76414704\n",
            " -4.51400443  4.70968762]. \t  -544.2521882164513 \t -119.61569010596395\n",
            "95     \t [-4.77623035  4.05415869  2.35335882  0.34537232 -3.80388726  3.91175014\n",
            "  1.96184682 -4.9849692 ]. \t  -462.6765738519008 \t -119.61569010596395\n",
            "96     \t [-3.69108235 -5.07967852 -3.31286671  1.30650741  2.33721514 -4.81835254\n",
            "  2.56424839  4.17876319]. \t  -457.3195435869162 \t -119.61569010596395\n",
            "97     \t [ 1.10714079  2.55375662  1.36694606 -4.75277817  4.48884508  3.13599508\n",
            " -4.46376241  3.57316395]. \t  -511.602002727578 \t -119.61569010596395\n",
            "98     \t [-4.41883529  1.38836372 -0.62223402  4.43825563 -4.88719983  4.96205252\n",
            " -4.93269083 -4.42464843]. \t  -697.4307744298263 \t -119.61569010596395\n",
            "99     \t [-2.07031872 -4.14012415  1.79686442 -3.67769852 -0.83807508 -0.82204313\n",
            "  0.98007769 -3.78067058]. \t  -230.99351113391037 \t -119.61569010596395\n",
            "100    \t [ 4.6136852   0.5995698   3.70700385 -3.61393916 -4.19489706 -4.20717943\n",
            "  4.98718168 -4.72878863]. \t  -662.6562790548289 \t -119.61569010596395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoONg4VEtdy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d940cc94-3b05-4fd8-98cb-e13a5857f9ef"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 13\r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_loser_13 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_13 = dGPGO(surrogate_loser_13, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.64499773 -0.88472932  1.72137019 -2.76537936  3.15062616  1.40102108\n",
            " -3.35673495 -2.45364871]. \t  -232.19635670005127 \t -232.19635670005127\n",
            "init   \t [ 4.2528767  -0.38076919 -3.88924462  3.90026757 -2.80351794  3.18914893\n",
            " -0.55419986 -4.1015814 ]. \t  -361.66026260752943 \t -232.19635670005127\n",
            "init   \t [ 4.03920839  1.42981319  4.41130989  3.62084556  3.50044048  0.52242587\n",
            " -2.97909353  3.81846156]. \t  -372.8981589252669 \t -232.19635670005127\n",
            "init   \t [ 3.80219612  2.41871092 -4.9313143   3.0755089  -1.83535427 -0.17449361\n",
            "  2.95749718 -3.92317458]. \t  -338.32885418149425 \t -232.19635670005127\n",
            "init   \t [-2.96300648  4.98598367  2.14768853 -4.67440231  5.05344835  0.67544515\n",
            "  0.4351207  -3.01593487]. \t  -364.25359293813665 \t -232.19635670005127\n",
            "1      \t [-1.41587684  0.6866087  -4.2572567  -4.43835538 -3.85825728  2.59858633\n",
            " -1.34170499 -2.82749095]. \t  -327.62176614819333 \t -232.19635670005127\n",
            "2      \t [-3.07473092 -0.85317005 -1.50250422 -0.57720119  3.33558361 -3.93578852\n",
            "  2.61338059 -5.03677065]. \t  -418.34892386367665 \t -232.19635670005127\n",
            "3      \t [-3.39709501 -0.75844229 -0.28988583  0.01269954  5.05807698  4.77249476\n",
            "  1.49596497  2.4718132 ]. \t  -342.06868330388926 \t -232.19635670005127\n",
            "4      \t [ 1.27516357 -4.34285698 -4.80891717 -4.72525807 -4.64386877 -2.90111663\n",
            "  4.22750682 -2.79713746]. \t  -544.0571374073245 \t -232.19635670005127\n",
            "5      \t [-1.28755561  2.49550924 -3.16338938  4.97284539  2.94658354 -2.94783466\n",
            "  3.99040857  0.75239783]. \t  -354.59328624675135 \t -232.19635670005127\n",
            "6      \t [ 4.21114748  3.71785746 -0.43186403 -1.16578161 -1.21755106  3.28643373\n",
            " -0.5463672   3.41384411]. \t  \u001b[92m-218.914703726932\u001b[0m \t -218.914703726932\n",
            "7      \t [-3.40987577 -2.26485888 -3.91690985 -0.58734748 -2.26892898 -4.81818994\n",
            " -4.72729877 -0.05610511]. \t  -390.77945760778687 \t -218.914703726932\n",
            "8      \t [ 2.86595514  0.92351583  2.81782962 -2.44988057 -4.50628865  3.57859906\n",
            " -3.68028052 -4.82083464]. \t  -516.8538522864185 \t -218.914703726932\n",
            "9      \t [-4.42963778  4.62707615  2.80169529 -2.14225784 -2.24188875 -4.43196144\n",
            " -2.56287418 -3.89458016]. \t  -414.6512467628057 \t -218.914703726932\n",
            "10     \t [ 3.18435631 -0.11660101 -1.88130665  4.6712052  -2.63434937 -4.84577943\n",
            " -2.16305908  2.98027432]. \t  -387.46239786721355 \t -218.914703726932\n",
            "11     \t [ 2.0374149  -4.18202871  1.36279378  4.41193347  2.79823539  4.3554836\n",
            " -1.43537589 -1.16427415]. \t  -300.80046956494806 \t -218.914703726932\n",
            "12     \t [ 1.11694286 -0.65880005 -1.89749913 -1.52252305 -4.61147313 -1.64357992\n",
            "  3.37238444  4.35249061]. \t  -375.89019619004796 \t -218.914703726932\n",
            "13     \t [-2.37554244  1.65647281  1.78721759  0.78783508 -3.4807812   4.77606073\n",
            "  2.24984424  0.79155457]. \t  -261.08497103385497 \t -218.914703726932\n",
            "14     \t [ 1.51688878 -4.11072603 -4.96940342  3.66824351  3.21889152 -3.84000432\n",
            " -1.66926281 -0.67132266]. \t  -327.3966147081477 \t -218.914703726932\n",
            "15     \t [-4.60314753 -3.19706748  2.87981804  2.67582955 -4.56568783 -1.74633567\n",
            " -0.21209673  2.15431485]. \t  -255.12089049617902 \t -218.914703726932\n",
            "16     \t [-2.96135533 -4.85764355 -2.94721908 -4.60857792  1.58976376 -0.30365672\n",
            "  3.32644401  0.83058005]. \t  -263.1427925078817 \t -218.914703726932\n",
            "17     \t [-0.11834623  4.92705116 -4.3604005  -1.37430597  3.76924904  3.35299698\n",
            "  4.46322323 -0.04754562]. \t  -391.11215712334564 \t -218.914703726932\n",
            "18     \t [ 1.85638398  2.02163281 -3.01735059 -3.35023212  2.68954594 -4.21881992\n",
            " -3.79772488  4.05487191]. \t  -459.28342052219034 \t -218.914703726932\n",
            "19     \t [-4.09844455 -1.48850034  3.67572703 -4.52659048 -3.40363089 -2.71521557\n",
            "  3.96260847 -1.02038732]. \t  -364.1247802550225 \t -218.914703726932\n",
            "20     \t [ 3.86465122  3.95113312  3.73758623 -1.76710627  3.5476809  -0.9302056\n",
            "  4.03393956  3.46199849]. \t  -378.47178663185707 \t -218.914703726932\n",
            "21     \t [-0.14475583  4.40134478 -2.4354744   4.15154633  5.02401187 -0.65413913\n",
            " -3.96422916  2.6485566 ]. \t  -420.39605126823034 \t -218.914703726932\n",
            "22     \t [-3.01708331 -1.83975134  4.04441597  1.36291376  4.42434258 -4.59618585\n",
            " -3.79944945  3.34001622]. \t  -487.2941611598006 \t -218.914703726932\n",
            "23     \t [ 3.47946079 -0.20865945  4.22764831  4.30667176 -2.24080282 -3.49752172\n",
            "  2.220785   -3.18623894]. \t  -354.2445288327723 \t -218.914703726932\n",
            "24     \t [ 4.74911553 -3.57355147  2.02881433 -1.20139555 -4.06427082 -0.71396603\n",
            " -2.84554848  1.88910129]. \t  -237.09593014417555 \t -218.914703726932\n",
            "25     \t [-4.09322692 -2.34029456 -3.2497013   1.37033171  0.52246424  4.10258651\n",
            " -4.94870218 -2.27470096]. \t  -382.0752047369767 \t -218.914703726932\n",
            "26     \t [-2.33069311  0.2571237   4.97181179  3.79574058 -0.63447703  2.27175691\n",
            " -3.22162417 -3.1984963 ]. \t  -324.8248265532207 \t -218.914703726932\n",
            "27     \t [ 5.00982906  0.29139707 -4.86258337  0.62785031  4.62078153  3.29058204\n",
            " -3.70077923 -3.91692044]. \t  -488.1133321959023 \t -218.914703726932\n",
            "28     \t [ 0.96147075  0.71808488  4.03788557  0.81071344  5.04648547  1.88523024\n",
            "  4.03905975 -3.19193624]. \t  -397.8636198609694 \t -218.914703726932\n",
            "29     \t [ 2.37876615 -4.7934043   4.04810257 -4.82678313  2.31603498 -1.40095132\n",
            "  3.12687723 -4.16146587]. \t  -439.5447139689047 \t -218.914703726932\n",
            "30     \t [-0.31316826 -4.5438875   2.71646621  3.55272862  3.36556525 -2.84166133\n",
            "  4.88572693  0.49992637]. \t  -388.1940765381305 \t -218.914703726932\n",
            "31     \t [ 2.86080125 -4.19491364  3.57636436 -2.39688061 -3.95370563  4.04962494\n",
            "  5.04867728  2.41988035]. \t  -506.55635420725207 \t -218.914703726932\n",
            "32     \t [ 3.6511972  -5.03374778 -4.16733946 -1.67855127  0.48921985  2.86461262\n",
            "  4.52631586  4.22006982]. \t  -463.6961404211157 \t -218.914703726932\n",
            "33     \t [-1.09730036 -3.39607373 -2.77900487  0.95615668 -1.66003768  3.28861249\n",
            "  4.98040889 -4.86698593]. \t  -492.89643186493845 \t -218.914703726932\n",
            "34     \t [-3.29975062  3.92545999  2.91690979 -4.60120503 -0.97329617  0.40209428\n",
            " -2.21337405  4.70319976]. \t  -368.8767482469296 \t -218.914703726932\n",
            "35     \t [-3.7686316  -4.08028438  0.30472636 -4.5852498  -1.54312407  1.44566465\n",
            " -3.91871594  2.36510598]. \t  -308.5666527346285 \t -218.914703726932\n",
            "36     \t [-4.92270405  4.18624686  3.6789746   2.31171986 -1.75335782 -4.22286838\n",
            " -4.03551917  3.95534365]. \t  -482.78597177086925 \t -218.914703726932\n",
            "37     \t [-0.69447295  4.63936981  4.656429    1.53212369 -4.01220939 -1.84999725\n",
            "  4.13752413  3.969915  ]. \t  -464.90600415003667 \t -218.914703726932\n",
            "38     \t [ 1.500391    2.60925601 -4.79534013  4.64623327 -3.24564792  2.57456044\n",
            "  3.87995082  4.4837204 ]. \t  -529.8528405595223 \t -218.914703726932\n",
            "39     \t [-1.40372927 -4.73470966  2.53460916 -4.8436032   1.47672351 -5.03046556\n",
            " -3.6855238  -4.59345994]. \t  -586.5377630779865 \t -218.914703726932\n",
            "40     \t [ 3.42131001  3.95906691 -3.89151245 -3.33237951 -3.5193837  -5.09007799\n",
            "  0.47887731 -1.32289051]. \t  -365.89365484706354 \t -218.914703726932\n",
            "41     \t [ 0.3996688  -4.39948801  4.9595373   3.62139896 -5.02722575 -3.64635216\n",
            " -4.11544432 -3.22666025]. \t  -573.1090398162095 \t -218.914703726932\n",
            "42     \t [-4.63089419 -3.1455169  -4.46287324  4.97289747 -1.54719736  0.78884096\n",
            "  3.11348454  4.01979997]. \t  -412.7338394137357 \t -218.914703726932\n",
            "43     \t [-1.99467581 -2.96792392 -1.03156545  4.47596395 -4.89937718 -5.06134685\n",
            "  4.61541597 -1.80075008]. \t  -553.7042056499283 \t -218.914703726932\n",
            "44     \t [ 4.64164756  3.38232408  4.98205018 -4.937466    4.79315032  5.10542375\n",
            "  0.54066893 -0.60416901]. \t  -492.63186073632033 \t -218.914703726932\n",
            "45     \t [-4.11113414  4.92529484 -2.37974349 -1.20444112 -4.61191074 -2.79364156\n",
            " -0.42522285  2.34342637]. \t  -286.5848137830881 \t -218.914703726932\n",
            "46     \t [-4.33307394 -5.12       -2.84336104 -5.12       -5.12       -1.96813536\n",
            " -5.12       -5.12      ]. \t  -747.8453766535582 \t -218.914703726932\n",
            "47     \t [ 2.8386759   4.07371588 -0.04039553 -1.69863771  4.58955791 -4.3577661\n",
            " -4.01584047 -4.02287492]. \t  -514.4127439552744 \t -218.914703726932\n",
            "48     \t [ 3.60448473  4.74876479 -4.75996018  3.80882696 -4.75619547 -3.90247562\n",
            " -4.1549231  -3.63165535]. \t  -614.9320971910101 \t -218.914703726932\n",
            "49     \t [ 2.15955109 -4.05189858 -5.01590558 -3.57594626 -4.29361589  4.13431427\n",
            " -4.57492592  3.64985029]. \t  -611.9388195503122 \t -218.914703726932\n",
            "50     \t [-3.01743009  3.50183111 -4.68174825  0.22061144 -2.72389007  4.3426914\n",
            " -3.95360149  2.99087097]. \t  -430.81242785547227 \t -218.914703726932\n",
            "51     \t [-3.72821021  4.63152432 -1.89662469 -4.40029358  3.73398383 -3.64050016\n",
            "  4.3849761   4.93532945]. \t  -623.7320230870259 \t -218.914703726932\n",
            "52     \t [ 3.33725079  4.4466726   4.98405523 -3.98191892 -4.10027891 -3.83075998\n",
            " -1.15360313  3.30191013]. \t  -457.2744233230236 \t -218.914703726932\n",
            "53     \t [ 2.42755775  3.32084179  3.95034979 -5.00861294 -2.69706913 -1.52368546\n",
            "  2.96307227 -3.82003964]. \t  -403.6104385354229 \t -218.914703726932\n",
            "54     \t [ 4.30731796 -4.44754421  3.08111473 -5.01000714 -1.45470083 -4.3840288\n",
            "  3.78353423  5.03483422]. \t  -615.8961647362689 \t -218.914703726932\n",
            "55     \t [ 3.53190624 -5.10439959 -2.29791177  4.66313506 -1.93347286 -2.27808801\n",
            "  4.84462405  3.70569723]. \t  -491.384568810529 \t -218.914703726932\n",
            "56     \t [ 0.44374948 -4.70988466 -3.50924912 -0.12092544  4.54574228  2.11388885\n",
            " -2.92498353  3.69250615]. \t  -380.66145550861677 \t -218.914703726932\n",
            "57     \t [-4.19148775  4.64261347  4.05501822 -2.21915047  3.98903679  2.35350091\n",
            "  4.34972238  4.50032258]. \t  -536.9640140895895 \t -218.914703726932\n",
            "58     \t [ 4.53611898  2.85315605  4.45565713  4.60695918 -2.31998513  4.74683621\n",
            "  1.80620024 -3.52486856]. \t  -465.65278826837687 \t -218.914703726932\n",
            "59     \t [-4.30506814  1.85102595 -4.08866725 -3.59159664 -1.10395128  3.81831987\n",
            "  3.07344941  4.8474996 ]. \t  -474.8156711388732 \t -218.914703726932\n",
            "60     \t [ 0.2184935  -4.91185026  5.11858805  4.44171964 -0.50610567 -0.09972378\n",
            " -3.32829694  4.92280291]. \t  -478.5708252644768 \t -218.914703726932\n",
            "61     \t [2.74950564 3.44225158 1.83771014 4.83349007 2.26423133 4.68386532\n",
            " 4.30327294 4.83362179]. \t  -608.643600053095 \t -218.914703726932\n",
            "63     \t [-3.26904232  4.63906088 -4.64581443  4.64324941 -2.18832156  2.13942241\n",
            " -3.89520013 -4.12102535]. \t  -498.195658423227 \t -218.914703726932\n",
            "64     \t [ 3.51097103 -3.00116843  2.62552345  4.99637123  4.67059042 -3.07163905\n",
            " -2.63531271 -4.49418599]. \t  -526.7536093811982 \t -218.914703726932\n",
            "65     \t [ 1.87230074 -3.8513344  -3.48166713  3.99283315  4.65080164  1.11251229\n",
            "  5.09809882 -2.12395188]. \t  -466.9074825667713 \t -218.914703726932\n",
            "66     \t [ 4.09679308  2.76692185 -1.94849683 -2.53703673  3.44517311 -4.85072854\n",
            "  3.93863785 -1.27733718]. \t  -391.3978597208432 \t -218.914703726932\n",
            "67     \t [ 3.39305149 -2.60163602  4.0441825  -3.84306038  3.33412209 -0.45811699\n",
            " -4.92332766  4.6042102 ]. \t  -529.2976840444844 \t -218.914703726932\n",
            "68     \t [ 4.18779157e+00  3.08154908e-03  2.21335656e+00 -4.62109723e+00\n",
            "  1.16381998e+00  3.76683788e+00  4.99774754e+00 -3.50060533e+00]. \t  -482.43567237346394 \t -218.914703726932\n",
            "69     \t [ 4.17254964  4.39168639  4.57237317  4.56953035  3.73122788 -4.31812961\n",
            "  3.7942447  -2.10102442]. \t  -519.8024550399207 \t -218.914703726932\n",
            "70     \t [-3.95433121  1.29686166 -2.01491021 -4.71771435  0.71200371  4.95996316\n",
            "  4.40770278 -4.14953303]. \t  -544.0933946841219 \t -218.914703726932\n",
            "71     \t [-5.03121931  1.96430137 -3.52631814 -5.08343315  4.21579061  4.85786905\n",
            " -2.04320519 -0.30189469]. \t  -434.10979476414707 \t -218.914703726932\n",
            "72     \t [-3.88279736  4.92566386  3.89841038  4.74826305  3.98631984  0.20963136\n",
            "  0.34908598 -0.64906254]. \t  -283.31794859152194 \t -218.914703726932\n",
            "73     \t [ 4.02391581 -4.94543332 -3.4421724  -4.14467667  0.17366159 -3.71483051\n",
            " -1.50141782  1.72526887]. \t  -291.9083467385876 \t -218.914703726932\n",
            "74     \t [-4.86907152  4.81740633  3.30467329 -3.35133793 -5.07559196  0.86952146\n",
            "  2.83042534 -3.71378388]. \t  -447.57237822345525 \t -218.914703726932\n",
            "75     \t [-5.06040861 -4.78834912  4.37638619  3.72693951  4.04424723  4.7214533\n",
            " -4.7482257   4.34471457]. \t  -708.8471848847856 \t -218.914703726932\n",
            "76     \t [-4.42798875  0.36629021 -2.8917049   4.42391222  3.5102884  -3.02908428\n",
            " -2.77770996 -3.60714972]. \t  -398.009964731996 \t -218.914703726932\n",
            "77     \t [ 3.06729971  4.6167786  -2.06024978 -3.99895939  4.35062598  3.07241453\n",
            " -5.0577762   1.07282421]. \t  -468.2916425698801 \t -218.914703726932\n",
            "78     \t [ 4.54919254 -0.72039803 -4.26474196  4.92348162  4.88246938  4.0321738\n",
            " -1.30767974  3.04990948]. \t  -476.38871258845006 \t -218.914703726932\n",
            "79     \t [ 4.19564871 -4.96703752  5.0441952   4.63865379  1.75346031  3.50763686\n",
            "  4.40595652  2.44140767]. \t  -502.1116975434759 \t -218.914703726932\n",
            "80     \t [-0.39853841  4.77424718 -0.62414894  2.99698303 -3.70378766 -4.36871694\n",
            "  4.16449827 -2.37782183]. \t  -432.5799756963927 \t -218.914703726932\n",
            "81     \t [ 2.10606344  1.29166194  4.67166354  2.29708922 -1.38270055 -4.19944863\n",
            " -4.8822017   0.94915946]. \t  -383.7820809018181 \t -218.914703726932\n",
            "82     \t [ 4.02257076  4.86282379 -2.20052268 -3.23205475 -2.59285061  4.67462563\n",
            "  1.17298258 -4.17444486]. \t  -433.55305415718806 \t -218.914703726932\n",
            "83     \t [-2.51014017 -5.04371265  3.78446455 -4.80932512  4.94363722  4.41638185\n",
            "  5.04370332  3.21681811]. \t  -692.7440953840234 \t -218.914703726932\n",
            "84     \t [-3.99884647 -1.39675053 -1.09669086  0.31025644  1.25581469 -4.04307072\n",
            "  4.31561356  4.42463868]. \t  -416.8407659825536 \t -218.914703726932\n",
            "85     \t [-4.15068248  4.75800056  0.95216861 -4.22625018  4.97981415 -4.88038033\n",
            " -3.92911013  4.40024086]. \t  -666.5336613014593 \t -218.914703726932\n",
            "86     \t [-3.82305389  5.08995274 -4.62382086  1.72034971 -3.02769872  3.25705383\n",
            "  4.77791532 -4.95267639]. \t  -607.9250963703118 \t -218.914703726932\n",
            "87     \t [-0.5508932  -4.61347784 -5.11130818 -4.82353419 -4.05459548  4.81691135\n",
            "  2.77637566  0.69217854]. \t  -493.51943509468384 \t -218.914703726932\n",
            "88     \t [ 5.04989603 -5.07940306 -4.79166163  2.40440637 -1.37356409  4.82977272\n",
            " -2.57988864  1.24787177]. \t  -377.54873272403796 \t -218.914703726932\n",
            "89     \t [ 4.58892216 -4.90032411 -4.5098325  -4.65231832  3.4098105  -2.00459347\n",
            "  4.14634386 -2.00070943]. \t  -451.2888750911872 \t -218.914703726932\n",
            "90     \t [-0.27772823 -4.68516644  2.47515865  0.15640653 -1.4554392   4.98473286\n",
            " -5.0199206  -4.86048497]. \t  -587.5244041643667 \t -218.914703726932\n",
            "91     \t [-3.45975698 -0.47378289  5.04778336 -3.45749087  4.407128   -1.97684596\n",
            "  3.93073285 -0.44964181]. \t  -367.00963444648465 \t -218.914703726932\n",
            "92     \t [ 3.96957335  3.7283753   0.94173518  4.60124014 -4.47202478  4.97040644\n",
            " -4.34284439  4.84691051]. \t  -699.092398824805 \t -218.914703726932\n",
            "93     \t [-4.19013545 -4.61385917  2.67100906 -3.74395294  3.46145995  3.28842516\n",
            " -1.73967255 -4.96621793]. \t  -480.88698356431405 \t -218.914703726932\n",
            "94     \t [-2.50050421  0.03977465 -1.04782291 -5.12       -4.42460411 -5.12\n",
            " -0.42825582 -5.12      ]. \t  -580.5781129902467 \t -218.914703726932\n",
            "95     \t [-4.26338279 -3.71667279  3.97133919  2.82627941  0.65424449  2.68508475\n",
            "  3.34072027  3.31476935]. \t  -336.4924821944162 \t -218.914703726932\n",
            "96     \t [ 3.42811619 -4.65411356 -3.9962143  -3.40553722  0.87807929  4.29515793\n",
            " -0.33150548 -4.03843304]. \t  -395.15965630675373 \t -218.914703726932\n",
            "97     \t [-4.90801339  0.00976962 -1.48145107  4.60425836 -3.21537152 -0.09172538\n",
            " -4.89210982  3.33378343]. \t  -423.6552743067479 \t -218.914703726932\n",
            "98     \t [-1.44112249  1.32424354  3.40929845  0.89863282  0.38603974  4.94145343\n",
            " -5.01942729  2.57839382]. \t  -420.4845629187468 \t -218.914703726932\n",
            "99     \t [ 0.12977286 -4.02053372 -3.12359485  4.1858697   3.72601373  4.61831503\n",
            "  5.07048438  4.80279462]. \t  -693.5950443148765 \t -218.914703726932\n",
            "100    \t [ 4.67710543 -4.2942679   4.81633202  0.72812545 -2.15964028  2.12037206\n",
            "  2.55838462 -3.79967135]. \t  -342.08205679853415 \t -218.914703726932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoQHSe2Dtd1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcfee6a-6723-4f8b-f614-270d2285a7cd"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 14\r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_loser_14 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_14 = dGPGO(surrogate_loser_14, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.51092275  0.07321281  0.29021573  4.05796049  2.04790979  2.19440232\n",
            "  2.22554503 -2.83832871]. \t  -217.39677218415014 \t -198.56808439329558\n",
            "init   \t [-3.32641768 -0.44194316  4.39028154 -5.01876852 -4.19919673  3.58605074\n",
            " -0.14724036  3.85879646]. \t  -454.63061220313574 \t -198.56808439329558\n",
            "init   \t [-1.97290047 -1.14723281  0.83400441 -3.95584327  2.74309309 -1.91932375\n",
            "  1.49514711 -4.78516309]. \t  -329.7622575537801 \t -198.56808439329558\n",
            "init   \t [-3.41610929 -0.71369695 -2.78726175  4.77498845  4.14657954  3.74438823\n",
            " -4.79065311  3.06685697]. \t  -533.1877350004759 \t -198.56808439329558\n",
            "init   \t [ 4.15903244  2.08827731 -2.76774455 -0.90689946  4.90131417 -1.75056937\n",
            "  0.97821769  0.36706653]. \t  -198.56808439329558 \t -198.56808439329558\n",
            "1      \t [-0.39837742 -2.80781146  4.30646237  1.1348259  -2.86625872 -4.7177257\n",
            "  0.49038928 -4.19648802]. \t  -393.90076362444245 \t -198.56808439329558\n",
            "2      \t [ 3.59823797  2.93493829 -2.22286357 -2.31644834 -2.60040072  1.67020778\n",
            " -1.69312657  2.29311986]. \t  \u001b[92m-179.14405714824883\u001b[0m \t -179.14405714824883\n",
            "3      \t [-0.47349161  3.6595987  -0.69062425  3.93976687  0.73643447 -4.52423201\n",
            " -1.53249713  3.04543123]. \t  -306.68823053687424 \t -179.14405714824883\n",
            "4      \t [ 1.41775929  3.17892187 -0.61864258  3.15578588 -2.39206936  2.17862635\n",
            "  4.61888672  4.83006183]. \t  -456.26845971029707 \t -179.14405714824883\n",
            "5      \t [ 4.39589311 -2.63238916 -0.42473053  3.46291368 -4.45295055 -3.32856296\n",
            "  0.33154344  4.17398955]. \t  -387.45788340642343 \t -179.14405714824883\n",
            "6      \t [-3.02903475 -3.64189089  2.97031185  1.27114666 -1.76031793  2.83831373\n",
            " -4.24804996 -4.841301  ]. \t  -446.29010964797953 \t -179.14405714824883\n",
            "7      \t [-3.80204832  1.78051287 -4.825323   -1.75193211 -1.96549208  2.23249824\n",
            "  3.99460947 -1.80533003]. \t  -289.9164660631186 \t -179.14405714824883\n",
            "8      \t [ 0.94625912  4.81600644  3.50275893  4.96812724 -3.02292999  4.53107502\n",
            " -1.11729281 -1.41313361]. \t  -376.4087046229012 \t -179.14405714824883\n",
            "9      \t [ 1.03301786 -4.88160905  5.03337305  2.76125417  2.99418971 -4.11353872\n",
            " -4.01783109  2.03992856]. \t  -447.8742705189637 \t -179.14405714824883\n",
            "10     \t [-4.93530372 -1.17825508  2.51745698  2.51577202  0.61961621  4.23884071\n",
            "  1.92198526  4.47748059]. \t  -367.4300929150804 \t -179.14405714824883\n",
            "11     \t [ 2.85539411 -4.88996184 -4.24883203 -2.0136527  -3.07932454 -1.30324947\n",
            "  4.3001305  -4.89762701]. \t  -505.28745116712275 \t -179.14405714824883\n",
            "12     \t [-2.66371784  3.67836989  4.95734547 -4.11077469  1.54961196 -3.27610606\n",
            " -2.54049005  0.2918652 ]. \t  -297.7397213919187 \t -179.14405714824883\n",
            "13     \t [ 2.40537967 -4.43519619 -2.68785928  5.10874445 -4.67211226  2.06291398\n",
            " -2.27837885 -2.59770597]. \t  -396.19715515339806 \t -179.14405714824883\n",
            "14     \t [-3.98337617 -3.51389608 -2.03891801 -0.53776836 -0.70464394 -3.66682906\n",
            " -0.30620155  4.53500197]. \t  -302.5332422325131 \t -179.14405714824883\n",
            "15     \t [ 4.96704707  0.03520955 -1.33614114 -0.15348861 -4.85467546 -1.36565613\n",
            " -4.22068731 -4.72895031]. \t  -462.7567371690855 \t -179.14405714824883\n",
            "16     \t [ 3.8884749  -3.58714251  4.28048641  3.76979024  2.30220927  2.11091249\n",
            "  2.39658266  3.96726884]. \t  -372.0239677779635 \t -179.14405714824883\n",
            "17     \t [-2.05772009  0.23529643 -3.38742704 -4.61709315  4.0902806   2.40618111\n",
            " -1.75729841  3.45449585]. \t  -359.51436161637804 \t -179.14405714824883\n",
            "18     \t [ 4.45153975  2.42816825  2.0255446  -4.02001109  2.31476411  4.99766206\n",
            "  4.56680765 -4.52874875]. \t  -595.2757253627606 \t -179.14405714824883\n",
            "19     \t [ 0.24115532 -4.94767888 -3.06003454 -4.72047739 -2.84711293 -4.8229136\n",
            "  4.96137231  2.57914121]. \t  -571.8557649366685 \t -179.14405714824883\n",
            "20     \t [-3.94377474 -0.40829514 -3.18736374 -4.91253618 -3.73338331  0.8404564\n",
            " -3.60996468 -1.53359636]. \t  -326.8638925668034 \t -179.14405714824883\n",
            "21     \t [ 1.41894243 -0.42524573 -4.46954293  4.51250395 -3.9897445  -4.25495932\n",
            "  1.98406377 -3.87678392]. \t  -479.7658456196911 \t -179.14405714824883\n",
            "22     \t [ 0.70074988 -3.95743257 -0.94542815 -3.5049789  -2.15340699  4.21862254\n",
            "  2.87921658  0.54949926]. \t  -274.04588443169376 \t -179.14405714824883\n",
            "23     \t [ 4.44013244 -4.81936548 -4.53083105  4.6655052   4.64382385  4.36048038\n",
            " -1.6029142  -4.80458401]. \t  -639.3861808093668 \t -179.14405714824883\n",
            "24     \t [ 0.62839832  4.70889113 -3.46987945  4.39097753 -0.43313369  4.56884717\n",
            " -3.9924195  -4.8522846 ]. \t  -584.1025524241154 \t -179.14405714824883\n",
            "25     \t [-5.12       -5.12       -4.62706439 -5.12       -5.12       -5.12\n",
            " -5.12       -5.12      ]. \t  -929.3043744797287 \t -179.14405714824883\n",
            "26     \t [ 2.71405456  1.73979496  4.238507   -4.52181917 -1.19665743 -3.75980245\n",
            "  4.35815971  0.83328596]. \t  -379.5885325782893 \t -179.14405714824883\n",
            "27     \t [-1.88169217  2.4411314   4.43093553 -1.37298771 -3.59201045  1.52585992\n",
            "  1.82445462 -3.94403153]. \t  -308.12466748606363 \t -179.14405714824883\n",
            "28     \t [-4.61918779 -1.71416302 -4.63372952  4.81013087  4.92743265 -0.62656288\n",
            "  3.566389   -1.27167783]. \t  -409.9020672014811 \t -179.14405714824883\n",
            "29     \t [-5.05526793  3.85003111  0.85595915 -4.57112717  2.96141259 -4.59078442\n",
            "  4.2326201   3.03276799]. \t  -510.2686211429887 \t -179.14405714824883\n",
            "30     \t [-2.85734626 -3.82316818  2.41209825  1.76390832  5.03574366 -4.47459953\n",
            "  3.53423417  0.6311657 ]. \t  -404.8462574991417 \t -179.14405714824883\n",
            "31     \t [-4.97613396  4.82808205 -0.64149981 -4.92414753 -2.2383558   5.05577022\n",
            "  4.20595758  4.19753595]. \t  -612.807219921953 \t -179.14405714824883\n",
            "32     \t [ 3.0518308   1.24544767  5.08487309  3.69177407  4.65216689  1.82436275\n",
            " -4.95668549 -0.58846562]. \t  -447.43506965842164 \t -179.14405714824883\n",
            "33     \t [ 4.53539613  0.21766946  4.31028056 -4.78257865  0.0531777  -4.49769939\n",
            " -4.63729102 -4.67362811]. \t  -614.555978878443 \t -179.14405714824883\n",
            "34     \t [ 4.26428858 -1.77991241  4.76554291 -3.25320422  0.0978536   3.76167624\n",
            " -5.04181401 -1.3317815 ]. \t  -412.0623626301501 \t -179.14405714824883\n",
            "35     \t [-2.16653722  4.27110866  0.94329541  2.29843962 -4.66641501 -4.30631317\n",
            " -4.03115637 -3.06842213]. \t  -474.1957492720553 \t -179.14405714824883\n",
            "36     \t [ 1.29512603  1.47888098 -3.33007366 -1.72259033  3.9461254   1.63102569\n",
            " -5.01164257 -4.32927594]. \t  -470.76693761054173 \t -179.14405714824883\n",
            "37     \t [ 0.36249109 -4.04087781  3.9716324  -4.80012774  3.69841142  1.46039956\n",
            "  0.20787699  4.7816369 ]. \t  -436.67802131557926 \t -179.14405714824883\n",
            "38     \t [ 4.62893912  1.73444535 -4.75375189  5.07622843 -4.80719864  4.80532157\n",
            "  4.56921527 -2.02809013]. \t  -631.4523108470972 \t -179.14405714824883\n",
            "39     \t [-3.7521143   0.5463932   3.91101225  2.75940412 -4.35072823  1.96260847\n",
            " -4.88684403  3.09289761]. \t  -452.47275720769915 \t -179.14405714824883\n",
            "40     \t [ 2.43805178 -2.90848894 -4.80756594  3.13462505  3.82024674  1.38649894\n",
            "  4.07804661  5.10071701]. \t  -540.561742479819 \t -179.14405714824883\n",
            "41     \t [ 4.21692788  4.49744187  2.28745553  3.27520704 -4.41465385 -1.90911654\n",
            "  4.21679914 -4.72172413]. \t  -538.9831240950099 \t -179.14405714824883\n",
            "42     \t [-4.53468821 -1.86958044  2.87498851 -2.01477772  3.72749079  5.04471485\n",
            " -4.57703112  0.27408732]. \t  -437.9993668596513 \t -179.14405714824883\n",
            "43     \t [-4.91342259  2.62611451  0.71846968 -2.64334385  5.05335564  5.114367\n",
            "  2.50444874 -4.31667766]. \t  -545.0303469021718 \t -179.14405714824883\n",
            "44     \t [ 5.03107414  3.60751295 -1.87033468  3.28919038  4.5931785   4.67371106\n",
            " -1.56049707  4.69641484]. \t  -535.1540056712837 \t -179.14405714824883\n",
            "45     \t [ 1.0767427   4.40760861  4.52120955  1.42219011  3.80705507 -2.22642263\n",
            "  4.23816896  4.9590656 ]. \t  -534.1111824113534 \t -179.14405714824883\n",
            "46     \t [-2.39316689  5.04331684  4.48235917  2.88997186 -3.27572529 -4.33473121\n",
            "  4.76793416  1.53184911]. \t  -494.57583353021437 \t -179.14405714824883\n",
            "47     \t [ 4.72913934 -2.30645511  4.53339207  1.44889222  5.01472892 -3.84339652\n",
            "  0.12255293 -4.31172367]. \t  -466.2568491549189 \t -179.14405714824883\n",
            "48     \t [ 0.57337198  3.18113248 -2.66678336 -4.89972848 -2.97719009 -4.94382051\n",
            " -1.02518221 -5.10991161]. \t  -545.1455555963 \t -179.14405714824883\n",
            "49     \t [ 4.49256633 -4.52634403 -2.43030459  1.89578855  4.81941591  1.4089427\n",
            " -3.68532017  3.99687468]. \t  -444.1696475996963 \t -179.14405714824883\n",
            "50     \t [ 3.8432084  -4.92276179 -4.73770622 -3.75932111 -2.5553544   2.47073133\n",
            " -4.51454486  3.34232761]. \t  -488.41827795363776 \t -179.14405714824883\n",
            "51     \t [-4.02511284 -3.73321252 -2.21736677  4.67332679  0.24321705 -3.47289547\n",
            " -3.09987026 -3.41542577]. \t  -379.43258933083496 \t -179.14405714824883\n",
            "52     \t [-4.89797297  4.48759638 -3.73944483 -1.50477039  1.60862279 -5.11884516\n",
            "  3.84844384 -5.09163062]. \t  -596.4999107267595 \t -179.14405714824883\n",
            "53     \t [ 4.771063    4.81496753 -5.1071876   1.42660585  1.632507    3.11050024\n",
            "  2.35882265 -4.69609576]. \t  -442.27327847494394 \t -179.14405714824883\n",
            "54     \t [-1.78359804 -3.56533645 -5.11561824 -3.23624435  4.64091845  2.86713653\n",
            "  4.99335662  1.26437364]. \t  -493.34407883840913 \t -179.14405714824883\n",
            "55     \t [ 3.98616068 -5.08580557  2.35517152  0.80369527 -1.84277488  4.16824202\n",
            "  0.06114862 -4.5327869 ]. \t  -372.4644925541079 \t -179.14405714824883\n",
            "56     \t [ 2.68550492  2.77767643  3.34967004 -3.29286456  3.18264289  4.59653131\n",
            "  2.58046316  3.60337845]. \t  -427.57650599826684 \t -179.14405714824883\n",
            "57     \t [-4.73086641 -4.8650459   3.76321574  3.64878882  0.71375156  2.87814596\n",
            "  4.32625023 -3.96473092]. \t  -474.4758263296067 \t -179.14405714824883\n",
            "58     \t [-0.42020953  3.95263994 -4.37718627 -1.33024026 -4.19488311 -4.70719731\n",
            "  1.10442916  4.40034564]. \t  -480.354877841665 \t -179.14405714824883\n",
            "59     \t [-4.69740763  3.39407234 -4.29508772  3.39127108 -0.94162195  4.63780908\n",
            "  1.453522    3.87084505]. \t  -414.5968187340818 \t -179.14405714824883\n",
            "60     \t [ 4.21064505 -3.34148542  2.7020819  -4.56108997 -4.52883799 -0.14669129\n",
            " -1.11600463  5.00671974]. \t  -457.1156703599248 \t -179.14405714824883\n",
            "61     \t [-3.85824556 -4.99363423 -3.46708016  3.90588437 -3.65390657  0.55741923\n",
            " -5.09291403  3.62016295]. \t  -516.8730050417385 \t -179.14405714824883\n",
            "62     \t [-2.49451252  3.58335156  4.85724406  4.98315878  4.70224216 -2.67279823\n",
            " -1.46555541 -3.59601244]. \t  -473.91327636426394 \t -179.14405714824883\n",
            "63     \t [-1.63610083 -4.8981661   5.03819628 -4.99796292 -1.10176614 -5.05986929\n",
            " -2.13386807  1.6503702 ]. \t  -440.0763182644959 \t -179.14405714824883\n",
            "64     \t [-4.94849447  0.92474297 -2.55703905 -3.88002598  4.32980955 -4.19050488\n",
            " -4.73707916 -0.97570857]. \t  -469.82538032632505 \t -179.14405714824883\n",
            "65     \t [-4.88997421 -1.99280877  5.05870473 -1.9490197  -2.98771215 -2.3053063\n",
            "  4.03414821  4.38903541]. \t  -468.36887289365717 \t -179.14405714824883\n",
            "66     \t [ 3.37997778  3.04065289  3.29233212 -4.19832427 -4.90921256 -3.87011687\n",
            " -5.04176351  2.73076071]. \t  -580.8982034373284 \t -179.14405714824883\n",
            "67     \t [ 4.32968656  3.45339146 -4.05245593  5.09514289  4.97427354 -4.00447404\n",
            "  5.11281255 -4.93247031]. \t  -793.2590646170327 \t -179.14405714824883\n",
            "68     \t [-4.2228092   3.65849036  1.45442504  4.42288911  4.74794207  1.28583452\n",
            "  2.95418795  0.31777541]. \t  -313.7284966025756 \t -179.14405714824883\n",
            "69     \t [-3.36445458 -1.83407205 -4.6426502  -1.45973175 -4.5287885   3.34815867\n",
            " -0.28661236  4.79174726]. \t  -445.3054511105204 \t -179.14405714824883\n",
            "70     \t [ 3.441201   -4.93389218  4.00239115 -4.82207135  1.19339669  1.88564925\n",
            "  5.00589676 -4.62148472]. \t  -576.3283435470056 \t -179.14405714824883\n",
            "71     \t [ 1.76701872  4.25654233  2.42072924 -0.06442414  4.61877374 -3.58708791\n",
            "  4.30936891 -4.84583442]. \t  -558.6751167742981 \t -179.14405714824883\n",
            "72     \t [-2.74088177 -3.78574713 -4.04076239  3.96037975 -4.94204006  3.23688632\n",
            "  5.06362139  0.56729469]. \t  -514.9377245514424 \t -179.14405714824883\n",
            "73     \t [-5.12       -0.81980531 -1.77527983 -1.03131716 -5.12       -5.12\n",
            "  1.35562443 -1.96698035]. \t  -373.4423940942729 \t -179.14405714824883\n",
            "74     \t [ 4.81031564 -5.08391902  3.49827193  4.63447174 -5.0881809  -1.51392905\n",
            "  4.82029677 -4.99830449]. \t  -703.1696546458896 \t -179.14405714824883\n",
            "75     \t [ 3.66068974 -4.92065277 -4.96439345 -4.68150019  4.57475894 -2.97041579\n",
            " -0.58754284  2.4109378 ]. \t  -429.9274110601041 \t -179.14405714824883\n",
            "76     \t [ 1.90514061 -3.56665686 -2.48619388  4.96112818  1.99236446 -4.3460203\n",
            "  3.72769311 -0.23812272]. \t  -376.9647206816334 \t -179.14405714824883\n",
            "77     \t [ 4.1692792  -0.01792313 -4.54331288 -4.334793   -1.22002147  4.74921092\n",
            "  0.84408284 -4.31460306]. \t  -451.156344419428 \t -179.14405714824883\n",
            "78     \t [ 4.81185495  2.37724727  4.68236884  5.04044024  0.45388768 -4.0274404\n",
            " -5.11057486  2.92887938]. \t  -551.6586730683501 \t -179.14405714824883\n",
            "79     \t [-4.65855077 -3.72138799 -1.70208876  3.51791609  4.71267411 -3.60764385\n",
            " -4.9550391   3.79261869]. \t  -583.6693961163407 \t -179.14405714824883\n",
            "80     \t [ 3.49601248 -4.60329464 -3.93648965  0.06654299  4.48151044 -0.42751887\n",
            "  4.25013556 -5.03134999]. \t  -531.5860515258532 \t -179.14405714824883\n",
            "81     \t [-0.45030723  3.89670983 -4.4545308   3.51665063 -4.50201133  0.23788106\n",
            " -3.10018841  2.45583487]. \t  -356.77456307545657 \t -179.14405714824883\n",
            "82     \t [-4.62925488 -4.65830939 -4.69568575 -2.81068809  0.61858217  1.266126\n",
            "  1.00085723 -4.89777432]. \t  -373.0271794618299 \t -179.14405714824883\n",
            "83     \t [ 3.91174128 -4.96714668 -1.04424025  1.76556003  0.39038672 -3.51964323\n",
            " -1.22148492 -5.01897756]. \t  -367.44153754722964 \t -179.14405714824883\n",
            "84     \t [-1.97065527 -4.04518494  3.23799606 -4.82201921  4.99549362 -4.54950457\n",
            " -4.77208749 -4.48426194]. \t  -730.3131653528321 \t -179.14405714824883\n",
            "85     \t [-0.76202844  4.92185364 -4.95210008  0.86343595  4.31971545  1.81380413\n",
            "  3.22623966  4.67118967]. \t  -486.04142642702453 \t -179.14405714824883\n",
            "86     \t [ 4.2219614  -1.678051   -3.75672675  4.3989763  -2.95560368  3.28417323\n",
            " -2.04024116  4.65335154]. \t  -453.95988681255125 \t -179.14405714824883\n",
            "87     \t [ 3.65986976 -0.5200619   1.03836117 -4.59257531  2.88866798 -3.66163716\n",
            " -4.7787233   3.39918589]. \t  -475.9937752949539 \t -179.14405714824883\n",
            "88     \t [ 3.77031213  4.66895776  2.58877271  1.17168763  3.96127035 -3.44440593\n",
            " -4.44489887 -5.07504402]. \t  -577.4005903387597 \t -179.14405714824883\n",
            "89     \t [ 1.97425396  4.64988637  4.21210059  0.11746943 -0.28979976  1.89255958\n",
            " -3.60804876  4.92181016]. \t  -407.25157871369015 \t -179.14405714824883\n",
            "90     \t [ 4.78468201  5.05985565  1.95309432 -1.41521906  1.17830244  4.22080685\n",
            " -2.26715798 -2.60530115]. \t  -297.6666083709912 \t -179.14405714824883\n",
            "91     \t [-2.45326184 -5.0957297  -4.87587091 -2.16638384  5.05977101  4.56249854\n",
            " -4.15872039 -4.46790736]. \t  -681.7136707245561 \t -179.14405714824883\n",
            "92     \t [-3.6651111  -4.91613935  1.30416596  3.81318564 -4.63741842 -4.94843592\n",
            "  5.01722023 -0.50824301]. \t  -557.7583124270807 \t -179.14405714824883\n",
            "93     \t [-1.4239411  -4.7338776   4.31109927  3.61955585  0.30515646  3.48285724\n",
            " -3.79108851  3.80731421]. \t  -444.8272376599396 \t -179.14405714824883\n",
            "94     \t [ 1.16339724 -4.82410115  0.36805958 -4.58323521  4.160855    5.08733571\n",
            " -2.14943321 -0.40490825]. \t  -407.8295073673714 \t -179.14405714824883\n",
            "95     \t [ 4.92272731  0.38316357 -5.03798328 -4.43720451  1.23262551 -3.57980692\n",
            "  2.38851832 -4.04656153]. \t  -434.84518870362996 \t -179.14405714824883\n",
            "96     \t [-4.71506588  4.78624144 -2.07916208 -0.09679898  4.01990392  4.55815533\n",
            " -5.02384676  4.67079592]. \t  -637.7170327090826 \t -179.14405714824883\n",
            "97     \t [ 3.1331172  -3.2775418  -3.88179948 -2.72435105 -4.6778556  -4.24239834\n",
            " -1.91397755  1.339144  ]. \t  -363.58339096731277 \t -179.14405714824883\n",
            "98     \t [ 4.06988253  4.28607066 -3.92501593 -0.84741056  0.04355286 -4.83972126\n",
            " -4.30530229  0.36578398]. \t  -373.7610890673372 \t -179.14405714824883\n",
            "99     \t [-4.70283868  2.4490052   3.71087316 -4.66854486 -4.70261392 -2.64076854\n",
            " -3.66473805  3.9545065 ]. \t  -534.1368747949849 \t -179.14405714824883\n",
            "100    \t [ 4.34039325 -5.00166443  3.49363536 -2.57730285  5.05973456 -4.13235133\n",
            "  3.4239275   0.99677863]. \t  -452.5327632773219 \t -179.14405714824883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq4J_FTytd4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cca2b7-3862-493a-d359-d88f43e315bc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 15\r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_loser_15 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_15 = dGPGO(surrogate_loser_15, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.79751023 -2.50366638 -2.53412486  2.14942059 -0.5370638  -2.79610411\n",
            " -1.00649405  3.91431921]. \t  -228.93586258775446 \t -111.84379356128198\n",
            "init   \t [-0.6429341   3.87507385  2.87260414  0.35035432 -4.99985399 -2.39865368\n",
            " -1.72857241  1.17580582]. \t  -247.18214418832017 \t -111.84379356128198\n",
            "init   \t [ 3.84255585 -0.47241396 -1.33929378  0.83608715  1.37927538 -3.11654164\n",
            " -0.55786658  1.52017343]. \t  -111.84379356128198 \t -111.84379356128198\n",
            "init   \t [ 3.74892071 -4.8478471  -1.40433719  2.34767012  1.9855191   0.6647632\n",
            " -3.76057172  2.51723021]. \t  -261.0681305251046 \t -111.84379356128198\n",
            "init   \t [-0.55198121 -0.67596996 -3.19596718 -4.19216237 -1.4139613  -0.32482896\n",
            " -2.05442948  4.53772941]. \t  -307.060259396398 \t -111.84379356128198\n",
            "1      \t [-0.52388747 -3.42929075  2.89517266  2.53504193  3.75358406 -1.1432719\n",
            "  4.15543613  4.50271513]. \t  -436.00483739485145 \t -111.84379356128198\n",
            "2      \t [ 4.14774515 -2.73925931 -3.09753322  0.4526622  -1.29476026  3.69406409\n",
            "  2.49410568 -2.35661698]. \t  -240.046390335786 \t -111.84379356128198\n",
            "3      \t [-2.09525434  2.85625188 -3.14465335 -4.11513009  1.1189636  -3.74713359\n",
            " -0.04451839 -3.50225484]. \t  -306.7568005812394 \t -111.84379356128198\n",
            "4      \t [ 2.30794585 -0.47809431 -1.98766893 -1.37636588  1.56641173  4.94587112\n",
            " -4.88684159 -4.82172875]. \t  -537.4129435681026 \t -111.84379356128198\n",
            "5      \t [ 5.02549587  1.117597    1.81591151 -2.3410321  -1.93506609  3.81286408\n",
            " -4.19099904  2.61844649]. \t  -343.3193897552946 \t -111.84379356128198\n",
            "6      \t [-4.0263796  -0.77383161 -2.05286055 -2.28787167 -4.97897206  0.38624297\n",
            "  0.90446435 -1.91092299]. \t  -210.77481949407985 \t -111.84379356128198\n",
            "7      \t [ 3.48232154  5.03687354 -3.01147096 -4.79352379  3.57661824  2.15634808\n",
            " -0.11212276  0.33631896]. \t  -274.83800310365143 \t -111.84379356128198\n",
            "8      \t [-5.03768506  3.53829612  2.48836388  3.38450011 -2.01893507  2.35152248\n",
            "  2.86583985  1.59267601]. \t  -246.1552212800262 \t -111.84379356128198\n",
            "9      \t [ 4.56854819  3.8372487  -3.63580412  4.98694191  4.41237249 -2.98081678\n",
            "  3.82862467  4.74467935]. \t  -622.8173527283325 \t -111.84379356128198\n",
            "10     \t [ 3.59897245 -0.60075779  5.05301321  4.3095355   0.26046326  2.61185244\n",
            " -2.46882197 -2.65365376]. \t  -304.8320789906985 \t -111.84379356128198\n",
            "11     \t [ 2.34833021 -5.11988695  5.07172838 -4.85377777 -0.17599614 -3.46856202\n",
            " -5.06975064  4.89663465]. \t  -673.4183168441568 \t -111.84379356128198\n",
            "12     \t [ 5.09447593 -2.1872201   0.59197015 -3.25114595 -4.50772758  4.63927925\n",
            "  4.97145223  4.47246255]. \t  -642.6188773944903 \t -111.84379356128198\n",
            "13     \t [-2.92054175  3.28229322  3.57371098 -4.78653471  0.05386906  2.83419154\n",
            "  1.84121191 -0.31830194]. \t  -232.78566767263152 \t -111.84379356128198\n",
            "14     \t [ 4.15875321  4.65001999 -4.70729707  4.66087436 -4.94228845  3.54640908\n",
            " -3.71048765  3.20555839]. \t  -590.0835839670559 \t -111.84379356128198\n",
            "15     \t [ 3.91212021  2.52773945  5.02637985 -3.48026889  4.07280558 -3.9793234\n",
            "  2.09866032  1.4711016 ]. \t  -378.4187476887283 \t -111.84379356128198\n",
            "16     \t [-2.92403523 -4.91169199 -0.56219093  3.87738452  3.57144051  3.22206089\n",
            "  3.91601104 -2.57059904]. \t  -404.15986524839275 \t -111.84379356128198\n",
            "17     \t [-2.8914385   1.08671104  3.7202034   0.68563558  4.35023604 -0.03197702\n",
            " -3.50651755 -1.97592856]. \t  -266.0553330118174 \t -111.84379356128198\n",
            "18     \t [-4.8710636   1.60582181 -4.29871524  4.60869162 -5.07769462  3.98908283\n",
            " -3.5168841   2.89989052]. \t  -547.5274404992564 \t -111.84379356128198\n",
            "19     \t [-1.73553666 -3.76103147  4.0475593   4.85195193 -2.9234933  -1.81836727\n",
            " -5.04424237 -0.95725435]. \t  -422.630938688367 \t -111.84379356128198\n",
            "20     \t [ 3.53749095  1.95014947 -4.63373577  5.06689628 -3.92876546 -1.1318539\n",
            "  4.3010156  -4.72593657]. \t  -580.2577885298107 \t -111.84379356128198\n",
            "21     \t [-5.00145947  4.84147102 -2.93288088  1.90710026  2.93749625  3.19723667\n",
            "  3.06872419 -4.14895115]. \t  -420.355973609686 \t -111.84379356128198\n",
            "22     \t [-4.89321921  0.67044909  2.6694813  -4.60746628  4.95292806 -4.66246971\n",
            " -2.74345119  3.79111633]. \t  -551.8913716105942 \t -111.84379356128198\n",
            "23     \t [ 3.80548816 -4.47297591 -0.52990148  3.62690297  1.17080698 -4.8662134\n",
            "  4.28426652 -3.65129538]. \t  -492.03123728392444 \t -111.84379356128198\n",
            "24     \t [-0.27212989 -4.02762662  0.0203437   4.23691424 -5.06801587  3.38706751\n",
            "  0.97670144  2.99291017]. \t  -379.91960993990267 \t -111.84379356128198\n",
            "25     \t [ 3.28280408 -4.86004996 -0.7300239  -3.3400747  -3.07250941 -2.19064267\n",
            " -2.46960669 -3.10817468]. \t  -300.21393579612385 \t -111.84379356128198\n",
            "26     \t [-2.42093556 -5.01489239  1.34351716 -2.44410711  0.69909453 -1.57665508\n",
            "  4.61405725 -3.99563531]. \t  -379.5751691687568 \t -111.84379356128198\n",
            "27     \t [-0.8704956  -2.07558054  3.77990911  3.14272296 -3.37821305 -4.63127811\n",
            "  4.8646515   0.00855032]. \t  -443.15226354920077 \t -111.84379356128198\n",
            "28     \t [ 0.18311197  4.71195689 -4.33448788  3.62255249  1.34858027  0.21366078\n",
            " -4.48232174 -3.67064753]. \t  -411.08844001015143 \t -111.84379356128198\n",
            "29     \t [ 1.65534033e+00  4.28605139e+00  1.57839601e+00  3.96939257e+00\n",
            " -2.06143120e-03  2.70495997e+00  5.10221935e+00 -3.56517399e+00]. \t  -437.7920290869329 \t -111.84379356128198\n",
            "30     \t [-4.56197848 -0.86663745  3.36407686 -2.91185916 -5.04540774 -3.45255604\n",
            "  2.43655697  4.8993994 ]. \t  -522.5726431581137 \t -111.84379356128198\n",
            "31     \t [ 4.53539239  3.39991656 -0.6703452  -4.57618355 -3.38267353 -1.26478534\n",
            "  3.32818324  1.0108024 ]. \t  -281.32445169974125 \t -111.84379356128198\n",
            "32     \t [ 5.02543486  4.27410741  4.12383291 -1.63413416 -3.8739765  -5.04322147\n",
            "  0.50570804 -3.97371061]. \t  -479.24671412225086 \t -111.84379356128198\n",
            "33     \t [-4.78838861 -4.64956131 -0.31229648 -2.69376485  4.91451828  4.02382978\n",
            " -2.25394018  0.57420334]. \t  -351.59265589106974 \t -111.84379356128198\n",
            "34     \t [ 4.81522095 -2.46836897  4.65725296 -3.49644325  4.35755382  0.2256203\n",
            " -3.9958259  -0.63123948]. \t  -359.5434023102729 \t -111.84379356128198\n",
            "35     \t [-0.04673122 -3.69781812 -2.92304684  3.41706583 -4.03134954  2.90759612\n",
            " -3.22770287 -4.1467515 ]. \t  -442.16229711771615 \t -111.84379356128198\n",
            "36     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -111.84379356128198\n",
            "37     \t [-2.58899936  3.25967556 -4.7156334   2.84133365 -0.15730322  0.58552946\n",
            "  4.47228926  4.71411969]. \t  -446.931973766469 \t -111.84379356128198\n",
            "38     \t [ 3.18211897 -3.63665185  4.93957302 -2.54564036 -4.76691554  0.01110285\n",
            "  4.52251456 -2.5745226 ]. \t  -445.5110956933015 \t -111.84379356128198\n",
            "39     \t [-4.59329134  2.13593618 -1.81428154 -4.75754736  1.27257425 -2.11006319\n",
            "  4.73482626  4.04505591]. \t  -453.27595434784484 \t -111.84379356128198\n",
            "40     \t [-4.87865974  2.0568111   1.74268696 -0.96811094  2.55981296  4.90345505\n",
            " -3.21551005  5.09561797]. \t  -502.24764839181046 \t -111.84379356128198\n",
            "41     \t [-3.8252446   4.61867952  0.72879989  3.56165727  3.18761879 -4.82491429\n",
            "  4.01281724 -4.65910072]. \t  -586.4919816007132 \t -111.84379356128198\n",
            "42     \t [-0.97249616 -4.38149479  4.61478275 -2.09220744 -0.73753982  4.7757387\n",
            "  0.68324453  1.67282229]. \t  -285.9590721654871 \t -111.84379356128198\n",
            "43     \t [-2.90091859  1.4314858  -4.44699515  4.36202213 -4.45102415 -4.60644161\n",
            " -4.5998389  -1.36446823]. \t  -537.3275966084966 \t -111.84379356128198\n",
            "44     \t [ 2.99832713  4.11968562  4.03696557 -1.08231237  0.72910515  3.95637247\n",
            "  4.90205191  3.54258301]. \t  -461.6956741486083 \t -111.84379356128198\n",
            "45     \t [ 3.71385474 -3.85925183 -1.44752699 -4.26284028  5.07158618  1.58542692\n",
            "  3.58020855 -4.98736208]. \t  -554.9554981681046 \t -111.84379356128198\n",
            "46     \t [-5.04238036 -4.88809143 -0.54100923  2.08000101  4.1893676  -3.63764978\n",
            " -4.92682848  1.90726756]. \t  -457.56197398231984 \t -111.84379356128198\n",
            "47     \t [-2.7548247   4.93410299  4.39440329  1.73918059  4.25476724 -4.23023732\n",
            "  4.32684802  4.97459614]. \t  -653.219959582728 \t -111.84379356128198\n",
            "48     \t [-2.28313577  3.4638722   0.05942026 -3.79567822 -4.93569353  4.98100222\n",
            " -5.02074166 -2.58659419]. \t  -587.4951505924079 \t -111.84379356128198\n",
            "49     \t [-4.07108799 -3.71071716 -2.82679607  4.5117079   4.76664006 -4.79790564\n",
            "  1.06599681 -3.44515064]. \t  -504.1375879151029 \t -111.84379356128198\n",
            "50     \t [ 3.18353106  2.69173732 -3.57434783  3.91161205  4.2087033   2.66152804\n",
            " -2.96533841  4.83540445]. \t  -503.8265114881208 \t -111.84379356128198\n",
            "51     \t [ 3.75589978 -4.28122825 -0.68589981 -3.48095504  3.82642022  4.47457953\n",
            "  2.94167574  4.86297022]. \t  -543.7448397382238 \t -111.84379356128198\n",
            "52     \t [-4.14529525  3.5962076  -3.54291897  2.92682512 -5.03473052  4.95409222\n",
            "  1.06475549 -3.86938704]. \t  -516.6848494340381 \t -111.84379356128198\n",
            "53     \t [-2.42580509  4.99553759 -4.04803476 -4.88732997 -1.70305538  3.32118679\n",
            "  3.69734561 -3.54122068]. \t  -477.19723618591763 \t -111.84379356128198\n",
            "54     \t [ 1.62833622  2.47427543 -4.82660524 -3.23014043 -3.03521305 -5.00519476\n",
            " -5.00318892  0.43865973]. \t  -499.6562533540806 \t -111.84379356128198\n",
            "55     \t [-3.22190568  3.4231673   4.20469012  3.80506017  2.100239   -4.64731895\n",
            " -4.11250987  4.96436387]. \t  -611.9579044185905 \t -111.84379356128198\n",
            "56     \t [-2.15618599 -4.15219492  4.73435744 -4.4914121  -4.76604735  0.38260198\n",
            " -4.66354546 -4.50546658]. \t  -616.1529045970638 \t -111.84379356128198\n",
            "57     \t [-2.13515405 -5.06611742 -4.89726449 -4.51830975  4.44597771 -4.22161232\n",
            "  2.76601529  1.01744175]. \t  -477.10310285433957 \t -111.84379356128198\n",
            "58     \t [-3.89806297 -3.39803779 -2.20456949 -3.64763333 -3.67342538  5.07928209\n",
            "  4.27258988  3.46729673]. \t  -552.3167639964997 \t -111.84379356128198\n",
            "59     \t [-0.49574855 -2.31321682  3.62655349  3.1124392  -3.92125912  4.3062726\n",
            "  3.20802661 -3.98634421]. \t  -476.46532416698744 \t -111.84379356128198\n",
            "60     \t [ 4.0677319   4.81468048 -0.50376172  4.67882702 -5.09143165  2.2509964\n",
            "  4.69718871  4.47498573]. \t  -625.9000968496756 \t -111.84379356128198\n",
            "61     \t [ 1.75961659 -3.63082762  2.56378848  4.07376943  3.41696135 -4.57459943\n",
            " -4.85259203 -4.97553359]. \t  -662.3843987004384 \t -111.84379356128198\n",
            "62     \t [ 4.59290591  1.76692903  4.3288903  -2.96907024  1.57168141  4.85828826\n",
            "  3.9603661  -4.94172708]. \t  -577.9437779934655 \t -111.84379356128198\n",
            "63     \t [ 4.94596929  4.34570262  5.08515199  4.56942148  2.61788413  5.06618136\n",
            " -3.79258788  4.03904455]. \t  -642.7884916814609 \t -111.84379356128198\n",
            "64     \t [ 4.0152087   4.43131066  2.7792571  -1.10596144  4.00887011 -4.50788763\n",
            " -4.72026993 -3.77276592]. \t  -555.5785844004531 \t -111.84379356128198\n",
            "65     \t [-3.44251966 -3.44648302 -4.20540773  4.5928151  -3.57582828  4.00222464\n",
            "  4.9457755  -2.90784706]. \t  -571.9486116679466 \t -111.84379356128198\n",
            "66     \t [ 5.06547664  3.54048027 -2.85280567 -0.84390675  5.11912781 -4.72578366\n",
            "  4.92550957 -3.4633796 ]. \t  -608.8033021647027 \t -111.84379356128198\n",
            "67     \t [ 2.34024548  4.78869672  2.64164414  2.29347154 -4.89836353  4.46059316\n",
            " -3.28282844 -3.85518285]. \t  -527.0042708316516 \t -111.84379356128198\n",
            "68     \t [-3.13848084 -4.51040857  4.76085833  4.51733385 -3.65493432  4.09797585\n",
            " -4.5592153   5.04648278]. \t  -716.954347188027 \t -111.84379356128198\n",
            "69     \t [ 3.83340596 -3.45366139  4.47254192  4.17294849  2.81400313  4.70002725\n",
            "  0.12699249  4.31329085]. \t  -489.29876376215896 \t -111.84379356128198\n",
            "70     \t [-4.23971411  2.2943966  -3.89109097 -4.54815718  3.18222485  2.61584967\n",
            " -0.49764297  1.00933439]. \t  -258.240767569897 \t -111.84379356128198\n",
            "71     \t [ 4.37734239 -1.62010583  4.83529512  3.73050474 -1.66107753 -1.66681097\n",
            " -2.03778991  4.33896981]. \t  -360.36434283295705 \t -111.84379356128198\n",
            "72     \t [-5.02123426 -4.22060935 -4.29334428  3.39530342  3.39629229  0.83537104\n",
            "  4.98079521  5.01755356]. \t  -599.17670781965 \t -111.84379356128198\n",
            "73     \t [ 3.55849609  0.9980438  -4.23442333  3.43860286  4.91930237  3.33429502\n",
            "  5.0402224  -5.03657694]. \t  -684.2086278333484 \t -111.84379356128198\n",
            "74     \t [ 2.44669597  5.03751323  2.81047641  4.72464963 -0.98437864 -5.04780635\n",
            "  1.91100183  3.01483902]. \t  -425.72962039685297 \t -111.84379356128198\n",
            "75     \t [-3.73235149 -4.77472408 -3.52801368  4.37075747  2.75990171  3.90331225\n",
            " -4.79133701 -1.5328906 ]. \t  -482.27792005082875 \t -111.84379356128198\n",
            "76     \t [-5.01143879  2.8699774  -4.70901023  2.4786914   4.75451715  0.43313557\n",
            " -1.91441203  4.91897279]. \t  -466.0660014508526 \t -111.84379356128198\n",
            "77     \t [-4.01340618  4.21062938  4.69371418 -3.38697388 -0.37030101 -3.08328625\n",
            " -3.08086918 -4.35898459]. \t  -439.7192520000723 \t -111.84379356128198\n",
            "78     \t [-4.31921884 -2.44050708  3.00849626 -4.39896651 -2.7103623   4.6276208\n",
            "  4.46257633 -4.78978075]. \t  -623.2822493041523 \t -111.84379356128198\n",
            "79     \t [-4.49874981  1.16546326 -4.59986117  1.57179277 -1.94251442 -4.85595152\n",
            "  4.99474781 -1.67829471]. \t  -453.82798477007503 \t -111.84379356128198\n",
            "80     \t [-1.89269169  4.90881099  2.72448039 -1.9495385  -5.05030912 -0.1814311\n",
            "  4.79756482 -4.79759849]. \t  -562.2239360133948 \t -111.84379356128198\n",
            "81     \t [ 4.26665992 -4.84080503 -0.36891454 -4.68797696  0.28079093 -4.48212392\n",
            "  2.27294455  2.99335605]. \t  -382.1641878536109 \t -111.84379356128198\n",
            "82     \t [ 1.27040319 -1.42042754 -4.30060053 -4.04015395  4.39865438 -4.47069341\n",
            " -4.99108775  0.23026219]. \t  -517.8902864586751 \t -111.84379356128198\n",
            "83     \t [ 3.63806693  1.58823031  0.30972912 -4.92744736 -2.85748717  2.71814113\n",
            " -1.08637682 -4.78621983]. \t  -392.3678441570606 \t -111.84379356128198\n",
            "84     \t [-5.12       -2.58560065 -2.43046406 -3.88938802  0.75319509  0.20914706\n",
            " -5.12       -2.98806343]. \t  -375.8438381851538 \t -111.84379356128198\n",
            "85     \t [-4.38817144 -2.18483043  4.26072436 -1.30472637 -4.90749577 -4.78705908\n",
            " -0.28787049 -3.07782913]. \t  -424.3511014174213 \t -111.84379356128198\n",
            "86     \t [-4.78100315 -3.34659814  3.43073775 -2.81229735  4.99064554  1.69921456\n",
            "  4.76268769  1.59417227]. \t  -433.17351469771495 \t -111.84379356128198\n",
            "87     \t [-2.26873459 -4.30805234 -4.94983089 -0.93676302 -4.40740389 -4.40846993\n",
            " -4.3292443   2.12807384]. \t  -500.4381316509543 \t -111.84379356128198\n",
            "88     \t [-4.63010611  2.91835566  3.19528694  4.98869494 -2.90345445  2.31318501\n",
            " -3.23004553 -3.59963981]. \t  -419.59616820846253 \t -111.84379356128198\n",
            "89     \t [-0.25768145  5.02845623  1.84019905 -2.16881434  3.33678961 -0.71695409\n",
            " -2.51409344  3.59434839]. \t  -285.9655110166432 \t -111.84379356128198\n",
            "90     \t [-4.47633853 -4.25027738  4.85977827  4.43887875  0.64686361 -4.99025723\n",
            " -1.79717551  3.97898228]. \t  -506.6096795039171 \t -111.84379356128198\n",
            "91     \t [ 3.40228584  0.17225395 -4.43869689  3.6978509  -4.87884532 -3.29927473\n",
            "  4.66472545  4.2569522 ]. \t  -607.0551083317055 \t -111.84379356128198\n",
            "92     \t [ 4.5378625  -1.80876201 -3.95117531  2.24705083  0.53434204  3.51827104\n",
            "  3.01191216  4.67405243]. \t  -408.14017154242356 \t -111.84379356128198\n",
            "93     \t [-0.42284189 -0.47297103 -3.73556293  2.41370649  5.07232732  1.75686633\n",
            " -0.8392576  -0.74770289]. \t  -222.35835394533882 \t -111.84379356128198\n",
            "94     \t [-2.72576676 -3.81156201 -4.12643414 -1.57943159 -2.56680335 -4.94562421\n",
            "  4.27985494  4.53068724]. \t  -569.6813199556725 \t -111.84379356128198\n",
            "95     \t [-5.12       -0.97154723 -0.61269536  0.04164009 -5.12       -1.48020696\n",
            " -5.12       -5.12      ]. \t  -566.6694062756596 \t -111.84379356128198\n",
            "96     \t [-4.15963825 -4.09644011  2.67405762 -0.27984747 -4.29195875 -2.36153346\n",
            " -3.96968761  4.43640363]. \t  -465.95719130923317 \t -111.84379356128198\n",
            "97     \t [ 5.03420759  5.05985813  3.90938694  3.21612961 -2.36765556 -1.65188165\n",
            " -4.60619828 -1.22937043]. \t  -368.78294592597354 \t -111.84379356128198\n",
            "98     \t [ 3.22689607 -0.33237271  0.74126573 -1.26206352  5.11724439  3.47968663\n",
            " -3.57609043  3.76776708]. \t  -425.32121827512094 \t -111.84379356128198\n",
            "99     \t [ 2.18951103  3.79632194 -4.70109151 -4.52416869  2.01531603 -2.91719319\n",
            "  2.99415587  4.22945682]. \t  -459.02008810909047 \t -111.84379356128198\n",
            "100    \t [ 1.3215368   1.8356774  -4.02849969  5.08636125  3.1340806  -5.04905694\n",
            "  4.89044952 -1.61192216]. \t  -550.9285763784783 \t -111.84379356128198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tJ-ta9Gtd7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9e62c4-3b69-4398-c949-3799776ab63c"
      },
      "source": [
        "\r\n",
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 16\r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_loser_16 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_16 = dGPGO(surrogate_loser_16, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.72683092 -1.88041214  1.76282397  0.08101548  2.88420277 -2.21509961\n",
            " -2.72682205  0.65330879]. \t  -156.8066019097497 \t -156.8066019097497\n",
            "init   \t [ 3.84024949  2.2419755  -3.25497095 -2.62348378 -4.23877911  0.35067282\n",
            "  3.47852441 -0.5561546 ]. \t  -261.8650591886947 \t -156.8066019097497\n",
            "init   \t [ 0.26105361  3.64645501 -0.31006696  0.15828746  1.76956804 -4.75312845\n",
            " -1.21380639  1.33368774]. \t  -202.8033628398822 \t -156.8066019097497\n",
            "init   \t [ 1.67575729 -3.93174065 -4.05292123 -2.2111691  -3.83176859  3.19394297\n",
            " -2.91057129  0.66405444]. \t  -300.0085240682813 \t -156.8066019097497\n",
            "init   \t [-1.33059735  4.11084689 -1.25252503 -4.4633888  -4.89127772 -0.62411111\n",
            " -2.74874149  4.74659878]. \t  -475.05316372608854 \t -156.8066019097497\n",
            "1      \t [-4.38660667  1.62450493 -1.22519012  1.94388211  1.6423205   4.26907265\n",
            "  2.26974299  0.96861339]. \t  -210.5421323027258 \t -156.8066019097497\n",
            "2      \t [ 2.61028241 -3.36468155  0.93627224 -0.42091032 -2.46815808  0.35245197\n",
            "  0.09302001 -4.97280011]. \t  -261.8890695362936 \t -156.8066019097497\n",
            "3      \t [ 3.08840881  1.09355518 -2.27221671  0.20362313  5.04563824  3.88780797\n",
            "  4.45226401  4.09078879]. \t  -518.2023890662198 \t -156.8066019097497\n",
            "4      \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -156.8066019097497\n",
            "5      \t [-1.74419421 -2.97566387 -2.51770045 -0.22404063 -2.57004044 -3.18775746\n",
            "  2.26407505  4.33743539]. \t  -320.3539300741578 \t -156.8066019097497\n",
            "6      \t [ 2.96013115 -1.73092944  4.21146258 -2.95046952 -3.23495797  4.98687786\n",
            " -1.2761485   2.59996815]. \t  -369.8019723735642 \t -156.8066019097497\n",
            "7      \t [ 1.06085603  1.66769511  1.968799   -4.40016384  1.25028225  3.81733385\n",
            "  2.80577966 -1.3908571 ]. \t  -261.59302478121987 \t -156.8066019097497\n",
            "8      \t [-5.0154287   4.08468976 -5.10290307  3.05064696 -0.88664699  3.30734321\n",
            " -2.93221677 -3.757143  ]. \t  -416.54463631790196 \t -156.8066019097497\n",
            "9      \t [ 1.36723193  0.52425837 -4.65019601  4.93451875  0.75602746  0.68584194\n",
            "  2.25857245 -2.83815146]. \t  -270.5189253477478 \t -156.8066019097497\n",
            "10     \t [2.80027156 4.68890317 3.61855726 0.29264533 0.82952492 0.13475458\n",
            " 3.5531842  4.90102322]. \t  -375.52314712782993 \t -156.8066019097497\n",
            "11     \t [-4.93635129  2.55766944 -1.25848161  4.96559818 -1.43852606 -4.19444241\n",
            " -3.63998264 -3.7665619 ]. \t  -462.979991392237 \t -156.8066019097497\n",
            "12     \t [ 5.07381016 -0.62423772  3.32699763  4.55494027  2.87215991 -1.83760387\n",
            "  4.50582748 -1.87362703]. \t  -374.427993928474 \t -156.8066019097497\n",
            "13     \t [-2.72961452  4.59025582 -2.96237344 -0.34812156 -3.11193657 -3.98737154\n",
            "  3.84133375 -3.66064947]. \t  -430.7127037238413 \t -156.8066019097497\n",
            "14     \t [-2.96527307 -1.76419803 -3.96077435  4.52370751 -1.63436906  2.15953412\n",
            " -4.7718135   5.11170367]. \t  -553.7014335008497 \t -156.8066019097497\n",
            "15     \t [-4.44703603  4.54410352  4.11500256 -1.08286348  4.70679157  0.0671524\n",
            "  1.95659366  2.65975533]. \t  -310.7526839529857 \t -156.8066019097497\n",
            "16     \t [ 2.05381102  3.48611571  1.32054164  3.83589645  5.10022843  3.38232249\n",
            " -1.55773674 -3.09758995]. \t  -385.06063924382283 \t -156.8066019097497\n",
            "17     \t [-3.27180474  1.18483204  3.52227647 -3.41817601  2.50827484 -2.89990888\n",
            " -4.91003641 -4.66574765]. \t  -522.2942179348121 \t -156.8066019097497\n",
            "18     \t [ 2.64195265  4.08828057  5.11149862  1.50586971 -2.83926318  3.63957421\n",
            " -3.16295414 -2.43981117]. \t  -365.2982787729772 \t -156.8066019097497\n",
            "19     \t [-4.71861438 -4.38219512 -4.52160463 -4.3855915   3.38271861  1.48867488\n",
            "  0.17979007  1.17968276]. \t  -280.81129206841615 \t -156.8066019097497\n",
            "20     \t [-2.92825457  4.37622271 -4.21905334 -1.39039833  4.14848906  1.30862285\n",
            "  3.60128232 -5.05976184]. \t  -499.9303181123679 \t -156.8066019097497\n",
            "21     \t [ 4.04177992  1.47428667 -3.67172479  2.25261872 -4.38548637 -4.39066273\n",
            " -1.00623256 -4.65900297]. \t  -473.99284623621605 \t -156.8066019097497\n",
            "22     \t [-3.74983704 -3.56612205  3.89050857  1.34039754 -2.01613595  2.15190847\n",
            " -4.84291874 -0.28991912]. \t  -305.04830334632646 \t -156.8066019097497\n",
            "23     \t [-4.19854992  0.57139142  3.95725345 -1.67479664 -3.41688133 -0.57872753\n",
            "  3.86077617  0.64648399]. \t  -244.5477616911439 \t -156.8066019097497\n",
            "24     \t [ 4.85984191 -2.58365977  2.46734373  0.87176038 -4.16633707 -5.03058942\n",
            "  2.73456725  0.62874669]. \t  -352.41226651159417 \t -156.8066019097497\n",
            "25     \t [ 4.49795841 -3.69120205 -3.54131365 -3.92642595  3.41119339 -3.05068281\n",
            "  3.6368887   3.59239053]. \t  -456.6236345831135 \t -156.8066019097497\n",
            "26     \t [ 4.63972944  0.11753145 -1.38745268 -2.81489601  4.36834737  4.38362357\n",
            " -3.8424548  -3.07612649]. \t  -448.78522260279846 \t -156.8066019097497\n",
            "27     \t [-1.0595955  -3.55484511 -1.32588813 -4.30273363 -1.5678672  -4.50387203\n",
            "  4.56502399 -3.05128661]. \t  -460.08372011003786 \t -156.8066019097497\n",
            "28     \t [-2.35157916 -3.97864633 -3.75167564  3.06783018  2.74940641 -2.59671001\n",
            " -2.56868701 -3.41527267]. \t  -334.814081806295 \t -156.8066019097497\n",
            "29     \t [-1.07747177  5.00573725  2.54191571 -4.46743956 -3.70664373 -0.55836378\n",
            " -0.61914349 -4.71966964]. \t  -401.94410970687176 \t -156.8066019097497\n",
            "30     \t [-2.55530499 -4.22957844  0.91909462 -4.33924534  0.90277014 -2.86544281\n",
            " -4.40318032  4.49665213]. \t  -470.9732231318807 \t -156.8066019097497\n",
            "31     \t [ 1.19046239 -2.13713324  3.6576483   4.66306061  0.78705052  3.56359559\n",
            "  0.71301848  3.02711458]. \t  -293.822260445507 \t -156.8066019097497\n",
            "32     \t [-3.20429685 -4.07318169  3.37863001 -4.75400043  4.88396739  4.42329491\n",
            " -1.36748758  3.7266871 ]. \t  -528.9512834546574 \t -156.8066019097497\n",
            "33     \t [ 3.46790688 -4.16438465  2.20292265 -2.81898532  4.06417982  0.17076047\n",
            "  5.05171924 -5.00057051]. \t  -554.5033518274639 \t -156.8066019097497\n",
            "34     \t [-4.25167978  4.65469243  2.22069625  4.55644664  5.02231669  0.17278159\n",
            " -4.83861862  1.05240318]. \t  -458.29187996727217 \t -156.8066019097497\n",
            "35     \t [ 4.99763937  0.65772135  2.94094802 -4.23517263 -4.85013069 -4.59565853\n",
            " -2.03430448 -4.69569585]. \t  -573.2404098277572 \t -156.8066019097497\n",
            "36     \t [ 4.34238335  4.56699517  4.76809233 -4.76071053  0.35997674 -1.80077692\n",
            " -2.87997269  3.79957261]. \t  -413.0911716059033 \t -156.8066019097497\n",
            "37     \t [ 1.92571017 -0.21444117 -0.8520663   2.25417202 -4.7728601  -4.2596061\n",
            " -5.09256537  2.69575398]. \t  -488.7462495117321 \t -156.8066019097497\n",
            "38     \t [-2.30198491 -4.114028    3.56192318  3.2929331   2.72420648 -5.01135253\n",
            "  2.64281867 -0.09961387]. \t  -357.3443576764738 \t -156.8066019097497\n",
            "39     \t [-0.12434784  2.0880431   0.82521549  2.30521646 -4.78558349  2.47975489\n",
            "  4.6476726  -4.5208526 ]. \t  -498.149386328132 \t -156.8066019097497\n",
            "40     \t [ 4.67817331  4.55849632  4.85491302  3.7919512   4.54193498 -1.255337\n",
            " -3.44744091  4.47427749]. \t  -547.6195074696037 \t -156.8066019097497\n",
            "41     \t [ 4.35868468  4.81316319 -3.46033865 -3.71173163  4.30990807 -4.98813767\n",
            "  4.05920002 -3.92788529]. \t  -637.2924880100421 \t -156.8066019097497\n",
            "42     \t [-3.05974479 -4.61837211 -3.65231133  4.5489212  -4.32468498 -0.3021903\n",
            "  1.65656208 -4.22256957]. \t  -430.7221812734539 \t -156.8066019097497\n",
            "43     \t [-5.02158726  5.1097137  -0.59690091  3.98036252 -4.34853118 -0.23054776\n",
            " -3.31823151  4.11311684]. \t  -449.16069652107547 \t -156.8066019097497\n",
            "44     \t [ 4.08753094  3.80278865  0.51545972  4.84931683 -2.57791904  2.7718704\n",
            " -4.83079829  4.02783282]. \t  -512.9626120735163 \t -156.8066019097497\n",
            "45     \t [ 2.64335899  3.98200935 -4.07498359  2.42315181 -3.61422848 -3.69307168\n",
            "  2.57443626  4.92295351]. \t  -499.42700953233043 \t -156.8066019097497\n",
            "46     \t [ 0.68933462 -4.67434863 -3.60331356  4.78178738 -0.57047737  4.77416528\n",
            " -2.94450954 -3.95865409]. \t  -499.0294602618772 \t -156.8066019097497\n",
            "47     \t [-4.54712993 -4.26239023 -4.13988938  3.82109803  4.38574439 -0.83199017\n",
            "  1.10828074  4.58755041]. \t  -444.121512449962 \t -156.8066019097497\n",
            "48     \t [-3.72935728 -4.90281907  3.75412801  3.63958098  4.26317254 -0.85318639\n",
            " -3.95705375  4.98193725]. \t  -560.6562795233859 \t -156.8066019097497\n",
            "49     \t [-4.16258209  4.20157019 -3.12697445 -5.06627257  3.02287935  0.05464522\n",
            " -4.93149115 -1.05979617]. \t  -409.56534473368544 \t -156.8066019097497\n",
            "50     \t [-4.36430814 -4.60586277  3.85578681  1.20298627  1.25474422  5.02032013\n",
            "  4.38456929 -4.86674853]. \t  -595.0117747648459 \t -156.8066019097497\n",
            "51     \t [-4.17289804 -4.82385459  3.86174958 -4.4961787   1.51165099 -3.00276542\n",
            "  4.29234611  1.93929009]. \t  -414.1355042642413 \t -156.8066019097497\n",
            "52     \t [ 0.38928272  2.45928827 -3.81558986  2.97925771 -4.01645693  4.30021725\n",
            "  3.49268127  4.85463923]. \t  -556.9705978745857 \t -156.8066019097497\n",
            "53     \t [-4.79228502  0.40138387 -3.11677753 -4.64933422 -3.63985244  4.1161407\n",
            "  0.55276204 -1.77320626]. \t  -334.08757433690084 \t -156.8066019097497\n",
            "54     \t [ 1.56442697  3.6107359   4.78737444  2.57588286 -2.37779314 -4.57260313\n",
            "  3.06106236 -4.01586817]. \t  -472.1498056362909 \t -156.8066019097497\n",
            "55     \t [-1.33749447  3.49192936  0.30925999 -4.34185663 -4.72338305  3.01372465\n",
            "  4.35283366  4.82990019]. \t  -587.1704011304056 \t -156.8066019097497\n",
            "56     \t [ 4.98339761 -4.65246746 -4.93246837  4.40853799 -4.15153762  3.73959306\n",
            " -0.64731686  5.03082798]. \t  -594.3443563388361 \t -156.8066019097497\n",
            "57     \t [ 4.94413429 -3.11209493  4.57092772 -4.81806223 -3.70957362 -5.08477405\n",
            " -4.54286958  4.73206618]. \t  -746.8872643939474 \t -156.8066019097497\n",
            "58     \t [ 0.69067887  3.53713085  5.01788291 -2.76518872  4.46177056 -4.79087156\n",
            "  4.73562403 -2.37873488]. \t  -571.1238146022156 \t -156.8066019097497\n",
            "59     \t [ 5.03193175 -3.74793919 -3.9667936   3.83745279  0.61926464 -3.6318395\n",
            "  4.03096925  2.9993484 ]. \t  -426.29367423756264 \t -156.8066019097497\n",
            "60     \t [ 4.68546823  0.17925963  2.7234062  -3.90654977  5.08516265  4.19331226\n",
            " -4.66180498  4.86634981]. \t  -681.6886945532783 \t -156.8066019097497\n",
            "61     \t [ 0.4763013   4.15421911 -3.38098029 -4.91546583 -4.38445348 -3.62870496\n",
            " -5.02401865 -1.54820463]. \t  -536.6652403478621 \t -156.8066019097497\n",
            "62     \t [ 2.80789369  4.45935277 -5.00207449  3.0289322   4.76926865 -4.66913859\n",
            " -0.82609146 -4.70333051]. \t  -585.6981711694061 \t -156.8066019097497\n",
            "63     \t [ 3.97298031 -4.95943973 -3.53831788 -1.9433322   2.11117481 -1.46898094\n",
            " -4.54042793  5.11999683]. \t  -506.8979638507151 \t -156.8066019097497\n",
            "64     \t [-4.31152103  4.75173366  3.17060533 -3.70875683  2.52846913  4.88450014\n",
            " -4.48256072  4.87463128]. \t  -654.7904083706412 \t -156.8066019097497\n",
            "65     \t [ 2.51703577 -1.35795279 -4.0080319  -3.67928453  3.84941531 -4.31595722\n",
            " -4.98218848 -4.57496353]. \t  -639.4176946091469 \t -156.8066019097497\n",
            "66     \t [-1.49266722 -5.0730271  -5.0154347  -0.07242736  1.2163098   3.07735925\n",
            "  4.72461672 -2.18737341]. \t  -387.93273053954425 \t -156.8066019097497\n",
            "67     \t [-4.27049113 -1.21087166  1.939069   -3.76357723 -5.12       -4.39866566\n",
            " -2.65477471 -2.44744663]. \t  -433.5238536971619 \t -156.8066019097497\n",
            "68     \t [-4.31120081 -3.48565453  4.81111697  4.39240957  4.64762173 -4.17640837\n",
            " -5.10889015 -5.03509758]. \t  -787.6788454712179 \t -156.8066019097497\n",
            "69     \t [ 0.43800157  4.30840128 -3.58244185 -1.58323388  3.45252817  4.19930558\n",
            " -3.36792261  4.92042548]. \t  -524.3344480420718 \t -156.8066019097497\n",
            "70     \t [ 4.7406347  -4.94073952 -4.97769492 -1.227366    4.92522413 -4.73939477\n",
            "  1.88806247 -4.82528898]. \t  -618.9345901186159 \t -156.8066019097497\n",
            "71     \t [ 0.36827569 -5.12       -5.12       -0.7294947  -5.07555503 -5.12\n",
            " -1.16119491 -2.22453233]. \t  -468.4559394892432 \t -156.8066019097497\n",
            "72     \t [ 3.31154611  4.91078165 -2.25045129 -4.15549656 -4.45978752  5.08781276\n",
            " -2.38019905 -2.56991092]. \t  -490.72061585048397 \t -156.8066019097497\n",
            "73     \t [-4.68282726 -1.29259918  3.66621666 -3.60760487 -3.77784607  4.83427581\n",
            " -1.0231259   5.10538726]. \t  -545.0824604322567 \t -156.8066019097497\n",
            "74     \t [-5.07883318  1.83951699 -2.77788822 -3.22528062  4.41746685 -2.82831034\n",
            "  0.8278771   3.16367177]. \t  -327.75624028122536 \t -156.8066019097497\n",
            "75     \t [-4.77420929  3.74037609  2.8511903  -0.28202959 -3.2704286   4.22960311\n",
            " -1.22728009 -2.07681254]. \t  -281.3444110344335 \t -156.8066019097497\n",
            "76     \t [-2.78310225  1.56956308  2.95021309  3.96197501 -2.00831896 -5.00854206\n",
            "  1.60312366  4.85367324]. \t  -478.7078463101761 \t -156.8066019097497\n",
            "77     \t [ 4.05734676  3.36639869  4.69039279  4.95449571 -4.11467526 -4.3741028\n",
            " -4.66153594 -3.32685176]. \t  -643.4171839206099 \t -156.8066019097497\n",
            "78     \t [-3.64288651  2.86532304  0.59494027  4.97251567  3.79592075 -3.02523476\n",
            "  2.60527676 -2.42981478]. \t  -351.357896492636 \t -156.8066019097497\n",
            "79     \t [-1.39944958 -4.57111086 -2.85769668 -4.80214142 -4.43410974  4.36345104\n",
            "  5.04011352  1.85433985]. \t  -578.3628047256431 \t -156.8066019097497\n",
            "80     \t [-4.23655806 -3.77295404  2.65779993  4.9706204  -4.75462082 -3.89693366\n",
            "  5.08220057 -2.25712082]. \t  -592.1455000710192 \t -156.8066019097497\n",
            "81     \t [ 3.91331994 -1.70528395 -2.7501124   3.92755617  2.63457054  3.06134163\n",
            " -2.93436764  2.88550943]. \t  -323.340800794046 \t -156.8066019097497\n",
            "82     \t [ 3.30646965 -5.02627818  0.14842361  4.85251825 -4.95131932 -0.16359081\n",
            "  4.33541336  1.31883648]. \t  -423.9371951886513 \t -156.8066019097497\n",
            "83     \t [ 4.41513579 -4.65017503  5.01186831 -4.77910365 -4.64795289 -2.24396366\n",
            "  4.1561525  -2.54906907]. \t  -540.5842961065252 \t -156.8066019097497\n",
            "84     \t [-4.74064599 -4.64053424 -0.17329318  5.03521545 -3.22631304  2.92968065\n",
            "  4.81193412  3.43691164]. \t  -527.1720254950577 \t -156.8066019097497\n",
            "85     \t [-4.71679307 -4.78655347 -0.39613236  4.67803275 -3.95699707 -4.65887398\n",
            " -2.59444467  0.29533981]. \t  -412.412625447318 \t -156.8066019097497\n",
            "86     \t [ 4.38441813  4.66433428  4.36577041  3.76990138  5.00052777 -4.81842973\n",
            " -0.23452378 -2.23454335]. \t  -481.42409197172003 \t -156.8066019097497\n",
            "87     \t [ 4.74052362 -4.90020741  3.68886502  0.75126241  4.97188607 -0.51037276\n",
            "  3.87328151  4.36089863]. \t  -495.89418572383585 \t -156.8066019097497\n",
            "88     \t [ 3.75127274  4.87856292  0.52604642 -5.11802604  4.89870845 -4.04161314\n",
            "  4.15279364  4.47844416]. \t  -666.4458415787577 \t -156.8066019097497\n",
            "89     \t [-1.06075232  3.57064984 -4.57317015  3.56232704  4.62262133 -3.38849267\n",
            "  4.77002714  3.40096023]. \t  -567.6654191663055 \t -156.8066019097497\n",
            "90     \t [ 3.86696864 -4.44896075  5.07363234  4.152372   -2.83968277  3.50059329\n",
            " -4.73081938 -2.6385061 ]. \t  -526.9361493583731 \t -156.8066019097497\n",
            "91     \t [ 5.06778894 -4.63937613  0.50160176 -4.7015424  -3.78591906  4.57577504\n",
            "  3.88580641 -2.17499258]. \t  -498.73632377493385 \t -156.8066019097497\n",
            "92     \t [ 4.0449472  -3.86912304 -4.74521388 -4.31080674  0.41533456  4.93114062\n",
            "  3.16956359  3.9284262 ]. \t  -528.7278011504524 \t -156.8066019097497\n",
            "93     \t [-3.0832531  -4.79975059  0.16118056 -4.55243499 -0.39256642  2.75448107\n",
            " -3.99642047 -3.04425369]. \t  -370.7912740148163 \t -156.8066019097497\n",
            "94     \t [-0.73074114 -5.12       -5.12       -5.12        0.07042234 -5.12\n",
            " -5.12        0.00749089]. \t  -577.276028055549 \t -156.8066019097497\n",
            "95     \t [ 2.14503281 -1.10545975  4.10182492 -4.90252613  2.22436723 -1.63971245\n",
            "  2.82918696  2.2879954 ]. \t  -292.43966596296974 \t -156.8066019097497\n",
            "96     \t [ 0.40666819  4.62069211  3.05896749  4.40493463 -3.84277455  5.07967679\n",
            "  1.41055262  2.34161851]. \t  -434.9989204655395 \t -156.8066019097497\n",
            "97     \t [-0.40849909 -0.36837898  4.94197703 -1.42042469  3.42165913  3.76147471\n",
            " -3.60124114 -4.25756144]. \t  -461.00622115379997 \t -156.8066019097497\n",
            "98     \t [-5.12       -0.9872672  -5.12       -3.80792862 -1.36346807 -2.48965557\n",
            "  0.16788522 -5.12      ]. \t  -421.2063077287768 \t -156.8066019097497\n",
            "99     \t [-4.64578004  4.4108803  -4.84186472 -1.89028612  0.40988279  2.19124074\n",
            "  5.09304644  4.33215512]. \t  -506.48232419678163 \t -156.8066019097497\n",
            "100    \t [-1.89038501 -0.11112047  5.02357901  4.77948769  1.90872023  0.50725108\n",
            " -2.09580579 -2.40036336]. \t  -267.28195372454275 \t -156.8066019097497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqjDLo0otd9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d95485-1ec1-4639-cfbe-b3204188f618"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 17\r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_loser_17 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_17 = dGPGO(surrogate_loser_17, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.55467805  2.36052095 -3.13991821  0.20149492  1.80616465  3.1175155\n",
            "  0.34317173  4.17827   ]. \t  -258.41326242861834 \t -235.79782281711795\n",
            "init   \t [-0.57875324 -2.49884457 -2.26647022 -4.67638414 -0.31769608  4.52212527\n",
            "  1.02815985  3.77559691]. \t  -360.3515407216042 \t -235.79782281711795\n",
            "init   \t [-1.56342663  0.20561354 -4.2801447   1.05706761 -4.41947127 -0.8235598\n",
            "  0.12249555 -4.00962754]. \t  -292.4074163867352 \t -235.79782281711795\n",
            "init   \t [ 4.87253618  0.77758176  1.94038044  4.01713279  4.85251496 -0.60490047\n",
            " -0.9483114   1.04745517]. \t  -235.79782281711795 \t -235.79782281711795\n",
            "init   \t [-1.91993985 -0.06178726  4.23457571  3.73427573  1.95047484 -4.92945438\n",
            "  2.09212815 -3.62478353]. \t  -413.83828931150714 \t -235.79782281711795\n",
            "1      \t [4.51401957 4.23400766 4.83433318 3.1296932  0.24588569 1.21802929\n",
            " 4.61282793 1.4098879 ]. \t  -339.57567715308704 \t -235.79782281711795\n",
            "2      \t [ 0.44209635  3.94428873 -2.87035824 -2.26924831  3.90993901 -4.45930514\n",
            "  2.82734457 -3.75319363]. \t  -441.0244672495591 \t -235.79782281711795\n",
            "3      \t [ 4.42595181  0.54614973  2.56689034 -3.13851565  1.0307697   2.47296272\n",
            " -4.33428986  0.81887648]. \t  -258.2261564362497 \t -235.79782281711795\n",
            "4      \t [-4.20941955 -4.31584018  2.06026664 -5.09485394  2.09607399 -2.80668053\n",
            "  1.0900119  -2.6554595 ]. \t  -305.49737571712524 \t -235.79782281711795\n",
            "5      \t [ 2.67117625  0.41299568  4.43883274  0.14211974 -1.31876413 -4.67433041\n",
            " -3.51524601 -1.16802904]. \t  -303.8717125415504 \t -235.79782281711795\n",
            "6      \t [-3.54981102  1.64712868  4.75022021 -2.68762755 -1.76612738  1.29808464\n",
            " -3.65160611  1.34769435]. \t  -248.19037042791027 \t -235.79782281711795\n",
            "7      \t [-4.43446054  5.08197854  0.75076171  2.56198624  1.63763772  2.63852708\n",
            " -0.19299006 -0.12646221]. \t  \u001b[92m-154.83237029755054\u001b[0m \t -154.83237029755054\n",
            "8      \t [-1.30613858 -4.33854085 -3.37026713  1.0355193   2.91986214  3.43611244\n",
            "  0.95342411 -1.86829135]. \t  -225.4735839852827 \t -154.83237029755054\n",
            "9      \t [ 1.09944193 -4.64316009 -3.32041737  2.08789452 -0.15464131 -4.29343284\n",
            "  1.9320331  -0.92008962]. \t  -238.46211790406912 \t -154.83237029755054\n",
            "10     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -154.83237029755054\n",
            "11     \t [ 2.95580948 -3.80049642 -4.96869453 -4.6953779  -4.79816573 -1.50424847\n",
            "  4.43468588 -0.72526383]. \t  -470.43611167134793 \t -154.83237029755054\n",
            "12     \t [-2.54364523  2.33883604  1.42069182 -4.05636986  3.70664301 -4.68960538\n",
            " -2.58664462  3.81251026]. \t  -453.04947291990277 \t -154.83237029755054\n",
            "13     \t [ 1.52304157 -2.35739009  0.7121777  -2.0496404  -3.69428374  4.58362589\n",
            " -2.43696327 -4.6762387 ]. \t  -442.5655423406065 \t -154.83237029755054\n",
            "14     \t [-4.22613976 -4.34074043 -4.81022554 -2.1370736   3.949608   -2.39092025\n",
            " -4.69858406  2.82883722]. \t  -474.0788755252838 \t -154.83237029755054\n",
            "15     \t [-4.80561505  3.37060646 -4.87158689 -0.42857934 -4.1316635   3.99450207\n",
            " -4.83850869  1.29478781]. \t  -476.12717467218414 \t -154.83237029755054\n",
            "16     \t [-0.15670324 -5.04547588  1.8267038   4.65806376 -3.75485528  3.37965816\n",
            "  3.71343154  1.82109122]. \t  -409.82421093482986 \t -154.83237029755054\n",
            "17     \t [ 4.78287702  3.12011018 -4.47839917 -2.24195684  4.59736692  3.8551014\n",
            "  0.51524812 -4.45400124]. \t  -478.0328814172733 \t -154.83237029755054\n",
            "18     \t [ 2.65953549 -3.70240546  2.94277433 -2.82448482  3.21976706  4.78076477\n",
            "  2.56065292 -1.06721442]. \t  -336.35830842717144 \t -154.83237029755054\n",
            "19     \t [ 0.56271723  3.93400983 -2.96044792 -5.01647803 -3.18069993 -1.38919401\n",
            "  4.82780518  2.71372461]. \t  -442.4542307084757 \t -154.83237029755054\n",
            "20     \t [-4.29450336  1.34782329 -4.44199496  4.43142777  0.47836868 -3.59255955\n",
            " -4.43738931  3.13143828]. \t  -454.68348084492396 \t -154.83237029755054\n",
            "21     \t [ 4.37155703 -1.02106606 -3.20646551 -0.47853375 -2.12385517 -3.63953652\n",
            " -3.59765806  3.75988674]. \t  -358.6830554758044 \t -154.83237029755054\n",
            "22     \t [ 1.08628319 -3.48748274  2.64021664  4.74032863  2.12378142  4.07071807\n",
            " -5.06192383 -1.46736377]. \t  -454.8636497255348 \t -154.83237029755054\n",
            "23     \t [-0.91364106 -4.0439668   2.63080503  2.87769095 -2.09830823 -2.05772773\n",
            " -2.7151601   4.27505243]. \t  -332.6630954149689 \t -154.83237029755054\n",
            "24     \t [ 5.01294029  4.43078465  0.66675486 -4.80069846 -4.78779884 -1.54983127\n",
            "  0.93312558 -3.0990618 ]. \t  -369.8692706852889 \t -154.83237029755054\n",
            "25     \t [-3.63476077  1.47298641  1.12651813  2.31550021 -3.34031307 -2.52281659\n",
            "  4.87011629  2.77773774]. \t  -364.5330806939506 \t -154.83237029755054\n",
            "26     \t [ 4.63517341  4.18357754  3.80711143  4.96063791 -3.68901948  4.11015782\n",
            " -5.02450531  1.92593404]. \t  -574.2015388377874 \t -154.83237029755054\n",
            "27     \t [ 3.59824761  5.07966004 -3.87096221  3.3794435  -0.92898592 -4.09273405\n",
            "  3.3233557   3.81448938]. \t  -453.7222685895868 \t -154.83237029755054\n",
            "28     \t [ 0.52899705  1.95534651 -0.86623995  3.03036951  5.00130821  4.61625821\n",
            "  4.99187172 -4.62651533]. \t  -645.5033638990153 \t -154.83237029755054\n",
            "29     \t [-0.19455442 -1.03866557 -1.89682342 -3.60794238  2.73980629 -4.49568544\n",
            " -4.97663562 -4.42579398]. \t  -553.9276647917729 \t -154.83237029755054\n",
            "30     \t [ 3.27623503 -1.21231288  2.88164635 -4.69764225 -4.88611499 -4.79671156\n",
            "  3.09869778  4.59984694]. \t  -620.7596285002005 \t -154.83237029755054\n",
            "31     \t [ 3.00421713 -2.40527194  3.83172606 -2.64846671 -4.16644571  3.721191\n",
            "  4.51825089  4.91896586]. \t  -599.0517271851368 \t -154.83237029755054\n",
            "32     \t [-5.00425446 -4.22243866  4.15918476  1.89921928  0.80078413  1.20751011\n",
            " -0.82049246 -3.9734022 ]. \t  -269.99574389958815 \t -154.83237029755054\n",
            "33     \t [-3.90590302 -2.07382626 -4.57162499  4.42836715 -0.22347088  4.33624174\n",
            "  1.13577027  5.00255495]. \t  -487.30051426579985 \t -154.83237029755054\n",
            "34     \t [-1.29698167  3.13657913  4.32072857 -2.66170263  0.17057728  3.10344997\n",
            "  5.05826999 -2.79002998]. \t  -405.01384764425046 \t -154.83237029755054\n",
            "35     \t [-3.14787765 -1.45190597  3.6662123  -0.54774788  3.69039092  2.12511912\n",
            "  0.60060294  4.0857959 ]. \t  -286.9152498939917 \t -154.83237029755054\n",
            "36     \t [ 4.76254396  3.08572617 -0.44898445  4.81856549 -4.5420816   3.05134397\n",
            " -1.68595412 -4.92107743]. \t  -507.8541319313182 \t -154.83237029755054\n",
            "37     \t [ 5.07407477 -3.95013039  4.69458446  3.59297264 -0.4760639   0.32835764\n",
            "  3.27628034 -3.91013279]. \t  -373.9397687130545 \t -154.83237029755054\n",
            "38     \t [-1.33371172 -4.61921658  4.80039486 -3.24979323  4.39390463 -4.99143563\n",
            "  2.16457989  4.05106469]. \t  -565.9345187071315 \t -154.83237029755054\n",
            "39     \t [ 0.82714986  4.76492341  3.66390202  0.38832699  4.90198693  3.56132511\n",
            " -3.80111585 -4.38153418]. \t  -537.936597015819 \t -154.83237029755054\n",
            "40     \t [-5.09682525e+00 -1.39062357e-03 -3.45047477e+00  4.52736287e+00\n",
            "  2.25862338e+00 -3.62551639e+00 -4.17984506e-01 -4.41246012e+00]. \t  -405.03754257808725 \t -154.83237029755054\n",
            "41     \t [-3.83303779 -3.38258738 -4.81728294 -3.91897274  2.31613609 -4.67852081\n",
            "  3.56855568  4.17550306]. \t  -555.402515201198 \t -154.83237029755054\n",
            "42     \t [-5.12       -1.58964118  0.62080657 -5.12       -5.12        0.37538802\n",
            "  1.12563746 -5.12      ]. \t  -487.7842353009871 \t -154.83237029755054\n",
            "43     \t [-5.00035202 -3.13798873 -3.19852679 -4.36507239 -4.89514704  1.23907022\n",
            " -4.84791862  4.95910579]. \t  -641.8867554950007 \t -154.83237029755054\n",
            "44     \t [ 2.83240812  4.51253025 -4.78662916  1.10368454 -4.32716596  4.74705451\n",
            "  4.03574054 -0.75838062]. \t  -469.7968549620438 \t -154.83237029755054\n",
            "45     \t [-4.85011297  3.96130963 -4.4323521  -4.51971434  2.6623591   3.76688158\n",
            "  3.25794934  1.23879682]. \t  -402.70978857672696 \t -154.83237029755054\n",
            "46     \t [ 4.73183114  5.01306721 -2.07444362 -0.90489156  0.55860006 -3.60022575\n",
            " -4.25405703 -5.00854793]. \t  -495.5305260230982 \t -154.83237029755054\n",
            "47     \t [ 3.56126847  3.78008096 -3.05309722 -1.39776146 -5.11222633  4.13422026\n",
            " -4.65302213  0.11191747]. \t  -461.9192751858122 \t -154.83237029755054\n",
            "48     \t [-0.52014047  3.82591952 -4.79993923  2.94805474  4.97403426  2.54462266\n",
            " -5.0055689  -0.68484738]. \t  -475.1261016855098 \t -154.83237029755054\n",
            "49     \t [-4.11950665  5.10956046  4.82557948  0.27090618  0.95587543  5.09315761\n",
            "  4.2359921   4.91695626]. \t  -618.5648542196219 \t -154.83237029755054\n",
            "50     \t [-4.94657431  3.17471554 -3.15416689  1.79033827  3.4591273  -2.88623643\n",
            "  3.75004879  4.77271212]. \t  -477.7740679697948 \t -154.83237029755054\n",
            "51     \t [-3.21350292  3.32374175 -0.07493218  4.50393421 -5.07158729  5.09937734\n",
            "  3.87928789 -4.0504296 ]. \t  -634.7965025762282 \t -154.83237029755054\n",
            "52     \t [ 2.82976832 -2.4217753  -5.05722168  4.83204092 -1.25670599  3.78646333\n",
            " -4.9077536   5.10597075]. \t  -660.9487243823793 \t -154.83237029755054\n",
            "53     \t [-2.33054222  4.55087069  1.98279194  2.03287362 -2.95502891 -0.12780927\n",
            " -4.85470863 -4.93378833]. \t  -478.6514671861531 \t -154.83237029755054\n",
            "54     \t [-4.07487897  5.06606509 -4.87904866 -3.60511861 -1.27791206 -2.04958025\n",
            " -4.67755653 -3.4529159 ]. \t  -473.24528094062015 \t -154.83237029755054\n",
            "55     \t [ 2.31899075  4.7576258   3.63603653 -3.79024871 -3.28421349 -0.34428599\n",
            " -0.60708451  4.71854292]. \t  -383.11247869567876 \t -154.83237029755054\n",
            "56     \t [ 5.01663022 -3.4226084   0.57647927  3.68497958  3.26428984  3.69778525\n",
            "  5.04748773  2.86163367]. \t  -483.07949851808405 \t -154.83237029755054\n",
            "57     \t [-4.59570578  4.68522069  2.27076985 -4.69100236  0.41317154 -3.7889447\n",
            "  0.76328375 -3.0366967 ]. \t  -333.35489196769987 \t -154.83237029755054\n",
            "58     \t [ 2.75777563 -4.73614797 -5.01852492 -0.97609475  4.8160879   2.20085829\n",
            " -3.97883083  5.11416783]. \t  -596.9268833989476 \t -154.83237029755054\n",
            "59     \t [ 2.85429341 -3.5996131  -0.73716145 -3.24371033  4.26931085  4.51365198\n",
            " -4.53847632 -4.97559398]. \t  -633.3883227081569 \t -154.83237029755054\n",
            "60     \t [-3.99025624 -3.55923974  4.66929271 -4.30571933 -3.42540505 -3.98652215\n",
            " -4.52968668 -3.3436235 ]. \t  -567.9084059667042 \t -154.83237029755054\n",
            "61     \t [-4.52898952  3.37788903  4.53343828 -5.03032655 -4.84499859  4.30050995\n",
            "  4.64966595  3.35415419]. \t  -675.8798714269002 \t -154.83237029755054\n",
            "62     \t [ 1.80424288  0.5384617   4.12328527  0.35337235 -4.44760677 -3.98788886\n",
            "  5.0590758  -4.955521  ]. \t  -625.2819254591919 \t -154.83237029755054\n",
            "63     \t [ 3.77569901  4.62693581  0.39152703  2.790895   -4.9183072  -4.70680128\n",
            " -3.79245823  2.58521031]. \t  -496.7075058336996 \t -154.83237029755054\n",
            "64     \t [ 4.63258521 -4.8859887   1.68873066  3.35631205  3.52755925 -5.10180205\n",
            " -0.41790751  4.89379735]. \t  -534.0265959163103 \t -154.83237029755054\n",
            "65     \t [ 3.39667359  3.05872272 -0.68970424  4.55599602  2.05115651 -4.84070612\n",
            "  3.86172903 -4.99082515]. \t  -579.9926085189783 \t -154.83237029755054\n",
            "66     \t [ 4.5395903  -4.75596365  1.20136778 -3.72442614  0.3948449  -4.20847612\n",
            "  1.70378651 -1.86551391]. \t  -280.8700108062407 \t -154.83237029755054\n",
            "67     \t [-4.95438336 -0.77895465  5.11133924  4.39758958  1.00931633  4.33707641\n",
            "  4.80854218  0.26578887]. \t  -461.86668054639557 \t -154.83237029755054\n",
            "68     \t [ 2.98727384  1.5858213  -4.55512747 -4.9026551   4.63313179 -3.73558921\n",
            " -0.11006864  4.38894839]. \t  -517.5901916765552 \t -154.83237029755054\n",
            "69     \t [-2.18858743  2.88621404 -0.75378283 -4.96866475  1.41923851  4.79033088\n",
            " -5.05383517 -2.08566885]. \t  -483.2491363161326 \t -154.83237029755054\n",
            "70     \t [ 4.97553073 -4.73010372 -4.88708073  3.17369742 -4.62586496  1.28193946\n",
            "  3.40596497 -1.56659931]. \t  -399.1351585740257 \t -154.83237029755054\n",
            "71     \t [ 3.3923223  -0.57101074  3.475672    4.26622959 -4.65864496 -2.00656875\n",
            "  3.55910424  5.09219643]. \t  -549.9907539085957 \t -154.83237029755054\n",
            "72     \t [ 4.86897793 -4.42927849  3.59502936  0.2299465  -2.97113226  4.26058214\n",
            " -3.64688046  4.57258805]. \t  -515.3483192448512 \t -154.83237029755054\n",
            "73     \t [-2.39730592  5.02535959  2.30238477  4.58693365 -3.35240958 -1.22327265\n",
            " -2.08480608  5.01860682]. \t  -453.40617717022474 \t -154.83237029755054\n",
            "74     \t [-4.7773965   1.6388035   2.99664197  2.42803223  3.28385928 -5.0577227\n",
            " -4.51225545  0.71425385]. \t  -432.7222474967092 \t -154.83237029755054\n",
            "75     \t [ 2.97917011  0.83769598  4.90911078 -3.85024382  2.65531598 -3.00477745\n",
            "  5.06600858 -4.7684909 ]. \t  -592.8593239027853 \t -154.83237029755054\n",
            "76     \t [-4.35100233 -2.13302938  0.63040436  2.77416749 -4.12888302  4.82343107\n",
            " -4.19138565  4.05861072]. \t  -539.5909624812895 \t -154.83237029755054\n",
            "77     \t [ 3.9370151  -3.91418331  0.22322576  5.0566556  -0.01537934 -4.6313636\n",
            " -3.12163946 -3.83752897]. \t  -463.2941168918678 \t -154.83237029755054\n",
            "78     \t [-4.09828841 -3.13278195 -2.11163655  3.69490178  4.11380192 -3.23552803\n",
            "  4.83693718  0.63435067]. \t  -418.83045347156434 \t -154.83237029755054\n",
            "79     \t [-2.40207364  3.12557418 -4.88078672 -2.72394215 -2.95564201 -3.6340501\n",
            " -1.58798733  5.03345133]. \t  -469.7080699748152 \t -154.83237029755054\n",
            "80     \t [ 3.75165227  0.22047447  4.7260001  -4.18738255  4.36443052 -0.05872053\n",
            "  5.04482862  2.41639216]. \t  -471.439670833272 \t -154.83237029755054\n",
            "81     \t [ 4.93310931  2.68752722 -5.03342398  4.10077471  0.94751776  1.04943439\n",
            " -2.0994416  -2.74582538]. \t  -284.3195226642413 \t -154.83237029755054\n",
            "82     \t [-1.2293496  -4.87924341  4.07737438 -2.25992952 -3.2682472  -1.21936716\n",
            "  3.87049437  0.6202788 ]. \t  -289.70079341779035 \t -154.83237029755054\n",
            "83     \t [ 2.43135514 -3.73967763 -4.85546599 -3.08391515 -5.10546728 -0.40487743\n",
            " -5.10832204 -3.03861315]. \t  -530.4932184946532 \t -154.83237029755054\n",
            "84     \t [ 3.70459704 -3.83389453  1.52146762 -1.78125913 -5.09134432  4.54156504\n",
            "  5.11364121 -4.6529923 ]. \t  -672.3694575038446 \t -154.83237029755054\n",
            "85     \t [ 2.33040163  3.63640521  4.03551548 -4.71026884 -4.21985888  4.74189044\n",
            " -5.11453316 -2.45648591]. \t  -624.8132686372315 \t -154.83237029755054\n",
            "86     \t [ 5.04632239 -4.54374358  2.41661669  4.56771    -5.01572358  4.42288152\n",
            " -2.29749721 -4.00251086]. \t  -576.001488495334 \t -154.83237029755054\n",
            "87     \t [-5.01823006 -4.15202752 -2.95783056  0.82621673 -4.44979771 -2.01053529\n",
            " -0.43790762  2.52921606]. \t  -264.41294270607847 \t -154.83237029755054\n",
            "88     \t [ 2.34524329 -3.45310237  5.11815947 -3.3780792   3.07314094 -4.35134941\n",
            " -5.10833632  4.56870313]. \t  -664.0568557777133 \t -154.83237029755054\n",
            "89     \t [ 4.61161233 -5.05189994 -3.64634601  1.35480473 -1.38254408  0.70722752\n",
            "  1.11536605  4.73754458]. \t  -320.3609399368072 \t -154.83237029755054\n",
            "90     \t [ 1.1559311  -3.43748914 -4.93555757  4.79010891  3.35578481 -4.74473106\n",
            " -4.44163072  1.50141031]. \t  -537.3403422114853 \t -154.83237029755054\n",
            "91     \t [ 2.73048326 -4.65267942  0.33065316 -3.7524744  -4.56661885 -0.57340618\n",
            " -4.87675271  2.71485694]. \t  -439.08805207078063 \t -154.83237029755054\n",
            "92     \t [-4.62109779  0.25233199 -4.75043983 -2.34870285 -4.30927618  4.94976137\n",
            "  2.62961684 -0.34791021]. \t  -400.4702005763574 \t -154.83237029755054\n",
            "93     \t [-1.61580475 -4.44123896 -0.98882492  3.83579623 -4.56295729 -2.38943137\n",
            " -4.26045074 -2.31727087]. \t  -412.22391464490204 \t -154.83237029755054\n",
            "94     \t [ 0.49266351  4.71690655 -3.23386498  4.52234177 -4.57172173  5.11055321\n",
            " -1.91099837  3.12593826]. \t  -522.8661266468455 \t -154.83237029755054\n",
            "95     \t [-3.26939703 -4.50819772 -4.70386133 -4.58666328 -0.59065935  0.53103189\n",
            "  4.18564013 -2.59104689]. \t  -381.6471411433107 \t -154.83237029755054\n",
            "96     \t [-5.10135218 -3.70916626 -0.62555835  4.49575315 -4.69152086  4.26692711\n",
            " -3.03128936 -4.07899698]. \t  -552.2793573201636 \t -154.83237029755054\n",
            "97     \t [-4.25053793  5.09481718 -4.02898053  4.48813351 -2.15225532 -4.06170606\n",
            "  5.01883804 -1.95481279]. \t  -528.2900620557837 \t -154.83237029755054\n",
            "98     \t [-3.84360278 -4.75053128  2.09089633 -4.33680627  0.76651909  4.03714317\n",
            "  4.29324534 -2.22375223]. \t  -417.56866238051435 \t -154.83237029755054\n",
            "99     \t [ 2.01121253 -3.92906408 -0.40105954  4.47276101  4.68258359 -0.73264798\n",
            "  3.947886   -4.8902254 ]. \t  -528.6936212540974 \t -154.83237029755054\n",
            "100    \t [ 1.61687133  4.88987403 -2.25003942  2.77565628  3.84821883 -2.33911025\n",
            " -4.46991052  3.71278916]. \t  -453.4528005753383 \t -154.83237029755054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOqNmgSIteAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db95cdae-ba38-4ad5-d941-b2c522de17bb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 18\r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_loser_18 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_18 = dGPGO(surrogate_loser_18, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.82391708  4.79785639  3.78055209  0.31596228 -2.73686192 -5.00327624\n",
            " -0.7119993  -0.99992207]. \t  -303.134303896496 \t -81.06401370190679\n",
            "init   \t [ 0.23218863 -0.22126801  0.56685029  0.44427282  2.67157069  2.17471564\n",
            "  1.22554466 -0.75682027]. \t  -81.06401370190679 \t -81.06401370190679\n",
            "init   \t [-2.15987171  4.85227767 -1.70215377 -2.87947714 -4.44612211  4.9445944\n",
            " -3.8107575  -1.82138068]. \t  -467.3384008943868 \t -81.06401370190679\n",
            "init   \t [-4.39354527 -2.81835582 -1.08917847  4.05652485 -1.58247309  4.96383424\n",
            " -4.82578382 -1.5187483 ]. \t  -446.39910875588674 \t -81.06401370190679\n",
            "init   \t [-1.21898097  2.70499975  4.49335207 -1.84637648 -0.69144645 -2.35370761\n",
            "  3.08281228  1.41556537]. \t  -208.5138761485756 \t -81.06401370190679\n",
            "1      \t [-4.72153807 -0.54862943 -3.19311344  1.30104982 -2.91514573 -3.5740661\n",
            "  0.3701177  -4.09203923]. \t  -314.305007357293 \t -81.06401370190679\n",
            "2      \t [ 2.67208712 -3.99037457 -2.148488    2.12737496 -3.90449112  2.55198214\n",
            "  0.12951135 -1.26301138]. \t  -199.1170525956219 \t -81.06401370190679\n",
            "3      \t [ 0.15531131  0.46668818 -4.01191051 -5.07342816  0.13730905 -0.46181146\n",
            " -0.5783223   5.06091098]. \t  -360.32233275140186 \t -81.06401370190679\n",
            "4      \t [ 4.11717363  3.03178758  2.01395375  1.63361829  4.47315693 -4.65011712\n",
            "  2.84599778 -3.76540159]. \t  -458.0885710056757 \t -81.06401370190679\n",
            "5      \t [-2.87613589 -2.36204857  3.86377212  4.81924511 -2.69254788 -0.09132169\n",
            "  3.3245157  -2.45169484]. \t  -318.8698045732099 \t -81.06401370190679\n",
            "6      \t [-3.49604359  1.45404494 -3.00825081 -3.19957983  4.90675057 -3.87056056\n",
            "  3.96577407 -2.81992642]. \t  -468.52464537528124 \t -81.06401370190679\n",
            "7      \t [ 4.63943718  2.6418305   1.38018945  4.29681613  2.63944848 -1.33298341\n",
            " -5.01709517  3.81276913]. \t  -453.0390834067 \t -81.06401370190679\n",
            "8      \t [ 5.08894648 -1.67538878  5.09575663 -3.06496959 -2.55374005  2.8402276\n",
            " -3.67330473  0.5368607 ]. \t  -324.7548195578733 \t -81.06401370190679\n",
            "9      \t [ 3.42223172 -2.12609735  4.8724154   2.39456946  4.42401398 -2.15469862\n",
            " -4.63598713 -5.02420695]. \t  -593.0131323017791 \t -81.06401370190679\n",
            "10     \t [-1.3478826  -3.9832212   4.72092649 -1.05778748 -3.56621932 -3.20173497\n",
            " -2.46251187  3.52569953]. \t  -371.87444035839957 \t -81.06401370190679\n",
            "11     \t [ 0.5305035  -2.40387146 -3.76947124  3.21663621  2.98389133 -2.09566893\n",
            " -3.69003782 -4.68456234]. \t  -437.5970195478538 \t -81.06401370190679\n",
            "12     \t [ 0.66447811 -3.83879279  0.73747644 -5.1199266   1.03763825 -0.97638321\n",
            " -3.15968102 -3.99483008]. \t  -345.0582379153705 \t -81.06401370190679\n",
            "13     \t [-1.12836081  4.69959827 -2.01832734 -3.58443072 -4.38360641  0.45474381\n",
            "  4.09898035 -1.18589722]. \t  -335.2422306188787 \t -81.06401370190679\n",
            "14     \t [-5.01459895e+00  2.73714762e+00  3.96484086e+00 -4.15403894e+00\n",
            "  1.53519887e+00  4.30126008e+00 -2.26250200e+00 -4.69660105e-03]. \t  -314.93599540925555 \t -81.06401370190679\n",
            "15     \t [-4.53980895  4.82572514 -1.17884387  2.7072872   4.94556367  0.2644122\n",
            " -0.64466555  3.46705064]. \t  -322.4569060693718 \t -81.06401370190679\n",
            "16     \t [ 3.650717    4.32278292  3.413414   -2.97229375  0.39380264  4.88043189\n",
            "  3.73331733 -4.52521879]. \t  -526.0644887363746 \t -81.06401370190679\n",
            "17     \t [-0.847513    5.11237294 -2.43290045  3.325202    4.95436671  3.91088864\n",
            " -3.90974155 -3.0770196 ]. \t  -512.2218770901723 \t -81.06401370190679\n",
            "18     \t [ 1.02429915  3.07391046 -4.27444879 -4.44802406  0.89057239 -3.76330187\n",
            " -4.62863464 -4.05718832]. \t  -524.4957172824636 \t -81.06401370190679\n",
            "19     \t [ 2.37105638  4.49385045  3.73577117 -2.45426     2.33699621  1.88631846\n",
            " -4.77091917 -3.24998846]. \t  -404.4608480089342 \t -81.06401370190679\n",
            "20     \t [ 3.0662871   4.52716193 -4.61899346  2.61714159 -1.89096243 -2.45598965\n",
            " -2.52688729  0.07445995]. \t  -240.60600470307475 \t -81.06401370190679\n",
            "21     \t [-5.02060074 -4.66199256  2.43260221  4.19272539  4.94157957 -0.74329845\n",
            "  1.49622764  3.12999905]. \t  -376.2002579357294 \t -81.06401370190679\n",
            "22     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -81.06401370190679\n",
            "23     \t [-3.42429116  0.24764067  3.17264151  4.75594036 -1.04160166  4.83153257\n",
            " -0.18130256  4.18608081]. \t  -418.42444608567325 \t -81.06401370190679\n",
            "24     \t [ 4.12778788 -4.94437223  1.42746574 -2.6446469   4.86156679  4.40666947\n",
            "  1.43714134  4.63015759]. \t  -520.6729449927628 \t -81.06401370190679\n",
            "25     \t [ 0.57290816 -0.15844274 -4.9320027   1.98058886  3.67925319 -4.34383597\n",
            "  2.93595194  2.23302508]. \t  -370.17120312325403 \t -81.06401370190679\n",
            "26     \t [ 2.11078302 -0.89504084  1.04167835 -3.03920418  4.95407011 -3.65470507\n",
            " -4.46335377  4.7342002 ]. \t  -567.8670996420659 \t -81.06401370190679\n",
            "27     \t [-1.75504787  4.52754909 -3.5814871   3.08556618 -4.68362728  4.21263606\n",
            "  1.24132782  4.43260486]. \t  -504.7714065066599 \t -81.06401370190679\n",
            "28     \t [-4.87806763  4.48605381  2.94410498  3.30247658 -4.68447048 -1.37863478\n",
            " -1.65864145 -2.51119692]. \t  -324.50521155595555 \t -81.06401370190679\n",
            "29     \t [-3.80949757 -4.29118363  1.45501763 -4.88432899 -5.02520892  4.10990179\n",
            " -3.85908957 -2.61973449]. \t  -539.8821492362991 \t -81.06401370190679\n",
            "30     \t [ 3.51893015  1.5632766   2.05302109  4.65625712 -4.66947404 -1.37186865\n",
            " -4.99761918 -4.77148418]. \t  -593.9200978678381 \t -81.06401370190679\n",
            "31     \t [-4.80319134  4.82349685 -2.61094054 -4.32603162  3.04891621  4.10222657\n",
            "  4.46295224  1.64857245]. \t  -473.5290754833484 \t -81.06401370190679\n",
            "32     \t [ 4.37381109  1.9692417  -2.12061416  4.15539633  4.38891059  2.8970259\n",
            "  4.62265389  5.04198358]. \t  -609.0708627652768 \t -81.06401370190679\n",
            "33     \t [4.80257085 3.3881167  4.82441901 1.56933306 0.09115682 4.81202437\n",
            " 0.49899836 4.46915796]. \t  -426.20463582167616 \t -81.06401370190679\n",
            "34     \t [-4.22679515 -2.20242172  3.51481421 -3.05619596 -2.01808741  4.65022789\n",
            "  3.81152896 -3.01331973]. \t  -426.4363494668309 \t -81.06401370190679\n",
            "35     \t [-4.90094479 -1.25937628 -2.18359839 -4.39430052  2.10192787  4.96611256\n",
            " -2.4891906  -4.93131316]. \t  -526.7145629269148 \t -81.06401370190679\n",
            "36     \t [ 3.84462474 -0.26043669 -4.12939642 -2.44233297 -0.03038449 -1.19449002\n",
            "  3.52581427 -4.44459258]. \t  -343.5527433201901 \t -81.06401370190679\n",
            "37     \t [-3.43237087 -3.65362625  1.39470203 -5.08261437  2.42450644  0.42547184\n",
            "  4.65690425  2.16451436]. \t  -367.41219049414616 \t -81.06401370190679\n",
            "38     \t [-1.72268625 -4.11138794 -0.08739609 -2.26712036  0.08097763  4.01866251\n",
            " -4.63189897  4.83984618]. \t  -491.8619048967753 \t -81.06401370190679\n",
            "39     \t [ 4.43888143 -2.78339492  4.05543031 -4.32293168 -1.24157182  1.25665427\n",
            "  4.82578695  2.45355803]. \t  -387.6484374031801 \t -81.06401370190679\n",
            "40     \t [ 4.67536047 -1.47920092 -4.18971724  1.28295545  2.27119307  4.48005573\n",
            " -2.74732063  2.6565191 ]. \t  -340.98828714459034 \t -81.06401370190679\n",
            "41     \t [-0.61789822 -4.27189654 -1.90347045  4.14951574 -2.11625531 -4.42703951\n",
            " -3.85813625  2.19453638]. \t  -399.3327032582384 \t -81.06401370190679\n",
            "42     \t [-2.97432337 -4.86200604 -4.20916148  4.00595386  4.65516358  1.50937996\n",
            "  3.29425569 -4.00375273]. \t  -499.6938297867464 \t -81.06401370190679\n",
            "43     \t [-4.92923813  1.32923868  4.19253175 -2.70786328  3.22582551 -4.72574665\n",
            " -4.46991686 -3.91502298]. \t  -558.3993779436602 \t -81.06401370190679\n",
            "44     \t [ 2.74882756 -0.25735665 -1.8126823   3.35568652 -3.5978553  -3.41470411\n",
            "  5.09987801 -0.092176  ]. \t  -379.40179713053874 \t -81.06401370190679\n",
            "45     \t [ 3.69961881  3.95740371  0.34178595 -4.48001207 -4.80015737  1.51716264\n",
            " -1.8688376   3.30120247]. \t  -366.2913813160801 \t -81.06401370190679\n",
            "46     \t [ 4.2422771  -4.26864282 -3.52469581 -4.75705647 -4.49505886 -3.26811424\n",
            " -4.79455868  2.16464956]. \t  -545.7397318721949 \t -81.06401370190679\n",
            "47     \t [ 3.64998573  4.71685771  0.63376275  4.95295964 -3.62858143  4.97494412\n",
            "  3.07234789 -1.35003812]. \t  -452.1415956958892 \t -81.06401370190679\n",
            "48     \t [ 4.65199705 -5.03112104  1.01548589  2.67097476  2.89476898 -0.27443223\n",
            "  2.99940908 -4.35950097]. \t  -361.26298265766206 \t -81.06401370190679\n",
            "49     \t [-4.66933842  5.09946967 -3.8569484  -0.79740898 -2.15723816 -3.61892254\n",
            " -3.70480341  4.48109893]. \t  -479.5524437745522 \t -81.06401370190679\n",
            "50     \t [-3.19362187  3.47555277  5.09982632  4.51530281  2.78422078 -3.7576635\n",
            " -3.37001293  4.75159914]. \t  -577.5347803892658 \t -81.06401370190679\n",
            "51     \t [-2.56003158 -5.08413757 -2.00243446  3.14461631 -3.68798783 -0.3583179\n",
            "  3.00379109  4.92309516]. \t  -435.6652251661167 \t -81.06401370190679\n",
            "52     \t [ 2.07753565 -0.99431764  4.81844935 -4.59895258 -4.82583661 -3.21043299\n",
            "  1.56991894 -3.5541143 ]. \t  -457.1384324423485 \t -81.06401370190679\n",
            "53     \t [-4.09561412 -1.54882173 -4.30551496  4.52111329  4.18008338  4.98204178\n",
            "  2.15901087  3.57166919]. \t  -529.9197804724695 \t -81.06401370190679\n",
            "54     \t [-4.13658161  4.24080477 -0.52011527 -5.09708181  3.41441651 -4.10498919\n",
            " -2.21837314  1.42883964]. \t  -367.9904249629685 \t -81.06401370190679\n",
            "55     \t [-2.08809177 -4.78145714 -5.02268914 -3.82134293  4.99135677  4.34877215\n",
            "  5.07258687  4.35974464]. \t  -754.3937338732549 \t -81.06401370190679\n",
            "56     \t [ 4.4530929   4.7556078  -0.59029459 -3.42459216  0.84813755 -4.79480935\n",
            "  3.51016006  4.96693506]. \t  -538.1682999732352 \t -81.06401370190679\n",
            "57     \t [-2.81717305 -2.49316045 -2.72198451 -4.33570366 -4.98835556 -4.09583164\n",
            "  0.22166128  1.71817947]. \t  -366.8236044531502 \t -81.06401370190679\n",
            "58     \t [ 0.10532251 -3.41414994  4.56537402 -3.20769552  4.13254896 -2.96361225\n",
            "  4.06561169 -3.31152421]. \t  -468.53081413932773 \t -81.06401370190679\n",
            "59     \t [-4.93855538  0.70416532 -4.70906454 -4.88575046  4.75675842  3.60209686\n",
            " -3.52813752  3.86502132]. \t  -585.0148866421165 \t -81.06401370190679\n",
            "60     \t [-1.83554942 -4.96511213 -3.69238571 -2.92817328 -3.79541954  0.8828646\n",
            "  4.28992489 -3.26271529]. \t  -418.5612749576631 \t -81.06401370190679\n",
            "61     \t [ 3.37518887 -4.9480749  -0.91419815  3.684003   -4.22174777 -4.85893252\n",
            " -1.5001111  -4.53320827]. \t  -528.076851307955 \t -81.06401370190679\n",
            "62     \t [-4.41700465  4.39690048  4.53775385 -1.4034771  -3.17608941 -4.01691623\n",
            " -4.86588535  3.35184602]. \t  -530.6962909951184 \t -81.06401370190679\n",
            "63     \t [ 2.59918633 -3.70957992  4.6452912   3.59536803 -0.90024756 -3.40632961\n",
            "  4.1313736   4.02602093]. \t  -473.5398197656641 \t -81.06401370190679\n",
            "64     \t [ 4.7754924  -4.78056285 -4.6101909  -3.05945151  2.04105936  5.06371042\n",
            " -0.40865538 -4.1550931 ]. \t  -483.67942458531144 \t -81.06401370190679\n",
            "65     \t [-3.54466251  5.10368615 -4.20653216  2.20284509  3.92569518  3.06203074\n",
            "  4.74261041 -4.38002887]. \t  -581.3900057786458 \t -81.06401370190679\n",
            "66     \t [ 4.14794636 -1.25120815  4.74127226  4.83536952 -3.65780528  0.30682377\n",
            " -4.81409953  3.93778552]. \t  -535.0393448797502 \t -81.06401370190679\n",
            "67     \t [-4.99290173 -2.84532053 -3.40952429 -3.4218214   2.61331074 -4.62109177\n",
            " -4.99307544  2.85074062]. \t  -524.6340732241991 \t -81.06401370190679\n",
            "68     \t [-5.08300208 -2.26273098  2.14199083  2.09594129  4.93421871  2.45964025\n",
            " -4.30705273 -3.97436268]. \t  -481.66401129077195 \t -81.06401370190679\n",
            "69     \t [-3.83771653  4.23781584  3.63291775 -2.28084599 -4.32915006  4.19236934\n",
            "  2.69053545  2.58054217]. \t  -414.159457283227 \t -81.06401370190679\n",
            "70     \t [ 1.14772704 -5.05148298  3.52206618  3.86687861  3.94893139 -0.57271472\n",
            " -4.44735608  2.20248046]. \t  -406.57659197395435 \t -81.06401370190679\n",
            "71     \t [-1.32359534  4.20986146  4.85243474  3.85846347  1.21204156 -0.81210832\n",
            "  4.65701009 -4.54982463]. \t  -496.1108793170346 \t -81.06401370190679\n",
            "72     \t [ 4.96669558 -1.81003778 -4.75070341 -1.01643771 -3.228242   -0.02108631\n",
            "  2.74864343  4.20371296]. \t  -349.4259757101438 \t -81.06401370190679\n",
            "73     \t [-1.78285186 -2.36127237 -4.29843809  4.46530661  4.80023686 -1.1559386\n",
            " -4.09505458  4.49820544]. \t  -552.0009926745167 \t -81.06401370190679\n",
            "74     \t [ 5.0705279   0.82321511  4.99822215 -4.89326716 -1.40691599 -4.00152903\n",
            " -0.77776879  5.06305711]. \t  -513.0698658473176 \t -81.06401370190679\n",
            "75     \t [-4.86112616  3.21284393 -5.01029824  4.54597635 -3.86363618 -0.9877199\n",
            "  5.05429293  0.46099055]. \t  -463.26135268977197 \t -81.06401370190679\n",
            "76     \t [ 4.87670999  4.57868411 -4.05395785 -4.54783654  2.85759239  4.11022087\n",
            "  1.42904609 -2.60251451]. \t  -408.41851661504637 \t -81.06401370190679\n",
            "77     \t [ 3.68638509 -0.60451993 -3.87533173  4.36053704  3.28959676  4.17869445\n",
            "  5.05213065 -3.39636101]. \t  -565.2585161389633 \t -81.06401370190679\n",
            "78     \t [ 1.2686452  -4.90217029  1.73320453 -3.03907766  4.44002607 -4.78988071\n",
            "  4.05364486  4.44512191]. \t  -604.9520019944265 \t -81.06401370190679\n",
            "79     \t [-1.70468394  2.18644578 -0.64418711  2.87221455  0.45893027  0.05769509\n",
            " -4.86808514  0.21364972]. \t  -214.03643164915232 \t -81.06401370190679\n",
            "80     \t [ 4.49162139  1.42081199 -1.01209324 -3.31548195 -1.82519629  1.2582092\n",
            " -3.08019295 -3.89362966]. \t  -285.1059419762588 \t -81.06401370190679\n",
            "81     \t [-4.5522897   2.82871051 -4.720571    3.13980912 -4.34110689  2.68349569\n",
            " -2.86910366 -2.23539564]. \t  -378.0427046314546 \t -81.06401370190679\n",
            "82     \t [-3.72695359  3.36168982  2.4070084  -4.20994814 -3.83654929 -4.81001084\n",
            " -1.50788074 -3.27384181]. \t  -438.84085150102646 \t -81.06401370190679\n",
            "83     \t [ 4.36011993  0.09658632 -4.13243627  4.06722744 -0.85865822  2.98870131\n",
            " -3.88480054 -4.76705531]. \t  -481.1504880993595 \t -81.06401370190679\n",
            "84     \t [ 2.1037957  -3.39448834  4.90375773  1.61089232 -5.02141386  3.88724603\n",
            "  3.25455627  1.23903194]. \t  -413.1551069652015 \t -81.06401370190679\n",
            "85     \t [-3.87765198  0.76510688 -2.98482173  5.01386685  4.5052722  -4.1096242\n",
            "  1.9413366  -3.50627945]. \t  -471.0448213745675 \t -81.06401370190679\n",
            "86     \t [ 2.31389077 -1.08896647 -4.51126038 -2.74251671 -4.52256859  4.19320165\n",
            " -2.50685644  2.36183386]. \t  -395.2479405726274 \t -81.06401370190679\n",
            "87     \t [-4.00708205  0.41946636 -2.12777368  0.44481206 -4.3014553   4.64535687\n",
            "  4.86424144  0.38208533]. \t  -419.564762328373 \t -81.06401370190679\n",
            "88     \t [-4.44925838 -4.44646048  2.03600494 -0.98863541  0.03397787 -4.87597513\n",
            " -0.85909028 -4.13335301]. \t  -360.18315249877827 \t -81.06401370190679\n",
            "89     \t [ 5.08195372 -4.22066429  5.09891588 -2.00245789  2.76478317  4.3630508\n",
            " -0.15636123 -4.90296988]. \t  -500.41190230464304 \t -81.06401370190679\n",
            "90     \t [ 2.97329414  4.66691339  2.96415568  5.08394859 -2.09635732  0.91155292\n",
            "  4.97980203  4.67886496]. \t  -557.8277874369735 \t -81.06401370190679\n",
            "91     \t [-3.90126411  5.03764308  2.01814345 -4.00722446  2.24386299  0.84943304\n",
            "  3.97212188 -4.68344573]. \t  -457.8510592132999 \t -81.06401370190679\n",
            "92     \t [-0.51845025  5.02234146 -2.89635919  1.7331369   0.45600363 -4.38836215\n",
            "  4.41788312 -2.70422264]. \t  -399.6107918198576 \t -81.06401370190679\n",
            "93     \t [-3.8662971  -4.46252306 -2.64641052 -4.14469679 -4.45670687  3.9478459\n",
            "  4.97559533  4.85607272]. \t  -699.2724740192923 \t -81.06401370190679\n",
            "94     \t [ 1.57532714 -4.15145369 -4.76064645 -5.10575937  4.50316855  4.72073635\n",
            " -2.86589074  3.29942684]. \t  -588.9049629984789 \t -81.06401370190679\n",
            "95     \t [-4.91272944  4.69819201  0.93826809  1.88535698 -3.19653462 -4.33420459\n",
            "  4.7286967   1.98574898]. \t  -437.01099570512406 \t -81.06401370190679\n",
            "96     \t [-4.36623912 -1.27813718 -0.17604768  0.45706138  1.10630584 -4.4943016\n",
            "  4.91974246  1.9709576 ]. \t  -351.0764080389013 \t -81.06401370190679\n",
            "97     \t [ 3.12265005  5.05986531 -0.94113718  4.59462297  0.19048386 -5.06631907\n",
            "  1.57051989  4.09950151]. \t  -453.95485964632655 \t -81.06401370190679\n",
            "98     \t [-4.87965219  5.10070312 -5.02822246  0.7661753   2.60858923 -3.93275011\n",
            " -2.16988867 -2.67542514]. \t  -371.0874565614132 \t -81.06401370190679\n",
            "99     \t [-0.7501438   3.15409967  5.02067137 -4.16879084 -1.37734623  4.80974791\n",
            " -4.19921823  4.98603395]. \t  -636.2018716523191 \t -81.06401370190679\n",
            "100    \t [ 4.56126487 -3.30158492 -4.58476083 -2.49382816  4.78162375 -4.96340572\n",
            " -1.63767296  0.34702604]. \t  -412.412106818473 \t -81.06401370190679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4HnKuoqteDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffd6772-a3d2-45f3-daaa-01e5e61beae1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 19\r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_loser_19 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_19 = dGPGO(surrogate_loser_19, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.60872271  2.67767798 -2.61599688  2.78210017 -1.49020588  3.03818137\n",
            " -1.57695977 -0.57472578]. \t  -152.73804339453181 \t -152.73804339453181\n",
            "init   \t [-2.01417124 -0.59275346  0.74966386 -4.44760047 -4.87332982  3.28317578\n",
            " -1.38099049  2.2742428 ]. \t  -323.7197488227736 \t -152.73804339453181\n",
            "init   \t [-1.01293527  0.56350397 -2.8300206   3.21862419  2.65507157  2.99837476\n",
            "  1.85657419  0.54493065]. \t  -182.81852961404186 \t -152.73804339453181\n",
            "init   \t [ 2.7452723   4.7291508   4.64956866  0.49623227 -2.52475319 -2.84587614\n",
            "  1.92234127  1.96987691]. \t  -255.4837579570394 \t -152.73804339453181\n",
            "init   \t [-4.14230197  2.55639339 -5.00090869 -3.49701125 -2.12620717  3.13206479\n",
            "  2.96251747  5.00628454]. \t  -497.5739847629385 \t -152.73804339453181\n",
            "1      \t [-4.8562831   2.5202371   0.65818482  1.85973564 -3.16121357  4.05790202\n",
            "  3.22145623 -3.32687085]. \t  -361.375551583699 \t -152.73804339453181\n",
            "2      \t [ 2.57100251  0.79792066 -3.07628175 -2.52290659  3.72181543 -2.17142815\n",
            "  0.43296226 -2.98450801]. \t  -231.8548176582704 \t -152.73804339453181\n",
            "3      \t [-3.93618292 -3.46237372  4.64426131  0.6176429   1.44357523  2.37373405\n",
            " -2.91445036 -3.74550726]. \t  -321.6189907894727 \t -152.73804339453181\n",
            "4      \t [ 1.71164252 -2.95911977 -4.03437442  2.02656742 -2.92122741 -4.85463732\n",
            " -0.57796608  4.45551234]. \t  -430.9228367169912 \t -152.73804339453181\n",
            "5      \t [-2.74511363  3.76685972  4.4246735   4.38496769  4.91433138 -4.6635153\n",
            "  2.73141886 -4.00045557]. \t  -603.0563016476349 \t -152.73804339453181\n",
            "6      \t [ 4.50659056 -4.66464622  3.8028831  -3.91576704  3.3573574  -4.86797933\n",
            " -4.62303005 -1.13925638]. \t  -527.078561690918 \t -152.73804339453181\n",
            "7      \t [ 0.74953388 -4.99535814  4.25708702  2.89287469 -1.57494968  2.82565918\n",
            "  3.52640293 -4.34470735]. \t  -436.6811827590352 \t -152.73804339453181\n",
            "8      \t [ 4.9309155  -4.66190939 -1.39842267  3.88626494  0.59667046  4.54090007\n",
            " -4.87810306  1.51474754]. \t  -444.48533101207744 \t -152.73804339453181\n",
            "9      \t [ 3.01635191  1.86005304  1.34166926 -2.51068592  3.41638962  1.81600167\n",
            "  4.53589168  2.03974105]. \t  -302.08268227537843 \t -152.73804339453181\n",
            "10     \t [-1.16939325 -2.28684993 -3.09314025  3.80451342  4.89935167 -4.58750093\n",
            "  2.16351982  3.05576772]. \t  -452.1833650503857 \t -152.73804339453181\n",
            "11     \t [-3.24511568 -0.03305903  4.88870822  0.92764935 -4.78906412 -2.64060126\n",
            " -2.04224143  1.16601697]. \t  -282.25783962950715 \t -152.73804339453181\n",
            "12     \t [ 4.93640568 -2.89768435  1.20317571  3.54544549 -0.26729781  3.02893365\n",
            "  3.73371079  3.06668439]. \t  -324.0093545381129 \t -152.73804339453181\n",
            "13     \t [ 2.14365395  4.475046   -2.75201252 -1.81775304  0.81961399 -4.9226742\n",
            " -3.48771314  3.02356846]. \t  -387.6248423390611 \t -152.73804339453181\n",
            "14     \t [-5.04932398  4.55038173 -3.10694766 -4.25752421  2.16921434  2.41196796\n",
            " -2.63486389 -1.24510704]. \t  -287.80591849658293 \t -152.73804339453181\n",
            "15     \t [ 1.6405952  -4.93154943  2.85629023 -4.11715021 -3.16915087 -4.54186279\n",
            "  3.29548824 -4.82525932]. \t  -579.8862082863274 \t -152.73804339453181\n",
            "16     \t [ 4.73847946  3.19733533  3.59621008 -2.79212097 -2.43502122  2.77966179\n",
            " -4.94097081  3.98422819]. \t  -486.77173471484025 \t -152.73804339453181\n",
            "17     \t [-2.8745998  -4.43294761 -2.7756965  -0.26035087  0.61747234  2.125617\n",
            " -4.33617557  0.41900913]. \t  -232.98730188285626 \t -152.73804339453181\n",
            "18     \t [-2.73967493  4.99555548 -0.82469551  4.75958381 -2.23328553 -3.281701\n",
            " -3.10154036 -3.74777769]. \t  -419.33064738448286 \t -152.73804339453181\n",
            "19     \t [-1.52397821  3.04966104  4.30824494  3.44634834  0.044055    3.23832487\n",
            "  1.71019372  4.79645974]. \t  -391.56730360215226 \t -152.73804339453181\n",
            "20     \t [ 1.48763247 -4.06042201 -4.91731623  0.4058509  -4.17883291  3.77314538\n",
            " -1.53661715  4.94854355]. \t  -493.55195149540185 \t -152.73804339453181\n",
            "21     \t [-4.81925376  4.51866071  4.90666757  1.96687806  3.74473169 -2.85411271\n",
            " -4.8901082   4.85155259]. \t  -626.4458334362118 \t -152.73804339453181\n",
            "22     \t [ 0.72884133 -0.81145476 -3.81890966 -4.69712409 -3.23566528  4.11537028\n",
            "  4.57107203 -3.56690639]. \t  -535.8629893518354 \t -152.73804339453181\n",
            "23     \t [ 5.02441086 -3.71026321  1.49715044 -4.54859603 -1.43081697  3.71368242\n",
            " -1.31951971  0.13773559]. \t  -247.58459542972733 \t -152.73804339453181\n",
            "24     \t [ 1.65627714 -4.4603674   0.33217543  2.75967509 -1.41582852 -1.73059252\n",
            " -2.83494913 -4.29491808]. \t  -305.1489383155981 \t -152.73804339453181\n",
            "25     \t [-5.08179909 -0.71598426 -3.21296628  4.69485866 -2.85708982 -1.58610168\n",
            "  4.17888225  0.82313093]. \t  -329.5570741636583 \t -152.73804339453181\n",
            "26     \t [ 0.75558714 -5.12       -3.72045759 -5.12       -3.97088422 -0.69427104\n",
            " -4.69427822 -5.12      ]. \t  -645.0833431227027 \t -152.73804339453181\n",
            "27     \t [ 4.46089602 -3.22814435 -2.69798742  3.44502345  3.34769414  5.07399664\n",
            "  1.71278211 -4.53904046]. \t  -505.9179755221916 \t -152.73804339453181\n",
            "28     \t [-5.12        0.5978882  -5.12       -5.12       -3.20079294 -3.59715183\n",
            " -5.12       -5.12      ]. \t  -732.5085253192245 \t -152.73804339453181\n",
            "29     \t [-2.02507367 -4.31372728  3.81049558  0.42270714 -3.13549057  3.371996\n",
            "  5.05560659  4.49516551]. \t  -543.5366224627609 \t -152.73804339453181\n",
            "30     \t [ 3.66951971 -1.47236747  3.30332462 -2.05406113  4.31684766  3.69055648\n",
            " -3.30502509 -4.54309323]. \t  -483.8906516033669 \t -152.73804339453181\n",
            "31     \t [ 4.79949273 -3.92018467  3.34062109  2.41600109 -4.97149092 -3.84565559\n",
            "  2.21715066  3.90688118]. \t  -479.43139445795344 \t -152.73804339453181\n",
            "32     \t [-4.97239095 -2.87504964 -0.92183661 -5.11832564  2.0659351  -3.10237591\n",
            "  4.71657872  4.91840566]. \t  -576.9322452090312 \t -152.73804339453181\n",
            "33     \t [ 4.69407217  4.57591402  3.80696205  2.84268071 -3.84278214  3.98693297\n",
            "  4.9604339  -2.20288641]. \t  -519.9861860143415 \t -152.73804339453181\n",
            "34     \t [-5.0260819  -1.21488293  4.01232295 -2.52846501  3.84478158  3.11931665\n",
            "  1.46765049  3.93517081]. \t  -373.3372131297547 \t -152.73804339453181\n",
            "35     \t [-3.39866628  3.00569424  3.16606724 -3.03277692  0.8084546  -4.43189454\n",
            " -1.28655949 -2.98375615]. \t  -300.40939944542583 \t -152.73804339453181\n",
            "36     \t [ 2.79679016 -2.77522545 -2.5914273  -4.51965605 -2.58920673 -1.96756792\n",
            "  3.82070395  2.99765975]. \t  -355.9014981730077 \t -152.73804339453181\n",
            "37     \t [-2.75924015 -5.05550787 -3.73136432  4.80687625  1.64920052 -3.99037409\n",
            "  4.50236875 -4.37974126]. \t  -597.4173647578108 \t -152.73804339453181\n",
            "38     \t [-4.55667568 -2.12164605 -4.30285141  0.82741672  5.11667806 -4.98023914\n",
            " -3.53750233 -4.76261817]. \t  -636.824499278169 \t -152.73804339453181\n",
            "39     \t [ 5.08390804  3.28985327 -1.4609699   3.78075782  4.89403825 -1.33891164\n",
            " -2.87913856  0.92997728]. \t  -306.53129975478726 \t -152.73804339453181\n",
            "40     \t [ 0.08944051 -3.73401507  3.96439982  1.62100229  3.97109872 -2.05235768\n",
            " -1.0680214   4.02217307]. \t  -327.08258338811277 \t -152.73804339453181\n",
            "41     \t [-0.77393755  4.42773897  1.77610697 -3.81516373 -3.73388046  4.88104821\n",
            " -4.92120729 -2.89761644]. \t  -556.8488116971153 \t -152.73804339453181\n",
            "42     \t [ 1.38410175  4.56637169  1.90835178 -0.67332623  5.10272498  3.8302022\n",
            " -3.22627626  2.40012927]. \t  -393.5168089198683 \t -152.73804339453181\n",
            "43     \t [ 4.36009301  4.34841085  3.55996743  0.42007256  1.15841139 -3.44515606\n",
            " -2.81968378 -4.35263215]. \t  -380.69546931323333 \t -152.73804339453181\n",
            "44     \t [-2.35618003 -4.49266608  4.1565802  -5.10126703 -1.72474327  4.09428589\n",
            "  4.0443262  -3.1132364 ]. \t  -509.32956619294794 \t -152.73804339453181\n",
            "45     \t [ 2.44831286 -4.9949258   3.91281193 -3.74764691  3.25921598 -4.70267853\n",
            "  4.62412737  2.47521485]. \t  -542.4974660734474 \t -152.73804339453181\n",
            "46     \t [ 3.72055248 -1.64407553  4.30615828  4.64697806 -3.43347904  0.19164357\n",
            " -4.73337763  2.06216975]. \t  -411.27375167226086 \t -152.73804339453181\n",
            "47     \t [-4.74794588  0.7746091   2.214691   -3.2059102   4.37615119  3.36188279\n",
            "  4.66466502 -3.83368454]. \t  -513.0268650048852 \t -152.73804339453181\n",
            "48     \t [ 4.09568674  5.03955519 -4.88196619  4.78191659 -4.71709108 -3.37299512\n",
            " -0.06682128 -3.03044289]. \t  -483.55381628555966 \t -152.73804339453181\n",
            "49     \t [-4.72760832  5.03898793 -1.831471    0.57048519  2.72523871 -3.09303842\n",
            "  4.59982808 -1.30851647]. \t  -340.84035188333354 \t -152.73804339453181\n",
            "50     \t [ 4.09106501 -2.52386104  1.53623307  3.86109486  4.79227916 -2.42540099\n",
            "  2.76715639 -3.1906763 ]. \t  -381.3573330329529 \t -152.73804339453181\n",
            "51     \t [-0.2859619   4.89377946  2.62696746 -4.31112308 -3.64840521  1.79484265\n",
            "  3.65631987 -4.59190458]. \t  -491.1744224642688 \t -152.73804339453181\n",
            "52     \t [-2.86479366  2.9412352  -1.85002765 -1.712708   -4.98775034 -2.64258665\n",
            "  4.64771992 -1.44216429]. \t  -381.64571182586405 \t -152.73804339453181\n",
            "53     \t [ 4.25948088  1.3149383   4.30923982  2.92075721 -3.25133549  3.00563916\n",
            " -2.60410431 -4.67709426]. \t  -440.96355101238726 \t -152.73804339453181\n",
            "54     \t [ 3.97864237  2.48836787 -4.2509363  -4.94256882 -3.39829392 -0.31528832\n",
            " -2.66842287 -2.17102241]. \t  -326.0293879171836 \t -152.73804339453181\n",
            "55     \t [ 0.64419742  4.01028314  0.39166458 -4.20356346 -0.48253831 -4.69336821\n",
            "  4.76331065  5.01346722]. \t  -596.9528926442035 \t -152.73804339453181\n",
            "56     \t [ 1.02684775 -3.64805945  0.98989122 -4.7236657  -4.80729088 -3.65975473\n",
            " -4.46704994  2.76233086]. \t  -516.5013930358274 \t -152.73804339453181\n",
            "57     \t [ 3.11498496 -1.323034   -3.6597088  -4.22299632  3.55789139  3.70061591\n",
            " -3.67539134  0.05743782]. \t  -364.7653740966541 \t -152.73804339453181\n",
            "58     \t [-4.65805469  2.12865379 -5.03679717  3.70244259 -0.65354896 -3.15921944\n",
            " -4.33926272  3.89205851]. \t  -476.7091070038947 \t -152.73804339453181\n",
            "59     \t [-5.12       -5.12       -1.68609756 -4.25519225 -5.12       -2.17571958\n",
            "  1.00164691 -1.52123855]. \t  -344.6095628496773 \t -152.73804339453181\n",
            "60     \t [ 4.40230857 -2.96737793 -4.98122695 -4.40401203  4.04132616  5.02196378\n",
            "  4.89302131  4.32806942]. \t  -739.4415272242841 \t -152.73804339453181\n",
            "61     \t [ 2.57018932  2.88837136 -3.12909725  4.3492508   0.25259859 -2.72378822\n",
            "  4.57242481  3.99491743]. \t  -447.1864968607787 \t -152.73804339453181\n",
            "62     \t [ 3.70708618 -3.92629043 -4.95950812 -4.38938929  3.64116162 -2.04395204\n",
            " -0.47685464  4.99333539]. \t  -487.8467653390934 \t -152.73804339453181\n",
            "63     \t [-3.48016215 -2.00216995 -1.90278918  4.57182481  4.68365022  3.65072466\n",
            " -2.10272348 -5.00531094]. \t  -535.6219088840761 \t -152.73804339453181\n",
            "64     \t [ 1.99565825 -1.27578402  3.85813003  3.09751049 -4.79988065 -4.18897084\n",
            "  3.30681978 -4.38572509]. \t  -541.172895817521 \t -152.73804339453181\n",
            "65     \t [-4.6605583  -4.70803083 -3.93667182  0.49511831 -0.52270532  3.99356123\n",
            "  4.56005295 -3.63003485]. \t  -461.55773235645336 \t -152.73804339453181\n",
            "66     \t [-5.03430749  1.90371793 -1.00144749  4.0806421   2.7356181   4.95884524\n",
            " -4.86015523  0.75740047]. \t  -457.1037012253525 \t -152.73804339453181\n",
            "67     \t [-1.7201126  -4.74452402  0.86605433 -2.88107587  3.39723011 -2.19152036\n",
            "  0.65025838 -2.39464617]. \t  -218.78927180376547 \t -152.73804339453181\n",
            "68     \t [ 3.9227189  -4.51840625  4.74584607 -4.29274533  3.8537263   2.53005367\n",
            "  4.31761462 -3.44056822]. \t  -535.3552386229392 \t -152.73804339453181\n",
            "69     \t [ 3.39591795 -3.95357246 -3.97710275 -0.3530106  -4.05636161  4.41168914\n",
            " -1.65653665 -4.60867107]. \t  -478.92017617629597 \t -152.73804339453181\n",
            "70     \t [-4.02069164 -4.0330224   4.74817991  3.47442787  1.73638884 -4.25363108\n",
            "  1.76327396 -3.93081012]. \t  -433.62831978694334 \t -152.73804339453181\n",
            "71     \t [-0.01009906  0.62795904  4.15493925  5.11616893  1.81983185 -0.07727703\n",
            " -4.71017338 -2.36570207]. \t  -373.94733931960536 \t -152.73804339453181\n",
            "72     \t [ 5.05141408  1.94030177 -2.65385624  1.21106301 -1.81846509  0.60534404\n",
            "  4.25980735 -1.78906151]. \t  -231.4022431312851 \t -152.73804339453181\n",
            "73     \t [-4.78212961 -4.88402868  1.99794722  3.00307206 -2.96815232 -2.51361267\n",
            " -4.83211224  4.80500924]. \t  -548.7345865618074 \t -152.73804339453181\n",
            "74     \t [ 4.84382616 -4.40235402 -4.28706566 -1.23500576 -1.66244758 -2.64895547\n",
            "  2.17010008 -4.18032821]. \t  -352.14878901261716 \t -152.73804339453181\n",
            "75     \t [-3.40229655  4.34661837  2.35489319  2.79786202  0.96045276 -4.83214292\n",
            "  3.0431217   5.02790085]. \t  -509.0828993755149 \t -152.73804339453181\n",
            "76     \t [ 4.47773363  4.86273271  5.06517294 -1.69852563  1.48623376 -2.51946612\n",
            "  4.96581053 -4.09158894]. \t  -511.5247557803191 \t -152.73804339453181\n",
            "77     \t [-4.53434803  4.94480073  4.24932604 -4.45308312 -2.18479244 -3.48578938\n",
            " -0.29623264  3.63521014]. \t  -406.0557873483332 \t -152.73804339453181\n",
            "78     \t [-3.08047585 -3.62128123 -0.52975333 -4.45931296  4.17266537 -4.35343845\n",
            " -4.80595573  3.51016269]. \t  -577.1211408759783 \t -152.73804339453181\n",
            "79     \t [ 0.5120268   1.58094301  0.54645986 -3.49684265 -5.12       -5.12\n",
            " -4.023183   -5.12      ]. \t  -666.4440323933189 \t -152.73804339453181\n",
            "80     \t [-2.90959117 -2.3799853   1.29808395  3.6576453  -5.09719066  4.71790777\n",
            " -2.61068699  0.20482469]. \t  -389.867040320837 \t -152.73804339453181\n",
            "81     \t [-4.28957845 -4.94752942 -4.26157602  4.42705011 -2.74628309  0.92318833\n",
            " -5.07010875 -4.64102975]. \t  -595.314049201819 \t -152.73804339453181\n",
            "82     \t [-3.18056267 -3.14187577  4.12117945 -3.85385741 -4.95678483 -3.43704388\n",
            "  4.5077793   2.46005312]. \t  -524.6035863489437 \t -152.73804339453181\n",
            "83     \t [ 2.19783536  2.01704106  4.76269488 -4.00314198 -4.1813349   4.33630109\n",
            "  3.03670451  2.51114915]. \t  -460.3545908992264 \t -152.73804339453181\n",
            "84     \t [-3.03783141 -0.43236108  4.53816085 -3.86034045 -4.40313222  0.40534257\n",
            " -2.8118081  -4.22478666]. \t  -427.0540315044459 \t -152.73804339453181\n",
            "85     \t [ 0.24215307 -5.01637748  4.32474443 -3.94514715 -1.12327741  4.58841958\n",
            " -5.11919073  4.65660787]. \t  -658.2988090726801 \t -152.73804339453181\n",
            "86     \t [-2.28912484 -1.40653702  5.01779324  2.58201368  1.79845957  5.00058731\n",
            " -4.40922023  4.76988194]. \t  -595.7089867672369 \t -152.73804339453181\n",
            "87     \t [-5.09371687  5.10101616 -4.87953466  4.43445528 -4.59603403  4.19917681\n",
            " -4.38973889  2.11431278]. \t  -610.1411934691321 \t -152.73804339453181\n",
            "88     \t [-4.95887736  4.96546955 -4.2381063   2.56974395  5.06130059 -1.77911594\n",
            " -5.11720646 -3.31429997]. \t  -572.453839056646 \t -152.73804339453181\n",
            "89     \t [-3.64706155 -1.55708584  2.98106612  4.96920244  1.9416634  -1.47119345\n",
            "  4.38905353  2.17647871]. \t  -348.1620050387696 \t -152.73804339453181\n",
            "90     \t [-4.9483906  -0.25640036 -3.03668656 -5.01937591  1.48675985  4.7035563\n",
            " -4.59648713  4.54714356]. \t  -610.1578851069596 \t -152.73804339453181\n",
            "91     \t [-4.51166199 -0.28840035  1.90613665 -4.32368744  4.88633468  1.42008308\n",
            " -4.41188402 -0.09306951]. \t  -374.00209473131656 \t -152.73804339453181\n",
            "92     \t [ 1.74322594  1.86874441 -4.5989925   4.83911549  3.15260692 -4.30525788\n",
            "  0.21249619 -3.64878211]. \t  -434.87469285871947 \t -152.73804339453181\n",
            "93     \t [ 0.77293137  1.97111171 -4.28736873  2.45648938 -4.99609229  4.22940049\n",
            "  4.77551527  2.03510548]. \t  -512.5536565344634 \t -152.73804339453181\n",
            "94     \t [-0.44761124  0.34820107  5.02789919  2.75080785  3.5325564   4.98564275\n",
            "  4.05757694 -4.03861394]. \t  -563.8152404193071 \t -152.73804339453181\n",
            "95     \t [ 4.27242188  0.53614581 -2.39354292 -4.79587547 -1.92233426  4.89215605\n",
            "  1.31721785  4.34092597]. \t  -452.987858713763 \t -152.73804339453181\n",
            "96     \t [-3.71002455  2.60647693 -3.18597458 -5.07401353 -3.44467282 -1.42484352\n",
            " -2.96740893  4.11094787]. \t  -429.13315937665857 \t -152.73804339453181\n",
            "97     \t [ 4.61327717  4.90070114 -4.03236253 -4.97457071 -0.28742076  2.13915509\n",
            " -4.34205837  3.87206267]. \t  -496.8675385591207 \t -152.73804339453181\n",
            "98     \t [-3.4457865   3.97455798 -1.85166224  0.27857295  5.01751537 -2.51186244\n",
            " -1.34283234  4.87125469]. \t  -420.253426581802 \t -152.73804339453181\n",
            "99     \t [ 0.97148563 -4.81306652 -3.17957365  4.49669754  4.61820948 -4.67574705\n",
            " -4.94201458  1.33345181]. \t  -581.4894870090851 \t -152.73804339453181\n",
            "100    \t [-1.21756842  4.91911202  3.08703768  5.05157816 -2.77783997 -3.54898675\n",
            "  4.14632609 -2.88782925]. \t  -481.75539012323145 \t -152.73804339453181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qixLpcuc24ey",
        "outputId": "b7ebbf79-d94f-4b55-8c4f-244521216dba"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 20\r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_loser_20 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_20 = dGPGO(surrogate_loser_20, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.722097    0.66077445 -0.11835563 -1.6744678  -1.27110986  0.3280473\n",
            " -4.42259161  0.86557758]. \t  -164.28536719065698 \t -132.28213531381235\n",
            "init   \t [-2.6839269  -3.47385261 -3.56229991 -3.8188112  -1.76700246  1.98813566\n",
            " -1.44418335  4.00758432]. \t  -310.1550894686203 \t -132.28213531381235\n",
            "init   \t [-3.05275003 -3.98743036  0.28218124  3.76479057 -2.43840637 -0.00619396\n",
            " -0.73150053  0.30723982]. \t  -132.28213531381235 \t -132.28213531381235\n",
            "init   \t [ 0.75721546 -1.10739814 -4.30577546  3.76095755 -3.43548334  3.1076518\n",
            " -2.17161474 -2.36983115]. \t  -310.1222484793693 \t -132.28213531381235\n",
            "init   \t [ 2.22697488  3.90559391  5.0393091  -0.42649562  2.91972373  2.4442259\n",
            " -0.2705103  -0.15529262]. \t  -191.55277957356324 \t -132.28213531381235\n",
            "1      \t [ 4.30728864  2.61813474 -2.20410079  4.60389393  3.48040036  3.22508805\n",
            "  2.4952604   4.24826238]. \t  -442.5587609971722 \t -132.28213531381235\n",
            "2      \t [ 1.64417887 -4.25346266 -0.53384123 -3.88827288 -3.49237376 -3.32866682\n",
            "  4.97929121  4.42131042]. \t  -557.6176193329263 \t -132.28213531381235\n",
            "3      \t [-0.51012006 -0.74868806 -0.30505697  3.86744867  1.7594746   4.11963334\n",
            "  4.47966981 -2.33505232]. \t  -362.88797991469033 \t -132.28213531381235\n",
            "4      \t [ 4.44955614 -2.13360821  4.10720185  2.39925212  2.88050458 -0.27507236\n",
            "  2.51470917  4.28698122]. \t  -335.76860348287215 \t -132.28213531381235\n",
            "5      \t [-3.91293411  2.88532018  1.65072288  2.76545681  4.60039161 -4.26943569\n",
            "  1.23156863 -3.93232258]. \t  -420.23597912178127 \t -132.28213531381235\n",
            "6      \t [-1.26257825 -3.6572517   1.92916383 -1.20022741  1.84333074 -4.53359964\n",
            " -4.51902056 -4.5981504 ]. \t  -497.67750685336034 \t -132.28213531381235\n",
            "7      \t [-1.36114306  4.12459045  0.45523257 -4.7981147   4.46392568 -1.90118512\n",
            " -4.61594301 -3.62407127]. \t  -504.1263731038 \t -132.28213531381235\n",
            "8      \t [ 3.18549963  1.39147754 -3.29705633 -4.21724791 -3.38666378  0.79298607\n",
            "  1.7390529  -4.1889532 ]. \t  -340.44147425079825 \t -132.28213531381235\n",
            "9      \t [-5.12       -4.95937989 -3.9831332  -3.50368761 -3.89699554 -5.12\n",
            " -5.12       -5.12      ]. \t  -798.5399266588842 \t -132.28213531381235\n",
            "10     \t [ 4.12876868  4.80520776  4.77941632 -4.90271379 -0.05901974 -3.58815148\n",
            "  0.25554618 -4.18406528]. \t  -445.6763934769549 \t -132.28213531381235\n",
            "11     \t [-4.73358359  0.35401167  1.08036012 -5.09279157  0.85489432  3.80346997\n",
            "  4.43695619 -4.22235364]. \t  -500.7898477309751 \t -132.28213531381235\n",
            "12     \t [ 1.34048309  0.69597845 -4.83646794  3.69068387 -1.37750937 -1.84499674\n",
            " -0.50560173  5.09314637]. \t  -366.6468123795353 \t -132.28213531381235\n",
            "13     \t [ 2.22015245  4.99900615  4.38913471  4.62874018 -3.79354301 -2.24991212\n",
            " -2.50196261 -0.99147537]. \t  -352.4140311601115 \t -132.28213531381235\n",
            "14     \t [ 4.79087088 -0.94799833  4.91024952  3.88005337 -0.62997974  3.33557191\n",
            "  0.41603295 -4.71723837]. \t  -405.27165212742636 \t -132.28213531381235\n",
            "15     \t [ 4.92677125  1.53912033 -3.04542069 -0.59011188  4.72885737  4.76827568\n",
            " -3.90562594 -0.6927353 ]. \t  -417.0731802779107 \t -132.28213531381235\n",
            "16     \t [ 3.65868812  2.56579156 -1.38016142  4.72992989  2.19125752 -3.445696\n",
            "  0.20866163 -1.80736153]. \t  -243.43825185342058 \t -132.28213531381235\n",
            "17     \t [-1.04356817  1.67474864 -0.50494701 -3.90815974 -1.27826809  5.06554936\n",
            "  4.72015522  3.13206553]. \t  -465.1246865017904 \t -132.28213531381235\n",
            "18     \t [-4.43873326 -2.71773728  3.72734547 -0.94996697 -0.79508233 -4.79736714\n",
            "  3.73814091 -1.31561486]. \t  -332.6753968826721 \t -132.28213531381235\n",
            "19     \t [ 1.78866288 -5.1028478   3.33605197 -4.86754739  4.39084072  1.08225382\n",
            " -2.67082228 -0.73853794]. \t  -341.1588233956468 \t -132.28213531381235\n",
            "20     \t [-3.01773588 -0.60336082  3.01730218 -0.53133665  3.29747499 -4.34078569\n",
            " -3.03556623  4.46207479]. \t  -429.48118690199294 \t -132.28213531381235\n",
            "21     \t [ 0.08296276 -4.24504454 -1.29299679 -3.17528341  2.6114569  -3.91025846\n",
            "  4.33192539 -4.43272585]. \t  -495.7836837649471 \t -132.28213531381235\n",
            "22     \t [-4.50459226  4.92854671 -3.81002921  0.85977529  3.83952549  3.58843789\n",
            " -2.44917507 -3.21284186]. \t  -390.9174498397427 \t -132.28213531381235\n",
            "23     \t [-3.00405964 -3.04606103 -0.52231307  1.13360097  3.57919601  4.06574232\n",
            " -4.30839356 -4.8674063 ]. \t  -516.2437096199313 \t -132.28213531381235\n",
            "24     \t [-3.70176067 -1.38641892 -2.24133892  4.54881945  4.54699679  2.42051045\n",
            " -1.24746711  3.62082879]. \t  -369.6907333577205 \t -132.28213531381235\n",
            "25     \t [ 4.37837236e+00 -4.68151088e+00  3.79781015e+00  2.98847088e-03\n",
            " -3.82600785e+00 -3.05298886e+00 -4.58088088e+00  4.28281806e+00]. \t  -529.0210121069344 \t -132.28213531381235\n",
            "26     \t [-4.36901913  3.708553   -1.00233903 -3.55839758 -2.02817687 -3.42920121\n",
            " -0.13593644  4.34234501]. \t  -342.3589481435898 \t -132.28213531381235\n",
            "27     \t [ 1.59219624 -4.37740095  4.46903271 -1.83935635 -2.87181407  5.01996796\n",
            "  0.25366106 -0.56185339]. \t  -309.7209458184118 \t -132.28213531381235\n",
            "28     \t [ 3.33020962  3.79062089  3.2210877  -4.05988623 -5.02963221 -2.48540496\n",
            " -1.8871732   5.07192358]. \t  -531.1594891465263 \t -132.28213531381235\n",
            "29     \t [ 1.32723519  4.59736317 -2.29790054 -4.06327296  5.06642424 -1.70805853\n",
            "  3.28241285 -1.56997654]. \t  -366.90114498298686 \t -132.28213531381235\n",
            "30     \t [-4.78398604 -0.9080889  -4.7166842  -1.52484158  4.75148093 -5.02104635\n",
            "  0.52416447 -1.51469392]. \t  -385.0035845538857 \t -132.28213531381235\n",
            "31     \t [ 3.6256787  -4.72024494 -4.07563999  0.16337912  3.63918736 -1.20402648\n",
            "  0.90963829  1.75701572]. \t  -213.0516937384514 \t -132.28213531381235\n",
            "32     \t [ 4.49249774  2.59055522  3.57987514 -4.8154984   1.00238482 -2.02326784\n",
            "  4.69288692  4.9670409 ]. \t  -545.9269346287647 \t -132.28213531381235\n",
            "33     \t [ 0.65647757  2.62589303  4.67957595  4.14152706 -4.34638345  4.12219231\n",
            "  4.72639017  4.47502934]. \t  -661.5143805288717 \t -132.28213531381235\n",
            "34     \t [-3.86651974  4.91482368 -2.27514161  4.95295096 -4.97365079 -0.00894866\n",
            "  4.46267411 -3.70198725]. \t  -549.6490495098249 \t -132.28213531381235\n",
            "35     \t [ 4.11723247 -3.97201285 -0.26975294  2.93739875 -3.57328272 -2.44494961\n",
            " -4.53491658 -4.93413107]. \t  -521.6688138772249 \t -132.28213531381235\n",
            "36     \t [-4.30818271 -0.15085506 -1.89619714  3.01191803 -4.55097171  5.00032155\n",
            " -4.08384759  4.79519561]. \t  -619.9511412268035 \t -132.28213531381235\n",
            "37     \t [-1.10511012  1.79249863  3.15103425  2.58137412 -3.52668105 -4.17466683\n",
            "  4.43390634  4.55756524]. \t  -534.6307309041911 \t -132.28213531381235\n",
            "38     \t [ 1.11146657 -4.5313971   3.53521779 -4.6500569  -4.03571194 -2.13207306\n",
            "  1.29236717 -5.06723902]. \t  -492.10393622152446 \t -132.28213531381235\n",
            "39     \t [-3.95491318 -4.96561533 -3.03360534  3.38479251 -4.18462808  4.49476065\n",
            "  3.31255324 -4.830339  ]. \t  -610.6328375651256 \t -132.28213531381235\n",
            "40     \t [-4.17214038  1.79042877  4.92079921 -4.24070095 -2.90632998  0.02091369\n",
            " -4.85329778 -2.92277773]. \t  -443.8539254875753 \t -132.28213531381235\n",
            "41     \t [ 2.37665316 -2.44026576 -2.58813515  4.96487971 -4.2036418  -3.27176684\n",
            "  4.92592072 -4.09680622]. \t  -592.9569325640667 \t -132.28213531381235\n",
            "42     \t [-2.94337814 -0.30132935 -4.30749995  2.3505918  -1.91626416 -4.76114462\n",
            " -0.44155297 -5.08021252]. \t  -448.81445556596617 \t -132.28213531381235\n",
            "43     \t [ 3.81901256 -2.30069736 -4.26806047 -4.83744545  2.98230921  5.05308766\n",
            "  1.63868137  4.07367883]. \t  -522.6526282848426 \t -132.28213531381235\n",
            "44     \t [-4.58284526  1.99798186  2.14690668 -5.10213173  4.80708675  4.42989787\n",
            " -1.22951364  1.92713381]. \t  -420.5180216704457 \t -132.28213531381235\n",
            "45     \t [-3.85068863 -4.2227434   4.90648877 -3.02424539 -2.27919975  1.78592313\n",
            "  2.54887448  4.98902187]. \t  -449.0069907969167 \t -132.28213531381235\n",
            "46     \t [-4.02511708  2.95054394 -4.36753055  4.01959544  4.27007882 -4.83190891\n",
            " -1.21468252  3.16045229]. \t  -476.9553185897689 \t -132.28213531381235\n",
            "47     \t [ 5.03724485 -4.10422338  3.87090172  3.20281017  4.67863374 -2.69327794\n",
            " -0.11648928 -3.23435103]. \t  -381.8004932063827 \t -132.28213531381235\n",
            "48     \t [-2.42459096  3.5172467   3.54722133  2.77649431 -3.85607446  4.2594164\n",
            " -0.52688781 -4.18092872]. \t  -424.19162495394573 \t -132.28213531381235\n",
            "49     \t [ 4.7797872   3.96134955 -0.41919145  4.79503951 -1.734741    3.73479707\n",
            " -4.73355259  2.28913382]. \t  -444.2333226990391 \t -132.28213531381235\n",
            "50     \t [ 1.86579487  4.99854161  1.0033673   2.12205727 -3.22946323 -4.83685886\n",
            "  4.7122199  -3.68407377]. \t  -531.017469530529 \t -132.28213531381235\n",
            "51     \t [ 4.74863442  0.69407034 -4.80359229 -4.78139621 -4.32177364 -0.10034368\n",
            " -0.77265772  3.89383313]. \t  -403.10703276346345 \t -132.28213531381235\n",
            "52     \t [-1.6429885   0.0494173   4.57696325  3.57099391  4.86568577 -4.55846234\n",
            "  5.02279833  4.71362454]. \t  -713.9555985061122 \t -132.28213531381235\n",
            "53     \t [-2.99278985  4.09402315 -2.25427974 -4.15812396 -4.98598826 -3.23930795\n",
            "  5.04723872 -2.00337815]. \t  -524.5737664233332 \t -132.28213531381235\n",
            "54     \t [-2.10707126 -1.79078364  4.10321695  3.01751542  4.65665302  0.8910786\n",
            " -0.50658875 -0.75646939]. \t  -217.34493240298133 \t -132.28213531381235\n",
            "55     \t [ 0.43443398 -4.82568451 -3.89063841 -2.9323994  -4.06573673 -4.87121313\n",
            " -4.21561552  2.49684776]. \t  -525.867530815453 \t -132.28213531381235\n",
            "56     \t [ 1.17415488  3.88300702 -4.78572348  3.21666921 -4.7994311   4.54940094\n",
            "  3.23879536  5.00873182]. \t  -655.1141288830049 \t -132.28213531381235\n",
            "57     \t [ 4.9409656   3.29563116  3.85194897 -2.86103607  4.08979341 -3.27685511\n",
            " -4.26568893  3.5782632 ]. \t  -501.2533344384266 \t -132.28213531381235\n",
            "58     \t [ 1.77125645 -5.11497996  4.29102027  1.70332684  3.00657374  2.73235778\n",
            " -3.98865859  4.96093613]. \t  -520.5522262091306 \t -132.28213531381235\n",
            "59     \t [ 4.80989237 -0.34598638  0.63856064  0.88473553 -4.64851945  0.51189312\n",
            "  3.36774237  1.91713721]. \t  -246.13979876624404 \t -132.28213531381235\n",
            "60     \t [ 3.84084832 -4.15648781 -1.48444165 -2.65297354  2.73128322  4.03348968\n",
            "  3.79335143 -4.7734201 ]. \t  -501.9933683839742 \t -132.28213531381235\n",
            "61     \t [-4.68403777  4.78343056  2.50373307  4.39015881 -2.62076406 -1.16547745\n",
            " -4.51918591  4.37148411]. \t  -501.93496391706594 \t -132.28213531381235\n",
            "62     \t [ 4.8125266  -4.14883374 -4.60223094 -4.86505344  2.72308395 -3.99785857\n",
            " -2.68065196 -2.64873994]. \t  -455.2036441497522 \t -132.28213531381235\n",
            "63     \t [-4.06453579 -4.94789968 -4.83707994  3.92992882  0.49036452 -4.56900797\n",
            " -3.43307238  3.99979727]. \t  -534.3994801796765 \t -132.28213531381235\n",
            "64     \t [ 4.29907783 -4.18804713  4.60294067 -3.97045656  0.91648359 -0.63462298\n",
            "  5.06292815  0.26048321]. \t  -366.7725282490275 \t -132.28213531381235\n",
            "65     \t [-4.85028361 -1.33118419 -1.43604211 -4.8217969   0.50586317 -2.21495035\n",
            " -1.00921088 -4.50873369]. \t  -326.729405805846 \t -132.28213531381235\n",
            "66     \t [-1.47334145 -3.43478903 -1.56153651  4.97947713 -3.53338243  1.06150654\n",
            "  4.49620671  5.11942722]. \t  -552.6263828445142 \t -132.28213531381235\n",
            "67     \t [-4.60318334  3.29832292 -4.81575769 -0.50638108 -4.60151559  4.0727718\n",
            "  0.25095789 -2.47405063]. \t  -368.3502397126819 \t -132.28213531381235\n",
            "68     \t [-3.73051006  3.79231747 -4.75050712  2.22188097 -4.57988567 -4.68025656\n",
            " -4.45552724  3.91756282]. \t  -628.1750436926087 \t -132.28213531381235\n",
            "69     \t [ 4.01514129  4.03857753 -2.55995633 -1.07135519 -2.63228332 -4.77262821\n",
            " -0.61107319  0.33551708]. \t  -247.81981796933985 \t -132.28213531381235\n",
            "70     \t [-3.09263311 -2.85811429 -4.78909245 -0.87625343  2.55810264  3.77770925\n",
            "  3.69459828  1.25643633]. \t  -324.3049352590146 \t -132.28213531381235\n",
            "71     \t [ 4.06223082  4.50470765  0.71686673  4.2989692  -4.80995356  2.80221033\n",
            "  3.24715262 -3.29405271]. \t  -455.9595695386739 \t -132.28213531381235\n",
            "72     \t [-3.5535053   5.01196027 -3.87530704  2.32054893  1.88121856  1.8006963\n",
            "  4.91322996  0.72004935]. \t  -339.73722267661253 \t -132.28213531381235\n",
            "73     \t [-3.53909797 -4.05483232 -4.63821738  4.79159766  3.03026949 -1.58957218\n",
            "  4.29332012 -1.82634038]. \t  -418.5708000113503 \t -132.28213531381235\n",
            "74     \t [ 2.54065264  4.59062236  4.10638927 -2.58355376 -5.03052008  0.85672041\n",
            " -2.76366799 -4.85647798]. \t  -498.9713745967064 \t -132.28213531381235\n",
            "75     \t [-2.6998693   4.64433272  4.94518275 -1.40683959 -3.0874715   4.14720868\n",
            " -1.18811207  3.49193238]. \t  -389.99868098937736 \t -132.28213531381235\n",
            "76     \t [-4.96184156 -4.81695404  2.27494179 -4.23250692  5.05349888  3.05741584\n",
            "  0.36287897 -3.85801598]. \t  -461.98057478529313 \t -132.28213531381235\n",
            "77     \t [ 4.90167377 -3.76831883 -0.81232246  3.97091052  1.12041741  4.61301593\n",
            " -1.65925273  0.13059752]. \t  -270.8434388812133 \t -132.28213531381235\n",
            "78     \t [-1.41713113  4.49869529  5.09930383  4.8101848   3.19594992  0.79341284\n",
            "  4.47526635  1.13512367]. \t  -418.39660021726945 \t -132.28213531381235\n",
            "79     \t [-5.04028501 -4.6393292   5.08557532  1.43869276  4.32776343  2.30545821\n",
            "  4.47327375  4.31482437]. \t  -568.8712280891283 \t -132.28213531381235\n",
            "80     \t [ 0.54721314  1.83971479  2.94164187 -4.15861803  4.22537584  5.08482966\n",
            " -3.93764879 -4.15069289]. \t  -592.9682488183498 \t -132.28213531381235\n",
            "81     \t [-5.12        0.85549038  0.74317575  0.17206623 -5.12       -5.12\n",
            " -5.12       -1.2349897 ]. \t  -513.5142818713937 \t -132.28213531381235\n",
            "82     \t [ 0.57117002 -0.80279648 -5.04436395 -5.05500057  4.97848119 -4.40341781\n",
            "  4.19247316  4.15043525]. \t  -681.2777718168121 \t -132.28213531381235\n",
            "83     \t [ 5.03435565 -4.9242681  -3.11087812  4.48563227  0.34606962 -4.57324953\n",
            " -3.59794403  3.36330223]. \t  -490.55515741414206 \t -132.28213531381235\n",
            "84     \t [-4.79200081  4.81826665  3.93458252 -2.77176357  3.43443086 -3.13868286\n",
            "  3.57345208  3.57181969]. \t  -456.1028133934816 \t -132.28213531381235\n",
            "85     \t [ 0.91806988 -0.21686847 -4.93716773 -2.40491543 -5.0405948  -2.74189214\n",
            " -4.69905039 -5.01441652]. \t  -625.0665854430682 \t -132.28213531381235\n",
            "86     \t [ 3.9821822  -4.66561367 -2.11627911 -3.876779   -0.64911566  4.40474836\n",
            " -4.4532276  -0.57223559]. \t  -392.90313609917536 \t -132.28213531381235\n",
            "87     \t [-2.89566722 -2.67370469  4.35852809  0.38436728 -2.32519611  5.07442282\n",
            " -3.86454526  3.85107792]. \t  -484.98420252802623 \t -132.28213531381235\n",
            "88     \t [ 4.33362589  4.86454229 -3.86350599 -4.74979548 -0.13163849  1.40083722\n",
            " -5.00390614 -3.00824671]. \t  -460.66075666625494 \t -132.28213531381235\n",
            "89     \t [ 5.08367889  3.61984313 -4.6643294   0.68693191  2.3989084   2.40521966\n",
            "  4.55929977 -3.01029078]. \t  -400.695330415366 \t -132.28213531381235\n",
            "90     \t [-2.50380428  1.85368733 -4.80431782 -4.83320476 -0.28729918  5.03445595\n",
            " -5.03450479 -1.89627826]. \t  -534.5030551811024 \t -132.28213531381235\n",
            "91     \t [ 4.3074709  -2.09211978 -2.95273532  2.33947159  4.71319625 -2.95834664\n",
            "  4.52527469 -3.74529607]. \t  -494.50338467440054 \t -132.28213531381235\n",
            "92     \t [ 4.37369686  1.64404179  4.64844497 -2.7917668  -3.06694447  4.29029129\n",
            " -4.73046282  3.6604643 ]. \t  -541.8382190229837 \t -132.28213531381235\n",
            "93     \t [ 0.44985771 -5.04018311 -2.67352371 -1.98745115 -4.13204736  4.40905542\n",
            "  4.44234105 -1.50988587]. \t  -446.6387949917347 \t -132.28213531381235\n",
            "94     \t [ 4.45160046  0.85827729  4.31029756 -3.50117674  4.61732147  1.27672196\n",
            "  3.97381346 -4.0892082 ]. \t  -486.7487209708847 \t -132.28213531381235\n",
            "95     \t [ 2.29183362 -4.25880269 -1.60290865 -3.84858402  4.8914368  -2.46004838\n",
            " -4.75621962  4.61687575]. \t  -593.299153821644 \t -132.28213531381235\n",
            "96     \t [ 3.20266808  0.7090719  -4.52728769  4.21093389  4.97003275 -1.27198075\n",
            " -4.8400682  -4.63203128]. \t  -612.5227764965464 \t -132.28213531381235\n",
            "97     \t [-0.66551097  4.51914064  3.38283834 -4.396338   -5.10659132 -0.80795747\n",
            "  4.45304114  2.37845833]. \t  -471.29679190919546 \t -132.28213531381235\n",
            "98     \t [ 4.15523548  4.89760637 -4.52582521  2.60039168  4.35751514 -0.56381114\n",
            " -3.51413984  4.65119041]. \t  -510.096326025636 \t -132.28213531381235\n",
            "99     \t [ 0.78204696  0.83270194  2.60888247 -4.33041426 -4.79979036  4.58985252\n",
            "  3.79167165 -4.66580997]. \t  -613.813229638116 \t -132.28213531381235\n",
            "100    \t [-2.78453089 -1.47255593  0.3676772  -3.15026286 -3.97190591  4.56368814\n",
            " -2.4883475  -3.67832185]. \t  -407.6198428979011 \t -132.28213531381235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kM4bcwSteJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5eeeda-cf1b-4791-c47b-9d62118ebe5b"
      },
      "source": [
        "end_lose = time.time()\r\n",
        "end_lose\r\n",
        "\r\n",
        "time_lose = end_lose - start_lose\r\n",
        "time_lose\r\n",
        "\r\n",
        "start_win = time.time()\r\n",
        "start_win"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1614503763.3564086"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eplfVnDk7RIG",
        "outputId": "de91a300-24ab-4c2a-e700-1ee8d5ac84f0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 1 \r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_winner_1 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_1 = dGPGO_stp(surrogate_winner_1, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.1486226  -3.38872572 -0.65475564  2.75724772 -2.09586888 -3.59257132\n",
            " -4.88982196 -0.8169012 ]. \t  -328.0959084909929 \t -201.54672633894333\n",
            "init   \t [-2.67589487 -1.6624006   5.02489564 -2.68568111 -4.28858717  1.73670644\n",
            "  1.24152749 -2.31164385]. \t  -280.8839324859534 \t -201.54672633894333\n",
            "init   \t [-0.34589276 -3.90791423 -4.36267454  4.10392759  3.01017662  3.4874332\n",
            "  3.22772436  5.02737768]. \t  -548.5335043326104 \t -201.54672633894333\n",
            "init   \t [ 0.79128402  3.21297323 -0.80570494 -4.83893289 -0.46964077 -4.04146089\n",
            "  3.24833343  2.024732  ]. \t  -322.64234862459267 \t -201.54672633894333\n",
            "init   \t [ 0.66852251 -2.31191249  5.10437114 -3.70644938  1.18185664 -0.15322828\n",
            " -0.97252315  2.33317475]. \t  -201.54672633894333 \t -201.54672633894333\n",
            "1      \t [-1.8143854  -1.01841357 -1.85378403  4.57955153  4.28757363  3.21376643\n",
            " -4.77105058  4.54013818]. \t  -577.6945507490634 \t -201.54672633894333\n",
            "2      \t [-0.85685749  4.37545244  1.02757506 -1.367164    2.72142012  1.32454858\n",
            " -4.17664952 -4.70221304]. \t  -396.22213339906483 \t -201.54672633894333\n",
            "3      \t [ 4.66308842  0.84598875 -4.15122453  1.11050319 -3.49839947  4.87163532\n",
            " -2.05963361 -0.01488499]. \t  -313.09403696321726 \t -201.54672633894333\n",
            "4      \t [ 4.50211867  3.52020401  0.59833872  4.66546641 -0.06524297 -0.97792544\n",
            "  0.60780846  2.84541126]. \t  -206.30933206172915 \t -201.54672633894333\n",
            "5      \t [-1.03156768 -4.09716338 -2.65023964  0.34176635  0.30694719  3.16298674\n",
            "  4.18980601 -3.18576573]. \t  -320.74829573525165 \t -201.54672633894333\n",
            "6      \t [-5.00073662  1.52813283 -4.81227914 -4.1373695  -1.5276949   2.70157047\n",
            " -4.98038175  3.67939215]. \t  -505.0161297967612 \t -201.54672633894333\n",
            "7      \t [-3.93220317 -3.69843659 -2.81018095  1.23484693  4.50101399 -3.36676303\n",
            " -2.10707555  1.44062107]. \t  -289.5975053416226 \t -201.54672633894333\n",
            "8      \t [-4.12558236 -4.0606954   2.63942955 -3.62357305  4.86767692  1.54210721\n",
            "  3.35016639 -1.3149525 ]. \t  -348.5578810169892 \t -201.54672633894333\n",
            "9      \t [-4.75817249 -0.99322514 -1.50822354  0.20869353 -3.33009375 -2.63325281\n",
            "  4.71182959  1.79887385]. \t  -309.96031249828116 \t -201.54672633894333\n",
            "10     \t [-3.64943616  4.76787457 -3.77407107  1.51899132  3.04907989  3.14110259\n",
            "  2.35817095 -3.44937339]. \t  -350.5396156120918 \t -201.54672633894333\n",
            "11     \t [ 4.03221345  3.58698611  1.24648967 -5.02074478 -3.71518292  1.82387278\n",
            " -0.50911699 -1.88878525]. \t  -266.81087668898175 \t -201.54672633894333\n",
            "12     \t [ 4.63674551 -4.6281269  -0.42155692 -3.88885714  1.81238622  4.32806214\n",
            " -1.61546108  3.49219493]. \t  -370.0123514248279 \t -201.54672633894333\n",
            "13     \t [-0.12596247  4.35779699  2.65609637  1.19983946 -4.88336546 -2.84094986\n",
            " -4.16830866  3.44941961]. \t  -449.39347109826764 \t -201.54672633894333\n",
            "14     \t [ 3.76467274 -1.81782839  2.25008069  0.72537853  3.84366629 -4.87742973\n",
            "  3.15140597  1.78559961]. \t  -349.70626856742626 \t -201.54672633894333\n",
            "15     \t [-1.22258763  0.90856751  3.13104671  3.85690408 -3.10141916  4.87282644\n",
            "  4.36504616  4.41712003]. \t  -572.08252685319 \t -201.54672633894333\n",
            "16     \t [ 4.02048756  0.91381162 -1.55145409 -0.16421347  4.95252691  3.37402237\n",
            "  2.43986153 -4.04480546]. \t  -388.65917263088727 \t -201.54672633894333\n",
            "17     \t [-4.61491168  0.22560982 -4.4900489  -4.05259464  4.86459139  0.25186857\n",
            " -2.70035443 -3.92739636]. \t  -440.7157295852119 \t -201.54672633894333\n",
            "18     \t [4.61873336 0.83964776 4.47081406 4.50065107 2.49815134 4.71072113\n",
            " 3.50702545 0.40377992]. \t  -415.47875034411805 \t -201.54672633894333\n",
            "19     \t [-4.85815546  1.59734913  2.92348916  3.69416848 -0.39115483 -0.42778408\n",
            " -3.30273009 -2.20353355]. \t  -225.9962819138438 \t -201.54672633894333\n",
            "20     \t [ 4.77995323 -3.53596255  3.94977777  3.33687398 -1.4959541   2.01786005\n",
            " -1.9408511  -2.62136459]. \t  -256.1558481987143 \t -201.54672633894333\n",
            "21     \t [-2.17149059 -3.59638969  4.80494534 -0.21803099 -4.46695367 -3.25794579\n",
            " -3.89312838  4.85422792]. \t  -558.093067666367 \t -201.54672633894333\n",
            "22     \t [ 3.49133701 -3.86697222  0.92159634 -4.18773352 -5.03610244 -3.81265309\n",
            " -3.5976832   1.53402444]. \t  -438.251548868952 \t -201.54672633894333\n",
            "23     \t [ 2.59874194 -3.33129644 -3.87254822 -1.58202482 -4.10283151 -4.91029881\n",
            "  4.4859348  -4.94632265]. \t  -649.3761087377535 \t -201.54672633894333\n",
            "24     \t [-3.09916885  2.94379667 -3.34454626 -0.54141198 -2.61410357 -3.91045828\n",
            " -0.02911508 -3.72278946]. \t  -298.46421819369573 \t -201.54672633894333\n",
            "25     \t [ 3.73693557 -2.43352427  4.396001   -0.5944916  -4.13716753 -3.44188037\n",
            "  4.38637397 -5.03548203]. \t  -579.3875132863946 \t -201.54672633894333\n",
            "26     \t [-4.82692697 -5.02314071 -2.96362424 -2.47117992 -4.64932239 -0.29259831\n",
            " -1.09790987 -2.22026194]. \t  -281.0082593094844 \t -201.54672633894333\n",
            "27     \t [-3.99609118  4.95113729  0.60470182 -2.89396888  3.94936536 -3.87086832\n",
            "  3.61499395 -4.08149306]. \t  -492.2285989910501 \t -201.54672633894333\n",
            "28     \t [-4.11385682  4.94276867  3.8709544   0.23949521  0.0455915   4.67436055\n",
            "  3.96153709 -3.72860503]. \t  -463.1527066129755 \t -201.54672633894333\n",
            "29     \t [ 3.36444364 -1.63999011  4.04012686 -1.09531888 -4.32849003  0.08810346\n",
            "  4.97565104  3.79138663]. \t  -452.4877118821266 \t -201.54672633894333\n",
            "30     \t [ 4.65403043  2.46591919 -2.36586501  0.60685337 -3.76523203  0.7614489\n",
            "  4.97096417 -1.54968462]. \t  -318.63581057054273 \t -201.54672633894333\n",
            "31     \t [ 4.49855503  3.09289469 -1.28472905 -0.49341256 -1.26308729 -4.63363614\n",
            " -3.07314868 -4.08017492]. \t  -381.38717216457644 \t -201.54672633894333\n",
            "32     \t [ 5.00253654  3.239052    2.07737943 -4.62612043  4.00971261  3.29127815\n",
            " -2.66743976  3.0448558 ]. \t  -413.91863077350513 \t -201.54672633894333\n",
            "33     \t [-3.63047934  4.71263026 -3.81408637 -4.98248057 -2.97049411  2.88123525\n",
            "  3.91350438  0.13819394]. \t  -401.8300352431608 \t -201.54672633894333\n",
            "34     \t [ 3.94506145  4.6219637  -4.05883276 -3.62467217  4.56192664 -4.92182544\n",
            " -4.30806291  3.44376204]. \t  -634.4578556365511 \t -201.54672633894333\n",
            "35     \t [-3.4995586   3.71790141 -1.0624482   3.28758637  1.45925005 -1.88281739\n",
            "  2.25233966  5.0516682 ]. \t  -358.09488898271115 \t -201.54672633894333\n",
            "36     \t [ 2.63802225 -4.00684813 -3.35755631 -1.36467282  4.3451529   0.77776063\n",
            " -3.31065861 -4.51674166]. \t  -418.2998095347933 \t -201.54672633894333\n",
            "37     \t [ 0.63055569  4.9953729   3.91728199  4.73809894 -4.30685725 -4.70600059\n",
            "  4.30730748  3.53521213]. \t  -641.6145513030394 \t -201.54672633894333\n",
            "38     \t [-4.51260628 -0.94366779 -0.45814386  4.50369554 -4.919382    1.26842236\n",
            "  3.90741448 -4.48597884]. \t  -502.42964726450975 \t -201.54672633894333\n",
            "39     \t [-1.68320819 -1.67411426  4.18686796  4.35442511  1.78421067 -2.41408691\n",
            "  2.93624867 -2.67325403]. \t  -305.2772915757213 \t -201.54672633894333\n",
            "40     \t [ 3.55512649 -2.581703   -4.54759393  3.76656471  0.8545759  -2.4123835\n",
            "  2.39635881 -1.40688515]. \t  -239.36059572519378 \t -201.54672633894333\n",
            "41     \t [ 4.43858766  2.10403276 -4.30741351  2.60579466 -4.06331952 -5.03566611\n",
            "  3.71073047  4.94099247]. \t  -637.7713890019648 \t -201.54672633894333\n",
            "42     \t [ 3.38225706  0.81101684  4.75370528  2.92931596  2.67393075  4.66937398\n",
            " -5.00639378  1.9355584 ]. \t  -486.8586594332529 \t -201.54672633894333\n",
            "43     \t [-4.75049403  3.87203886  0.05588416 -3.91534225  4.00071614  0.90493084\n",
            " -0.3175523   3.84653316]. \t  -317.89601431775617 \t -201.54672633894333\n",
            "44     \t [-0.38133763  0.3085388  -5.00889842 -4.96970633  3.14863896  3.34993697\n",
            "  4.76952709  3.13288666]. \t  -529.05557839901 \t -201.54672633894333\n",
            "45     \t [-2.50358196 -0.41728937  4.13729633 -5.02402201 -5.05658796 -4.33062379\n",
            "  2.86409028  3.84744806]. \t  -575.1462033186323 \t -201.54672633894333\n",
            "46     \t [-4.84841045 -1.77822351  0.92037077  0.21043686 -1.23364859  3.0349123\n",
            " -1.82777176  4.6658711 ]. \t  -292.9712957402547 \t -201.54672633894333\n",
            "47     \t [-4.88252713 -3.96020726 -1.53949925 -2.78733654  3.5088297  -5.05189709\n",
            "  2.18641641 -4.33873623]. \t  -492.142095969489 \t -201.54672633894333\n",
            "48     \t [ 0.59412566  2.39169917 -4.29138257 -1.47740976 -2.99220913 -3.74300031\n",
            " -3.02005579  3.5678597 ]. \t  -370.28131318493723 \t -201.54672633894333\n",
            "49     \t [-3.99134063 -3.15334957  2.42660694 -4.93275999  0.24331533  4.87031056\n",
            " -4.44408492 -0.89679383]. \t  -438.11048588746394 \t -201.54672633894333\n",
            "50     \t [ 1.12195583 -4.51683244 -1.05506503 -0.61958291 -3.17430458  4.2380258\n",
            " -4.9979383  -2.85373993]. \t  -445.0899406986292 \t -201.54672633894333\n",
            "51     \t [-3.61516018 -0.77104988  1.54455048  2.42982591  4.74163605  4.38818965\n",
            " -0.06703834 -3.36173413]. \t  -363.4258656746655 \t -201.54672633894333\n",
            "52     \t [-0.25807514  4.84470854  5.09369975 -1.10910023  1.27820283 -1.01222097\n",
            "  2.35776138  5.00838632]. \t  -383.6680487283604 \t -201.54672633894333\n",
            "53     \t [ 1.07934743  2.55631172 -4.00607106  3.911157    0.39443258  4.09194131\n",
            " -3.88176597 -5.10627192]. \t  -538.8795025314877 \t -201.54672633894333\n",
            "54     \t [-1.24282247  3.94627694  3.34455036  4.24909982  3.66185675 -1.35033567\n",
            " -4.98052249  4.22882896]. \t  -533.1578571329549 \t -201.54672633894333\n",
            "55     \t [ 4.05643636  0.59523541 -4.97917256 -0.2833642   5.04776514 -3.34440169\n",
            "  4.47554485  4.79971994]. \t  -610.8827505982509 \t -201.54672633894333\n",
            "56     \t [ 4.72815918  0.38050166 -3.93262398  3.51892326  3.72032308 -3.09229489\n",
            " -4.63510623 -0.26376104]. \t  -396.0967027357098 \t -201.54672633894333\n",
            "57     \t [ 2.53628102  2.96213734 -2.44785681 -4.82327938 -4.58667039  2.20822096\n",
            "  4.32451683  4.41894878]. \t  -556.5854939317538 \t -201.54672633894333\n",
            "58     \t [-4.08631166  5.03317101 -3.45093174  4.47173387  3.53066418 -3.37319907\n",
            " -3.86201159 -2.38302824]. \t  -463.5112717176821 \t -201.54672633894333\n",
            "59     \t [-1.42980664 -4.95687106 -4.11452226  4.64788319 -4.39377155 -0.60936577\n",
            "  0.63770779  3.8685483 ]. \t  -409.71076934681065 \t -201.54672633894333\n",
            "60     \t [-2.57680542 -3.8526742   4.54152495 -1.14599758  3.96974977 -2.14682726\n",
            " -4.86428134 -2.47491517]. \t  -424.53375268776426 \t -201.54672633894333\n",
            "61     \t [ 5.09762027 -4.11752181  4.79551488 -1.2743292  -4.94845215  3.43860937\n",
            " -4.89257636  2.94542147]. \t  -565.7255369425181 \t -201.54672633894333\n",
            "62     \t [ 4.96296702 -4.05347425 -1.81708161  3.1794231   0.87387694  1.38869373\n",
            " -2.57993399  3.6643077 ]. \t  -277.23137961766065 \t -201.54672633894333\n",
            "63     \t [-4.35811664  3.11720876  3.58054714 -4.32966194 -3.20447218 -3.88426756\n",
            " -3.66184876 -0.472559  ]. \t  -389.39087193414105 \t -201.54672633894333\n",
            "64     \t [-0.39822456  4.6495185  -2.39944775  1.22302834  0.80525279  4.99275184\n",
            " -0.30027595  3.39482576]. \t  -312.2873500608127 \t -201.54672633894333\n",
            "65     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -201.54672633894333\n",
            "66     \t [-5.10412658 -3.10712386 -3.17940034 -4.78488113 -1.36979352 -4.96823704\n",
            " -2.66680955  4.19141947]. \t  -515.0756911594598 \t -201.54672633894333\n",
            "67     \t [ 3.47330315  4.72191459  3.54277161  4.43181283  2.37302937 -4.97213651\n",
            "  0.25842993 -4.65485297]. \t  -523.1722837068255 \t -201.54672633894333\n",
            "68     \t [ 2.02603303  4.07461689 -3.60163538  1.20077341  2.89563313 -5.07438111\n",
            "  2.69961826 -2.05809874]. \t  -363.313827519593 \t -201.54672633894333\n",
            "69     \t [ 3.70689705 -5.06773793  1.35813166 -4.69725806 -1.14962269  0.57211918\n",
            " -0.17550761 -4.87671712]. \t  -357.942182302825 \t -201.54672633894333\n",
            "70     \t [ 0.5520616  -4.83282099 -4.63087779 -3.7825841  -0.85628675 -1.34637373\n",
            "  2.223229    4.314689  ]. \t  -366.6579742683525 \t -201.54672633894333\n",
            "71     \t [ 0.99377342  2.98360404  4.61502499  4.96149154 -4.20673426  3.29262555\n",
            " -4.66049831 -0.95165973]. \t  -493.9706565167026 \t -201.54672633894333\n",
            "72     \t [ 5.11526004  1.42687666  4.56826517  2.63480585 -4.80427572  4.9792734\n",
            "  3.75202188 -4.94999262]. \t  -679.3411869370444 \t -201.54672633894333\n",
            "73     \t [ 4.90833977 -4.58801419 -4.62552152  3.60882239 -4.3150363  -4.38323241\n",
            " -2.90619039  3.85035029]. \t  -568.5695185453917 \t -201.54672633894333\n",
            "74     \t [ 0.92398762  3.92095878 -2.52659033  4.97598675 -4.23854117 -0.41744138\n",
            " -0.28197591 -3.60082888]. \t  -344.95036303683213 \t -201.54672633894333\n",
            "75     \t [-3.75175498 -1.76856358 -3.48367527  4.89205086  0.99979887 -3.34966958\n",
            " -0.6728747  -3.58583941]. \t  -330.82290978346697 \t -201.54672633894333\n",
            "76     \t [-1.14529641  3.16552175  3.87155444 -4.83271766  4.43380757 -2.31964042\n",
            " -0.76170942 -0.39395176]. \t  -295.62083158882393 \t -201.54672633894333\n",
            "77     \t [ 4.73199043  2.58480107  4.78980078 -4.62389021 -4.87923933 -4.68496523\n",
            "  0.06263762  1.98443055]. \t  -472.36160272485296 \t -201.54672633894333\n",
            "78     \t [ 1.98457646  2.67571795  2.29357814 -4.18257072  2.25325915  1.98579713\n",
            "  5.0346386  -1.22661314]. \t  -342.5305352505411 \t -201.54672633894333\n",
            "79     \t [ 0.32328987 -1.06150327  2.32209837  4.26818946  4.99182872 -5.10373102\n",
            " -4.15512556 -3.97213711]. \t  -619.3629380811951 \t -201.54672633894333\n",
            "80     \t [ 4.93094917 -3.25880174  4.64981765 -3.22807196  3.91576939 -4.44503044\n",
            " -3.27154294 -2.2037308 ]. \t  -461.08645558252124 \t -201.54672633894333\n",
            "81     \t [-0.32151741 -2.41147451 -4.31841861 -4.40601889  4.8276448  -4.61666998\n",
            " -0.23484018  0.79717414]. \t  -395.21458392155984 \t -201.54672633894333\n",
            "82     \t [-3.77760668  1.27303476  3.36207657 -0.51205713 -2.34401547 -4.14978527\n",
            "  3.21562951 -5.07167224]. \t  -461.42417006930475 \t -201.54672633894333\n",
            "83     \t [-2.64902335 -2.91998323  3.16881202  3.95260889 -2.6967158  -4.88316246\n",
            "  2.45667141  4.65782671]. \t  -511.92897853290543 \t -201.54672633894333\n",
            "84     \t [ 4.93471067  3.81145391  4.11498117  2.54737149  4.49255463  3.53668241\n",
            " -2.72234347 -5.07849016]. \t  -564.3318945477258 \t -201.54672633894333\n",
            "85     \t [ 4.01276479 -5.09455918 -4.86609984  2.6921475  -3.92433907  3.52847384\n",
            "  4.79197524  0.50729757]. \t  -482.5417082261594 \t -201.54672633894333\n",
            "86     \t [-0.31053975 -3.97277179  4.76468454  4.48548315  4.89452451  5.08005199\n",
            "  4.34774288  4.48366678]. \t  -748.0167980337808 \t -201.54672633894333\n",
            "87     \t [ 3.95112324  4.98218195 -3.70349697 -4.10490258  0.3110347   0.89193422\n",
            "  4.55960167 -5.01222012]. \t  -525.5697880375109 \t -201.54672633894333\n",
            "88     \t [ 4.73406626 -2.38287795  4.79779726  0.73102402 -3.85127737 -4.56267959\n",
            " -3.85925048 -3.69120203]. \t  -517.2881946136911 \t -201.54672633894333\n",
            "89     \t [ 4.59306874  1.54778639 -4.00177835 -4.87571747  5.01712729  5.10586133\n",
            " -3.94919124 -2.31024085]. \t  -603.1679722441133 \t -201.54672633894333\n",
            "90     \t [ 0.33900206 -3.768283   -2.5006558  -2.61262868  3.98669024 -1.44368794\n",
            " -3.93710013  4.8623805 ]. \t  -464.1991487028523 \t -201.54672633894333\n",
            "91     \t [-3.95979938 -4.69442074  4.88871726  3.81181712  4.73461277  1.21025925\n",
            " -1.3362652   2.1070409 ]. \t  -358.4610103895619 \t -201.54672633894333\n",
            "92     \t [ 1.23619261  3.12447241  4.99762608 -0.36048564 -1.28440065 -2.46822395\n",
            " -0.47078276 -1.36895633]. \t  \u001b[92m-157.84641486098795\u001b[0m \t -157.84641486098795\n",
            "93     \t [ 2.84846163  2.79583445 -2.96103584 -3.12397262 -0.77118891  4.70594644\n",
            " -1.84177434 -4.69939251]. \t  -425.3556353125123 \t -157.84641486098795\n",
            "94     \t [ 0.87568321  3.56955537  4.62944858 -4.39851336 -4.0497689   4.35465735\n",
            " -1.09759148  3.30812165]. \t  -459.6970186414322 \t -157.84641486098795\n",
            "95     \t [-0.91873789  4.48948429 -2.61314377 -0.66371825 -4.89901793  4.5804235\n",
            "  3.93392054 -4.46409464]. \t  -577.0414704938432 \t -157.84641486098795\n",
            "96     \t [ 3.15044446 -4.16650097  3.55442328  1.6209787   5.03167268  1.36469275\n",
            " -4.28211377 -1.83831992]. \t  -386.21063991804743 \t -157.84641486098795\n",
            "97     \t [-0.38480844 -5.0620549  -3.29590308  0.1877216  -4.75840505  2.7571084\n",
            " -3.75202801  3.43153348]. \t  -435.6961154216379 \t -157.84641486098795\n",
            "98     \t [ 0.15871587  1.10760992 -1.47515637  4.93320551  0.73395187  3.95906359\n",
            "  5.02504375 -3.67054704]. \t  -487.63242696752786 \t -157.84641486098795\n",
            "99     \t [-3.39332039 -4.62520273 -0.05193212  4.4922384   0.68393879  4.71071205\n",
            " -5.00572449 -4.73913554]. \t  -625.5884359174293 \t -157.84641486098795\n",
            "100    \t [-4.01887013 -4.05274733 -5.01400146 -0.71342045 -3.23188805  4.50312697\n",
            "  2.19944045  4.98209199]. \t  -532.784455417673 \t -157.84641486098795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBLcW6tlteS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614caf20-db8e-4df7-ba29-f9018da06098"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 2 \r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_winner_2 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_2 = dGPGO_stp(surrogate_winner_2, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.60433145 -4.36322715  4.04410125 -0.65030607 -3.81258     0.77678463\n",
            "  3.48642222 -0.66436556]. \t  -266.73879363027606 \t -205.20381448253355\n",
            "init   \t [ 2.00612414  1.89069411  2.05463926  2.86406925  1.46175353  4.72090796\n",
            " -4.00931957  3.03212891]. \t  -387.12857956211883 \t -205.20381448253355\n",
            "init   \t [ 3.40562005 -2.39607436  3.44765838  0.32897952  0.17313346 -4.11046182\n",
            "  4.2892185   1.70658296]. \t  -312.7789728136913 \t -205.20381448253355\n",
            "init   \t [-3.33025814 -2.89083891 -0.32895713 -0.65647368  3.98698988 -2.84058346\n",
            "  0.91155831 -2.28145592]. \t  -205.20381448253355 \t -205.20381448253355\n",
            "init   \t [ 0.26339516 -2.46418319  0.29643398 -1.92367877  0.45222142 -2.6413414\n",
            " -4.15500263 -3.17986428]. \t  -271.9028038542476 \t -205.20381448253355\n",
            "1      \t [-3.58107824  4.03913561 -2.04029852 -2.32586783 -5.05364741  1.00365777\n",
            "  3.01415303  1.00987973]. \t  -285.07587324909576 \t -205.20381448253355\n",
            "2      \t [ 4.18021262 -1.11976423 -2.36632484 -1.94732869 -4.97029632  1.99215769\n",
            " -1.27677137  3.8314449 ]. \t  -328.1309142393032 \t -205.20381448253355\n",
            "3      \t [-2.33939103  3.42595734  2.45061491 -3.17801789  4.72775184 -4.60559431\n",
            " -4.96352682  3.94635514]. \t  -623.4359705286043 \t -205.20381448253355\n",
            "4      \t [-3.48637274 -3.89123995 -1.38904965 -5.09060776 -5.02164417  4.52607733\n",
            " -1.28724552 -3.83352781]. \t  -530.0471157456185 \t -205.20381448253355\n",
            "5      \t [-2.21749132  3.31612471 -1.8780737  -3.95441088  2.82677089  1.75664842\n",
            " -1.24224273  0.01314203]. \t  \u001b[92m-169.31317882574902\u001b[0m \t -169.31317882574902\n",
            "6      \t [-2.10140792  2.67807242  1.68628494  4.56034289 -1.8500807  -3.14762825\n",
            " -4.13600895 -2.97135732]. \t  -377.41471871614783 \t -169.31317882574902\n",
            "7      \t [-0.16493007 -4.63047848  1.22639383  4.87971401 -2.84904526 -3.88322148\n",
            " -0.6136232  -1.49220563]. \t  -294.1793286313926 \t -169.31317882574902\n",
            "8      \t [ 3.87919599  0.5703219  -0.01821571  4.28050658 -1.86521261  4.39987968\n",
            " -0.5423715  -4.01011221]. \t  -353.2465426117693 \t -169.31317882574902\n",
            "9      \t [ 0.20431581  4.04497437  4.82476316  1.43338663  4.70359591  4.17853526\n",
            "  1.11066732 -4.25772378]. \t  -479.8595690478112 \t -169.31317882574902\n",
            "10     \t [ 2.23810202 -4.097244   -3.13989838 -1.61879897  4.24681764  3.8110931\n",
            "  0.5966154   2.37036984]. \t  -303.4076022895437 \t -169.31317882574902\n",
            "11     \t [ 3.31386882  4.20874624  2.80639656  4.70516753  0.77583565 -1.58822836\n",
            "  2.17294614 -1.95275945]. \t  -240.29324869898412 \t -169.31317882574902\n",
            "12     \t [-2.08141258 -2.64469346  0.04445711  3.24781098  4.20440011  4.72778981\n",
            "  0.59437171 -1.7853385 ]. \t  -310.98941248090955 \t -169.31317882574902\n",
            "13     \t [-2.76086403 -4.57795664 -4.83509079 -0.96938259  2.40971448 -2.71791874\n",
            " -0.89998849  4.59320673]. \t  -371.23721574598903 \t -169.31317882574902\n",
            "14     \t [-2.8757327  -4.72299502 -2.16755936  3.1574926  -3.72153375  2.64682582\n",
            "  5.021845   -3.67729534]. \t  -502.85286884845095 \t -169.31317882574902\n",
            "15     \t [-0.88643923  4.80610418 -4.95779804  3.32053101 -0.14313835 -0.6041757\n",
            " -2.36866112  3.53279031]. \t  -306.23739860772207 \t -169.31317882574902\n",
            "16     \t [ 4.43359982  4.1027933  -4.04471842  4.33170846 -3.55496184  3.35648416\n",
            "  3.59795049  2.97955161]. \t  -469.8799075026084 \t -169.31317882574902\n",
            "17     \t [-4.4957108  -1.60177811  4.7053958   4.06866872 -2.18435017  4.12610297\n",
            " -2.61204871 -2.01988572]. \t  -364.38568921849327 \t -169.31317882574902\n",
            "18     \t [-4.61968796  0.78786726  3.95100547  4.81505391  3.86779689 -3.68881212\n",
            "  3.98945164  0.06503618]. \t  -430.04047725424493 \t -169.31317882574902\n",
            "19     \t [-4.76750173  1.30939219 -0.93440447 -1.66206922 -4.28771943 -2.76698945\n",
            " -4.82578735  4.31430513]. \t  -489.6107880434111 \t -169.31317882574902\n",
            "20     \t [ 3.26487483  1.12917922 -4.64525851 -2.3463826   0.81953301  3.22995639\n",
            "  4.62451513 -1.37624418]. \t  -330.7760713104953 \t -169.31317882574902\n",
            "21     \t [-4.78489803 -2.41979538  2.99986707 -2.46299596  0.43117938  3.19292183\n",
            "  1.59679611  1.40874144]. \t  -181.69187359749793 \t -169.31317882574902\n",
            "22     \t [ 2.35778315 -4.4845486   3.23209445 -1.43320869  1.08258847 -3.29813697\n",
            " -3.91334207  4.68573548]. \t  -439.3120381810914 \t -169.31317882574902\n",
            "23     \t [ 4.07530807 -4.17604944 -4.73574783 -1.61960315 -3.48288888  0.55763745\n",
            " -2.18649761 -4.2493575 ]. \t  -369.7013412362093 \t -169.31317882574902\n",
            "24     \t [ 4.21274751  1.74338762 -2.90466151  3.87194955 -5.10010559 -5.0815282\n",
            "  1.0691521  -1.79303088]. \t  -427.8134311524847 \t -169.31317882574902\n",
            "25     \t [ 3.83979553  1.48184107 -1.7439722   3.15633214  4.43126687 -4.71169675\n",
            " -3.66443456  1.26185135]. \t  -406.22564628128055 \t -169.31317882574902\n",
            "26     \t [-4.03913391  3.87819358  3.15300343 -5.03522468  3.42413908 -1.25884211\n",
            "  3.18612405 -4.38935752]. \t  -470.9567394475918 \t -169.31317882574902\n",
            "27     \t [-4.78281992 -3.1733766   5.0575263  -3.89255314 -3.86036586 -0.74472548\n",
            " -3.71797816 -2.30888003]. \t  -397.61036720624094 \t -169.31317882574902\n",
            "28     \t [ 3.55326666  3.93875976  5.00820111 -3.60007997 -5.10336264 -1.28933452\n",
            "  2.04806101 -1.68270993]. \t  -362.9517301300212 \t -169.31317882574902\n",
            "29     \t [ 4.94521866 -4.81166768 -1.59240724 -1.29683457  3.5350293  -0.33106334\n",
            "  1.80134761 -4.7174823 ]. \t  -348.9847462086963 \t -169.31317882574902\n",
            "30     \t [ 0.0639888   1.8178293   4.9866869  -4.36665032 -1.8889621   1.53503119\n",
            "  4.99624444  5.07866139]. \t  -570.5432150310099 \t -169.31317882574902\n",
            "31     \t [-0.63771352 -4.64082075 -5.00143266  4.20706563  2.81158345 -3.51632093\n",
            " -4.94617292 -3.73069925]. \t  -585.6311096780846 \t -169.31317882574902\n",
            "32     \t [ 3.65125047 -0.99245754  2.86258528  4.48745306 -4.61035977 -4.45876348\n",
            " -2.26873707  4.74058314]. \t  -561.8094170538496 \t -169.31317882574902\n",
            "33     \t [-5.07493032  4.84578945  3.77902323  0.10244051 -3.61994104  3.82051334\n",
            "  2.85649489 -3.75983363]. \t  -438.90882559771836 \t -169.31317882574902\n",
            "34     \t [ 1.40093871 -4.53879079 -4.73962445  5.07190238  4.77299586  3.83229223\n",
            " -4.80598034  0.07412166]. \t  -577.2050781835369 \t -169.31317882574902\n",
            "35     \t [-0.57258836  4.25502402 -3.58061191 -1.63498361 -1.55744883 -4.21580078\n",
            " -0.15814373 -4.56570644]. \t  -371.3999066545043 \t -169.31317882574902\n",
            "36     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -169.31317882574902\n",
            "37     \t [-3.35686775 -2.75780207  1.16619598  4.30772719  4.39254268 -0.06371758\n",
            " -4.05898016  4.88631857]. \t  -507.6182277557201 \t -169.31317882574902\n",
            "38     \t [-4.98709745  3.72863116 -1.37854368 -0.12612612  3.39642081  4.73436995\n",
            "  4.31272483  3.17599331]. \t  -461.4978617345329 \t -169.31317882574902\n",
            "39     \t [ 5.08894842 -3.9397156  -3.70618185 -4.84141102 -3.71059077 -4.81076582\n",
            "  3.74087278 -4.0087368 ]. \t  -626.1264044104054 \t -169.31317882574902\n",
            "40     \t [-3.4506335   0.28291644 -4.8578133   1.73996887 -1.75912119  3.69157686\n",
            " -4.46227788 -2.74502456]. \t  -391.875692767654 \t -169.31317882574902\n",
            "41     \t [ 2.73953451 -3.83137128 -3.17404188  4.95174897  0.38855526 -1.50062722\n",
            "  1.59628505  4.87117991]. \t  -387.09695817981435 \t -169.31317882574902\n",
            "42     \t [ 3.05077491  3.42080076 -1.45457549 -4.73302285 -3.43685989  2.43482898\n",
            " -4.80844774 -3.87972374]. \t  -505.56099483885777 \t -169.31317882574902\n",
            "43     \t [-3.95164381  1.62806586 -0.46275955  4.68705663 -2.75672983 -0.94094651\n",
            "  4.1202016   0.01154757]. \t  -271.5766986598036 \t -169.31317882574902\n",
            "44     \t [ 1.65580732  0.74515419 -1.84507148 -4.82108443  2.18663266 -3.14326112\n",
            "  4.80810171  4.68762929]. \t  -527.8396906981393 \t -169.31317882574902\n",
            "45     \t [-3.97755508 -4.78953048 -4.23355458 -3.48722095 -3.82161664  4.83960173\n",
            " -2.80370621  4.97634451]. \t  -630.8035964870385 \t -169.31317882574902\n",
            "46     \t [ 0.64056064  4.41150712  3.48622047 -1.75601874 -3.61224431 -4.30173207\n",
            " -0.99707082  4.98128858]. \t  -469.86459182614584 \t -169.31317882574902\n",
            "47     \t [-2.50163494 -3.65342203  2.33857828  2.13132035 -0.91181207 -4.91057618\n",
            "  5.00314613 -4.99023257]. \t  -590.8093373219943 \t -169.31317882574902\n",
            "48     \t [-3.92788925 -3.42312441  5.1099417   4.01791104  2.97212014  3.63840378\n",
            "  4.11857388  4.83510693]. \t  -611.1328356325879 \t -169.31317882574902\n",
            "50     \t [-0.24458642  1.86874379 -4.45821111  4.57166498  2.72144894  1.18627016\n",
            " -0.01214928 -3.11097734]. \t  -273.1729671444606 \t -169.31317882574902\n",
            "51     \t [ 4.20440393 -3.13475091  3.35145393 -4.0896613  -2.37675859  4.05684575\n",
            " -2.76710741 -3.84686121]. \t  -436.9061918432802 \t -169.31317882574902\n",
            "52     \t [-4.27805516 -1.74413738  1.73616366 -4.42301829 -2.1280766  -4.85084958\n",
            "  3.9317017   4.82458017]. \t  -569.9294811295076 \t -169.31317882574902\n",
            "53     \t [-1.90261209 -0.63886061  1.68554481 -4.27908288  2.81105069  5.00094305\n",
            " -4.43586204 -4.4591111 ]. \t  -572.5757004470956 \t -169.31317882574902\n",
            "55     \t [-4.99748813 -1.04902355 -4.89487031  4.30345899 -1.02216079 -3.5922673\n",
            " -1.73858645 -0.62851626]. \t  -280.1035023941334 \t -169.31317882574902\n",
            "56     \t [ 4.27725246  4.89528561 -2.7382732  -0.97579499  1.44878289  2.32061576\n",
            " -0.5831834   2.52282556]. \t  -188.62996969348254 \t -169.31317882574902\n",
            "57     \t [-1.36276994  4.96921625  4.31980047 -2.2906993  -3.92574252 -5.01088598\n",
            " -1.34306646 -4.82948987]. \t  -555.144316535798 \t -169.31317882574902\n",
            "58     \t [ 4.1149142  -2.4906041   4.57654986 -4.33064348  2.22559489  4.83489337\n",
            " -1.02934507  4.81198702]. \t  -524.8731919721635 \t -169.31317882574902\n",
            "59     \t [-4.33027493  2.75182957 -3.11301926 -0.47902804  1.35668521 -3.00840072\n",
            "  4.47345898  2.43397328]. \t  -314.8694283439536 \t -169.31317882574902\n",
            "60     \t [ 1.08713662 -1.24307244  4.37866407 -3.53714014  4.64441763  3.32027282\n",
            "  4.80688525 -1.68324168]. \t  -470.24364930741825 \t -169.31317882574902\n",
            "61     \t [ 2.59614762  4.46931715  3.62211383 -3.3432357   1.78225894 -3.75651592\n",
            " -4.59735503 -2.5510269 ]. \t  -431.3199243801221 \t -169.31317882574902\n",
            "62     \t [-3.31347412 -3.43409421 -4.59397708 -4.2626303  -2.02658595 -0.72998751\n",
            "  5.00292518 -0.9844339 ]. \t  -377.2493088537238 \t -169.31317882574902\n",
            "63     \t [-3.68017297 -5.11418288 -1.21566766  3.60431622 -3.26289955 -1.07563747\n",
            "  0.10984998  4.30261912]. \t  -330.61059363960806 \t -169.31317882574902\n",
            "64     \t [-1.74971339 -4.03188897  4.80720494 -1.96598303  4.48450386  3.02079559\n",
            " -3.97643904  1.30851402]. \t  -400.04902345398386 \t -169.31317882574902\n",
            "65     \t [ 1.3625118  -2.64325814 -4.38970367  2.5993038   3.5979113  -4.26190582\n",
            "  4.30386097 -3.32988071]. \t  -492.7393366276273 \t -169.31317882574902\n",
            "66     \t [ 2.30214051  1.2366742  -4.2069116  -1.57864697  4.17293465  4.13737088\n",
            " -4.04928674 -3.49886055]. \t  -473.9086048353205 \t -169.31317882574902\n",
            "67     \t [-4.3490476   1.34980181  4.73142845  5.07622284  2.87658307 -5.06310699\n",
            " -4.66299543  1.74090326]. \t  -564.4241472443039 \t -169.31317882574902\n",
            "68     \t [ 3.45615753  1.5438658  -1.08325461 -2.78201306 -4.47779892 -3.37971658\n",
            " -4.23955873  0.24042539]. \t  -346.2585396743417 \t -169.31317882574902\n",
            "69     \t [-4.00830256  3.44138187 -1.60957252  5.04135793 -5.08443713  4.96617298\n",
            " -4.0513234   3.94863128]. \t  -666.0468479467613 \t -169.31317882574902\n",
            "70     \t [ 0.4683247  -3.58443563  0.11095835 -2.60312843 -3.34565963  4.49188183\n",
            "  3.94798869  3.44295489]. \t  -434.0247474110108 \t -169.31317882574902\n",
            "71     \t [ 1.51122196  2.30473935  2.23959375 -5.03979463  4.75233792  1.37303023\n",
            " -3.97225258  3.07339225]. \t  -439.8052028590116 \t -169.31317882574902\n",
            "72     \t [-2.57258627 -3.44275653  4.37296932 -0.69430678 -1.77076061  2.98099832\n",
            "  2.07155931 -5.10515819]. \t  -397.1568734891461 \t -169.31317882574902\n",
            "73     \t [ 0.13443811  1.57226679  4.64074093 -4.0657113  -3.26734533  3.31685974\n",
            " -2.70430214  2.39846678]. \t  -352.2925542041875 \t -169.31317882574902\n",
            "74     \t [ 3.83335838  4.8625708  -3.1699386   1.04228752  2.91305791 -2.30453384\n",
            "  2.88147141 -2.94169888]. \t  -298.1184816122798 \t -169.31317882574902\n",
            "75     \t [ 5.09663915  4.70930583 -3.48704926 -4.99123534 -4.36899363 -0.63280153\n",
            "  3.98405359 -3.92581296]. \t  -538.7071059458451 \t -169.31317882574902\n",
            "76     \t [ 1.52766372 -3.22923877  4.85615665  3.99860334  3.80009077  0.44280211\n",
            "  4.80073733 -1.98295963]. \t  -424.05828471269655 \t -169.31317882574902\n",
            "77     \t [ 3.46843443  4.58998051 -2.45008206  4.2206751   4.06538636  2.68521567\n",
            "  4.45823473  4.50796211]. \t  -571.0348866063454 \t -169.31317882574902\n",
            "78     \t [ 4.21514401 -4.10944416  4.70645829  4.36656143 -4.68434537  2.66094675\n",
            " -4.57929101 -4.11415411]. \t  -628.6609242109971 \t -169.31317882574902\n",
            "79     \t [ 4.19446551 -3.97759586 -2.65199111  4.23947945 -4.8304192   4.88766827\n",
            "  4.88316451  2.2953013 ]. \t  -611.2928821805135 \t -169.31317882574902\n",
            "80     \t [-1.70500705 -3.4893655   4.55885905  4.08338867  2.42295442 -0.15249149\n",
            " -4.95502809 -3.55215604]. \t  -458.60591833313646 \t -169.31317882574902\n",
            "81     \t [-2.9834016   4.95193231  4.32036732  0.50850393  4.63383717  2.41154436\n",
            " -5.10508529  3.50654231]. \t  -538.0304724751669 \t -169.31317882574902\n",
            "82     \t [ 4.72366536 -2.94056594  4.22860845  2.60444857  2.9338194   4.16906668\n",
            "  2.4748911   3.44832409]. \t  -405.70916550786154 \t -169.31317882574902\n",
            "83     \t [-1.50414731  1.45380616 -5.02561229 -4.95765824  3.00291662 -4.94472644\n",
            " -4.6450796  -2.70052055]. \t  -581.7427015545682 \t -169.31317882574902\n",
            "84     \t [ 0.74338138  4.92796811 -2.89611806  4.90995246  2.34117479 -4.61866084\n",
            "  3.42488344  3.51619086]. \t  -507.1306232498704 \t -169.31317882574902\n",
            "85     \t [ 4.85234134  4.47733158  4.92835696  4.36158493 -2.95151111  4.25687602\n",
            "  2.99153096  3.4282242 ]. \t  -521.5476334182067 \t -169.31317882574902\n",
            "86     \t [-3.32312305  4.64469678  3.97308411  2.22627109 -2.10370612  2.51659217\n",
            " -0.83684552  3.10327523]. \t  -263.4429115073099 \t -169.31317882574902\n",
            "87     \t [-4.10859072  4.37767882  3.87373406 -2.39813382 -5.09563913  3.27544891\n",
            " -4.13785554 -5.00934714]. \t  -638.0307851774701 \t -169.31317882574902\n",
            "88     \t [-4.70810926  4.58562845 -4.2673622  -4.62284967 -2.02199045  2.38565522\n",
            " -1.97400626  4.75324474]. \t  -466.95028720017535 \t -169.31317882574902\n",
            "89     \t [-4.75332297  2.32855053 -2.39047904  3.63685325  4.50768542 -5.0253758\n",
            "  1.01161028 -2.93107635]. \t  -432.50405754811806 \t -169.31317882574902\n",
            "90     \t [ 3.41591151  3.50986967 -4.30558382  3.49225447  0.87084147 -3.60400075\n",
            " -4.72378432 -5.10193872]. \t  -586.8662941295028 \t -169.31317882574902\n",
            "91     \t [ 3.35131392 -4.24637154  4.54076334 -3.85610393 -5.08330631 -5.11903546\n",
            " -3.76120462 -2.9510482 ]. \t  -623.7516574648881 \t -169.31317882574902\n",
            "92     \t [ 1.17263686 -3.84637295 -5.02578502 -1.84926464 -3.74913821 -3.53926421\n",
            "  4.64466955  3.97199227]. \t  -543.081911526206 \t -169.31317882574902\n",
            "93     \t [ 2.63350024  1.44665345  1.38395556 -4.17637135 -2.28048533  3.62621794\n",
            "  4.86240651 -5.05698922]. \t  -561.6211503765683 \t -169.31317882574902\n",
            "94     \t [ 4.30006621 -4.9869798  -1.84804953  4.61640924 -2.82680985  3.17631288\n",
            " -4.12501885  4.50995074]. \t  -546.0370619508554 \t -169.31317882574902\n",
            "95     \t [-4.77534043  2.23722986  4.44823128 -4.14673782  0.90034593 -1.44294752\n",
            " -1.1625053   0.52902532]. \t  -189.20086538737408 \t -169.31317882574902\n",
            "96     \t [-4.77383062 -4.76048013 -4.20404862 -1.73465272 -0.62730865 -0.19644329\n",
            " -1.81632821 -2.56277962]. \t  -211.0071282429525 \t -169.31317882574902\n",
            "97     \t [-4.32673921  2.5990806  -2.78708962  4.17976885  4.88684928  4.90595792\n",
            " -3.74359226 -1.09327904]. \t  -496.8970600455893 \t -169.31317882574902\n",
            "98     \t [ 3.97469946  4.84966372  4.83916188  4.65461372 -4.25418691 -5.07878057\n",
            "  4.95229071  3.92441   ]. \t  -759.88972724769 \t -169.31317882574902\n",
            "99     \t [-4.39839531 -3.12217345 -2.1978014  -0.34715987  3.9764672   4.24226418\n",
            "  4.70111814  5.07345578]. \t  -601.480388300897 \t -169.31317882574902\n",
            "100    \t [ 2.01323808  2.91980319  4.00442277 -4.52483134  2.10723346 -4.48759157\n",
            "  2.95538299 -2.06923745]. \t  -389.5332313552969 \t -169.31317882574902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emgjXwfeuvRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3912f6f-7659-45d7-e1c4-bb5decc9836c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 3 \r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_winner_3 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_3 = dGPGO_stp(surrogate_winner_3, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.57613422e+00 -4.00126694e+00 -1.42118102e-01 -1.72873986e-03\n",
            "  1.60880639e+00 -2.70454056e+00  1.15501968e+00 -3.89475939e+00]. \t  -226.23757295607857 \t -200.83819991364615\n",
            "init   \t [ 2.17295152 -1.30498005  0.25362711 -2.42394027  1.24550372 -0.52121845\n",
            " -2.87678861  3.56542093]. \t  -200.83819991364615 \t -200.83819991364615\n",
            "init   \t [ 4.51432417  5.05385819 -3.54862621  1.12022459 -2.14496207 -2.14068561\n",
            "  3.26002484  1.12353371]. \t  -249.2524227715819 \t -200.83819991364615\n",
            "init   \t [ 1.1383917   3.70078893 -1.31804167 -3.13683123 -0.37390212 -2.85955193\n",
            " -3.88879197  1.70639   ]. \t  -252.1724482635516 \t -200.83819991364615\n",
            "init   \t [ 2.32018826 -0.4223289  -1.35717313 -2.05342954 -2.49788598  2.26036994\n",
            " -4.91879441  2.94613072]. \t  -328.7841092566316 \t -200.83819991364615\n",
            "1      \t [-3.55865421  4.31406842 -3.85626065 -3.59130616  2.02875186  3.68832922\n",
            " -3.19072393 -3.1190355 ]. \t  -397.3824499112952 \t -200.83819991364615\n",
            "2      \t [ 4.20312907  5.02301841  2.37347995 -2.42404182  3.1767739   1.10381544\n",
            "  2.76259721 -1.23640066]. \t  -231.9548674593155 \t -200.83819991364615\n",
            "3      \t [ 1.10671857 -4.15154398  1.1901689   4.57845332  0.59346879  1.03889791\n",
            " -4.84349155 -3.64881951]. \t  -402.7577288418222 \t -200.83819991364615\n",
            "4      \t [-4.12874772  4.77086715  4.43158116  2.92424375 -4.19713104 -3.38348989\n",
            " -2.35816039  0.9252171 ]. \t  -358.2326693147111 \t -200.83819991364615\n",
            "5      \t [-2.37079491 -1.21173666  3.5833956   4.95644465 -3.88089579  2.67162054\n",
            "  4.96609713 -4.59080633]. \t  -604.7157912633598 \t -200.83819991364615\n",
            "6      \t [-3.5553363  -2.51308271 -2.98117052 -0.24939697 -2.0899883   0.42425475\n",
            " -2.2295405  -2.63903951]. \t  \u001b[92m-165.6149144600416\u001b[0m \t -165.6149144600416\n",
            "7      \t [-0.35993332  4.55991045 -4.6808642   4.15537144 -3.28971053  3.78541054\n",
            "  3.43936544  2.57725979]. \t  -452.54479650408683 \t -165.6149144600416\n",
            "8      \t [ 2.34389404 -3.07356427  3.41443394 -3.72032987 -2.64066034  4.52915328\n",
            "  4.48647257 -0.30386733]. \t  -414.30847647154036 \t -165.6149144600416\n",
            "9      \t [-2.19887099 -0.3989578  -3.77540966  4.68038287  0.38087753 -3.38391162\n",
            "  3.1741463   1.9242806 ]. \t  -305.1182231593023 \t -165.6149144600416\n",
            "10     \t [ 1.99060721 -4.14574025  2.89764932  4.66662845 -1.8217684  -1.65925127\n",
            " -3.73866684  4.49320648]. \t  -443.10317369827254 \t -165.6149144600416\n",
            "11     \t [ 1.29740206  2.72916369  3.6010348   3.01644857 -4.35557695 -4.60106109\n",
            "  4.52928445 -0.95432297]. \t  -464.63873782045454 \t -165.6149144600416\n",
            "12     \t [-5.06460164  3.92642251  4.19954258 -4.14915557  4.86321254  0.86589201\n",
            "  1.74112993  5.02310081]. \t  -524.0800813236228 \t -165.6149144600416\n",
            "13     \t [-3.20886447 -1.37766552  1.54033436  3.47024025  3.25617427  0.66351963\n",
            " -1.2152921   1.39356217]. \t  \u001b[92m-150.91046800670185\u001b[0m \t -150.91046800670185\n",
            "14     \t [-0.05490096  4.72577476 -0.16755521  3.97774362  1.94943711 -1.15559228\n",
            "  0.56436675 -3.54215377]. \t  -237.6611915157113 \t -150.91046800670185\n",
            "15     \t [-1.00345942 -3.4396889  -4.4558846  -5.00858705 -4.17212317  3.22710585\n",
            "  4.51358303  5.01445725]. \t  -677.8619568544066 \t -150.91046800670185\n",
            "16     \t [ 1.12475845 -0.75869709  3.39409386 -4.9329143   2.66522386  3.19685177\n",
            " -2.20827123 -3.99951608]. \t  -393.25103952620873 \t -150.91046800670185\n",
            "17     \t [ 3.74717368  4.93332353  4.42912001  1.74866334 -1.4015247   0.73584451\n",
            " -3.16082965 -0.5819831 ]. \t  -219.51498239443552 \t -150.91046800670185\n",
            "18     \t [ 3.76073064 -3.23518624 -2.38760605  1.82185775 -0.95201443  1.07723194\n",
            "  3.53639277  3.62971175]. \t  -269.8898108735824 \t -150.91046800670185\n",
            "19     \t [ 0.85843952  1.98462836 -4.78537003 -2.86379647  3.19320959 -1.54206406\n",
            "  4.05750166 -1.55979766]. \t  -310.076732265838 \t -150.91046800670185\n",
            "20     \t [-3.17504195  3.72565792  2.16748797 -2.40653088 -3.96620837  1.20705181\n",
            "  0.59490489 -4.09022192]. \t  -298.81411534937126 \t -150.91046800670185\n",
            "21     \t [-3.48085105 -3.12987933 -0.28094271 -3.89332344  3.77502292 -4.29072475\n",
            "  4.63701736  0.06090402]. \t  -424.83635764607453 \t -150.91046800670185\n",
            "22     \t [-4.65138428  4.56209364 -4.93508667  3.12314362 -4.34639927 -4.28088875\n",
            "  2.86999865 -3.92402244]. \t  -560.5959649212805 \t -150.91046800670185\n",
            "23     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -150.91046800670185\n",
            "24     \t [-4.26369086 -3.00816968 -4.33078242 -0.02131847  3.99035438 -2.7527389\n",
            " -2.10683888  4.89070021]. \t  -440.04912355624475 \t -150.91046800670185\n",
            "25     \t [-5.08019997 -2.93298683  3.12444399 -0.41901536 -2.44403379  2.58602349\n",
            "  3.6883161   4.10410669]. \t  -372.9688753190329 \t -150.91046800670185\n",
            "26     \t [-4.39104431  0.37050064 -3.30926721  0.89086282  3.31661433 -5.09097603\n",
            " -4.62893384 -2.08286557]. \t  -450.7878118271016 \t -150.91046800670185\n",
            "27     \t [ 3.58676207 -0.36859551  4.9628052   3.32807494  3.03537427  4.6776411\n",
            "  3.05259362 -0.92104911]. \t  -380.6936138427964 \t -150.91046800670185\n",
            "28     \t [-1.64780651 -1.1893068  -4.88614102  4.41996127  4.26124305  2.47320796\n",
            "  3.0130859  -4.58378875]. \t  -514.4427886209961 \t -150.91046800670185\n",
            "29     \t [ 2.76250286  1.73969095 -3.2999552   4.74336525  1.97018095  3.37449648\n",
            " -2.59281963  0.83115007]. \t  -276.6685428488514 \t -150.91046800670185\n",
            "30     \t [ 1.02901213 -0.70051688  0.57588637 -3.90400596 -3.88881389 -3.74365179\n",
            "  3.0951041   3.9448878 ]. \t  -415.2590428076784 \t -150.91046800670185\n",
            "31     \t [-4.98841092  4.80924724  3.01006599  1.89439743  3.0902033  -4.84538699\n",
            "  1.1783013   3.99650361]. \t  -438.78693921835315 \t -150.91046800670185\n",
            "32     \t [ 3.9823499   2.61616406  2.07630404 -2.87663051 -3.97581554 -2.89253287\n",
            " -3.62971875 -4.93703745]. \t  -492.03560934841227 \t -150.91046800670185\n",
            "33     \t [ 3.43620852 -1.57968598 -3.59097644 -3.83105392 -2.86329271  4.38986945\n",
            "  0.02084985 -2.74130539]. \t  -330.9306099189498 \t -150.91046800670185\n",
            "34     \t [-3.47059551  3.72470984 -0.63608636  3.42151075  2.74240865  3.30519782\n",
            "  3.70925636  4.95996327]. \t  -484.1027074785336 \t -150.91046800670185\n",
            "35     \t [-4.76163171 -3.09317087  0.76697455 -1.42776423  3.59921392  2.39993287\n",
            "  2.33872265 -4.62265495]. \t  -360.2959877650387 \t -150.91046800670185\n",
            "36     \t [ 2.81767235  3.9179708  -4.57723738  0.80527473 -1.93504441  1.11544329\n",
            " -4.94473656 -4.76660885]. \t  -483.1921273722976 \t -150.91046800670185\n",
            "37     \t [-4.16078266 -3.62713444  5.02370145 -4.87668218  4.7293528   1.15910379\n",
            " -0.48583453  1.85242882]. \t  -363.4643716077683 \t -150.91046800670185\n",
            "38     \t [ 4.29835123 -0.88214005  4.72358992  0.71039797  3.91849889 -3.77402011\n",
            " -5.08079728 -3.21579215]. \t  -514.652326418082 \t -150.91046800670185\n",
            "39     \t [-2.27253201  4.62942846 -0.49428551  3.31791219 -4.22645306  3.61036104\n",
            " -4.17898961  2.18326328]. \t  -420.69829282011244 \t -150.91046800670185\n",
            "40     \t [-1.94655124 -4.61830806 -4.47702172  3.43172334 -3.62742423  1.57001267\n",
            "  4.18574115 -2.54198357]. \t  -408.60178891777167 \t -150.91046800670185\n",
            "41     \t [-4.98677147 -3.88862463  4.81342865  4.62679186 -3.60008247 -3.72884806\n",
            "  2.06090254 -0.13745397]. \t  -388.3579900874567 \t -150.91046800670185\n",
            "42     \t [ 3.27066715  3.57473654 -3.97199886 -3.0718843   4.30740157  4.33280664\n",
            " -0.35530402  2.89821158]. \t  -394.8195149893388 \t -150.91046800670185\n",
            "43     \t [ 4.76462821 -3.69558315  4.36880309 -2.30548608  2.45121137 -2.26903473\n",
            "  4.41942853  2.2760649 ]. \t  -367.63324570548025 \t -150.91046800670185\n",
            "44     \t [-2.20086689 -3.32222356  3.64415854 -1.27470632  0.15325502  5.02571288\n",
            " -4.51668472  4.81758584]. \t  -553.3976610418011 \t -150.91046800670185\n",
            "45     \t [-4.86836667  0.72034888 -2.60249785 -3.67642243  4.23883394  4.29725266\n",
            "  2.13776288  1.78185253]. \t  -357.1491591742786 \t -150.91046800670185\n",
            "46     \t [ 4.96619173 -4.34760624 -4.79448523  1.00682895  3.91385479  2.63711414\n",
            " -2.2279208   4.67096024]. \t  -463.0884009303775 \t -150.91046800670185\n",
            "47     \t [ 5.00181098  3.8107478  -2.19925982 -3.54136132  5.05261171  0.12441899\n",
            " -4.23218062 -3.10017284]. \t  -448.7422506460938 \t -150.91046800670185\n",
            "48     \t [ 1.10244126  3.93927975 -4.83700628  3.75176432 -1.37318066 -5.0639404\n",
            " -2.9545803   4.27330054]. \t  -529.2287315326463 \t -150.91046800670185\n",
            "49     \t [-5.1199303   1.64730049  4.91495203 -1.00787108  4.55555597 -3.73215303\n",
            "  4.22312205 -4.73146921]. \t  -599.4513358285265 \t -150.91046800670185\n",
            "50     \t [-4.36949708 -2.71500404  3.08701271 -5.07708971 -5.00611418 -4.08510039\n",
            " -4.23595469 -4.03499644]. \t  -646.8182227589185 \t -150.91046800670185\n",
            "51     \t [ 3.31541423 -5.07362875 -4.51578421 -3.49703914 -4.68642716 -4.13231057\n",
            " -1.36024545  1.60536965]. \t  -418.4079502151941 \t -150.91046800670185\n",
            "52     \t [ 4.68641772  2.97910401  4.47012581  3.74650443  4.77865345  2.65832694\n",
            " -3.14917838  3.61414209]. \t  -486.29920104870615 \t -150.91046800670185\n",
            "53     \t [ 5.1138114  -4.84947978 -1.90244835 -4.91800319  4.27758567  4.68901431\n",
            "  4.44306009  4.90315793]. \t  -734.7138959152186 \t -150.91046800670185\n",
            "54     \t [ 2.80118475 -5.04581987  5.01465207 -0.78095274 -3.80247952  4.73675317\n",
            " -4.01465238 -3.18035216]. \t  -537.3013778899599 \t -150.91046800670185\n",
            "55     \t [-3.85035171  3.36686413  3.43604509  3.55055807  4.50911953  4.6152416\n",
            " -3.38430662 -4.38115196]. \t  -586.5360082411364 \t -150.91046800670185\n",
            "56     \t [ 3.95236195  2.17733278 -0.73780853  4.67414271 -2.53539463  2.19929512\n",
            "  4.21172327 -2.82885864]. \t  -363.4785893537803 \t -150.91046800670185\n",
            "57     \t [-3.75027101  4.8534991  -1.96548539 -4.59100743 -3.70307864 -5.08948344\n",
            "  2.02644009  1.46129415]. \t  -426.88550327150546 \t -150.91046800670185\n",
            "58     \t [ 4.28343433  3.77552185  4.4183024  -3.25582025  2.06032349 -4.49504068\n",
            "  1.82459389  5.11591062]. \t  -522.9639314867015 \t -150.91046800670185\n",
            "59     \t [ 0.53947503 -3.0403414   4.93405178 -2.44168606  5.05429659  3.88761683\n",
            "  4.50705983  4.35805942]. \t  -628.2078402476136 \t -150.91046800670185\n",
            "61     \t [-3.1674445   3.64822108  1.57169316 -4.36718356 -4.99670358  3.63225292\n",
            " -2.46251202  4.29094791]. \t  -514.0919968303267 \t -150.91046800670185\n",
            "62     \t [-3.7447051  -2.07819438 -2.82386285 -5.11697684 -5.05538647 -3.33264429\n",
            " -2.20090152  2.78625665]. \t  -441.7543631683144 \t -150.91046800670185\n",
            "63     \t [ 0.36820342 -2.19780625  0.04195628 -4.38451186  5.07783573 -4.58773508\n",
            " -4.13705832 -5.07562378]. \t  -667.8057096132966 \t -150.91046800670185\n",
            "64     \t [-3.35379067e+00 -4.35823445e+00  4.83588561e+00 -4.04702931e+00\n",
            " -2.39265033e+00 -4.83182470e-03  4.74523760e+00 -5.00177894e+00]. \t  -571.2947981259695 \t -150.91046800670185\n",
            "65     \t [-2.16353622 -4.17429275 -3.60859412 -4.85441897 -3.82621401 -3.4016274\n",
            "  4.71964924 -3.20707976]. \t  -553.692206965817 \t -150.91046800670185\n",
            "66     \t [ 3.55018506  3.46066288 -0.36734678  4.98791821 -4.71947281 -4.40571604\n",
            " -1.88160032 -5.06419982]. \t  -594.2593497807134 \t -150.91046800670185\n",
            "67     \t [ 3.15685441 -4.16088202 -0.15632249  4.84568211  4.8117954  -0.32143425\n",
            "  1.45432196  4.38266986]. \t  -423.4419806559715 \t -150.91046800670185\n",
            "68     \t [ 1.61586884  1.76666915 -2.93210067 -4.10633075 -2.48574073 -4.2104161\n",
            "  1.72748249 -4.88711618]. \t  -451.3134875036556 \t -150.91046800670185\n",
            "69     \t [ 4.18465132  4.87387076 -4.38881901  3.93301409  4.4336996  -3.80234865\n",
            " -3.31816647 -2.7180584 ]. \t  -505.89006050070134 \t -150.91046800670185\n",
            "70     \t [-4.68100927 -4.83364798 -0.5671837   4.04508856  2.39339921 -3.74876659\n",
            "  4.03480504 -4.35320092]. \t  -513.577944261707 \t -150.91046800670185\n",
            "71     \t [ 2.52183132 -4.0041318   4.72809341 -0.67666186 -3.47125488 -3.68141536\n",
            " -2.15073199 -1.36303397]. \t  -296.1292589117099 \t -150.91046800670185\n",
            "72     \t [ 0.66250068  4.22023462 -1.99684684 -2.78632178 -2.20170335  4.52604909\n",
            "  4.92125909 -3.17953814]. \t  -476.63166563772415 \t -150.91046800670185\n",
            "73     \t [-3.65548999 -1.69561106  4.88963825  1.64136415 -2.68688916 -5.03595481\n",
            " -3.87546553  2.96971002]. \t  -465.56475652410853 \t -150.91046800670185\n",
            "74     \t [-3.7979753  -4.64791055 -2.6479763  -3.74404829  3.85577545  3.10654761\n",
            " -4.33939785 -2.69838144]. \t  -457.039251985949 \t -150.91046800670185\n",
            "75     \t [ 2.02216027  3.30703047  4.89927927 -4.57531587 -4.6987924   2.35169956\n",
            "  2.25779592  3.01771254]. \t  -433.8173102974987 \t -150.91046800670185\n",
            "76     \t [ 3.6079614  -2.11547809  4.03193754 -3.18993751 -4.78636134 -4.5104888\n",
            "  4.86801958 -2.60583218]. \t  -568.2597698271295 \t -150.91046800670185\n",
            "77     \t [-0.61755926  4.94327463  1.28475822 -3.4088697   4.69109047 -4.18956823\n",
            "  2.46565071 -2.09229579]. \t  -393.6108767500818 \t -150.91046800670185\n",
            "78     \t [-4.94151531 -3.15576797  2.20062317  2.28976708  4.38231657 -3.18032351\n",
            "  4.72422864  3.78170681]. \t  -507.1857201430117 \t -150.91046800670185\n",
            "79     \t [ 2.63847313 -4.78027776 -4.91526381  3.93746778  2.05708299 -4.54519341\n",
            " -3.51438659  2.94585258]. \t  -488.1491389629456 \t -150.91046800670185\n",
            "80     \t [ 0.99733968  4.3322645   1.93041438  4.28582977  4.69689802 -4.69714541\n",
            " -4.58038684  4.59236492]. \t  -681.4459989548013 \t -150.91046800670185\n",
            "81     \t [-2.72024357  4.79927685  2.99968489  0.33343101  2.66700095  5.08617913\n",
            " -2.96727314  4.17703184]. \t  -472.8983836427034 \t -150.91046800670185\n",
            "82     \t [ 2.71884896 -4.98047054 -3.62925576  4.49556144 -3.83118267 -4.37380054\n",
            "  4.17486173 -0.34172591]. \t  -488.46819262230065 \t -150.91046800670185\n",
            "83     \t [-0.99523326  4.57301701  1.64025597  3.13242291  4.97756553  4.81504752\n",
            "  3.4615533  -3.69545857]. \t  -546.2517303604358 \t -150.91046800670185\n",
            "84     \t [-2.08072868  4.57438363  5.03375773 -2.48962688  3.07787366 -0.83278118\n",
            " -3.43653005 -4.64206329]. \t  -453.57438438847714 \t -150.91046800670185\n",
            "85     \t [ 4.95840532 -2.03648939  1.75513139  4.92464842 -2.14429927  5.03747821\n",
            " -0.30649513 -0.07268064]. \t  -315.0775200543343 \t -150.91046800670185\n",
            "86     \t [ 4.31793122  2.15684981  2.72196441 -1.98687719 -3.86143404  4.83462885\n",
            " -1.46137015 -4.19764675]. \t  -436.6728331050999 \t -150.91046800670185\n",
            "87     \t [ 2.54870954  4.70311118 -4.61605779  1.53685197  4.04407676 -4.01542705\n",
            "  2.92245623  4.94958934]. \t  -558.3934950219625 \t -150.91046800670185\n",
            "88     \t [ 1.7561101   1.15784294  4.29437243  3.35105018 -4.47245625  2.27256791\n",
            "  4.08727909  4.3648452 ]. \t  -506.36583191466764 \t -150.91046800670185\n",
            "89     \t [-4.87917131  3.89610413  4.74492988 -3.79911642  3.84599038  4.2467039\n",
            "  1.60781127 -4.04502532]. \t  -510.6002007614677 \t -150.91046800670185\n",
            "90     \t [ 5.11171413  2.18718371  1.78812935  2.62974846  4.93606179 -2.81142637\n",
            "  3.65436716 -4.95279083]. \t  -531.9218252469753 \t -150.91046800670185\n",
            "91     \t [-2.90389486 -2.90225766 -0.24184001  4.65841864 -4.1784133   5.03161914\n",
            " -3.20888666  1.91946971]. \t  -453.01014351342315 \t -150.91046800670185\n",
            "92     \t [-3.9178554  -4.22825717  4.50545743 -0.74151383  1.59426123 -1.82904831\n",
            " -1.87629579 -4.58428069]. \t  -339.75200715593513 \t -150.91046800670185\n",
            "93     \t [-3.60109381  3.11253003 -4.26857912 -4.37960568  3.79878173 -5.07203998\n",
            "  4.89256769  3.41553296]. \t  -651.1243539073696 \t -150.91046800670185\n",
            "94     \t [-4.85198627 -1.474098   -4.86848469 -2.90572084 -1.44316289  3.9911242\n",
            "  4.2951752  -3.20333618]. \t  -449.98562568478525 \t -150.91046800670185\n",
            "95     \t [-1.61437925  3.44553822 -4.94354672  2.94805334  3.40666298  3.49650273\n",
            " -2.44269958 -3.74920845]. \t  -420.0296563554624 \t -150.91046800670185\n",
            "96     \t [-4.94853378 -4.62206919 -3.24477127 -1.44835065 -3.46238285  2.46353411\n",
            " -0.46463445  4.06333841]. \t  -337.142959099064 \t -150.91046800670185\n",
            "97     \t [ 4.47117362 -0.55155102 -4.12943162  0.88478254  4.20745483 -3.86752488\n",
            "  0.60967512  0.65520522]. \t  -259.1839377040826 \t -150.91046800670185\n",
            "98     \t [ 4.49440326 -3.98135763 -4.64224488  2.21443477 -4.63657878  4.59288683\n",
            " -4.44505901 -3.54929695]. \t  -609.3151641899943 \t -150.91046800670185\n",
            "99     \t [ 0.95678877 -1.6018042  -4.79123372 -0.79918778  1.29486604  4.53886321\n",
            " -4.45799344 -1.42634247]. \t  -364.8521910743211 \t -150.91046800670185\n",
            "100    \t [-1.51905746  3.51004968 -0.84363652 -4.52733946 -0.61090239  3.98672373\n",
            "  4.8487456   4.48022898]. \t  -533.4525666767036 \t -150.91046800670185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8riJpBBKuvT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff4d2e2-8cd5-4e05-d5e1-79288cb7a004"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 4 \r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_winner_4 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_4 = dGPGO_stp(surrogate_winner_4, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.47505713  3.29006044  1.45620137  1.71235961 -4.71920737 -4.44751474\n",
            " -2.28863345 -1.88046844]. \t  -346.80639555492485 \t -165.62625697677552\n",
            "init   \t [-3.1376137  -3.10176889  3.57585195  3.50574682 -1.56298519  2.45496116\n",
            " -0.06749038 -0.27635987]. \t  -165.62625697677552 \t -165.62625697677552\n",
            "init   \t [-3.7790926  -1.54671161  4.27823555  2.60935971 -4.15202172  0.36061924\n",
            "  2.14992129  0.60475125]. \t  -223.4687278056974 \t -165.62625697677552\n",
            "init   \t [-0.25707746  4.70597666  2.91673192  2.51031751  4.76862861  1.58260827\n",
            "  2.63690453 -2.92386101]. \t  -340.87882459564884 \t -165.62625697677552\n",
            "init   \t [-4.10230933 -4.5220156  -2.28380738  4.65096756 -4.15019246  2.30585903\n",
            " -2.53997873  4.26674294]. \t  -468.7231264209916 \t -165.62625697677552\n",
            "1      \t [-5.01918393  0.79364164 -1.36560668  2.11685063 -4.95451332 -1.5583133\n",
            " -2.89797694 -3.01695924]. \t  -318.88110310996603 \t -165.62625697677552\n",
            "2      \t [ 3.38576809 -4.3130908  -3.53830876  2.15054785  0.27847194  0.50551805\n",
            "  3.97000942  1.13685114]. \t  -227.31453273392674 \t -165.62625697677552\n",
            "3      \t [-0.6886086  -1.43145706 -0.31580828 -4.46654462  3.35049964  0.27980904\n",
            " -4.56051967  0.68552565]. \t  -290.618546996452 \t -165.62625697677552\n",
            "4      \t [-3.86756311  4.38856448  0.42274798 -0.81644185 -0.58896168  1.5495776\n",
            " -2.04661219  2.34948859]. \t  \u001b[92m-146.3021445183416\u001b[0m \t -146.3021445183416\n",
            "5      \t [ 2.24935468  3.62297272 -3.38191621  1.32525079  2.91295512  4.26665495\n",
            " -4.95797077  3.27809936]. \t  -482.33909643382617 \t -146.3021445183416\n",
            "6      \t [-5.10422744 -2.96957095  0.12169161 -3.49092846 -3.36091293  1.77731674\n",
            "  2.01845452 -2.85427212]. \t  -261.60646620320523 \t -146.3021445183416\n",
            "7      \t [ 4.07399877 -1.40885832 -0.72048101  3.264926   -3.7566101   1.93859512\n",
            "  0.27400098 -4.43890597]. \t  -316.02960401738403 \t -146.3021445183416\n",
            "8      \t [ 3.62918725 -3.18431037  3.76376293  4.84862432  1.68522388  2.75533686\n",
            " -4.14313579  1.65749666]. \t  -371.87359578066287 \t -146.3021445183416\n",
            "9      \t [ 1.92372408  2.61202069  2.8481628  -4.04330074 -4.93240225  0.95347616\n",
            "  0.57276068  4.88777913]. \t  -427.59235872786473 \t -146.3021445183416\n",
            "10     \t [-3.3541894   3.89900104 -4.70945128  4.6414727  -3.17638744  1.80844266\n",
            "  2.06376834 -4.56644388]. \t  -461.0681050222969 \t -146.3021445183416\n",
            "11     \t [-4.53527416 -3.73970625 -1.11284447  2.85898317  1.96538511  4.97256876\n",
            " -4.1666148  -3.6412399 ]. \t  -480.21603479022326 \t -146.3021445183416\n",
            "12     \t [ 3.22412015 -0.25475316  1.09877381 -3.31291554  0.33986372  4.57355098\n",
            "  0.88638865 -4.67465616]. \t  -364.4491217475104 \t -146.3021445183416\n",
            "13     \t [ 1.82735632  0.28045449 -4.98570614 -4.42278731 -4.05748135  3.13682169\n",
            "  4.77092718  1.79823373]. \t  -482.86758417372874 \t -146.3021445183416\n",
            "14     \t [ 3.96809598  2.17167434  5.05137093 -4.86020822  2.47404724 -3.6968291\n",
            "  0.34500027  0.43956392]. \t  -311.1963939787383 \t -146.3021445183416\n",
            "15     \t [ 1.44851679 -3.55804525 -1.58856358  2.13357113  4.25760422 -1.73388059\n",
            " -3.21925444 -3.17177188]. \t  -314.8969876230169 \t -146.3021445183416\n",
            "16     \t [ 0.63347605 -1.93609734  1.74023979 -3.07483767  4.66595971  2.49445403\n",
            "  2.55184389  3.46384782]. \t  -342.5610378635806 \t -146.3021445183416\n",
            "17     \t [ 2.41064427 -1.12805758  4.36631416  4.87402616  2.53575533 -2.72074816\n",
            "  1.37964702 -4.24732817]. \t  -394.7823084519998 \t -146.3021445183416\n",
            "18     \t [-0.7025362   4.40924389 -2.85974804 -4.10274948 -3.43533595 -4.8705516\n",
            " -2.83945196 -1.54234026]. \t  -408.05033342453765 \t -146.3021445183416\n",
            "19     \t [ 3.81382517 -0.03011874 -4.93782375  4.10588391 -3.43688686 -1.38985165\n",
            " -1.62820446  3.9223462 ]. \t  -367.41334545675204 \t -146.3021445183416\n",
            "20     \t [-4.42395956  4.79079632  4.42810491 -3.56541236  3.74768255 -2.91520747\n",
            "  3.75162855  0.22720203]. \t  -395.3000911033991 \t -146.3021445183416\n",
            "21     \t [ 2.92863164  3.71576039 -4.99288802  0.30399217  0.73088157  1.89245012\n",
            "  0.11199064 -3.06467314]. \t  -210.73177996518808 \t -146.3021445183416\n",
            "22     \t [-4.96329736  4.96365676 -3.81166527 -3.25499944  2.00977268  3.78180898\n",
            " -4.34280101 -4.12609666]. \t  -534.1017988023593 \t -146.3021445183416\n",
            "23     \t [3.71952888 5.08278495 4.7431279  2.28785225 2.04605464 0.26092335\n",
            " 3.58044563 4.7691359 ]. \t  -446.96773702072005 \t -146.3021445183416\n",
            "24     \t [-3.33317209 -2.00605614 -0.06635313 -4.72844543 -3.5673605  -2.29310757\n",
            "  3.64060318  4.60803472]. \t  -466.43472292286657 \t -146.3021445183416\n",
            "25     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -146.3021445183416\n",
            "26     \t [-1.75909395  0.94331241 -4.16206972  3.41730323  2.4830277  -3.40781682\n",
            " -0.02875039  2.91060158]. \t  -271.8394308351967 \t -146.3021445183416\n",
            "27     \t [-4.66300472 -4.9671362  -1.21119701  0.36675827  0.64784103 -4.65828461\n",
            " -3.81224682 -0.15382984]. \t  -310.2456106476028 \t -146.3021445183416\n",
            "28     \t [ 0.90568769 -0.27283592 -1.64109322 -3.92213924  2.24749888 -3.84655314\n",
            "  4.13430735 -0.70533039]. \t  -308.2409061967011 \t -146.3021445183416\n",
            "29     \t [-4.41676404  1.90733563  2.53050905  0.63211075  4.86757828 -4.25757366\n",
            " -3.25090223 -4.50451697]. \t  -511.12448210148665 \t -146.3021445183416\n",
            "30     \t [-4.99097224 -3.53792402 -4.36233826 -4.87589301  1.46536873  4.39575127\n",
            " -2.44009417 -4.49726126]. \t  -532.2845227664976 \t -146.3021445183416\n",
            "31     \t [ 4.99946898 -4.16172086  4.79399087 -0.61266479 -1.13853807 -3.83958111\n",
            " -3.3287258   2.36250878]. \t  -347.23314201051136 \t -146.3021445183416\n",
            "32     \t [ 0.38105067  4.59804319 -2.21353496  3.23159899 -3.96889433 -5.02481741\n",
            "  4.86280467 -0.75756728]. \t  -499.2740427841084 \t -146.3021445183416\n",
            "33     \t [ 2.856321   -4.82143515 -4.35850867 -2.45302618 -4.62187878 -4.36812625\n",
            "  0.2563302  -4.4203084 ]. \t  -513.7751126384626 \t -146.3021445183416\n",
            "34     \t [-0.78524203 -4.72958009  5.05991941  2.82304864  4.40051008 -3.24604342\n",
            "  1.09912201  4.12873362]. \t  -458.91247564312977 \t -146.3021445183416\n",
            "35     \t [-1.72233556 -4.67100025  4.10903298 -3.29202149 -2.88915146  2.56347906\n",
            " -1.91992345  5.09808462]. \t  -455.4960109889022 \t -146.3021445183416\n",
            "36     \t [ 0.21917246 -0.64178228 -2.31355852 -4.2037116  -4.35503807  5.07096244\n",
            " -4.812319    0.01986208]. \t  -498.84602830015024 \t -146.3021445183416\n",
            "37     \t [-2.32899478 -1.36548993  4.23591724 -4.53882252  5.07991624  5.09372727\n",
            " -1.64044587 -4.45319203]. \t  -607.5748490067065 \t -146.3021445183416\n",
            "38     \t [-0.57965299  3.97565101  4.60096301  5.08724617  4.60981041 -2.3191684\n",
            " -4.94315131  1.01836813]. \t  -516.8372913091074 \t -146.3021445183416\n",
            "39     \t [-2.52018643  4.7440573   4.05549937  1.94851108 -5.07921519  4.31976923\n",
            " -2.47894233 -2.2416984 ]. \t  -440.0638570475211 \t -146.3021445183416\n",
            "40     \t [-1.58724684  4.67632244 -5.04067367  2.04481106 -0.79111433  5.04242705\n",
            "  2.29202907  4.70158918]. \t  -508.50455804186754 \t -146.3021445183416\n",
            "41     \t [ 4.70670372  4.63473216  4.04869422 -4.33539338  2.76288591  1.88880935\n",
            " -4.84656392 -3.23484982]. \t  -497.1844593719484 \t -146.3021445183416\n",
            "42     \t [ 3.32924017 -1.48934856  1.6126568   0.03684817 -4.49330743 -4.10590787\n",
            "  4.52293472 -3.05016953]. \t  -443.0543532429105 \t -146.3021445183416\n",
            "43     \t [ 4.20113722  3.78605191  0.50036257  4.06465602 -4.83628313  3.44389331\n",
            " -4.64831948  4.95069766]. \t  -648.5886906691898 \t -146.3021445183416\n",
            "44     \t [ 3.16146588  3.57542765 -4.13907413 -3.30804753 -3.69660801 -3.22060792\n",
            "  1.35415132  4.34229938]. \t  -424.9697882652673 \t -146.3021445183416\n",
            "45     \t [ 5.04274676  2.96728202  2.85650568  4.30807236  3.60634648  5.11895369\n",
            " -3.10667484 -4.21663395]. \t  -573.806454343144 \t -146.3021445183416\n",
            "46     \t [-1.26290079  3.68276917  4.88368723  2.37110314 -3.81426669 -4.76895947\n",
            "  3.20016727  4.47817513]. \t  -564.0811319562519 \t -146.3021445183416\n",
            "47     \t [-0.46941021 -3.66611103  4.82638447 -3.32805658 -2.87941195 -4.03482225\n",
            " -0.86167108 -4.68321036]. \t  -461.07771262067325 \t -146.3021445183416\n",
            "48     \t [ 0.14613133  3.62717255 -4.70934641 -3.91054248  4.67242969 -3.7246583\n",
            " -1.27692736  4.96309287]. \t  -554.9059206390359 \t -146.3021445183416\n",
            "49     \t [-3.62038919  4.60091743 -3.0480345  -2.90192928  2.12911955  1.29394064\n",
            "  3.8447851  -3.5027759 ]. \t  -351.34398127474884 \t -146.3021445183416\n",
            "50     \t [-1.55873706 -1.24359174  2.85096464  2.45075694 -3.90780316 -4.69217638\n",
            " -4.37186962  3.43909574]. \t  -490.7970253529816 \t -146.3021445183416\n",
            "51     \t [ 3.47931003  3.73699132 -3.33286996 -4.54504379  3.26197536  2.87189633\n",
            "  4.42721075  0.48596762]. \t  -397.7693942879476 \t -146.3021445183416\n",
            "52     \t [ 3.49926522 -4.18152861  2.02709444  4.520488   -4.06368225 -4.3913492\n",
            "  0.74998801  2.38068948]. \t  -388.83188982752364 \t -146.3021445183416\n",
            "53     \t [-3.42462978  2.83797396  0.88170682  4.60313541 -3.30784678  4.64780521\n",
            "  4.95853719  1.96989613]. \t  -502.39929938934256 \t -146.3021445183416\n",
            "54     \t [-4.76524101 -3.98372411 -3.61580861 -2.36540378  3.33982259  2.79323051\n",
            "  2.79835775  0.71309591]. \t  -277.51897686487126 \t -146.3021445183416\n",
            "55     \t [-5.05443213  4.90828413  2.13894856  4.73399032  4.07572176  3.95483795\n",
            " -3.77788279 -2.00356413]. \t  -486.0206920151199 \t -146.3021445183416\n",
            "56     \t [-7.36239237e-02  4.80515489e+00 -5.00945836e-03  5.05823466e+00\n",
            "  2.06034723e+00 -3.46035114e+00  1.99836822e-01 -4.88882182e+00]. \t  -433.0809815542357 \t -146.3021445183416\n",
            "57     \t [ 2.20684775  0.83992508 -5.02149824 -4.59927266  4.32973578  4.78470766\n",
            " -2.07100192  0.13591884]. \t  -427.8054534653857 \t -146.3021445183416\n",
            "58     \t [ 4.25709711  3.75544538  2.29147416 -3.7018982   3.20058234  4.14026034\n",
            " -4.08017045  4.15393248]. \t  -525.5433255885641 \t -146.3021445183416\n",
            "59     \t [ 5.0919685  -4.13985447 -0.41304443 -0.74867385 -4.10315086  1.77429975\n",
            " -3.45690744  4.16341879]. \t  -388.3507848436175 \t -146.3021445183416\n",
            "60     \t [-2.72548517  4.7912949  -4.80441495  4.7764504  -1.25041224  0.96980211\n",
            " -4.45096757  2.05060908]. \t  -399.6249238376175 \t -146.3021445183416\n",
            "61     \t [-4.15380588  3.52903369  3.19683559 -4.05996458 -1.13958134 -3.51373622\n",
            " -4.16278803 -4.68014777]. \t  -515.857959739339 \t -146.3021445183416\n",
            "62     \t [ 4.52401554  3.15808095  4.85105397  3.71157077 -4.58464292  3.76842323\n",
            "  5.09990776  1.18201955]. \t  -549.6564823223646 \t -146.3021445183416\n",
            "63     \t [ 4.45966235  4.4024732  -3.64533765  2.85903955  3.66697959 -3.41949595\n",
            " -1.86829103  3.2245642 ]. \t  -376.2215230183126 \t -146.3021445183416\n",
            "64     \t [ 4.74887091 -0.87873918  1.97416782  0.6854927   4.68300112 -4.05768849\n",
            " -3.65989367  4.29841301]. \t  -487.683856371281 \t -146.3021445183416\n",
            "65     \t [-2.96388624 -2.66002287 -4.89571829  1.86001907 -1.2588112  -2.41463135\n",
            "  4.72572362 -4.61596589]. \t  -478.36899200198206 \t -146.3021445183416\n",
            "66     \t [-1.37175944 -1.57498417 -0.98810533  4.05449904  4.42709039  4.62425255\n",
            "  0.51071846  3.1121375 ]. \t  -381.1347289777317 \t -146.3021445183416\n",
            "67     \t [-2.8067636   2.57999122  3.00524668 -3.95745919 -4.96436349  4.5203808\n",
            "  3.41575723 -4.41159163]. \t  -594.1275748444643 \t -146.3021445183416\n",
            "68     \t [ 4.4578621  -3.80741175  4.52034218 -4.04270956  1.7332398   4.42415363\n",
            " -4.27037261  0.7761196 ]. \t  -440.470667145212 \t -146.3021445183416\n",
            "69     \t [ 4.97697474  1.69309632 -0.19417545 -3.8473819  -2.95367004 -2.85542181\n",
            " -5.10760912  4.43225706]. \t  -522.140283959709 \t -146.3021445183416\n",
            "70     \t [ 4.73386797 -3.83169846 -4.71580596 -0.23361909  2.7314736  -0.72485879\n",
            " -3.57097851  2.86342125]. \t  -314.0220453858925 \t -146.3021445183416\n",
            "71     \t [ 4.82118241  3.70792529 -5.07521623  5.01925968 -4.91843018  3.1451126\n",
            "  3.07940665  5.11129067]. \t  -684.4732825320875 \t -146.3021445183416\n",
            "72     \t [-4.65647539  1.27720503  2.85233942  4.59339734  3.23505858 -1.64011688\n",
            "  5.03270256 -0.32303244]. \t  -380.34937118806556 \t -146.3021445183416\n",
            "73     \t [ 0.12480091 -4.6642734   3.39542824 -2.74226882  0.77282377 -0.33881611\n",
            "  3.74936205 -1.4480097 ]. \t  -227.0463483765121 \t -146.3021445183416\n",
            "74     \t [ 2.19881271 -0.95508592 -1.02012292  3.21869879  4.76296541 -5.05698667\n",
            "  4.55932795 -0.66123854]. \t  -467.09926913127254 \t -146.3021445183416\n",
            "75     \t [ 4.37494013 -4.35749834 -4.14041012 -2.9897019   3.05748617  2.59867502\n",
            "  4.74089708 -3.88264554]. \t  -509.4899494302347 \t -146.3021445183416\n",
            "76     \t [ 4.54462648  0.29960371 -2.57313534 -0.45475158 -0.50954886 -3.13875178\n",
            " -3.74367813 -5.04995845]. \t  -404.05472757500047 \t -146.3021445183416\n",
            "77     \t [-3.16802288  4.31919809  3.56034036 -3.61517657  5.06233873 -4.72966007\n",
            " -3.1525915   4.80313155]. \t  -654.140278058291 \t -146.3021445183416\n",
            "78     \t [4.76973772 0.40806644 1.52014574 1.06581554 3.33584376 4.91037757\n",
            " 4.16013862 0.30255348]. \t  -356.74951206578504 \t -146.3021445183416\n",
            "79     \t [-2.03396254 -2.25645236  1.67209357  3.53450784  2.11655098  4.22331141\n",
            "  5.10884407 -4.54398222]. \t  -549.9801375537324 \t -146.3021445183416\n",
            "80     \t [-5.07247087 -0.39799318  1.94113919  5.01106147 -1.24110828 -4.73438593\n",
            "  0.1935636  -1.99767787]. \t  -312.169982752308 \t -146.3021445183416\n",
            "81     \t [-4.51563128  4.94574174 -0.36139375 -0.10889307  4.53012148  3.27667087\n",
            "  4.48412279  3.09805225]. \t  -454.31525284421355 \t -146.3021445183416\n",
            "82     \t [-1.54257273 -1.11748904 -3.81056437 -4.58768168 -4.41713    -4.31094398\n",
            " -4.86169539  5.07752016]. \t  -713.3884669522375 \t -146.3021445183416\n",
            "83     \t [ 4.31312109 -0.97605007 -4.94502491  4.96027613  2.29633008  4.83202833\n",
            " -5.10328031 -3.26982491]. \t  -626.5805068532095 \t -146.3021445183416\n",
            "84     \t [ 2.3813673   4.86913424  0.11616491 -4.47667715  4.77358413 -0.65135147\n",
            "  1.80510873 -5.09390717]. \t  -480.16400737548895 \t -146.3021445183416\n",
            "85     \t [ 4.22729159 -4.70856319  4.89313407 -0.88769884 -3.5276401   1.97646429\n",
            "  4.98492899  1.92828974]. \t  -426.54416861578255 \t -146.3021445183416\n",
            "86     \t [-1.4583203  -4.52062327 -0.35578582  3.78774907 -4.83167549  2.77721786\n",
            " -4.19572238 -4.62092946]. \t  -557.8222819054766 \t -146.3021445183416\n",
            "87     \t [ 4.83357214  4.47966423  0.96624731 -4.9712099  -4.58922018  3.1662362\n",
            " -1.4016299  -1.87473069]. \t  -372.4747210054916 \t -146.3021445183416\n",
            "88     \t [-3.31516516  5.11540755  4.45794133  4.27700484 -3.03035136 -0.46530821\n",
            "  4.68061461 -3.14920532]. \t  -476.0271557982395 \t -146.3021445183416\n",
            "89     \t [-4.55790257  4.93469914  0.67740023  1.25152809  1.24718187 -3.978709\n",
            "  1.43990424  4.28006127]. \t  -340.9416211552198 \t -146.3021445183416\n",
            "90     \t [ 4.41288387  4.24787968 -5.11668306 -3.11185186 -3.8763189  -2.4601717\n",
            "  4.72948775 -4.97476325]. \t  -638.8447779344086 \t -146.3021445183416\n",
            "91     \t [-4.24884047 -4.20143738 -0.64922868 -1.40664715  2.29735589 -4.18242657\n",
            "  4.26669253  3.32200847]. \t  -409.5998665501587 \t -146.3021445183416\n",
            "92     \t [-3.53298483 -4.30277657 -4.64436563  2.67404952  3.10894989  2.3647066\n",
            " -4.1289208   2.26146681]. \t  -384.95095078850807 \t -146.3021445183416\n",
            "93     \t [ 1.29385234 -4.99123698  0.43203096 -1.13685108 -3.62845102  3.71017418\n",
            "  4.24345028 -4.91350774]. \t  -524.8378177548914 \t -146.3021445183416\n",
            "94     \t [-2.62141424  4.22819617 -3.72424459  5.09103651  3.93758887  0.05470521\n",
            "  3.84153686 -3.20182849]. \t  -450.76817258191767 \t -146.3021445183416\n",
            "95     \t [ 2.3525354   3.56787547  5.09744911 -4.62217288  1.09311383  4.89002792\n",
            "  4.32114545  1.57336306]. \t  -494.36236869168636 \t -146.3021445183416\n",
            "96     \t [-2.05511846  1.95591375  4.99243911  4.04007918  2.63859265  3.53567253\n",
            " -3.60180461  4.83368724]. \t  -539.4809841535698 \t -146.3021445183416\n",
            "97     \t [-3.89039454 -4.20253718  4.95060723  0.85277235  3.75876299 -2.30676873\n",
            "  0.57737415 -4.25666829]. \t  -376.7481396826448 \t -146.3021445183416\n",
            "98     \t [-4.67993299  1.12421007 -5.10316374 -1.19348295 -2.20715044 -4.46236948\n",
            "  3.00082611  2.27632967]. \t  -356.5760450172845 \t -146.3021445183416\n",
            "99     \t [ 0.77611054  1.18124913  5.10018676 -3.97159912 -2.97484943 -1.6747241\n",
            " -4.86694522  0.42722501]. \t  -372.87027044057857 \t -146.3021445183416\n",
            "100    \t [-1.646111   -0.3805924  -3.6397202  -4.03130816  4.71140454 -1.18135051\n",
            " -0.28899332 -4.38984649]. \t  -381.85868910980855 \t -146.3021445183416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrvkDXP0uvWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2409fb-6949-44ac-c003-c1816cd06824"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 5 \r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_winner_5 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_5 = dGPGO_stp(surrogate_winner_5, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.58729753  0.42762882  0.61873954 -1.20782752 -3.90047561  3.54303094\n",
            "  2.45495411  4.42734146]. \t  -358.07993275421416 \t -191.0582179343833\n",
            "init   \t [ 3.67951879  2.13099137  1.85311997 -0.93591243  2.81174646  4.9610363\n",
            "  4.76656492  2.68257959]. \t  -440.2387279623039 \t -191.0582179343833\n",
            "init   \t [ 2.28457508 -3.1898747  -0.24613755 -2.16324482  3.55437597  3.73325571\n",
            " -1.2826718  -0.39471791]. \t  -204.02442667207546 \t -191.0582179343833\n",
            "init   \t [3.75520732 3.06877821 2.55257243 0.39811528 0.98991542 2.6976486\n",
            " 2.32004232 2.54212732]. \t  -191.0582179343833 \t -191.0582179343833\n",
            "init   \t [ 0.5992029   3.04558915 -1.51609106  4.46525397  4.55980658  3.872474\n",
            " -1.66783187  4.83819235]. \t  -506.2318322394824 \t -191.0582179343833\n",
            "1      \t [ 2.93499453 -4.66586726 -4.44927383  4.16377803  3.1780443  -4.4736638\n",
            " -0.65762836  1.31319723]. \t  -368.2961856386949 \t -191.0582179343833\n",
            "2      \t [-3.36202716  0.9751399  -0.98615644  2.90532312  3.91477757 -3.638786\n",
            "  0.82668116 -1.83217109]. \t  -237.59676331051745 \t -191.0582179343833\n",
            "3      \t [ 3.38049033 -2.620933   -0.0712623  -2.25177506  3.20656637 -3.17286342\n",
            " -3.47233925  4.88112165]. \t  -432.27897372171685 \t -191.0582179343833\n",
            "4      \t [-1.92157682 -3.75075798 -4.0377457   4.80063144 -1.15467219  1.27346354\n",
            " -2.73055369  0.52224006]. \t  -243.69318556764293 \t -191.0582179343833\n",
            "5      \t [-5.00945286 -3.09210297 -0.39880369 -4.45719124  4.55915523 -2.45794355\n",
            " -4.27979665 -3.13774118]. \t  -471.3185418432943 \t -191.0582179343833\n",
            "6      \t [-0.05794635  1.92483547 -4.38897436 -1.69922758  1.16135117 -4.74755465\n",
            "  0.31027438  3.73327154]. \t  -330.9038823567389 \t -191.0582179343833\n",
            "7      \t [-4.31450528  4.80511433  4.53287247 -1.30767464  3.86760946 -0.7561011\n",
            " -4.02542796  4.08643456]. \t  -458.5162729872259 \t -191.0582179343833\n",
            "8      \t [-4.42904907  2.22889591  0.29905893 -3.03981043  2.11032903  0.55963354\n",
            "  5.06528481 -3.7134262 ]. \t  -380.84515405154747 \t -191.0582179343833\n",
            "9      \t [ 4.51874036 -1.20032029 -2.55935692  4.46325734 -2.10504339 -1.2292994\n",
            "  3.58439135 -0.45803182]. \t  -245.47061481984463 \t -191.0582179343833\n",
            "10     \t [-3.95212917 -4.77814163  2.74774225 -3.2003693   3.80603318 -1.90102196\n",
            "  4.90229505  0.07146516]. \t  -387.281402022425 \t -191.0582179343833\n",
            "11     \t [-2.96489911e-03  3.20621581e+00 -1.53267486e+00  4.29738075e-01\n",
            " -3.51692901e+00 -4.59367930e+00  1.11305274e+00 -3.84765614e+00]. \t  -343.9087769128066 \t -191.0582179343833\n",
            "12     \t [-1.96750308 -3.78076123 -4.0804221   4.35188302  4.65004433  2.81581226\n",
            "  4.77997907  2.20705293]. \t  -512.7578704089362 \t -191.0582179343833\n",
            "13     \t [ 2.67987994 -3.59260565  4.65819968 -4.41792167  0.54195462  4.08103757\n",
            " -3.98658326  4.63537659]. \t  -560.7054187283353 \t -191.0582179343833\n",
            "14     \t [-1.42167188  0.66893234  4.10233943  4.92162383 -0.83987545  4.31183454\n",
            " -3.8031181   1.02491464]. \t  -375.0211901380205 \t -191.0582179343833\n",
            "15     \t [-2.56237463  4.10852463  1.22633667  0.53086682 -4.8245088  -4.9304006\n",
            "  2.37356317  4.32815265]. \t  -497.4970796641493 \t -191.0582179343833\n",
            "16     \t [-0.41616104 -3.05469614  2.70688123  1.93084803 -3.11397838 -0.02818534\n",
            " -3.67741922 -4.70805005]. \t  -376.2086818189558 \t -191.0582179343833\n",
            "17     \t [-5.06309372  2.54114725  2.47591872  0.84921772  2.46561811  2.58778467\n",
            " -4.17214766 -4.42459252]. \t  -408.8649851953495 \t -191.0582179343833\n",
            "18     \t [ 4.49010932  1.34677374  2.31690938  2.74796067  3.54797483 -2.8657133\n",
            "  3.78236188 -2.97377251]. \t  -353.2029558390906 \t -191.0582179343833\n",
            "19     \t [-5.03292098 -0.08609374  1.62372182 -4.13622016 -4.95224814 -0.21672473\n",
            " -0.17205378 -3.08639051]. \t  -301.0070986681606 \t -191.0582179343833\n",
            "20     \t [ 4.51872639  2.31652647  3.83627038 -2.89255531 -4.36114443 -0.18473971\n",
            " -4.79685298  1.33657707]. \t  -379.43266649829155 \t -191.0582179343833\n",
            "21     \t [-3.72724178  4.6151294   0.99922068  4.66334548 -4.86242247  3.19529514\n",
            "  2.14129775 -4.01659658]. \t  -487.109365573133 \t -191.0582179343833\n",
            "22     \t [ 4.86689866  0.66618016 -3.01896516 -4.65992524 -2.32169752 -1.16597445\n",
            "  0.52164121 -3.62467148]. \t  -280.8954485359844 \t -191.0582179343833\n",
            "23     \t [-3.19345611 -4.56631791  4.4316723   0.47438899 -1.42380809  3.46368648\n",
            "  1.58534887 -0.59842704]. \t  -214.29714661177738 \t -191.0582179343833\n",
            "24     \t [ 4.80823043  4.74988549  4.96492747  4.95832495  0.21960506 -0.31844695\n",
            " -2.76344731 -4.39599645]. \t  -449.4377122247749 \t -191.0582179343833\n",
            "25     \t [ 0.6719663   3.30302918 -4.59414955  2.74105869  4.42909745  0.31404913\n",
            " -4.29700089 -4.33201553]. \t  -493.70045116550733 \t -191.0582179343833\n",
            "26     \t [ 1.94955203  2.3461492   3.43272214  3.35504859 -1.1086825  -1.99968358\n",
            " -3.32227256  4.85298092]. \t  -390.9978792770163 \t -191.0582179343833\n",
            "27     \t [ 3.99769844 -1.36088439 -3.04028212  4.96236093 -2.03692793  4.45181649\n",
            " -1.84956984 -4.54752418]. \t  -474.9592226443051 \t -191.0582179343833\n",
            "28     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -191.0582179343833\n",
            "29     \t [-5.01372694 -4.51139878 -4.61209674 -3.89421434  0.08216564  4.29238463\n",
            "  1.35875589  1.56903035]. \t  -333.51634988185606 \t -191.0582179343833\n",
            "30     \t [-1.69153758 -4.24825173 -1.90309476 -3.24533572 -4.46689798 -2.7811458\n",
            " -4.16095931  2.38471849]. \t  -404.8153641396954 \t -191.0582179343833\n",
            "31     \t [ 1.45320363 -4.37265039 -2.17076124 -5.09610172 -4.44546487  3.35291193\n",
            "  5.00241981 -0.08892102]. \t  -499.8651508540984 \t -191.0582179343833\n",
            "32     \t [ 1.78136209  4.88276321  4.40408338 -3.6654527   2.39953078 -0.01988734\n",
            " -1.63779782 -4.68029555]. \t  -385.59514573921285 \t -191.0582179343833\n",
            "33     \t [ 4.26459826 -4.82420616 -2.7445499   2.89787711 -4.33755639 -4.4070789\n",
            " -5.08615471  3.69424432]. \t  -621.7895182028726 \t -191.0582179343833\n",
            "34     \t [-0.2692674   0.69980287 -4.60219563 -4.24882176 -2.1963052   3.71238021\n",
            " -4.72265848 -0.47821692]. \t  -401.5659493534647 \t -191.0582179343833\n",
            "35     \t [ 0.29260898 -1.95462677 -1.93021673 -4.94545715  2.0267832  -4.83143946\n",
            "  3.85492892 -4.581706  ]. \t  -549.289819905456 \t -191.0582179343833\n",
            "36     \t [-5.02624752 -4.03983005  1.77022235 -3.65302581 -4.98320367 -1.43275503\n",
            "  3.67992022  4.01325162]. \t  -480.80358409176483 \t -191.0582179343833\n",
            "37     \t [ 4.81184847 -3.20080873  3.4243377   2.86129584  1.66239788  4.79297587\n",
            "  3.93917396 -2.41689338]. \t  -418.57472920665367 \t -191.0582179343833\n",
            "38     \t [ 4.74060944 -4.55002044  2.39229664 -5.04267486  3.63437584 -2.80048352\n",
            "  3.76824039  2.41977236]. \t  -442.1018001511656 \t -191.0582179343833\n",
            "39     \t [-3.22776297  4.66903412  3.764177    4.85925712  4.24328969 -4.73428773\n",
            " -4.94018416 -1.36311683]. \t  -601.1858731887626 \t -191.0582179343833\n",
            "40     \t [-1.56107189  4.73608916  3.38338209  4.93434255  4.39420974  4.68085035\n",
            "  5.00333212  4.13617084]. \t  -719.1349512404149 \t -191.0582179343833\n",
            "41     \t [-4.20944551 -4.98340058  4.20767244  4.3011089  -2.0865909  -4.4023072\n",
            "  4.75294133 -4.76080048]. \t  -672.0057564315451 \t -191.0582179343833\n",
            "42     \t [ 4.79979357  5.02075769 -3.55108063  4.93308233  4.06133036 -0.25910152\n",
            "  3.0048378   1.59763566]. \t  -375.12345179147576 \t -191.0582179343833\n",
            "43     \t [ 3.69204317 -3.88662553  1.5005702  -1.42501752 -3.61714354 -4.96482451\n",
            "  0.05399708 -0.56001432]. \t  -274.5656006535746 \t -191.0582179343833\n",
            "44     \t [-1.61431691  4.73413395 -5.06756846 -0.65873898  3.50358606  4.72784949\n",
            "  4.97701508  1.02111674]. \t  -503.4336960931008 \t -191.0582179343833\n",
            "45     \t [ 4.8524643  -1.09078109 -2.93565676 -4.15683522 -5.00061335 -4.66919507\n",
            "  3.38886627  4.94233298]. \t  -652.5404846003503 \t -191.0582179343833\n",
            "46     \t [-4.55619073 -4.88533266  2.8835501   2.04793789  4.96933737  4.12387618\n",
            " -3.19172543  5.05361641]. \t  -611.3443929385479 \t -191.0582179343833\n",
            "47     \t [ 1.5875267  -4.74312032 -0.95572437 -1.25121447 -4.51280985  4.8546069\n",
            " -4.44557778  4.49588733]. \t  -599.7936679765157 \t -191.0582179343833\n",
            "48     \t [-4.89979311 -3.78944103 -3.77581581 -5.0404071  -4.73662212 -2.97582073\n",
            "  4.61483485 -4.64670004]. \t  -684.2433438248321 \t -191.0582179343833\n",
            "49     \t [ 2.6509622   2.05147806 -2.02853265 -0.18660687 -0.41503766  3.28984647\n",
            "  4.85354242 -4.92713214]. \t  -452.8398355736062 \t -191.0582179343833\n",
            "50     \t [-4.75331585  4.92708958  0.09097447  0.65961686  0.25679312  3.83298123\n",
            " -0.63751833  2.05100849]. \t  -197.889920012296 \t -191.0582179343833\n",
            "51     \t [-4.28477642 -5.09545514 -1.86415225 -2.51081229  4.81389849  4.87958306\n",
            " -4.75036814  0.30429046]. \t  -523.3613414716497 \t -191.0582179343833\n",
            "52     \t [-4.5724747  -3.33181191 -4.8435402  -3.64154014  4.84366719  0.51054166\n",
            "  2.94825444 -4.60232956]. \t  -515.6987741542582 \t -191.0582179343833\n",
            "53     \t [ 3.29613877  4.08546554 -2.66934118  4.2772238  -4.74192694  4.40117787\n",
            "  2.23634896 -0.62601005]. \t  -405.5967693094763 \t -191.0582179343833\n",
            "54     \t [ 1.76777638  0.49630876  3.82663489  4.5893272   4.60107009  4.86453391\n",
            " -1.87316052 -4.38726511]. \t  -558.172022947385 \t -191.0582179343833\n",
            "55     \t [-2.20307483 -3.51156687  4.34832505  4.63556707  4.13432756  1.55934023\n",
            "  4.14228716  3.60258704]. \t  -496.1849035777576 \t -191.0582179343833\n",
            "56     \t [ 5.08290252  4.36511966 -4.00083108 -0.78326439 -3.32865915  4.75748549\n",
            " -2.5964726  -4.93891905]. \t  -547.9553261837542 \t -191.0582179343833\n",
            "57     \t [-4.86223835  4.11480445 -4.03361029  4.68415899 -1.74162274 -0.50988698\n",
            "  3.52825822  1.6755816 ]. \t  -320.4070003456024 \t -191.0582179343833\n",
            "58     \t [-4.68969889  4.90087992 -2.36252947 -3.18017888 -4.843878   -0.07787627\n",
            " -1.88053165  5.09961213]. \t  -477.3846150251172 \t -191.0582179343833\n",
            "59     \t [-2.94970845  0.15630389 -0.72982906  4.95858385 -5.06821455 -0.53350248\n",
            " -5.10803282  4.92698718]. \t  -615.6851676703075 \t -191.0582179343833\n",
            "60     \t [-1.72602461  3.1679381   4.33417155  3.6566972   0.14099963 -0.02416334\n",
            "  4.1639942  -0.90028428]. \t  -260.85062731090017 \t -191.0582179343833\n",
            "61     \t [ 3.48915086 -3.60074657 -4.68755583 -0.56433558  0.23797678 -1.57872422\n",
            " -4.68908436 -3.92549255]. \t  -397.72426732171 \t -191.0582179343833\n",
            "62     \t [ 4.36974974 -3.91289319 -1.23660917  3.42772249  2.19450343  2.37365739\n",
            " -4.25588683  2.9814841 ]. \t  -357.0876226226869 \t -191.0582179343833\n",
            "63     \t [-4.24046438  4.87577054 -2.58014623 -5.01426782 -1.00066227 -4.01545766\n",
            " -4.71859715 -4.05197085]. \t  -575.0246875750993 \t -191.0582179343833\n",
            "64     \t [ 4.64325518  3.96966383 -3.51804159 -3.16128847  1.45262683  1.20989679\n",
            " -1.25043366  1.28299436]. \t  \u001b[92m-173.62852098705426\u001b[0m \t -173.62852098705426\n",
            "65     \t [ 4.18916099  3.85473733  3.29768532 -4.74723431  2.89372626  1.17163776\n",
            " -3.65628814  4.20414167]. \t  -455.11841652362136 \t -173.62852098705426\n",
            "66     \t [ 2.41946029 -0.98205835  4.6003541  -4.73394794 -0.40140595 -4.3740459\n",
            "  1.13281082 -4.84160103]. \t  -473.02441668950735 \t -173.62852098705426\n",
            "67     \t [ 2.140039   -4.92384601  2.57466777  3.10790339  5.09786777 -0.38736298\n",
            "  0.7588794  -1.25051046]. \t  -258.9743585446121 \t -173.62852098705426\n",
            "68     \t [ 4.06598628  4.46635191  3.94204828 -3.99736456 -4.47649155 -2.47398883\n",
            "  3.72131381  3.50462666]. \t  -499.07887740742575 \t -173.62852098705426\n",
            "69     \t [ 4.11383308  2.5783165  -2.07342353  4.94581647  3.4483146  -5.09645734\n",
            " -5.05164229 -2.10809241]. \t  -570.4444028645743 \t -173.62852098705426\n",
            "70     \t [-3.59534969  4.8415036   1.24745039  3.75808887 -4.87612531 -2.32278331\n",
            " -4.68231935 -4.34698174]. \t  -576.8619067590777 \t -173.62852098705426\n",
            "71     \t [-4.68591773  1.14449238 -4.04054027 -4.75288739  4.41167602 -2.5622146\n",
            " -4.20728797  3.98684871]. \t  -551.687895326086 \t -173.62852098705426\n",
            "72     \t [ 5.11152946 -4.54448561  4.15463199  3.31338844  0.06766195 -2.17177431\n",
            "  4.3553261   3.97917132]. \t  -450.90451124632006 \t -173.62852098705426\n",
            "73     \t [-4.10297094  5.00830379 -0.06069471 -4.82887512 -1.78573971  3.75998642\n",
            " -5.02769991 -3.32349246]. \t  -526.3622758595692 \t -173.62852098705426\n",
            "74     \t [-4.7681655   4.74840121 -4.66453838 -2.61918523 -3.70461734  0.04217504\n",
            "  4.17962119 -1.29868175]. \t  -364.95315842865625 \t -173.62852098705426\n",
            "75     \t [-3.71871206 -2.59753085  2.26417513  4.69995813  3.64196089  3.21862898\n",
            "  3.15308431 -4.08985515]. \t  -462.9467817034126 \t -173.62852098705426\n",
            "76     \t [ 0.86724561  4.96894966  2.37916651 -3.16159984  2.78789948 -3.65170472\n",
            "  4.4541649   1.14351575]. \t  -375.3069129526937 \t -173.62852098705426\n",
            "77     \t [ 5.00935226 -0.15347553  4.47117903 -3.18009349 -3.56039191  2.82445988\n",
            "  1.40288889 -3.7888984 ]. \t  -365.43710743378426 \t -173.62852098705426\n",
            "78     \t [-4.17073298 -3.2353763  -3.20516625  2.54236312 -1.95088476 -4.99177989\n",
            "  3.1301547   1.87351053]. \t  -360.20641411224955 \t -173.62852098705426\n",
            "79     \t [ 1.40513863 -0.71009465  4.77065305 -3.3210333   4.97069024 -3.54942179\n",
            " -4.72902512 -2.12981628]. \t  -507.3411902560285 \t -173.62852098705426\n",
            "80     \t [-3.44281932  0.4728572  -4.57652198  3.21976541 -1.45037667 -3.32095846\n",
            " -4.24816929 -4.87003198]. \t  -509.35825145494584 \t -173.62852098705426\n",
            "81     \t [-4.26281811  0.71797497  2.4453254  -4.32809659  1.85633409 -4.78144179\n",
            "  1.23902951  2.55644   ]. \t  -329.50356099438505 \t -173.62852098705426\n",
            "82     \t [-1.86185931  0.53847977  4.68238787 -1.7423629   4.84742974  1.07622139\n",
            "  3.7927127   4.52058903]. \t  -470.5799026628588 \t -173.62852098705426\n",
            "83     \t [-3.40424358 -4.14987295 -3.48858215 -3.55925436  2.00283605 -3.26543387\n",
            "  4.44046489  4.76174818]. \t  -536.6687247157872 \t -173.62852098705426\n",
            "84     \t [ 1.18055201 -1.44570549 -1.36678509  4.1512959  -5.10632288 -4.02983404\n",
            "  0.7870535   4.8349763 ]. \t  -499.27334706314207 \t -173.62852098705426\n",
            "85     \t [ 5.06442404  3.9815271  -2.07076608  3.35182065 -5.02913002 -4.45079047\n",
            " -4.16337219  2.05635147]. \t  -515.638815496925 \t -173.62852098705426\n",
            "86     \t [-4.00163005  0.15414118 -2.84566881  2.79845754 -0.66999146  4.15477504\n",
            " -0.09865423 -3.30448706]. \t  -264.92209626765 \t -173.62852098705426\n",
            "87     \t [ 1.93058749 -2.5673403  -2.60179451 -5.10191504  2.43372698  3.4549934\n",
            "  2.32887911  5.03132738]. \t  -483.05259159311487 \t -173.62852098705426\n",
            "88     \t [-3.88907623 -0.95819418  2.20794082  4.64960019 -2.29496074  4.70212619\n",
            "  3.37891588  5.06262807]. \t  -562.0166212882028 \t -173.62852098705426\n",
            "89     \t [-1.85338929  3.61981251 -4.2085258   3.62442214 -4.09086205  4.47006909\n",
            " -3.2587939   3.22195835]. \t  -496.2731052017592 \t -173.62852098705426\n",
            "90     \t [ 4.92101195  4.06602299 -4.58347651  3.41323696  0.46198733  0.59325597\n",
            " -4.33144188  1.41742561]. \t  -317.4883231370131 \t -173.62852098705426\n",
            "91     \t [-2.54773482 -1.5881116   2.8124679  -0.63003868  0.01383915 -4.2570645\n",
            " -4.60446495  1.15000816]. \t  -304.5772509162917 \t -173.62852098705426\n",
            "92     \t [-1.94766283 -4.92784991  4.20341389 -3.56089429 -1.10318314  3.65373713\n",
            " -3.30997206 -4.02096845]. \t  -448.30747621435455 \t -173.62852098705426\n",
            "93     \t [-4.77683813 -3.51218304  0.94640865  2.31477979  4.76610895 -3.48310409\n",
            " -1.3977521   3.81853545]. \t  -388.305669467196 \t -173.62852098705426\n",
            "94     \t [ 3.30616854  4.57954624 -3.82187127 -1.5666811  -3.10005237 -1.66445629\n",
            "  3.39464034  0.64490105]. \t  -255.17966884441225 \t -173.62852098705426\n",
            "95     \t [ 4.2779558   4.57701299 -0.99660674 -4.41183605  4.50069116  4.28887519\n",
            " -5.10948521 -4.45303617]. \t  -694.0677961428911 \t -173.62852098705426\n",
            "96     \t [-5.00858754 -2.85020759  3.91291268  4.3282538  -3.18933721 -3.29339993\n",
            " -0.19607556  4.1275604 ]. \t  -414.70251238968416 \t -173.62852098705426\n",
            "97     \t [-0.3592579   4.43275782 -2.50943328 -0.69578334  1.86484032 -4.98997926\n",
            "  4.91504317 -2.61769054]. \t  -450.96545457204775 \t -173.62852098705426\n",
            "98     \t [ 4.6055116   1.52867633 -3.60805644 -3.91829475  4.87084238  3.28438575\n",
            "  3.41808181 -2.36872969]. \t  -436.36948014866294 \t -173.62852098705426\n",
            "99     \t [-1.05024855  0.8254194   0.60115301 -2.40267957  3.13271809  4.18241771\n",
            " -4.79969851  4.95561324]. \t  -538.3911693280085 \t -173.62852098705426\n",
            "100    \t [-0.98893665 -5.06658453 -4.54670365  2.84057048  0.33118909 -0.65991211\n",
            "  4.99935428 -3.26460108]. \t  -409.98855728564286 \t -173.62852098705426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO3I_9cbuvY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69869239-307e-4314-e804-0544854e33bd"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 6 \r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_winner_6 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_6 = dGPGO_stp(surrogate_winner_6, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.02288795 -1.72052679  3.28938622 -4.69302655 -4.0175956   0.97333314\n",
            "  0.30532979 -0.83141193]. \t  -235.23441702954543 \t -201.94095626044867\n",
            "init   \t [-1.68542362  1.25459899 -0.6334318   2.41543277  0.18469286  0.80751207\n",
            "  1.48843618  5.01989654]. \t  -251.71565703551553 \t -201.94095626044867\n",
            "init   \t [ 3.27534794 -0.88882243  3.85298079  3.31529659 -4.56218104  2.2388453\n",
            "  3.09422656  2.42080403]. \t  -348.8531157616155 \t -201.94095626044867\n",
            "init   \t [ 2.14150913  0.41919339 -3.84180045  4.68630831 -0.9906555  -2.89842012\n",
            "  2.22490467  5.06068417]. \t  -431.90936813726233 \t -201.94095626044867\n",
            "init   \t [-2.50251207  1.75420858  1.01382055  2.22548117  4.47845923 -1.51746797\n",
            " -2.52278684 -0.99868151]. \t  -201.94095626044867 \t -201.94095626044867\n",
            "1      \t [ 2.52426974  2.29448261 -0.96145617  5.01124965 -0.50688737 -1.29220163\n",
            "  2.14659693 -4.27562441]. \t  -309.93117061486333 \t -201.94095626044867\n",
            "2      \t [-3.94122701 -1.28480828 -0.06578283  1.82165145 -4.4292268  -3.47715752\n",
            " -1.23572881 -0.31463601]. \t  -214.23651607250392 \t -201.94095626044867\n",
            "3      \t [ 0.68495272 -1.12020105 -3.91648579 -4.1522513   0.27697028 -5.06255741\n",
            " -5.11410257  2.94682699]. \t  -524.6693250717898 \t -201.94095626044867\n",
            "4      \t [-0.90292441 -3.62134384  4.06919975 -3.14648372  3.40643678 -2.96215879\n",
            "  1.00052604  4.46507807]. \t  -393.48824400615496 \t -201.94095626044867\n",
            "5      \t [ 5.09872913 -2.35067757 -0.29347515 -4.52301675  4.73557543  2.06098602\n",
            " -0.24839256 -3.81236264]. \t  -373.4566300664054 \t -201.94095626044867\n",
            "6      \t [ 0.45041751  3.04462334 -4.19217931  4.07489457 -5.03627391  4.82675639\n",
            " -0.2109413  -1.32181192]. \t  -418.7792092236846 \t -201.94095626044867\n",
            "7      \t [-2.11122647  4.196848   -4.11257499 -2.91251049  3.32078439  3.28306277\n",
            " -4.12634234 -4.06027961]. \t  -495.23795573777846 \t -201.94095626044867\n",
            "8      \t [-4.02575353 -4.96908952 -0.40750639 -2.03711785 -1.54320181  1.65082713\n",
            " -2.76294025 -4.25624588]. \t  -309.3086180204047 \t -201.94095626044867\n",
            "9      \t [-0.5220839   0.75282282 -0.28521409 -3.93954765 -0.48379025 -1.79345543\n",
            "  3.41275848 -2.37433235]. \t  -210.82747497940244 \t -201.94095626044867\n",
            "10     \t [ 3.77435274  4.98323978 -3.49673487 -3.990752    2.02207512 -3.27932022\n",
            " -0.41758247  3.92423945]. \t  -373.6824197676583 \t -201.94095626044867\n",
            "11     \t [ 3.99531502 -3.58048569  1.96690361  1.16346462 -1.10982483 -4.267787\n",
            " -2.30004731 -1.32578776]. \t  -225.15884706627827 \t -201.94095626044867\n",
            "12     \t [-3.95614005 -1.82630411  3.2894209   2.29458665  3.66795106  4.40217692\n",
            "  4.1171064  -0.32397013]. \t  -378.8811018683255 \t -201.94095626044867\n",
            "13     \t [-3.1345121   0.2108516   2.07787827  2.94367407 -4.57786845  4.80300532\n",
            " -3.8471932  -1.32359046]. \t  -418.34664535781764 \t -201.94095626044867\n",
            "14     \t [-2.76675299 -3.93643419  4.01358587  1.54257244  4.26124832 -3.99666206\n",
            "  5.01236591 -1.33903159]. \t  -473.3324447138828 \t -201.94095626044867\n",
            "15     \t [ 3.71115089  4.88449954  4.86593922 -0.34742123  3.78051598 -2.92503548\n",
            " -0.40306706  0.63080169]. \t  -260.12124002026013 \t -201.94095626044867\n",
            "16     \t [ 4.17230617  4.56538953  3.52021908  1.42713737  1.79238904  4.17390386\n",
            " -2.22027985  4.10130806]. \t  -394.0818666384531 \t -201.94095626044867\n",
            "17     \t [-4.56387674 -3.20198508 -4.55585105 -2.69468356 -3.85926296 -4.56771792\n",
            "  4.81769501  0.62638462]. \t  -497.91099533054893 \t -201.94095626044867\n",
            "18     \t [ 4.25200079  0.70000068 -2.09788821  4.13285436  2.93854952  4.03963069\n",
            " -0.06127428  0.42003816]. \t  -243.109659486015 \t -201.94095626044867\n",
            "19     \t [ 0.54575391 -3.23351063 -3.92657205 -0.5773002  -4.78939184  3.40671317\n",
            "  3.95685153  3.91689223]. \t  -485.45465051868956 \t -201.94095626044867\n",
            "20     \t [-4.23605526 -2.65968545 -0.83089317 -4.19508899  3.97311989 -3.58432764\n",
            " -2.76903821 -1.73244557]. \t  -338.2550395272175 \t -201.94095626044867\n",
            "21     \t [ 2.00370321  4.13292603 -3.27630669 -3.03364926 -4.98552393 -3.95125077\n",
            " -0.87041597 -5.03171945]. \t  -532.9921620596438 \t -201.94095626044867\n",
            "22     \t [ 3.63057067  5.09175315  2.89282827  1.2451723  -4.17606128  3.45800414\n",
            " -2.36766439 -3.03858459]. \t  -368.3891342644322 \t -201.94095626044867\n",
            "23     \t [-2.99285463  4.89004464 -4.14736381  1.63531653 -1.02582249 -3.18020611\n",
            "  1.22300577 -0.96460926]. \t  -202.9389664882809 \t -201.94095626044867\n",
            "24     \t [ 1.97817465 -4.26379397 -0.54707974  3.86950893  5.01785132  3.9385706\n",
            " -5.06423416  4.01436762]. \t  -628.4779811146475 \t -201.94095626044867\n",
            "25     \t [ 4.60662539 -1.94082734 -0.15109054 -4.54801916  0.86927317 -4.84794494\n",
            "  4.6319442   4.09292825]. \t  -540.5554598762884 \t -201.94095626044867\n",
            "26     \t [ 0.25519007  3.0398217  -4.39485852 -5.03425222 -4.85087814  3.51537753\n",
            " -2.39627714  0.1206302 ]. \t  -409.9790707661819 \t -201.94095626044867\n",
            "27     \t [-3.96623945 -2.99895654 -4.66033129  3.66704938  4.69098038 -3.56871389\n",
            "  1.88566403  2.22674951]. \t  -403.6618101958919 \t -201.94095626044867\n",
            "28     \t [-2.86835684  4.2467735   2.9686474  -2.74568179 -1.64676889  3.3467584\n",
            " -2.80135771  3.07291994]. \t  -312.13123747340046 \t -201.94095626044867\n",
            "29     \t [ 2.65579224 -3.79455128 -1.78059187 -2.98287746 -4.08668447  4.79673836\n",
            "  4.66548265 -4.54962878]. \t  -620.4694434095638 \t -201.94095626044867\n",
            "30     \t [ 3.80549638 -4.22299587 -2.69089808 -2.29708295 -5.06128381 -0.70057014\n",
            " -3.10742611  4.58548119]. \t  -459.81188997840184 \t -201.94095626044867\n",
            "31     \t [ 0.14634926 -2.06456099 -4.90785654 -0.01793042  4.83270851  5.08476265\n",
            "  4.91815996  2.70246242]. \t  -580.4574268126146 \t -201.94095626044867\n",
            "32     \t [ 5.02618098 -5.03950621 -1.23563017  2.82856811 -4.45974558 -1.50935312\n",
            "  3.8237266  -3.88410221]. \t  -448.79100681499756 \t -201.94095626044867\n",
            "33     \t [-4.66881773 -3.05954571  0.70295383 -3.69521032 -4.09625287  1.19848195\n",
            "  1.21160741  5.10139258]. \t  -407.6044373905495 \t -201.94095626044867\n",
            "34     \t [-4.66752203 -3.03642653  2.63642488 -1.06583092  1.09162812  3.32908351\n",
            " -4.53918332  2.7463483 ]. \t  -342.6454948330666 \t -201.94095626044867\n",
            "35     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -201.94095626044867\n",
            "36     \t [ 0.69598124  2.35116678  4.59945961 -1.03104698  4.93035907  4.75792977\n",
            " -0.40864942 -4.93658695]. \t  -532.755341580188 \t -201.94095626044867\n",
            "37     \t [-2.63497992  4.42317251  4.84140556  0.87488415 -3.48791417  0.82214399\n",
            "  2.87472942 -2.79925835]. \t  -304.86985563733424 \t -201.94095626044867\n",
            "38     \t [ 4.7809176   4.85716429 -1.46094173  0.23043945 -4.51673537 -1.48175045\n",
            "  5.07248688  3.62474717]. \t  -477.05592086615604 \t -201.94095626044867\n",
            "39     \t [-2.47521342  4.9223336  -0.15387365 -2.05770095  3.76132609  4.12386583\n",
            "  4.78240876  1.85681033]. \t  -432.0504592472265 \t -201.94095626044867\n",
            "41     \t [ 2.34419325 -2.58938329 -4.79950682  3.81781484  4.074271   -2.83466997\n",
            " -0.97716116 -5.08286506]. \t  -490.8922805854277 \t -201.94095626044867\n",
            "42     \t [-0.77706953  0.57346829  4.64504518 -4.62283284  0.08998787 -1.15923183\n",
            " -3.31953736 -4.8409366 ]. \t  -424.1892714802641 \t -201.94095626044867\n",
            "43     \t [-3.42275664  0.99947328  4.54787952 -2.40793041 -1.58682069 -4.98880476\n",
            " -5.04867591  3.76954684]. \t  -552.9740996542266 \t -201.94095626044867\n",
            "44     \t [-2.78130098 -1.82487267 -4.10677486  4.16440431  4.46714524  4.97502839\n",
            " -2.76751759 -4.56570212]. \t  -603.023347909906 \t -201.94095626044867\n",
            "45     \t [ 4.4023833   1.41982497  5.0712333   3.4916585  -4.19584593 -4.52720175\n",
            " -3.23364999  3.1809066 ]. \t  -514.4714517868024 \t -201.94095626044867\n",
            "46     \t [ 1.41090861 -2.99477686  4.96506113 -3.47021556  3.29478872  3.57904554\n",
            " -1.70381049  1.70387818]. \t  -316.73508345349654 \t -201.94095626044867\n",
            "47     \t [ 4.4674594  -4.27943278  2.65565182  0.16684449  2.08075381  5.02953565\n",
            " -4.68255655 -3.69255261]. \t  -513.8430555261292 \t -201.94095626044867\n",
            "48     \t [ 3.7950955  -2.69880016 -4.32087891  0.87137513 -4.62925187 -4.65746855\n",
            " -5.02087267 -3.3722601 ]. \t  -592.7601433322355 \t -201.94095626044867\n",
            "49     \t [-0.8123768  -4.57748115  3.98424108 -0.85055219 -4.57191675 -2.47452797\n",
            "  3.85258189 -0.98655242]. \t  -346.017751993515 \t -201.94095626044867\n",
            "50     \t [-4.37587759 -4.81822519 -3.55354893 -0.84700546  4.56240886 -0.57439845\n",
            " -4.5451285   4.3637713 ]. \t  -509.336521111346 \t -201.94095626044867\n",
            "51     \t [ 4.77910886  3.43067727 -3.56089759 -4.61425713  3.71763172 -4.02739614\n",
            "  0.51639583 -4.51051571]. \t  -500.63253957880374 \t -201.94095626044867\n",
            "52     \t [-4.43185652 -0.96065993 -4.72447841  2.69647693 -1.71463762  4.80425211\n",
            "  4.23442693 -2.56902159]. \t  -449.0296439805894 \t -201.94095626044867\n",
            "53     \t [-4.84909306  3.4685975   3.4283115  -1.35676768 -3.35045081 -4.78513302\n",
            "  4.48208227  5.01870913]. \t  -625.834826718722 \t -201.94095626044867\n",
            "54     \t [-4.70755833  4.68376899  3.34440707  2.70833139  4.80849407 -4.62862094\n",
            "  4.76047642  0.91334178]. \t  -538.3932638980172 \t -201.94095626044867\n",
            "55     \t [-4.79595836 -0.42465077  4.86071446  2.70516409 -4.6917784   4.06462917\n",
            "  2.66102057  3.34863657]. \t  -471.97849167004233 \t -201.94095626044867\n",
            "56     \t [-3.8492514  -4.18835154  3.88923564  1.99254383 -0.52256147 -4.71312547\n",
            " -4.99013036 -2.87789626]. \t  -486.37546336795276 \t -201.94095626044867\n",
            "57     \t [ 4.04074732  4.65603792 -3.20689399  3.55176059  1.53926443 -0.67254524\n",
            " -4.36407208 -0.90242598]. \t  -295.3889723102313 \t -201.94095626044867\n",
            "58     \t [ 3.20332175 -4.66802727 -5.02378842  3.54051142  2.38033248 -4.34803865\n",
            " -3.16828924  3.86409112]. \t  -511.1770147373011 \t -201.94095626044867\n",
            "59     \t [ 4.73238204 -3.89230501  4.22077422  0.61051912  2.69974875 -0.91037577\n",
            "  3.77039793 -4.84217301]. \t  -436.13159571622015 \t -201.94095626044867\n",
            "60     \t [ 4.12051485  1.59677285  4.34220831  4.93786796  2.22550734  0.66034189\n",
            " -4.58921224 -3.64584315]. \t  -457.31667330480104 \t -201.94095626044867\n",
            "61     \t [ 0.35361398  3.1603411   3.30741707  3.64846434 -5.03012251 -3.44420619\n",
            " -2.63782166 -4.27290449]. \t  -498.61716961688614 \t -201.94095626044867\n",
            "62     \t [-1.14957354  3.00001648 -2.40781622  1.99382562 -4.50932934 -3.11645633\n",
            " -4.51493768  4.70863473]. \t  -532.6224363066291 \t -201.94095626044867\n",
            "63     \t [-2.58401064 -4.91267269 -0.72056171 -4.35872222  4.35616047  1.2179887\n",
            "  4.93626529  0.43879175]. \t  -408.38624189617514 \t -201.94095626044867\n",
            "64     \t [ 4.73054265  4.79953221 -3.18707664 -1.61677165 -0.32389003  4.98354514\n",
            "  1.96229437 -3.75614449]. \t  -398.7392497348468 \t -201.94095626044867\n",
            "65     \t [ 2.91474854  2.09341135  3.0936606  -4.4903181  -3.7833668   1.88863194\n",
            "  4.92782527  4.84931281]. \t  -577.706351874046 \t -201.94095626044867\n",
            "66     \t [-2.35153181  4.92304191 -2.70603984  3.88806167  0.25382464  4.45325428\n",
            " -4.1707243   3.97869145]. \t  -504.15388414129694 \t -201.94095626044867\n",
            "67     \t [ 3.23872017  4.25593552  2.98637873 -3.1236205  -2.53189553 -1.50438347\n",
            " -4.17948267  2.1859835 ]. \t  -318.63488730949587 \t -201.94095626044867\n",
            "68     \t [-2.17376716  2.45568279 -1.49678834 -4.03236497  4.72428129 -2.49895385\n",
            "  1.87343888  4.45561843]. \t  -420.9985028122717 \t -201.94095626044867\n",
            "69     \t [ 4.52063879 -3.6777116  -4.58228747 -4.9383294   4.1665882  -4.01883004\n",
            "  1.42304774 -3.50581322]. \t  -504.2372853664855 \t -201.94095626044867\n",
            "70     \t [ 2.59990166 -0.00805865 -4.04097511 -3.09520801  4.61958196  3.57939769\n",
            " -2.2641579   2.06292982]. \t  -347.5748357006736 \t -201.94095626044867\n",
            "71     \t [ 1.21879223 -4.65847947  3.59669848  2.64395826 -3.01523956  2.35444499\n",
            " -4.38558388  3.60662671]. \t  -429.0733843579837 \t -201.94095626044867\n",
            "72     \t [-4.70585529  3.16963131  4.86156986  4.10257066  3.9353486   3.94809015\n",
            " -3.88542803  4.42440463]. \t  -613.7051734001443 \t -201.94095626044867\n",
            "73     \t [-4.71586785  4.71074574  1.0241047  -3.67229148  4.22712815 -4.42280051\n",
            " -0.56951313 -1.89333434]. \t  -361.3691145742728 \t -201.94095626044867\n",
            "74     \t [ 4.79203044  0.5174298  -5.01097843 -1.96781608 -1.53520717  4.41260813\n",
            " -3.92193792 -3.1492137 ]. \t  -429.94046086454193 \t -201.94095626044867\n",
            "75     \t [-3.08762359  1.63275427 -1.96213633 -1.824533   -1.20999919 -3.94941144\n",
            " -4.69265139 -4.0357629 ]. \t  -425.0843032002855 \t -201.94095626044867\n",
            "76     \t [-1.52497469 -3.56122437 -4.41562008  4.02069266 -1.23421475  3.94492871\n",
            " -2.1542727   1.929761  ]. \t  -314.11642711638456 \t -201.94095626044867\n",
            "77     \t [ 0.66257973 -0.12265418  4.83875086  4.64730637  3.98380109 -4.00420977\n",
            " -2.11200177  4.05721356]. \t  -495.5667024125798 \t -201.94095626044867\n",
            "78     \t [ 4.77257672  4.51656878  1.06052983 -4.74305543  3.3764958  -0.3399351\n",
            "  4.3032592   0.03621777]. \t  -344.27047212636893 \t -201.94095626044867\n",
            "79     \t [ 3.97189133 -0.02252986 -5.07009295  3.72730509 -4.5307161   4.00162819\n",
            "  4.70299561 -5.05941675]. \t  -706.7895436207211 \t -201.94095626044867\n",
            "80     \t [-3.85446418 -4.43488512 -4.91953805  4.70462497 -4.4971218  -1.97038022\n",
            " -4.93829975  0.06810263]. \t  -510.49250096232976 \t -201.94095626044867\n",
            "81     \t [ 2.91407641 -3.73645161 -4.86003853 -3.93449335 -5.0031679  -2.05067102\n",
            "  0.65506112 -2.04331504]. \t  -355.98963917292383 \t -201.94095626044867\n",
            "82     \t [ 3.67779097  1.85861639  2.40675132  1.9564615  -0.36521735  4.21253539\n",
            "  5.05464309 -2.9300103 ]. \t  -407.78862345500505 \t -201.94095626044867\n",
            "83     \t [ 3.95921476  3.78974623 -3.88386858  4.86035848  4.97629056  2.08739476\n",
            "  4.87012373  4.27359275]. \t  -646.2415136288151 \t -201.94095626044867\n",
            "84     \t [-4.87081112  3.41642138 -4.20189672 -3.01535029 -0.05319311 -0.48306095\n",
            " -5.0993754   4.40178068]. \t  -474.8508551224811 \t -201.94095626044867\n",
            "85     \t [ 3.70616483 -4.57031988  2.40247671 -5.06454333  2.20504146  1.50356455\n",
            "  4.22853953  0.1983231 ]. \t  -338.77914465019876 \t -201.94095626044867\n",
            "86     \t [-3.80746109 -0.08234086 -2.12126581 -1.18038434  4.77066333  3.94944148\n",
            "  1.61294058 -4.35779411]. \t  -411.10152243251787 \t -201.94095626044867\n",
            "87     \t [-2.61675728  3.14677277 -2.51751176 -3.2091597  -3.370003    4.31302528\n",
            "  2.91191914  4.49494411]. \t  -476.2490121977595 \t -201.94095626044867\n",
            "88     \t [ 2.49939687  1.39269801 -2.05903653  1.35194748  4.90449717 -2.3518859\n",
            " -2.43354099  3.4459549 ]. \t  -320.06650211932583 \t -201.94095626044867\n",
            "89     \t [ 4.22259468 -2.83598205 -1.50754317 -4.99208909 -2.13536382  4.62939024\n",
            "  1.21342091  4.44230188]. \t  -459.9832842230943 \t -201.94095626044867\n",
            "90     \t [ 0.71970663 -3.27004724  4.93178637  5.0992878  -0.07707758  2.56475615\n",
            "  1.80090446 -2.09782304]. \t  -296.2901297747634 \t -201.94095626044867\n",
            "91     \t [ 1.80967715 -4.54807272  2.91962555 -3.16825974  5.05417353 -4.49001033\n",
            " -1.56779356 -4.86893241]. \t  -565.9113475035783 \t -201.94095626044867\n",
            "92     \t [ 4.65106996  1.90351949 -3.64110133 -4.97788517 -2.0321667   0.739978\n",
            "  3.07791763  1.31278812]. \t  -271.8056961711212 \t -201.94095626044867\n",
            "93     \t [ 3.7694746   2.41452037  2.54899197 -0.99417258 -3.67339224 -3.89522551\n",
            "  1.45735294 -1.82093328]. \t  -249.21362344295426 \t -201.94095626044867\n",
            "94     \t [ 4.30553668e+00  1.65692231e+00 -8.25985640e-01  7.65936988e-01\n",
            "  3.25469570e+00 -4.75192349e+00  3.97413237e+00 -1.20297819e-03]. \t  -327.4278140669287 \t -201.94095626044867\n",
            "95     \t [ 4.88321548e+00  2.11082720e+00  2.86612550e+00 -3.81288722e+00\n",
            " -5.13143691e-04  3.53130728e+00 -4.00532534e+00 -3.87715958e+00]. \t  -422.9315748761056 \t -201.94095626044867\n",
            "96     \t [-4.93617467 -2.42349748 -2.86988061  0.72466178  1.82210371 -2.43451068\n",
            "  4.3913794  -4.59090592]. \t  -418.6838753615629 \t -201.94095626044867\n",
            "97     \t [ 4.05952523 -4.3517118  -1.21191198  3.34306847 -2.91935597  2.13781569\n",
            " -2.13771605 -2.25543717]. \t  -246.18467121133838 \t -201.94095626044867\n",
            "98     \t [ 1.88654905 -4.89218591 -4.1647959  -3.97155521 -3.95292504  3.51914773\n",
            " -5.08775419 -0.30625694]. \t  -500.9371428324554 \t -201.94095626044867\n",
            "99     \t [ 1.07160039 -1.48273168 -4.75353372  1.92075821 -3.36301496 -5.01524545\n",
            "  3.41052915 -1.65378591]. \t  -398.8583065035865 \t -201.94095626044867\n",
            "100    \t [ 2.20572253  1.47282368 -4.25738952  0.75558549 -4.57969171  4.31654696\n",
            " -4.61154039  4.34245131]. \t  -582.2459125705428 \t -201.94095626044867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rQbLZD8uvbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a8dc4d-0158-4829-f7a2-4f33fac33b5b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 7 \r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_winner_7 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_7 = dGPGO_stp(surrogate_winner_7, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.55672335 -2.02386832 -4.48474711 -0.4110301   3.43299466  4.37244977\n",
            "  2.3243672   2.74940131]. \t  -353.7866241526368 \t -217.44194749723354\n",
            "init   \t [-2.36334012  1.47485995 -4.16385785 -4.30401653  0.91764484 -1.60419289\n",
            "  5.00609176  1.29508563]. \t  -344.5427966394509 \t -217.44194749723354\n",
            "init   \t [ 1.86141982  0.53510977 -2.36687301 -1.29782388 -2.83721627 -3.21082777\n",
            " -1.11976352 -3.14201697]. \t  -217.44194749723354 \t -217.44194749723354\n",
            "init   \t [ 1.13572794  3.9199585   1.25274956 -2.52806201 -3.27751366  3.23998177\n",
            " -2.8121946   0.17261711]. \t  -234.58737464459995 \t -217.44194749723354\n",
            "init   \t [ 0.18939719  1.02783934  0.33403374 -4.98370509  0.24675597  4.05385947\n",
            "  2.76378925 -3.86199863]. \t  -373.52986721661773 \t -217.44194749723354\n",
            "1      \t [-2.09026361  1.14712145  2.31565437 -0.3737859   2.75569016 -3.15769824\n",
            "  0.59255523  0.51996833]. \t  \u001b[92m-126.06288515837247\u001b[0m \t -126.06288515837247\n",
            "2      \t [-2.77132335  2.78280017  3.5921294   1.30892452  1.16014877  3.12561108\n",
            " -4.17745349 -3.70084057]. \t  -365.80548531515143 \t -126.06288515837247\n",
            "3      \t [-2.04716979  0.31652053 -3.72902456  3.97315929 -2.23037105  2.56657632\n",
            " -1.88076485 -4.88687095]. \t  -389.461781652991 \t -126.06288515837247\n",
            "4      \t [ 4.73629479 -1.34734679  2.20127751  3.52547737 -0.84747307  4.29069522\n",
            " -4.71170392  4.35685033]. \t  -511.6256870588915 \t -126.06288515837247\n",
            "5      \t [ 4.70555877  0.09158045 -3.80239688 -3.84226126 -4.1888473   2.12306748\n",
            "  3.79858017  1.96157841]. \t  -371.14910893749106 \t -126.06288515837247\n",
            "6      \t [ 2.58353174 -3.44591239  2.87539993 -2.74276789 -4.74115027  3.49936458\n",
            " -0.24675933 -3.53338977]. \t  -371.4889591476506 \t -126.06288515837247\n",
            "7      \t [ 4.2191701  -1.22543815 -1.43787317  3.87431541  0.42985254  4.87494941\n",
            "  2.89026166 -1.37831396]. \t  -304.2364498186564 \t -126.06288515837247\n",
            "8      \t [-2.6600479   2.89274771  1.13621044  4.9732926  -3.75084849 -5.00845225\n",
            "  1.62226294  3.98195246]. \t  -492.74092119813184 \t -126.06288515837247\n",
            "9      \t [-1.86553537  2.66611528  5.03500594  3.91408686  2.6018486   4.63137625\n",
            " -3.94379584  4.80278023]. \t  -610.9849412618994 \t -126.06288515837247\n",
            "10     \t [ 4.60306575 -0.86214225 -2.57311838  3.23890485 -1.01386668 -2.82458863\n",
            " -5.09984632  2.247192  ]. \t  -359.967062494124 \t -126.06288515837247\n",
            "11     \t [ 3.80241898 -4.76561259  3.75477373 -2.31697124  1.95612299 -4.8590656\n",
            "  3.87732368 -4.51857722]. \t  -553.0199071382995 \t -126.06288515837247\n",
            "12     \t [-4.93082189 -1.08547738  3.13985151  4.61447679 -1.12473443  1.83139203\n",
            "  3.52783216 -3.01896669]. \t  -327.9007090938635 \t -126.06288515837247\n",
            "13     \t [ 1.7461318  -2.45949147  4.40613061 -2.30600072  2.12929998 -1.95787066\n",
            " -4.87046649 -4.48206055]. \t  -467.0898688357513 \t -126.06288515837247\n",
            "14     \t [-4.40171168 -1.11412631 -3.22530876 -1.7132166  -2.74314755  3.76632665\n",
            " -4.04957011  4.49552755]. \t  -464.01277583428526 \t -126.06288515837247\n",
            "15     \t [ 3.95149817 -4.99450645 -4.51563062  0.26401164  2.01242039  1.53796201\n",
            " -0.35519101  4.30213569]. \t  -310.3473339324236 \t -126.06288515837247\n",
            "16     \t [-4.96923967  4.99129873 -1.28023331  1.75054141 -4.49069478 -0.76332902\n",
            "  4.33546104 -1.12845537]. \t  -337.78261614799845 \t -126.06288515837247\n",
            "17     \t [ 2.69256065 -1.9398923   2.84667753 -3.75022658  4.1868755   3.60686974\n",
            " -0.27868981  1.28807656]. \t  -274.86725769757334 \t -126.06288515837247\n",
            "18     \t [-1.21951511 -2.03118811  4.33393671  3.06502757 -4.39819052 -4.34326947\n",
            " -1.95456176 -1.94162451]. \t  -370.4710305353688 \t -126.06288515837247\n",
            "19     \t [-2.27923894  2.20303333 -3.01467044  4.97230378  2.28001386 -0.86151641\n",
            " -3.6102985   0.80637159]. \t  -267.94882234757625 \t -126.06288515837247\n",
            "20     \t [-3.45448926 -5.00989258  0.54952793  0.38096008 -4.67757689  1.92084015\n",
            "  1.67247731  3.06164417]. \t  -289.7239801893493 \t -126.06288515837247\n",
            "21     \t [ 4.25336166  2.46305363  2.67184226 -3.54293445 -3.18890695 -4.53677349\n",
            "  4.10565568  2.02538722]. \t  -427.0020401928008 \t -126.06288515837247\n",
            "22     \t [-2.63581843 -3.62079279 -3.88375603  0.07771112  2.87557256 -3.645255\n",
            " -4.48467444 -1.25275775]. \t  -352.85590014194344 \t -126.06288515837247\n",
            "23     \t [1.05039904 4.66273077 2.03364616 4.75044165 3.63891332 0.4328576\n",
            " 4.28238984 1.22631228]. \t  -354.99480686323244 \t -126.06288515837247\n",
            "24     \t [ 4.05284164 -4.31037185  2.15113932  2.40843626  4.73316376  1.84123356\n",
            " -0.89876593 -4.84290016]. \t  -416.30755713193236 \t -126.06288515837247\n",
            "25     \t [ 0.03323401 -1.886043    2.7243448   2.9828653   1.61356878  4.25294709\n",
            "  3.81149627  4.44114933]. \t  -445.9978865567899 \t -126.06288515837247\n",
            "26     \t [-5.10701977  1.47556477  1.13670088 -2.04804195 -4.04906564 -3.58772175\n",
            " -2.42256455  5.09435125]. \t  -458.9966008489413 \t -126.06288515837247\n",
            "27     \t [ 1.87064481  2.42930953 -4.25997183 -4.91930109  3.25242741  0.17750408\n",
            " -3.59930004 -2.44735996]. \t  -358.22433282920497 \t -126.06288515837247\n",
            "28     \t [-3.10149942 -5.07452958  3.98010691 -3.87285606  3.97064846 -2.597216\n",
            "  2.31167769  4.05772526]. \t  -457.072291034935 \t -126.06288515837247\n",
            "29     \t [ 3.68326311  4.55968167 -4.5736574  -0.98126348 -2.99660492  4.69874449\n",
            "  1.74610742 -4.79597777]. \t  -504.47522330634047 \t -126.06288515837247\n",
            "30     \t [ 3.99515401 -4.78254379  4.09825936  4.99548924 -2.74411234  1.01087865\n",
            "  4.38532494 -1.79011574]. \t  -415.94920127977787 \t -126.06288515837247\n",
            "31     \t [ 4.64173782  4.96859652  4.7186859   3.6092204  -2.0324803   4.33091044\n",
            "  3.43533884 -2.28926625]. \t  -447.5558925904345 \t -126.06288515837247\n",
            "32     \t [ 2.65139413  3.89610846 -2.9323788  -2.73474102  4.73353731  3.69909997\n",
            "  2.7024882   2.2047559 ]. \t  -377.2445899105666 \t -126.06288515837247\n",
            "33     \t [-2.34094661  4.17174297  3.70025933 -3.78903297 -1.82357812 -4.62154501\n",
            "  1.69358525 -4.48697419]. \t  -464.71012181882406 \t -126.06288515837247\n",
            "34     \t [ 3.43631647  4.35642386  4.47201376 -1.5853213   4.5943724  -0.36566146\n",
            "  3.5052201  -3.7994702 ]. \t  -427.65212876938966 \t -126.06288515837247\n",
            "35     \t [ 4.5643842   4.45895676 -2.34073508  4.44726022 -4.93999175  2.95208387\n",
            " -3.17935933  0.80221201]. \t  -406.36083064806195 \t -126.06288515837247\n",
            "36     \t [-3.53954541 -2.75495426 -5.0683635  -2.08516532 -4.12205083 -4.08116069\n",
            "  4.53156256 -4.92445819]. \t  -644.8039844205746 \t -126.06288515837247\n",
            "37     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -126.06288515837247\n",
            "38     \t [ 5.00230362  4.09110748 -2.02957307  4.39941308 -3.17229587 -2.63704487\n",
            "  3.95529785  0.95851769]. \t  -357.1762611862563 \t -126.06288515837247\n",
            "39     \t [ 3.0995157  -4.83564712  4.15973834  3.50015101  0.35509117 -2.32759569\n",
            "  0.07507951  4.57726695]. \t  -358.0755603492908 \t -126.06288515837247\n",
            "40     \t [-1.90216518 -4.58793786  3.43351834  4.77534389  4.36060203 -5.10199873\n",
            "  0.41428472 -4.75653506]. \t  -605.7543869809473 \t -126.06288515837247\n",
            "41     \t [ 3.71783018 -3.62494958 -3.89301902 -4.96338463  3.5554692  -4.73447431\n",
            "  3.14442446  4.81580369]. \t  -636.5561656707883 \t -126.06288515837247\n",
            "42     \t [ 2.96277758 -4.9577632   5.10105274 -3.95046221 -1.43448137  0.2750817\n",
            " -3.01312437  2.84171213]. \t  -337.32146236900843 \t -126.06288515837247\n",
            "43     \t [ 4.97129733 -1.68083118 -4.87817699 -4.86671673 -0.5994676  -3.81803964\n",
            " -5.10673473  3.38359304]. \t  -559.8959023006187 \t -126.06288515837247\n",
            "44     \t [-0.50078351 -2.22531238 -4.46094076  4.69651531 -3.02637369 -0.59730044\n",
            " -0.23668083  4.93618067]. \t  -401.3382732843859 \t -126.06288515837247\n",
            "45     \t [ 2.89943149  4.64452358  3.01393853 -2.60316434 -2.67524034  3.7945639\n",
            "  3.47473944  4.78138189]. \t  -495.4936829218551 \t -126.06288515837247\n",
            "46     \t [ 2.48184377  4.66551143 -4.9596751  -3.43903238 -4.35518841 -3.3123188\n",
            " -0.54239038  3.58194976]. \t  -436.1657379088569 \t -126.06288515837247\n",
            "47     \t [ 0.42868626 -4.43440816  3.13376214  4.4497962  -2.10217488  2.93624091\n",
            " -3.97224456 -1.9831291 ]. \t  -363.91412007488555 \t -126.06288515837247\n",
            "48     \t [ 4.21150889  0.28202685 -4.01893912 -1.33491183  3.74505961 -4.06734304\n",
            "  5.06287509 -4.72729127]. \t  -601.0736835117809 \t -126.06288515837247\n",
            "49     \t [-5.10967541  4.77305343 -3.14184773  4.37620497  2.03782674  0.38391348\n",
            "  4.49697512  3.45332119]. \t  -436.5021035820354 \t -126.06288515837247\n",
            "50     \t [-5.02747264 -3.43902494  2.44400116 -4.87855574  2.76020865  2.27130212\n",
            " -3.52343374 -4.63672331]. \t  -489.99227602566975 \t -126.06288515837247\n",
            "51     \t [-2.87478737 -3.54298003 -2.94219292  3.88298964  4.43799071  0.67268619\n",
            "  2.21413185 -4.01125916]. \t  -383.8818564821524 \t -126.06288515837247\n",
            "52     \t [ 4.68689869  1.69719471  1.2884125  -2.16678499  4.34998118 -2.63684449\n",
            "  0.10650628  3.96684742]. \t  -313.7836151754242 \t -126.06288515837247\n",
            "53     \t [-4.35875297  4.05985252  3.7429394  -0.88405051  4.21584357  3.24657787\n",
            "  5.04500819  2.5419328 ]. \t  -479.08292418852545 \t -126.06288515837247\n",
            "54     \t [ 0.83717936 -5.09011432 -3.24852641  4.39856623 -0.68478836 -3.70341675\n",
            "  5.05038664 -1.62783251]. \t  -445.9477025187326 \t -126.06288515837247\n",
            "55     \t [ 1.55064002  3.71931944  3.98030783  3.71983168 -3.34170026 -5.03908998\n",
            "  3.91748421 -2.73615456]. \t  -508.456782778271 \t -126.06288515837247\n",
            "56     \t [-3.57611138 -4.10193607 -4.99419781 -0.32505443  4.71516523  4.37379665\n",
            " -4.25362791 -4.56447926]. \t  -640.9627272164818 \t -126.06288515837247\n",
            "57     \t [-5.0083248   5.11026403 -1.18492991 -0.17718899 -0.57235897 -3.27087235\n",
            " -5.05734659 -5.07103573]. \t  -532.2407928857123 \t -126.06288515837247\n",
            "58     \t [-4.70869325 -4.67514929 -2.91532034 -4.79861114  0.53480511  2.7526173\n",
            "  3.90052453 -2.28737665]. \t  -378.73665886933094 \t -126.06288515837247\n",
            "59     \t [ 4.70531665 -3.6497336  -4.90590253 -4.35137407 -4.4399469  -2.7471283\n",
            "  3.9557836  -3.98143209]. \t  -576.9204843201339 \t -126.06288515837247\n",
            "60     \t [ 4.65906607  3.36515718  4.44476095  5.07380157 -1.20419929 -4.41107842\n",
            " -4.5483546  -0.80791166]. \t  -480.62764508556376 \t -126.06288515837247\n",
            "61     \t [-4.24283265  4.80007858  3.29229945  1.69266004 -5.03600619  0.91958738\n",
            "  3.79700844  4.85607328]. \t  -529.5143673778252 \t -126.06288515837247\n",
            "62     \t [-4.80969959  3.89662402 -1.39621478 -1.97390553  4.93201341  4.91079009\n",
            " -2.53885628 -1.57659049]. \t  -406.25860331533875 \t -126.06288515837247\n",
            "63     \t [ 3.90341241  0.7271449  -3.17033464  4.04988313  4.3810933  -1.73961296\n",
            " -4.21500868 -5.09057248]. \t  -557.8563109962846 \t -126.06288515837247\n",
            "64     \t [-3.46150036  1.86953176 -2.83101095 -2.98016144  3.1772903  -3.66351779\n",
            " -4.07703982  3.89924212]. \t  -447.5341334830154 \t -126.06288515837247\n",
            "65     \t [-5.07564183  0.63241934  1.93877705 -4.94189526 -3.23598501 -0.894699\n",
            "  4.73918918  0.90380836]. \t  -356.4432001056336 \t -126.06288515837247\n",
            "66     \t [ 3.26917878  5.03778428 -0.35017401  3.14330531  3.43389304  2.25726142\n",
            " -2.53386965  2.86462173]. \t  -301.4568206042408 \t -126.06288515837247\n",
            "67     \t [-3.69769663  4.92137952 -4.62602764  2.30257243  3.80144396  1.93661178\n",
            "  4.01781201 -4.04678983]. \t  -486.2900962377606 \t -126.06288515837247\n",
            "68     \t [-1.48610071 -4.62142483  3.29131047  1.14699399  5.08954575  3.61592282\n",
            " -4.5695027   3.30962841]. \t  -524.4425574843627 \t -126.06288515837247\n",
            "69     \t [ 4.96780163 -4.81269844  2.69303631 -4.15229241  0.32736337  4.84633609\n",
            "  4.26916063 -2.69726244]. \t  -488.96624791701055 \t -126.06288515837247\n",
            "70     \t [ 1.05829719  4.74222195  2.52878633  3.58435203 -3.11112239 -0.67480737\n",
            " -3.16685895  4.90087686]. \t  -430.1512541013317 \t -126.06288515837247\n",
            "71     \t [ 2.29142645 -3.90437102 -4.45216155 -4.32824319 -2.45464933  4.86596396\n",
            " -2.09654386 -3.26745797]. \t  -458.5097189510044 \t -126.06288515837247\n",
            "72     \t [-4.50609417  3.84149406 -4.29493653 -4.64067287 -0.49001397  2.57668292\n",
            " -1.93688099 -4.8868038 ]. \t  -449.6455601324768 \t -126.06288515837247\n",
            "73     \t [ 1.76038565 -2.90217468  3.67624666 -4.19715462 -4.00339346  4.92554485\n",
            "  2.39530912  3.8267536 ]. \t  -513.969623507569 \t -126.06288515837247\n",
            "74     \t [ 4.85745779  5.07629389 -4.33679826  2.49165688  0.84444426 -4.33156889\n",
            " -1.76298103 -0.41962478]. \t  -295.6950483269074 \t -126.06288515837247\n",
            "75     \t [-4.89593071 -3.85371816 -4.08409352  3.19125969 -3.2461181  -4.28218325\n",
            "  5.08829049  3.97429504]. \t  -614.7524810056337 \t -126.06288515837247\n",
            "76     \t [-3.03360134e+00  1.48251602e+00  4.54499438e+00 -3.18562313e+00\n",
            "  4.50838137e+00 -2.02050574e-03 -4.38095167e+00  4.07633967e+00]. \t  -485.07120565429733 \t -126.06288515837247\n",
            "77     \t [-3.95387363 -3.68406257  0.97055271 -1.05348837 -0.33480183 -2.35048916\n",
            "  1.20278338 -5.10604099]. \t  -302.45232819498426 \t -126.06288515837247\n",
            "78     \t [ 3.15900001 -4.76785284 -2.77489348 -4.50041051  3.55286217  1.78368166\n",
            " -4.83460354  0.14559585]. \t  -405.54559735405155 \t -126.06288515837247\n",
            "79     \t [ 2.99694702 -4.37175238 -0.80957162 -0.52876249 -2.4436186  -4.50508672\n",
            "  3.60000295  3.92060015]. \t  -415.6108975498045 \t -126.06288515837247\n",
            "80     \t [-4.6333684   3.96468851  4.50521121  4.91482817 -4.46962491 -5.03923329\n",
            " -4.29872131  0.32600801]. \t  -592.8727913226526 \t -126.06288515837247\n",
            "81     \t [ 4.69117852 -4.95966635  4.00120457 -2.61337472 -4.96747111 -3.62216146\n",
            " -4.17873666 -3.67319295]. \t  -578.8223800965548 \t -126.06288515837247\n",
            "82     \t [ 5.02093084  3.58232336  0.8168098  -1.0946189  -2.33889229 -0.33329967\n",
            "  3.62286398 -3.83737073]. \t  -295.3680594345658 \t -126.06288515837247\n",
            "83     \t [-1.69213891 -1.03896808 -4.79324514 -1.99321746 -4.92141787 -0.64548894\n",
            "  1.31802159  2.14991621]. \t  -262.5785930526664 \t -126.06288515837247\n",
            "84     \t [-2.6066023   5.07151054 -5.04752661  4.46621353 -4.72860186  1.69307455\n",
            "  0.212711    4.9856297 ]. \t  -542.6217781004166 \t -126.06288515837247\n",
            "85     \t [-3.69216356  3.43423503 -0.43441416 -3.66757321 -0.28391026  2.00053523\n",
            " -0.03281929  4.22707994]. \t  -258.95958270174987 \t -126.06288515837247\n",
            "86     \t [ 3.96766178 -4.1171513  -4.93189312  3.631731   -4.44243757  1.99401131\n",
            " -0.75146541 -1.09729374]. \t  -311.4908736693203 \t -126.06288515837247\n",
            "87     \t [-5.02239927 -4.85557818  4.56620473 -3.86560171  3.57532142  0.21295976\n",
            "  3.87210221 -2.74834173]. \t  -424.26597116447243 \t -126.06288515837247\n",
            "88     \t [-3.16579097  1.16457568  5.0466967   4.25375159  1.72253713 -2.93140422\n",
            " -3.98755077  3.44062764]. \t  -433.9214901411437 \t -126.06288515837247\n",
            "89     \t [ 0.94740319  3.87387287  4.26110205 -3.00171399  0.4274589  -4.70444318\n",
            " -4.8055492   4.86443853]. \t  -606.0830130632787 \t -126.06288515837247\n",
            "90     \t [-1.56907655  5.10778164  1.71859534  1.64432888  5.03324701 -5.06748945\n",
            " -3.36504479 -4.6113956 ]. \t  -604.4458612710002 \t -126.06288515837247\n",
            "91     \t [ 4.32620399 -3.63086328 -1.93931556  4.9443213  -3.29805233 -4.89871883\n",
            " -0.76392229 -3.6684274 ]. \t  -464.2648049149675 \t -126.06288515837247\n",
            "92     \t [ 3.44075983  4.84718235 -0.56442955  0.65119831  3.28247719  4.97089618\n",
            "  4.22109531 -5.08926957]. \t  -595.5421333381163 \t -126.06288515837247\n",
            "93     \t [-4.80280646 -1.72554127 -0.20982135  4.46401557 -0.06462437  2.80321464\n",
            " -2.83511818  4.18197844]. \t  -352.20952039715655 \t -126.06288515837247\n",
            "94     \t [ 4.62009032 -2.16282206 -4.2665947   3.17616198  4.39249713 -4.23515852\n",
            "  4.34641811  3.09906905]. \t  -538.8271896116803 \t -126.06288515837247\n",
            "95     \t [-0.14719555 -1.58602883  1.45964864  0.30854235 -0.80179804 -4.40718983\n",
            " -3.47743229  3.43968648]. \t  -310.87878338508847 \t -126.06288515837247\n",
            "96     \t [-2.88237755 -2.46127004 -0.78802228  4.22170457  4.57418874 -5.00298658\n",
            "  1.45550213  3.23238101]. \t  -446.78885862678726 \t -126.06288515837247\n",
            "97     \t [-1.76252271  4.19133344 -4.42913719  1.26717954 -0.87680683 -4.64641957\n",
            "  4.63653174 -4.44931282]. \t  -545.748086060438 \t -126.06288515837247\n",
            "98     \t [-3.98877856  0.96345474 -4.42167007 -0.26044163 -4.22506706  4.92999715\n",
            "  2.96282998 -2.49596711]. \t  -423.064197455111 \t -126.06288515837247\n",
            "99     \t [-4.92119058  0.16243028 -3.94635846  4.76211893 -4.78874016 -2.90688546\n",
            " -4.37987386 -0.55159175]. \t  -463.7803787335379 \t -126.06288515837247\n",
            "100    \t [ 0.05665318  3.39180121  4.991027   -3.61107447  4.91073529  3.63255794\n",
            " -3.54787731 -1.57436673]. \t  -457.5928745077361 \t -126.06288515837247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YRio_skuvd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e6f394c-ff86-4547-ee11-1c6f8db041f4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 8 \r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_winner_8 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_8 = dGPGO_stp(surrogate_winner_8, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.99872128 -4.68771825  1.02085207 -2.04932398  3.03730465 -1.37015168\n",
            "  3.89742944 -2.07010168]. \t  -277.86676122742784 \t -180.51916289603517\n",
            "init   \t [-1.74998258  0.70366122  2.49781681 -4.56854645  1.04524157 -0.72377777\n",
            " -3.01595019  0.49815264]. \t  -180.51916289603517 \t -180.51916289603517\n",
            "init   \t [-1.18004907 -0.43124987 -2.23607519  0.87291919  1.19692315  0.82388062\n",
            "  4.34999751 -2.6686217 ]. \t  -220.47800037058124 \t -180.51916289603517\n",
            "init   \t [ 3.35954485  4.67643031  4.19598825  2.82329052 -0.36849066 -1.29661262\n",
            "  4.62746655  4.05379841]. \t  -431.85390329456686 \t -180.51916289603517\n",
            "init   \t [-0.2416498   4.43676172  4.77427222  3.16353515  1.62974284 -3.16385107\n",
            "  1.99781252 -1.93490553]. \t  -279.0706376092465 \t -180.51916289603517\n",
            "1      \t [-0.80689796  0.12979216 -3.32388196  5.07613741 -3.43250948 -2.05510194\n",
            " -3.97044354  3.43910665]. \t  -426.1198945095334 \t -180.51916289603517\n",
            "2      \t [ 4.07058243  1.87505943  3.823545   -0.7045548   4.15212304  3.79618737\n",
            "  3.36854962 -1.74745794]. \t  -345.97103603679506 \t -180.51916289603517\n",
            "3      \t [-2.52284091  3.16667894  3.39881544 -3.45155575  2.66245312 -4.73836025\n",
            "  3.3830009   2.26473303]. \t  -400.0298461008507 \t -180.51916289603517\n",
            "4      \t [-3.38323741 -0.81655844  1.40105076  4.58830172 -2.54333418  1.80646949\n",
            "  4.90933886  4.55754025]. \t  -489.68208836931797 \t -180.51916289603517\n",
            "5      \t [ 3.06019179 -2.43870083 -2.47955666  5.02439222  1.06725782  2.83803554\n",
            " -2.28129529 -1.28756674]. \t  -244.39662275572095 \t -180.51916289603517\n",
            "6      \t [-0.50148047  1.93005816 -1.12481853 -4.97971357 -4.24871876 -1.46973755\n",
            "  3.82520467  2.9982716 ]. \t  -388.2487927521442 \t -180.51916289603517\n",
            "7      \t [ 4.44986416  2.59160065 -2.13776153  2.53965108  3.82229504 -5.02413012\n",
            " -1.59196109 -1.31218712]. \t  -328.7595208766232 \t -180.51916289603517\n",
            "8      \t [ 5.00582669 -2.64510506  2.52918584 -0.85261616 -0.81473594 -2.47506909\n",
            " -4.66226265 -1.67894506]. \t  -275.93210136648787 \t -180.51916289603517\n",
            "9      \t [-5.08884211 -4.07036696 -1.16524284  2.15616529 -0.46087038  0.19458933\n",
            " -1.71717592 -4.15561074]. \t  -241.78451072004538 \t -180.51916289603517\n",
            "10     \t [ 2.42111126 -3.81498682 -2.28650513 -4.73110546 -1.68005304  3.67124776\n",
            " -1.95849108 -0.65876857]. \t  -265.490652207225 \t -180.51916289603517\n",
            "11     \t [ 3.38777639 -1.50760259  3.77036565  1.01796157 -4.86928761 -1.64703553\n",
            "  0.18621712  3.23948886]. \t  -281.83792201450086 \t -180.51916289603517\n",
            "12     \t [-5.0472699  -2.44313224  3.31701556  3.82911387  0.24223857 -4.22723077\n",
            " -0.98973809  3.29731096]. \t  -330.4143769831294 \t -180.51916289603517\n",
            "13     \t [ 0.12075833  3.53187191 -1.13812866 -4.18492602  4.75846939  4.37401389\n",
            "  4.91290648  2.56838572]. \t  -548.6397863682118 \t -180.51916289603517\n",
            "14     \t [ 3.83260518 -3.59614177  4.94103107  3.02187054 -2.89650737  2.38820085\n",
            "  4.53826575 -4.92297598]. \t  -564.5478312162915 \t -180.51916289603517\n",
            "15     \t [-2.58867878 -0.33425295  3.28180212 -1.21540421 -3.36938161  4.44632882\n",
            " -0.0730957  -2.15190136]. \t  -257.609751801171 \t -180.51916289603517\n",
            "16     \t [-0.33981458  4.80190242 -2.31900518 -1.42487999 -0.87679152  4.42845998\n",
            " -3.04548719 -1.95158815]. \t  -287.3923744617263 \t -180.51916289603517\n",
            "17     \t [ 5.03657361  2.14121545 -5.0614108   0.9557451  -2.87767627  2.75542412\n",
            " -4.53535155  2.72962719]. \t  -405.59620242543093 \t -180.51916289603517\n",
            "18     \t [-4.52503434 -2.79893609 -2.89494466 -4.16884698 -5.11891908  0.08912653\n",
            " -4.72644401  4.73752945]. \t  -597.7959938484771 \t -180.51916289603517\n",
            "19     \t [-1.40357584  4.07972863 -4.10052014 -3.40004539  5.01647437 -4.28961617\n",
            " -0.7017217   3.39213477]. \t  -463.6718639786896 \t -180.51916289603517\n",
            "20     \t [ 2.48772524 -4.58165669  4.94386452  4.68087393  2.06204394 -3.45289054\n",
            "  2.25680516  4.07552723]. \t  -470.4660535578811 \t -180.51916289603517\n",
            "21     \t [-0.03717619 -0.66515397 -4.54744272  1.05199548 -4.65875225 -3.80723666\n",
            " -3.50251659 -3.62619482]. \t  -453.90856223476897 \t -180.51916289603517\n",
            "22     \t [-2.74122878  1.99498392 -1.54660235 -4.13658863 -3.28265047 -2.57967031\n",
            "  3.88649735 -5.08192672]. \t  -497.24468449491314 \t -180.51916289603517\n",
            "23     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -180.51916289603517\n",
            "25     \t [ 4.92588366 -3.56966688 -5.10088515 -0.57598876 -4.03928096 -4.30395984\n",
            " -4.90744358  2.80009791]. \t  -553.1622921166008 \t -180.51916289603517\n",
            "26     \t [-5.00411946  0.44264128  3.47943139  1.31201606  1.59913651  3.50610765\n",
            " -1.3911044   4.64701043]. \t  -341.4847277527873 \t -180.51916289603517\n",
            "27     \t [ 1.47485882 -4.72146838  5.07078636  0.99871702  3.41929386  3.49311156\n",
            " -2.06118931  0.31167425]. \t  -290.07356078419156 \t -180.51916289603517\n",
            "28     \t [ 1.36764931 -4.81950724 -4.35140729 -0.63607698 -3.35010521  2.28765476\n",
            "  4.4455872   3.88723855]. \t  -453.4922936971734 \t -180.51916289603517\n",
            "29     \t [-4.80888466 -2.18671857 -2.34022463 -4.99904992  4.49185778  3.71833114\n",
            " -4.4949737   4.88322447]. \t  -665.1212223034729 \t -180.51916289603517\n",
            "30     \t [ 5.03966577  1.09726405 -2.20689714  1.79521908  3.6620232   1.7851613\n",
            "  5.01071767  3.98391033]. \t  -444.2048864816629 \t -180.51916289603517\n",
            "31     \t [ 2.10484717  3.67633788 -0.94550013  4.41772355 -4.47698873  0.69187552\n",
            "  1.67327399 -4.9287631 ]. \t  -429.23819680513293 \t -180.51916289603517\n",
            "32     \t [-3.84463791 -4.6704415  -3.60317752 -2.25837761  4.92644306 -4.31582137\n",
            " -2.57288319 -5.08729286]. \t  -604.2466050479966 \t -180.51916289603517\n",
            "33     \t [ 4.03761438  2.56133194  5.1197742   2.35660972  4.75332242 -2.77386776\n",
            " -3.83140306  4.55349137]. \t  -558.0421125100511 \t -180.51916289603517\n",
            "34     \t [-2.02362791  3.41285879 -4.86827401  4.67420391  3.67748694 -0.79495647\n",
            " -1.31724279 -3.86771031]. \t  -389.11393466658996 \t -180.51916289603517\n",
            "35     \t [-4.41080782  4.51770348  4.4187224   1.76745458 -0.75127456 -1.58409186\n",
            " -4.95368463 -0.56143885]. \t  -323.5182188092367 \t -180.51916289603517\n",
            "36     \t [ 1.23561008 -4.59978455  4.39977335 -3.39063493 -2.79763124  1.46273855\n",
            " -4.61243911  3.78141284]. \t  -463.1885589274548 \t -180.51916289603517\n",
            "37     \t [-2.75681227 -4.23065895 -4.51545376 -1.27397572  4.51201762  4.96309081\n",
            "  2.20168761  2.67289003]. \t  -451.72885343007823 \t -180.51916289603517\n",
            "38     \t [-3.36525447 -1.54448367  0.12300683  3.56352321 -4.58313269 -4.93239854\n",
            "  4.89524317 -4.38312174]. \t  -639.3707274540823 \t -180.51916289603517\n",
            "39     \t [ 4.29339418 -4.7110987  -4.81064262 -4.87700357  4.17297015 -0.69476521\n",
            "  1.27450491  3.16652206]. \t  -408.9396643637019 \t -180.51916289603517\n",
            "40     \t [-3.77854353  3.17936999 -4.24604221  2.36963403 -3.50945646  5.10280427\n",
            "  3.1441825   1.99806299]. \t  -429.99378541928 \t -180.51916289603517\n",
            "41     \t [ 4.01854232  4.210912   -3.471071   -2.54964188  1.33335736 -5.09298034\n",
            "  4.80877048 -4.46960295]. \t  -599.9685592327364 \t -180.51916289603517\n",
            "42     \t [-4.28446196 -4.98091852  4.61001112  3.99869068  1.03268787  4.58527004\n",
            "  2.51153209 -1.43965319]. \t  -387.9062226421404 \t -180.51916289603517\n",
            "43     \t [ 3.14362532 -3.93355685 -4.7796049  -4.04487746  4.53567686  1.51165604\n",
            "  4.25494125 -4.63326969]. \t  -589.8477490752967 \t -180.51916289603517\n",
            "44     \t [ 4.06827468 -4.12955157 -1.04635122 -0.06014708 -3.92747645 -2.82449502\n",
            "  2.99677442 -3.56926813]. \t  -343.7302620355615 \t -180.51916289603517\n",
            "45     \t [ 3.50503851  4.96098179 -1.77107594  3.26338186  4.43104384  1.82068367\n",
            " -5.09034827  4.07971727]. \t  -546.1110940325218 \t -180.51916289603517\n",
            "46     \t [-0.86930232 -4.67265131  2.95971245 -4.32099591 -1.36543647 -4.38404687\n",
            "  4.28598299  4.88301063]. \t  -589.3659228066781 \t -180.51916289603517\n",
            "47     \t [-4.20093944  4.90776064 -4.90655492  3.91768588  1.7302173   4.05492585\n",
            " -2.35348614  3.44724431]. \t  -446.89904259412776 \t -180.51916289603517\n",
            "48     \t [-3.17533314  3.91122502  2.30276908  0.81993008  4.08216858  2.71811778\n",
            " -0.19265122 -4.03216909]. \t  -317.2518693683078 \t -180.51916289603517\n",
            "49     \t [ 4.33047422  2.42074046 -1.43045664 -4.68603411  3.76509867  4.27707309\n",
            " -3.68452713  0.99805946]. \t  -408.0863845967878 \t -180.51916289603517\n",
            "50     \t [-1.78996274  4.77720088  4.59860514 -4.03648124 -3.94034674 -4.33638585\n",
            " -4.14819873  4.29775634]. \t  -636.1371547050605 \t -180.51916289603517\n",
            "51     \t [ 5.01960078  4.66343278  2.47908295 -0.1380686   2.4412476   0.91037699\n",
            " -4.27646892 -4.63889164]. \t  -422.1484084919773 \t -180.51916289603517\n",
            "52     \t [ 2.07355426  3.64667861 -4.51828793  3.47522079 -4.48922259 -4.35665775\n",
            "  3.35941002  3.2352571 ]. \t  -517.8325283601242 \t -180.51916289603517\n",
            "53     \t [-3.45210472 -2.85824275 -5.03488824  3.52241494  2.80825483 -3.50283103\n",
            "  1.99185011  3.82480515]. \t  -411.7918272370765 \t -180.51916289603517\n",
            "54     \t [ 3.23203935 -3.66004929  3.69966538 -0.05193522  2.95292603 -4.5876363\n",
            "  2.39013311 -3.57457264]. \t  -390.39837339519835 \t -180.51916289603517\n",
            "55     \t [ 5.01495613  4.72703228  5.1057025   1.20003957 -4.71203964  3.4259669\n",
            "  0.28594921  1.88199907]. \t  -364.1522429017305 \t -180.51916289603517\n",
            "56     \t [ 3.95965136 -0.12761527  5.04237159 -5.0352804  -4.93825972  4.23929226\n",
            "  0.39218137 -2.78264708]. \t  -486.18741943376403 \t -180.51916289603517\n",
            "57     \t [ 0.21716751 -4.22776635  2.04987023  4.48341642  4.07424225 -2.94976709\n",
            " -3.78615604 -4.2931794 ]. \t  -511.8051360204521 \t -180.51916289603517\n",
            "58     \t [ 3.13903097  4.15131655  2.18342166 -4.30940714  2.66825456 -4.84201899\n",
            " -1.08896277 -2.62730781]. \t  -372.697973174463 \t -180.51916289603517\n",
            "59     \t [-1.27781189 -3.24067797  3.27259173  3.96131284 -3.82626451 -4.20910536\n",
            " -4.7154313  -1.75430014]. \t  -477.3028648592413 \t -180.51916289603517\n",
            "60     \t [-4.73626324  2.29343861 -3.14985659 -4.55119704 -0.15687829  3.8398321\n",
            "  4.61025401 -3.05092585]. \t  -457.40547850017845 \t -180.51916289603517\n",
            "61     \t [ 4.95274254  3.8599984  -1.21880932 -4.4853436  -4.96661147 -2.82054261\n",
            " -3.84830611 -1.99859874]. \t  -445.94885739594775 \t -180.51916289603517\n",
            "62     \t [-3.38927328 -4.58600497 -1.68489809 -1.20271331 -4.59167348  3.02381503\n",
            "  3.72983458 -4.26973673]. \t  -471.3577249065834 \t -180.51916289603517\n",
            "63     \t [ 4.68192442  3.55882791  0.47253165 -3.90164591  1.87346595 -4.54641849\n",
            "  4.5085833   3.54123483]. \t  -492.99506669200014 \t -180.51916289603517\n",
            "64     \t [-2.65387316  4.45483323  1.91566083  1.53425733  4.46071369 -1.95438471\n",
            " -1.53653631  4.03075695]. \t  -336.0693427120276 \t -180.51916289603517\n",
            "65     \t [ 1.73898402 -4.69509962 -3.63519484 -0.0587016   4.4769586  -4.2616951\n",
            " -4.83891268  0.4792049 ]. \t  -461.70038650918514 \t -180.51916289603517\n",
            "66     \t [-4.28916817  4.06381224 -3.36831227 -2.66706274 -1.71706997 -2.80588022\n",
            " -2.09275043  0.91949816]. \t  -213.31605553567408 \t -180.51916289603517\n",
            "67     \t [-1.03781796 -4.82740601 -2.48852136  2.80925536 -2.27896911  4.12043711\n",
            " -3.99730798  2.614759  ]. \t  -392.2121693961095 \t -180.51916289603517\n",
            "68     \t [-2.79074235 -4.13051393  2.59284193 -4.5990013  -1.01477443  4.99691277\n",
            "  4.68797702  1.18642084]. \t  -466.74658748706094 \t -180.51916289603517\n",
            "69     \t [-4.05207154 -3.02389333  3.94036275 -2.94442854 -4.02614593 -4.4348989\n",
            " -1.00089704 -2.20989554]. \t  -361.1060542165882 \t -180.51916289603517\n",
            "70     \t [-0.07449738 -4.94189921 -4.94846147 -4.58827696 -3.42585614 -3.82487857\n",
            "  0.75551367 -0.05092375]. \t  -356.99821999222945 \t -180.51916289603517\n",
            "71     \t [ 3.87333974 -4.16740068 -3.883898    1.18395794 -3.03775313  5.0025232\n",
            "  3.33771536 -4.93527906]. \t  -569.7276263414255 \t -180.51916289603517\n",
            "72     \t [-4.91981163  4.40425573  5.11431988 -3.00277183  3.14676643  5.04044336\n",
            "  2.29546584  0.92540393]. \t  -423.21707548205814 \t -180.51916289603517\n",
            "73     \t [-0.13202979 -3.11504139  2.98530132 -4.19977914  2.6950858  -4.1841334\n",
            " -2.76107802 -4.39353558]. \t  -465.8624218702015 \t -180.51916289603517\n",
            "74     \t [-3.30124574 -1.13158585 -4.1980333  -4.05814038  2.69272117  4.06408107\n",
            " -4.23970614 -3.15537924]. \t  -473.03502914525285 \t -180.51916289603517\n",
            "75     \t [ 4.05207489  0.86706438 -5.03334349 -5.04638044  3.80727246 -2.94375154\n",
            " -3.09386029 -1.63501019]. \t  -408.6508985788998 \t -180.51916289603517\n",
            "76     \t [-0.86601187  2.81435558  0.23356561 -2.95797086 -3.39187438  4.38741594\n",
            " -3.91311416  4.5337975 ]. \t  -496.40356263036733 \t -180.51916289603517\n",
            "77     \t [-1.8410917  -1.55356036 -4.39349936  4.01435423  3.84747453 -4.96987046\n",
            "  4.59813134 -3.49341294]. \t  -598.4295180293549 \t -180.51916289603517\n",
            "78     \t [-4.08569762  3.7928806  -4.81135734  3.52094086  0.20969951 -5.05716912\n",
            "  4.49623901  4.42567564]. \t  -616.3760103347921 \t -180.51916289603517\n",
            "79     \t [ 4.70507016  1.50384272  3.43267557  4.02859938 -0.83967358  3.98477713\n",
            " -4.83881323  3.95982065]. \t  -515.0651897776597 \t -180.51916289603517\n",
            "80     \t [-4.71057629  3.05417    -4.55595784  2.82585191 -4.04817753 -2.0476676\n",
            "  2.49488663 -1.31482467]. \t  -299.555138042337 \t -180.51916289603517\n",
            "81     \t [-4.80952215 -3.84158733 -2.83528517 -4.01498759  4.94210614 -4.45175323\n",
            "  4.47561699  3.2047601 ]. \t  -604.656754142369 \t -180.51916289603517\n",
            "82     \t [ 4.33965807  2.74160685 -2.14256498  3.47080441 -3.51959917  3.6887958\n",
            "  5.05377845  3.5158412 ]. \t  -517.0781646971608 \t -180.51916289603517\n",
            "83     \t [-3.57763188  0.24884141 -1.35947796  1.11506641 -3.76342605  1.43646807\n",
            " -5.08693935 -1.04597865]. \t  -296.5300827871441 \t -180.51916289603517\n",
            "84     \t [-4.79911322 -0.55984356 -2.56086766  0.43822071  1.92623872 -1.98271908\n",
            " -4.1930925   3.61814236]. \t  -314.04145028247956 \t -180.51916289603517\n",
            "85     \t [ 2.6774365  -4.86174121  5.06112804 -4.01427314  3.70866079  4.43112653\n",
            "  2.53339638 -3.40501761]. \t  -520.0042856428697 \t -180.51916289603517\n",
            "86     \t [ 3.38390842 -3.90520975  1.7660354   5.09798645  0.54649409 -1.81785949\n",
            " -4.54961204  4.35985931]. \t  -473.5474005000857 \t -180.51916289603517\n",
            "87     \t [-0.87522108  5.07922594 -1.29272057  4.93410574 -4.0126065  -4.3584217\n",
            " -4.3870108  -3.14365793]. \t  -563.0198818743911 \t -180.51916289603517\n",
            "88     \t [-5.0473608  -0.50749014  3.43840866 -2.02212284 -4.70604923  0.98960082\n",
            " -1.81662915  3.84475988]. \t  -335.7836031469092 \t -180.51916289603517\n",
            "89     \t [-0.59684956 -3.65122313 -1.40395717  3.65927944  5.00838729  2.36646061\n",
            " -2.43549939  3.50792458]. \t  -385.4800920210676 \t -180.51916289603517\n",
            "90     \t [-3.76864222  4.79946437  5.05508893  3.68379078 -3.65704745 -0.09762528\n",
            "  0.58882312  4.83739812]. \t  -447.7729284554401 \t -180.51916289603517\n",
            "91     \t [ 0.93322704  1.503024   -4.52339731 -2.34669137 -4.33958879  3.18943822\n",
            "  4.05245606 -5.08939467]. \t  -566.167842658067 \t -180.51916289603517\n",
            "92     \t [ 3.49926219  3.80315179 -0.64759391 -2.76184492  0.16277932 -4.15869956\n",
            " -4.13300537  3.48085222]. \t  -393.3460146218553 \t -180.51916289603517\n",
            "93     \t [ 0.34384872 -1.28172284  4.39577117 -1.61232205 -2.19563359 -4.31253949\n",
            "  4.34585077 -1.43804772]. \t  -356.211398790875 \t -180.51916289603517\n",
            "94     \t [ 4.99881706  2.85339765  3.90978186 -2.21438872 -4.78878122 -1.98207481\n",
            "  2.86049791 -3.47879567]. \t  -399.07232382369904 \t -180.51916289603517\n",
            "95     \t [ 5.04822668 -0.24815022  3.57506938 -4.48362471  4.66154785 -0.0077669\n",
            " -3.96701769  4.44459346]. \t  -521.2090723157891 \t -180.51916289603517\n",
            "96     \t [ 2.47163503  0.31569211 -3.95008347 -0.23717768 -0.56701436 -1.82444225\n",
            "  1.40725848  1.59561824]. \t  \u001b[92m-109.15247309596478\u001b[0m \t -109.15247309596478\n",
            "97     \t [ 4.64788258 -4.69645734 -4.37756059 -3.53037955 -4.85302937  0.36121673\n",
            " -4.97533054 -4.78152643]. \t  -647.7833586373142 \t -109.15247309596478\n",
            "98     \t [ 0.66776163  2.12858474  4.06167723  3.38816863 -0.98029742  3.45160729\n",
            " -2.30526967 -4.59806984]. \t  -387.54238422459326 \t -109.15247309596478\n",
            "99     \t [-4.23978193  3.33391212 -0.29953219  0.12530288  4.20374953 -4.82264092\n",
            "  1.61667832 -4.11932838]. \t  -422.4888678996924 \t -109.15247309596478\n",
            "100    \t [ 3.40755067  2.66842357  0.29189128  4.74004121  5.00277298 -0.8122025\n",
            "  5.11413452 -4.55364435]. \t  -594.0426775875231 \t -109.15247309596478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejw6v-Ihuvf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75b4832e-7a1a-4fc2-aa3a-b29fe14a152f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 9 \r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_winner_9 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_9 = dGPGO_stp(surrogate_winner_9, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.76413244 -0.12207719  3.33307058 -4.79798899  3.15443162  0.67192238\n",
            " -2.07234561 -4.64183582]. \t  -383.4493461208245 \t -276.8057458851627\n",
            "init   \t [ 5.02402457 -5.05010449  2.76268061  2.52689511 -1.25502529 -0.05993009\n",
            "  4.39243154 -1.07055059]. \t  -276.8057458851627 \t -276.8057458851627\n",
            "init   \t [ 4.85331248  0.25000669 -4.16140192  3.20827815 -2.95232732  0.55650083\n",
            " -2.12716425  3.23729777]. \t  -277.7575521997104 \t -276.8057458851627\n",
            "init   \t [ 3.35915588 -2.85104771  1.48310734 -4.14534019 -0.90456843 -4.12809972\n",
            " -3.64532737 -2.94711116]. \t  -371.7161372605202 \t -276.8057458851627\n",
            "init   \t [-0.23904098 -4.32523431 -2.71315168 -5.05289725  4.08211648  0.53488053\n",
            " -3.40432253  4.3917126 ]. \t  -482.1410604064339 \t -276.8057458851627\n",
            "1      \t [-0.3457215  -2.41570642  0.505635   -1.25610202 -3.03382172  4.25433599\n",
            "  4.49717681  3.45593439]. \t  -410.6056418678222 \t -276.8057458851627\n",
            "2      \t [ 3.79102982 -1.86774332 -3.76245939  3.69577129  3.01678056  1.74979237\n",
            "  3.19769481  1.83478698]. \t  -280.8358165940958 \t -276.8057458851627\n",
            "3      \t [ 4.1967864  -3.62383051 -4.07857858  4.26642924  0.97175294  1.12842288\n",
            " -0.90654271 -5.02684512]. \t  -386.8590556303891 \t -276.8057458851627\n",
            "4      \t [-4.8710492  -2.05323762  4.64732929 -2.32223252 -1.77534112 -0.74841883\n",
            " -0.60840948  5.09474963]. \t  -347.8856442527038 \t -276.8057458851627\n",
            "5      \t [-1.35739698  3.13372387 -1.81874951 -2.36077576  1.18828857  3.48605034\n",
            "  1.6175686  -4.00636277]. \t  -280.39824376989225 \t -276.8057458851627\n",
            "6      \t [ 0.81711508  0.33401963  5.0650915   3.97129991  1.53230457  1.60569378\n",
            " -0.18323784  2.41800804]. \t  \u001b[92m-215.1596001270892\u001b[0m \t -215.1596001270892\n",
            "7      \t [ 2.91243546 -2.47622884 -5.00852066 -0.17779531 -2.66430053 -4.43563613\n",
            "  0.849529   -2.18361589]. \t  -292.86699854088897 \t -215.1596001270892\n",
            "8      \t [ 2.02795906  4.8457081  -1.26954319 -2.39812669  4.53484958 -4.93015644\n",
            " -3.50972469  4.53471091]. \t  -578.3126130057084 \t -215.1596001270892\n",
            "9      \t [-3.31854584  2.04247219  3.30956382 -0.17415201  4.35201916 -4.82258864\n",
            "  4.88947837 -1.68824217]. \t  -476.7318910842152 \t -215.1596001270892\n",
            "10     \t [-4.0521322   3.52300708 -0.59871754  0.80404697 -4.83467926  0.17354503\n",
            "  2.28877277  1.05551119]. \t  \u001b[92m-207.53780922794502\u001b[0m \t -207.53780922794502\n",
            "11     \t [-2.89191518  5.03713566  3.9399025   0.16268942 -0.86578727 -1.06050022\n",
            "  0.91324662 -5.02524483]. \t  -324.14173433955773 \t -207.53780922794502\n",
            "12     \t [-4.75191925 -1.71899666 -4.77380114  1.90907046  3.53598641  1.45997595\n",
            " -1.23534464 -3.85690587]. \t  -316.4298634894203 \t -207.53780922794502\n",
            "13     \t [-1.67279734  5.08465247 -3.81032909 -1.87470914  4.85951532  4.06694595\n",
            " -3.74449426  2.32712218]. \t  -470.9069773016337 \t -207.53780922794502\n",
            "14     \t [ 3.13292498  4.83323207  0.02151348 -0.70455967 -1.31192335  1.91335553\n",
            "  1.08831688  2.8241438 ]. \t  \u001b[92m-161.19112124601764\u001b[0m \t -161.19112124601764\n",
            "15     \t [-1.11527917 -0.38988152  0.30494605  1.03183788 -0.08438276 -3.39428654\n",
            " -4.35086719  2.42438017]. \t  -254.77955672516424 \t -161.19112124601764\n",
            "16     \t [-1.72579875  5.08391295 -0.19225224  4.55521116  3.85441808 -1.14181157\n",
            "  1.04368935  3.81329262]. \t  -343.84111321580326 \t -161.19112124601764\n",
            "17     \t [ 3.25207762  3.02054951  3.39221164  4.58774245 -3.4985204   4.87014996\n",
            "  3.58259696 -4.24885414]. \t  -585.3097575683016 \t -161.19112124601764\n",
            "18     \t [ 3.11653097  2.24095074  4.00852509  2.91342265  1.61454667 -4.97950825\n",
            " -1.76667359 -2.96347232]. \t  -355.8255458820284 \t -161.19112124601764\n",
            "19     \t [ 4.26477598 -2.94372285  3.33442379 -1.62316528  4.68229578 -3.87426386\n",
            "  1.44772513  2.70682289]. \t  -352.3786003851066 \t -161.19112124601764\n",
            "20     \t [ 3.43898286 -5.04617334  0.40415517 -1.18642334 -3.48086599  4.48375334\n",
            " -4.94502121 -3.23935859]. \t  -505.20135947526063 \t -161.19112124601764\n",
            "21     \t [-3.36061148 -0.4619389  -4.44996125 -1.91215998  1.46988261 -3.81573099\n",
            "  4.96880668  3.47355871]. \t  -453.2621249789785 \t -161.19112124601764\n",
            "22     \t [-2.64620858 -1.3461983  -3.95621385 -3.83538708 -1.93358743  4.20130156\n",
            " -5.11501688 -4.96597285]. \t  -621.4528646278093 \t -161.19112124601764\n",
            "23     \t [-0.7187204  -1.15900805  1.03117075  3.6562408   1.1599271   4.0477319\n",
            " -4.84234457 -4.09733418]. \t  -463.3407258021713 \t -161.19112124601764\n",
            "24     \t [ 2.42686112 -3.79574487  1.78069264  0.74573763  4.41208038  3.58416528\n",
            "  4.28085909 -5.04053713]. \t  -552.388219405253 \t -161.19112124601764\n",
            "25     \t [ 1.36638397  3.47369692 -2.98194042 -4.50564212  0.85687926 -3.8039306\n",
            "  5.03733641 -2.38297127]. \t  -447.4215575704486 \t -161.19112124601764\n",
            "26     \t [-3.83293059 -2.47054784  2.87600328  4.18188985  0.32285047  0.5298248\n",
            "  5.07915167 -4.41078261]. \t  -460.09551178861636 \t -161.19112124601764\n",
            "27     \t [-4.35856595 -4.83933288  3.55641097  2.81101891  4.34074547 -0.40802455\n",
            " -3.65113202  1.33042056]. \t  -338.07163511091494 \t -161.19112124601764\n",
            "28     \t [-0.49209038  4.71186437  4.13055613 -4.82007271 -2.4375078  -3.73279056\n",
            " -3.35690629  2.95466801]. \t  -450.7941873285888 \t -161.19112124601764\n",
            "29     \t [-4.61612522  4.70771735  4.80499704  0.10310303 -3.35113823  4.4608578\n",
            " -4.40117728  1.72031936]. \t  -469.754999114328 \t -161.19112124601764\n",
            "30     \t [-2.01334539  0.24581957  2.50342178  2.06611202 -1.20436663 -4.10292764\n",
            "  4.23564101  4.93834383]. \t  -468.9901396668904 \t -161.19112124601764\n",
            "31     \t [-4.70756139 -0.70795433 -0.41358812  2.16203286 -3.98847951 -1.24858829\n",
            " -3.30880561 -4.54049894]. \t  -372.8343297717496 \t -161.19112124601764\n",
            "32     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -161.19112124601764\n",
            "33     \t [-4.78325941  4.5242268   4.48833463  0.71390823  3.1935567   4.6354751\n",
            "  0.44443809  4.86474605]. \t  -496.91943885746696 \t -161.19112124601764\n",
            "34     \t [-0.48440869 -4.74588973 -4.12747025  2.08172078 -3.46453909  4.82445129\n",
            " -3.01815903  3.20561501]. \t  -459.3637333750677 \t -161.19112124601764\n",
            "35     \t [-3.8055376   3.48079576 -4.94668632 -0.04562294  1.54263993  3.95220419\n",
            "  4.46723603  4.1611031 ]. \t  -495.9612509987757 \t -161.19112124601764\n",
            "36     \t [-1.41386298 -4.25277637 -4.18783644  4.44629405 -3.71755365  4.43791678\n",
            "  5.00301446 -2.52170938]. \t  -583.2181461552595 \t -161.19112124601764\n",
            "37     \t [-3.60028757 -4.25221948 -4.16096691  4.82315542  0.33942872 -4.98377871\n",
            " -5.04706915 -1.02837025]. \t  -530.4921339606846 \t -161.19112124601764\n",
            "38     \t [-2.87989981 -4.3197781   4.31187323 -4.17754531 -1.81873502 -2.98200861\n",
            "  3.48629829 -2.21523486]. \t  -365.4303721120453 \t -161.19112124601764\n",
            "39     \t [ 4.66733818  3.74085938 -3.08209838 -2.82545447 -2.64799853  2.32930377\n",
            " -3.40203596 -4.15491728]. \t  -396.9399254968581 \t -161.19112124601764\n",
            "40     \t [ 4.23295015  4.45199906  0.52058524  3.95265165 -4.57710742 -4.1950568\n",
            "  4.3490972   3.94438435]. \t  -588.0737447503195 \t -161.19112124601764\n",
            "41     \t [-4.28933855  2.93359006 -1.59744789 -5.00822888 -0.41824744 -2.51375705\n",
            " -4.160198   -2.6194194 ]. \t  -358.42536963727173 \t -161.19112124601764\n",
            "42     \t [ 3.74380809 -3.07399699 -3.96447944 -4.10593442 -4.62852992  2.66115671\n",
            "  2.99733184 -3.51799388]. \t  -459.00630673775674 \t -161.19112124601764\n",
            "43     \t [-4.02023423 -3.77194292 -4.4810829   1.55344249 -4.73632689 -1.36253525\n",
            "  0.5227254   0.4843606 ]. \t  -241.60294651571246 \t -161.19112124601764\n",
            "44     \t [ 3.97769514  0.37981177  2.54553625 -1.65049408  3.30650946  2.34856754\n",
            " -4.75150079  2.73591077]. \t  -352.1249814561264 \t -161.19112124601764\n",
            "45     \t [-4.49393615  1.03265155  5.01290727 -3.65458655  5.02908796  3.47880263\n",
            "  3.90965853 -2.49141137]. \t  -506.8660187079735 \t -161.19112124601764\n",
            "46     \t [-4.4539316   3.37579808 -5.1052758   4.34023851 -0.4815986  -1.97161506\n",
            "  2.31936605 -4.97535017]. \t  -456.3441046251337 \t -161.19112124601764\n",
            "47     \t [ 3.59571637  4.20881353  0.50166381  4.81156368  5.05520782  3.3613514\n",
            "  4.2868858  -2.63224404]. \t  -521.3561073244729 \t -161.19112124601764\n",
            "48     \t [ 3.12350606 -3.79762585  4.1721793   4.43521162 -3.80501179 -0.0951839\n",
            " -3.29290488 -1.52573031]. \t  -336.4761783739211 \t -161.19112124601764\n",
            "49     \t [-0.61648259  5.08024759 -0.8080952   2.04120042 -2.11990129 -4.09196831\n",
            " -4.1097678  -2.34788367]. \t  -355.8898683639792 \t -161.19112124601764\n",
            "50     \t [-4.7117543  -4.42167058 -1.94461047 -0.41872759  4.98781085  2.98976427\n",
            "  2.24940676  4.18609298]. \t  -426.978069108315 \t -161.19112124601764\n",
            "51     \t [ 1.94275383 -0.66527647 -4.89559467 -4.60103966  3.89557026  4.26420951\n",
            "  4.92872598  2.1867724 ]. \t  -554.518684629875 \t -161.19112124601764\n",
            "52     \t [-3.60745731 -5.01933548 -3.1535573   4.52813074  4.30770811 -4.56189395\n",
            "  3.7659125   2.95053872]. \t  -561.8189617385949 \t -161.19112124601764\n",
            "53     \t [ 2.91552737  4.95417652  3.19595574 -3.42699842 -3.25091469  4.96568474\n",
            "  2.75223064 -4.02114097]. \t  -518.3780947831918 \t -161.19112124601764\n",
            "54     \t [ 4.11273516 -5.04700969  3.66892494 -4.5501392   4.15332117  3.32252532\n",
            "  3.08450806  1.70144855]. \t  -433.3014796642094 \t -161.19112124601764\n",
            "55     \t [ 1.06751204  0.77762842 -0.25117904  2.89249555 -3.03832501 -2.27584747\n",
            "  4.69134885 -4.55296951]. \t  -433.1359025101643 \t -161.19112124601764\n",
            "56     \t [ 4.98522998 -4.95488317 -0.46095824  1.83123408  4.77148437 -0.57235352\n",
            " -4.67150603  1.09311786]. \t  -366.1262525793959 \t -161.19112124601764\n",
            "57     \t [-4.56730613 -2.97070426  2.17767325 -4.57130677 -2.64487194  4.49692699\n",
            " -0.27118802 -1.86624207]. \t  -321.01314573116167 \t -161.19112124601764\n",
            "58     \t [-1.96362803 -3.90096531 -3.39994127 -4.78394036  2.83018589 -3.28097626\n",
            " -0.28586609 -3.49972183]. \t  -363.70909018076986 \t -161.19112124601764\n",
            "59     \t [-3.12778002  4.08877733  4.23783343  3.74573093  4.17312373  4.77654152\n",
            " -0.5433369  -3.28090942]. \t  -465.3672446183035 \t -161.19112124601764\n",
            "60     \t [ 5.09602582 -4.43763189 -1.67720992 -4.01884882 -3.36823438  0.05451396\n",
            " -0.49402558  4.39380339]. \t  -351.29365522521095 \t -161.19112124601764\n",
            "61     \t [ 3.67066739 -2.67815939  4.33731888 -4.58945424 -5.10292247 -5.07739558\n",
            " -0.48377079  2.26778482]. \t  -496.16802806918975 \t -161.19112124601764\n",
            "62     \t [ 1.43478654  0.48269021  4.88279806 -1.9359367  -4.95791282  0.97036227\n",
            " -4.30850455 -4.73644094]. \t  -527.0087241038298 \t -161.19112124601764\n",
            "63     \t [ 1.44635528  2.15523229 -1.79182606 -3.19549893 -3.54047278 -4.85606615\n",
            " -0.07744778  0.76648669]. \t  -270.7637815745298 \t -161.19112124601764\n",
            "64     \t [-3.33085459  1.7804329   0.47908467 -4.13696706  4.32124344 -0.96434535\n",
            " -1.54821259  5.02348383]. \t  -404.1883767929156 \t -161.19112124601764\n",
            "65     \t [ 4.11530768  3.95606954 -2.95895062  1.48114694  2.59761097 -3.10090492\n",
            " -1.09125168 -2.8109212 ]. \t  -246.25569829025412 \t -161.19112124601764\n",
            "66     \t [ 4.79756415  3.26432906  3.98190539 -3.7209667   4.36166029 -0.59367355\n",
            "  4.65645006 -2.54035551]. \t  -447.91742602892816 \t -161.19112124601764\n",
            "67     \t [ 4.12016244 -0.11958556 -3.31289536  1.31741196  0.36598599 -4.87829478\n",
            "  4.44779515  3.89612065]. \t  -460.2469727644026 \t -161.19112124601764\n",
            "68     \t [-2.58440925  4.68933784 -3.2531777   3.62550471 -1.83074196  1.99675825\n",
            " -3.69067244  3.02223394]. \t  -344.08455034134676 \t -161.19112124601764\n",
            "69     \t [ 2.885633    1.43144296 -4.2812804   4.92219108 -2.956398    4.11477163\n",
            " -4.44081169 -4.79621353]. \t  -631.6893731652048 \t -161.19112124601764\n",
            "70     \t [-4.62537206 -4.68837549 -4.65747559 -2.77617837 -0.30694525  2.03112537\n",
            "  2.92466216 -2.07232143]. \t  -280.7162668895681 \t -161.19112124601764\n",
            "71     \t [-3.33987403  4.14688497 -3.10798948  3.53776657  4.7665765  -4.68699287\n",
            " -5.07337079  0.66954271]. \t  -553.7586412821274 \t -161.19112124601764\n",
            "72     \t [ 3.48424911  1.66531716  4.70042472  0.34995528 -4.27215226  4.16756255\n",
            " -3.66940333  3.52465635]. \t  -473.5635610232414 \t -161.19112124601764\n",
            "73     \t [ 3.56688719 -2.91622232 -1.09824525 -3.96599303  0.65020897 -1.57640224\n",
            "  4.74950315  0.42369711]. \t  -272.6309580682805 \t -161.19112124601764\n",
            "74     \t [-4.39967611 -4.43989281  1.34384563  4.72515537 -4.93608544 -0.65422259\n",
            " -3.63823265  2.96569983]. \t  -440.92148435695594 \t -161.19112124601764\n",
            "75     \t [ 4.57573876 -4.45598336  4.1457558   4.04975567 -1.59113852 -4.52846259\n",
            " -1.63408784  5.09085536]. \t  -539.5395354772486 \t -161.19112124601764\n",
            "76     \t [-2.86312993 -3.82400297  0.27928143 -5.06347253 -3.54388661  3.86880237\n",
            " -4.970317    4.71167779]. \t  -643.3615918022725 \t -161.19112124601764\n",
            "77     \t [ 2.57812268 -1.98568564 -3.04213511  3.9540583   4.59748443 -3.92082143\n",
            "  4.05838899 -4.81913635]. \t  -603.8422865501226 \t -161.19112124601764\n",
            "78     \t [ 4.90713701 -3.66603338 -4.82484168 -1.08290572  2.1488922   4.67507251\n",
            " -3.51950639  1.27009031]. \t  -379.3276437098469 \t -161.19112124601764\n",
            "79     \t [ 1.45936836  1.40912928 -2.8669634  -3.75233797 -1.88515885  4.94926983\n",
            " -2.6990908   2.78569762]. \t  -364.896923993087 \t -161.19112124601764\n",
            "80     \t [-4.49239946 -4.42770132  3.63671003 -4.37995126  4.99360527 -4.60018601\n",
            "  4.47880831  0.39135185]. \t  -569.0976555403174 \t -161.19112124601764\n",
            "81     \t [ 1.19877089  4.91363925 -4.05766065  4.59301985 -3.57007629  3.06407672\n",
            "  2.05837621  0.30377401]. \t  -333.9571466462589 \t -161.19112124601764\n",
            "83     \t [ 1.60589843  3.86485033  1.07537333 -2.84811224  4.84969461  4.74842386\n",
            "  3.27217384  3.04257952]. \t  -470.26033905512094 \t -161.19112124601764\n",
            "84     \t [-1.66321351 -4.48605725 -4.34027525 -3.45703693 -3.1849662  -3.60501111\n",
            " -5.0657354   1.68540833]. \t  -478.38729881774873 \t -161.19112124601764\n",
            "85     \t [-3.32207228 -0.08541248  1.67714618  0.93906586  5.0588126  -0.81908038\n",
            " -1.97371273 -4.1656616 ]. \t  -321.0905582296674 \t -161.19112124601764\n",
            "86     \t [-3.12806544 -0.82545668  4.54959606  4.26777771 -3.24338519 -5.11351605\n",
            "  1.085212   -3.19176284]. \t  -445.3283415801045 \t -161.19112124601764\n",
            "87     \t [-4.0608765   2.90852798 -0.49402663 -5.11534001 -0.38480437  0.34927383\n",
            "  4.65841481  0.79170135]. \t  -297.201242024974 \t -161.19112124601764\n",
            "88     \t [ 2.61449818  1.45641082 -5.04265178 -4.2445349   5.08316869 -0.83108771\n",
            " -1.29553254 -4.7407672 ]. \t  -484.3122641173285 \t -161.19112124601764\n",
            "89     \t [-4.80243532  4.67903749 -1.21485134 -4.70304968 -4.96114385 -4.49561347\n",
            "  5.07014795  4.66268334]. \t  -757.9501786556475 \t -161.19112124601764\n",
            "90     \t [ 4.13360024  4.84339695 -4.37693209  4.86162864  4.82334809  3.90482718\n",
            " -0.63075588  1.29631536]. \t  -440.05589949931385 \t -161.19112124601764\n",
            "91     \t [ 3.30468702  4.17777141  1.71813812 -4.23863325 -2.5907531  -4.56964914\n",
            " -2.66523764 -4.47988019]. \t  -495.6777692751549 \t -161.19112124601764\n",
            "92     \t [-1.57211395 -4.45816047  5.00649835 -2.10853491  3.27778731 -4.97136605\n",
            " -1.9687608   4.96428168]. \t  -561.4918922129687 \t -161.19112124601764\n",
            "93     \t [-5.09930328  3.59705329  2.23228703 -2.75377166  5.0565122   2.90516767\n",
            " -4.98698563 -1.53729463]. \t  -468.6407795396418 \t -161.19112124601764\n",
            "94     \t [-2.6552337  -1.98343849 -4.41552304  5.11239087 -0.58421356  1.15589885\n",
            "  1.50550649  4.84136832]. \t  -391.05478210516327 \t -161.19112124601764\n",
            "95     \t [ 2.77493528  4.55451796 -5.07975481 -2.43217273  4.64713941 -1.46512035\n",
            "  1.65587184  1.92867665]. \t  -320.07183662537676 \t -161.19112124601764\n",
            "96     \t [ 2.74681649 -4.70613614  1.54654624  4.70678747 -1.73784368  3.40224615\n",
            "  3.72866805  4.77376102]. \t  -511.8145330748215 \t -161.19112124601764\n",
            "97     \t [-2.20456053 -1.78122189  1.0679689  -4.31989769 -5.01650525 -4.42940998\n",
            "  1.69705164  4.27883333]. \t  -499.44519516785294 \t -161.19112124601764\n",
            "98     \t [-1.5680899   4.46766063  4.26558639 -0.78043495  3.43552516 -4.98289263\n",
            "  0.43130115  4.14796115]. \t  -446.3371632050177 \t -161.19112124601764\n",
            "99     \t [ 4.2867213  -4.87738692  4.34595572 -0.06215489 -4.7692856   4.7715501\n",
            "  4.37592773 -4.74036762]. \t  -686.7776857653938 \t -161.19112124601764\n",
            "100    \t [-4.54123211  4.82525134  4.33274234  3.82852284  0.53908309 -4.17381019\n",
            " -1.68556704  0.32839252]. \t  -308.86509580288765 \t -161.19112124601764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4xG5dbuuvig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208ab578-feaa-45dc-9ec6-7b7c4dffdb5a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 10 \r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_winner_10 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_10 = dGPGO_stp(surrogate_winner_10, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.57275736 -3.9423289   4.61089653 -0.18236005  3.81413924 -2.94571335\n",
            " -4.70313344 -1.05272872]. \t  -385.9754059539706 \t -352.16802530271787\n",
            "init   \t [-2.7327263   3.49942502 -2.99947679  2.48288802 -1.10434173 -3.25369324\n",
            "  2.49384361 -4.40747949]. \t  -352.16802530271787 \t -352.16802530271787\n",
            "init   \t [ 3.94585297  4.63507865  4.41490877 -0.86598704 -4.82322781  4.93596144\n",
            " -1.64211012  2.11647687]. \t  -437.2230551014739 \t -352.16802530271787\n",
            "init   \t [-1.41437883 -4.7605156   3.63579651  1.61027592  2.72059386  0.55385332\n",
            "  3.94335167  4.13898358]. \t  -382.1028014270721 \t -352.16802530271787\n",
            "init   \t [-5.01328179 -4.35653902 -2.61499689 -3.75495933  2.02675303 -1.04238199\n",
            "  3.92317124 -3.26648309]. \t  -360.16156644546146 \t -352.16802530271787\n",
            "1      \t [-0.69120848 -4.9342136   1.9603237  -0.31036772 -3.80700478  4.00729141\n",
            "  4.28240511 -4.37124102]. \t  -511.13628956580146 \t -352.16802530271787\n",
            "2      \t [-1.64422687  4.1658285   1.59045739 -3.50127712  2.88252444  2.96609181\n",
            " -3.49909343  0.47668923]. \t  \u001b[92m-275.89055024502613\u001b[0m \t -275.89055024502613\n",
            "3      \t [ 0.16275012 -3.26135029 -2.28264585 -1.25926838 -1.15670706  2.88937188\n",
            "  1.34959924  3.7622242 ]. \t  \u001b[92m-226.03899188137302\u001b[0m \t -226.03899188137302\n",
            "4      \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -226.03899188137302\n",
            "5      \t [-3.91625185 -1.29947065  3.91357886 -4.19414565  2.47667826  2.57853532\n",
            " -0.4747333  -4.41978184]. \t  -363.442122388006 \t -226.03899188137302\n",
            "6      \t [ 5.08639972  0.59547281 -4.35771525 -0.91677037 -3.63032957  1.36330471\n",
            "  0.06774278 -0.91962543]. \t  \u001b[92m-170.7574293822782\u001b[0m \t -170.7574293822782\n",
            "7      \t [ 4.21277274  4.13390787  1.29045167  0.976945    2.29964531 -4.45075225\n",
            " -2.63615032  2.89700819]. \t  -321.8226132274614 \t -170.7574293822782\n",
            "8      \t [ 4.78442126  4.89678967  2.03495    -4.9035254   2.19217751  3.49116606\n",
            " -0.29169789 -3.98365076]. \t  -404.1581496512427 \t -170.7574293822782\n",
            "9      \t [ 1.21737244  4.98466405  4.77042917  3.34871902  3.93529345 -3.93623004\n",
            "  4.2240787   3.5426243 ]. \t  -559.9999026716611 \t -170.7574293822782\n",
            "10     \t [-3.69151167  4.36076234 -5.07374087  1.97011201  1.04682543 -4.92492262\n",
            " -1.11737054  2.77708195]. \t  -365.85914511787394 \t -170.7574293822782\n",
            "11     \t [ 4.03267796 -4.53272386 -4.91481642 -3.08993267 -0.73657925 -4.16957581\n",
            " -2.62510246 -3.72926348]. \t  -434.53296894118955 \t -170.7574293822782\n",
            "12     \t [ 5.1140465  -1.15981285  4.0197045  -4.08344167 -3.54434877 -0.04264564\n",
            "  2.11257085 -5.0750915 ]. \t  -444.131931751421 \t -170.7574293822782\n",
            "13     \t [-1.28146537  0.94824581  4.4523804   2.15335356 -1.71254281 -0.83469425\n",
            " -0.71167755  2.19538313]. \t  \u001b[92m-142.40664593163214\u001b[0m \t -142.40664593163214\n",
            "14     \t [ 2.20007726 -1.16216649  2.98432558 -5.03840216  2.79386096 -2.52807752\n",
            "  1.83061711  3.43769959]. \t  -331.1778763053209 \t -142.40664593163214\n",
            "15     \t [ 4.68369713 -0.02114982 -3.66220033  1.29801887 -2.81082918 -4.28805625\n",
            " -2.0997606   4.56332603]. \t  -416.19533855178827 \t -142.40664593163214\n",
            "16     \t [-2.73445372 -3.87748458 -1.98951739  3.56935052  2.84121528  1.90939801\n",
            "  0.94813531 -1.45676895]. \t  -185.89005745960338 \t -142.40664593163214\n",
            "17     \t [-0.29901239  4.3013356  -3.20648732 -4.21871175 -2.12171986  3.67061427\n",
            "  3.64225999  4.18586056]. \t  -475.5099467915456 \t -142.40664593163214\n",
            "18     \t [-1.83436216  0.25370281 -0.34286741  4.7548482  -4.95625373  1.49370754\n",
            " -3.34168833 -5.06296037]. \t  -513.726550486559 \t -142.40664593163214\n",
            "19     \t [ 4.16537476  4.41590713  0.29450523 -0.53682591  3.18140054  1.61469837\n",
            "  3.16542548  4.81061062]. \t  -379.289024025127 \t -142.40664593163214\n",
            "20     \t [-4.6491526   4.22643111 -4.69464501  2.0916374   4.60574198  4.29829683\n",
            " -1.48305769  2.64924103]. \t  -429.4193985163885 \t -142.40664593163214\n",
            "21     \t [-4.099524    0.40722477  1.01236069  0.59492719 -1.76015113 -4.64635443\n",
            " -4.25919036 -3.87533008]. \t  -413.7808372922981 \t -142.40664593163214\n",
            "22     \t [ 2.43409407  0.59244246  1.91911708  4.02046906  1.43809938  4.51140597\n",
            "  2.61025695 -1.20707707]. \t  -274.14022935820384 \t -142.40664593163214\n",
            "23     \t [ 2.19643474 -1.63265701  0.178177    4.02263527 -2.36778971 -3.96817556\n",
            "  4.51075869 -0.23746833]. \t  -340.36746442919764 \t -142.40664593163214\n",
            "24     \t [-3.85934001 -1.1776208   2.75929796  2.90241406  2.99657923  5.09628274\n",
            " -3.27915929  2.69751517]. \t  -408.418218149427 \t -142.40664593163214\n",
            "25     \t [ 3.23371092  4.387936   -3.11511118  2.29689071  4.20455776  2.49647657\n",
            " -3.73947665 -2.98026983]. \t  -393.9071986157133 \t -142.40664593163214\n",
            "26     \t [-5.10025545 -1.58832086  1.44395417 -1.3725172  -3.94116704 -2.8622733\n",
            "  5.04042735  4.57369127]. \t  -516.8585655366013 \t -142.40664593163214\n",
            "27     \t [ 3.87269477  0.31631731 -4.39777813  0.13117625  4.5721269   2.23849666\n",
            "  3.28071248 -3.33980038]. \t  -372.4506431814126 \t -142.40664593163214\n",
            "28     \t [-5.01341919 -4.84249874 -5.09899608 -0.78889553 -3.91076157  2.79407134\n",
            " -3.50095337 -3.29302525]. \t  -448.3827997683644 \t -142.40664593163214\n",
            "29     \t [-4.55158001  4.6887436  -4.50291908 -3.65442386 -4.94790859 -2.96754307\n",
            "  3.27907764  0.25057578]. \t  -429.9492343588589 \t -142.40664593163214\n",
            "30     \t [-1.94487667  4.60612241  1.50964724 -4.72534849 -2.8072682  -1.95002578\n",
            " -0.77634569  4.45052917]. \t  -367.26409524210607 \t -142.40664593163214\n",
            "31     \t [-3.13811188  4.79328446  2.52011146 -0.21458966  3.10756095  3.02587191\n",
            "  4.27731989 -3.91981724]. \t  -429.24405425338915 \t -142.40664593163214\n",
            "32     \t [-4.67952834  3.94659321 -2.67314183 -5.11471486  3.27330825 -2.61518769\n",
            " -3.99947901  3.56223792]. \t  -487.222588588277 \t -142.40664593163214\n",
            "33     \t [-1.18745069  4.95992636  3.62493604 -3.69224404 -4.30164932 -0.81143467\n",
            " -2.30629401 -4.39428251]. \t  -432.74511272211817 \t -142.40664593163214\n",
            "34     \t [ 0.58085072 -3.62413433 -3.51633857  2.66205192  4.53578499  1.43810204\n",
            " -5.11265761  4.43242362]. \t  -547.4675404148924 \t -142.40664593163214\n",
            "35     \t [-1.01114914  1.77209548 -3.01026241 -5.04589255  4.4368226  -4.37544478\n",
            "  2.72421548 -4.03335352]. \t  -531.7192838088365 \t -142.40664593163214\n",
            "36     \t [-0.34509972 -2.85136583 -4.68044966 -2.71693335  4.80238275 -5.05679608\n",
            "  1.98641036  3.30870032]. \t  -495.5686879514702 \t -142.40664593163214\n",
            "37     \t [-4.95529921  2.97896054  4.26684192 -3.03647776  4.18208323 -4.2978525\n",
            " -0.64456517 -2.43134009]. \t  -382.2798951744719 \t -142.40664593163214\n",
            "38     \t [ 2.5941448  -4.35884483  0.01544972 -4.276983   -4.76413587  0.01017293\n",
            " -4.23029135  1.21448368]. \t  -368.45258719980995 \t -142.40664593163214\n",
            "39     \t [-0.33598918  4.47001487 -4.14802579  3.87620965 -4.00447041  2.46386575\n",
            "  3.62996014  4.89604958]. \t  -552.4027222762829 \t -142.40664593163214\n",
            "40     \t [ 4.75000609  4.60191985  1.5971933   4.64565505 -2.23339325  4.37389203\n",
            " -3.8415424  -2.67304776]. \t  -459.08883998726867 \t -142.40664593163214\n",
            "41     \t [-4.09365543 -3.10896162  4.12468835 -4.76255979 -4.16055056  4.16534638\n",
            "  1.74367675  2.60630145]. \t  -444.13325062320763 \t -142.40664593163214\n",
            "42     \t [-4.84307914 -0.03160042 -2.62146341  0.66395065 -4.25731172  4.23237257\n",
            " -4.23857812  2.85882397]. \t  -435.08013410079263 \t -142.40664593163214\n",
            "43     \t [ 4.33702135 -0.12772756  2.53831431 -3.18498179  1.8049087   4.81329862\n",
            " -2.08430899  4.13377242]. \t  -401.1584789314883 \t -142.40664593163214\n",
            "44     \t [-4.34466559 -0.88987713  4.23967231  4.82631768 -3.10048194 -2.46752109\n",
            "  2.85863142 -4.73958092]. \t  -489.06605200084095 \t -142.40664593163214\n",
            "45     \t [ 1.86279823  2.9905861  -3.21090705  4.45092756  5.07569313 -4.42288904\n",
            "  3.13558099 -0.2298808 ]. \t  -446.96085168262334 \t -142.40664593163214\n",
            "46     \t [-4.87255338 -0.90492653 -2.81618188  4.88103036 -3.9533663  -1.20525859\n",
            "  2.22962139  0.91328752]. \t  -272.80267999424103 \t -142.40664593163214\n",
            "47     \t [-2.52121398  4.32619905  5.09535518 -1.55136066 -2.76800293  4.20100013\n",
            "  4.84695582  3.30026699]. \t  -527.0879056246981 \t -142.40664593163214\n",
            "48     \t [-3.28624399 -2.68243537  3.40450701 -4.07180779 -0.70564836  0.16856347\n",
            " -4.72086333  3.51849398]. \t  -383.98523040911783 \t -142.40664593163214\n",
            "49     \t [-3.81572105 -4.6822648  -2.63021385 -2.1612568   4.49323391  2.8077968\n",
            " -4.518063   -4.42314617]. \t  -545.4972546001677 \t -142.40664593163214\n",
            "50     \t [-4.52348277  4.66712174 -3.76739798  4.89540803 -5.06200108 -4.31252129\n",
            " -3.97356291 -1.97468376]. \t  -583.8916258340821 \t -142.40664593163214\n",
            "51     \t [ 3.78693125 -2.94315732 -3.70901646 -3.87836139  2.21651958  3.49590995\n",
            " -3.70889168 -0.01636291]. \t  -327.28875378970224 \t -142.40664593163214\n",
            "52     \t [ 5.06129066 -3.79916336  4.35396148  3.61958218 -3.61870531  1.76236276\n",
            "  3.26203103  2.55350315]. \t  -374.5200169577615 \t -142.40664593163214\n",
            "53     \t [-4.91793862 -3.79170429  3.77774218 -4.86933356 -2.1469211  -4.66886657\n",
            "  2.59381477 -3.67917612]. \t  -499.81787031642915 \t -142.40664593163214\n",
            "54     \t [-2.80545166 -4.00085518 -2.92429095  4.40398971  3.88486239 -4.9019855\n",
            " -0.87848058  3.67857593]. \t  -476.4141915300219 \t -142.40664593163214\n",
            "55     \t [ 3.63648309 -4.08087092 -0.91796709  3.26995879  3.31932547  2.23379719\n",
            " -3.25376562 -3.1080569 ]. \t  -328.2473205210948 \t -142.40664593163214\n",
            "56     \t [-4.65651145 -3.42000844 -2.97036643 -4.11121763  3.62548201  2.82989339\n",
            "  4.20239354  4.67549572]. \t  -551.426927117845 \t -142.40664593163214\n",
            "57     \t [ 5.00961477  4.99110595  1.89928293  4.34027984 -3.947107   -4.50859103\n",
            "  2.4952769   4.58488227]. \t  -572.7090986877135 \t -142.40664593163214\n",
            "58     \t [-4.43259189 -3.13910113 -4.62365755 -2.5785712  -1.19271588 -1.85409783\n",
            " -2.88420494  3.57737759]. \t  -318.4369667054822 \t -142.40664593163214\n",
            "59     \t [ 4.04497768 -2.50884043  1.55608917  1.11954834  4.17116174 -3.27040656\n",
            "  3.81955125 -4.79312803]. \t  -478.30991791609125 \t -142.40664593163214\n",
            "60     \t [ 4.64623045 -0.22646566  4.8413908  -4.87646815 -4.130866   -4.09480811\n",
            " -3.80761992 -1.34314483]. \t  -488.97007253334345 \t -142.40664593163214\n",
            "61     \t [-4.96220077  3.10989633 -1.87508345 -3.20290211 -3.20241895  2.24063366\n",
            " -4.22528975 -4.93373263]. \t  -496.6538145680895 \t -142.40664593163214\n",
            "62     \t [ 3.76504281  0.58173965  5.08486571  4.87998304  1.8920845   4.51330862\n",
            " -5.01266357  3.3980295 ]. \t  -596.056960657437 \t -142.40664593163214\n",
            "63     \t [ 4.57766203  4.96282478 -4.9209104  -5.0587413  -2.57029558 -2.17842931\n",
            " -3.43159801  3.91224825]. \t  -511.6057482390568 \t -142.40664593163214\n",
            "64     \t [-4.76257032 -0.97975168 -4.92829594 -1.23272862  5.09132287 -3.75471977\n",
            " -4.46095886 -0.94749993]. \t  -464.2231775482759 \t -142.40664593163214\n",
            "65     \t [ 3.52976048  3.53311067  3.73096211 -3.42489992 -2.32888324 -3.89889933\n",
            "  4.57046906 -0.12797729]. \t  -390.78726329533 \t -142.40664593163214\n",
            "66     \t [-4.74277098  5.07835869  0.33890966  2.66244523 -0.43682906  4.25621439\n",
            " -3.56173593 -2.03473241]. \t  -334.3414600684609 \t -142.40664593163214\n",
            "67     \t [-4.89864238  1.76217577  4.11079598  4.94835397  4.16222719 -0.74912662\n",
            " -3.51081336 -3.26846889]. \t  -440.57958727906725 \t -142.40664593163214\n",
            "68     \t [ 1.2051552  -1.84003176 -1.90933973  3.54464063 -4.67249161  3.81600564\n",
            "  0.01721085  0.3615655 ]. \t  -266.99867024099274 \t -142.40664593163214\n",
            "69     \t [-4.78513041 -3.94865091  2.36618457  0.80531237  3.53361176 -4.47414288\n",
            "  0.02842239 -0.52415326]. \t  -258.2150968132719 \t -142.40664593163214\n",
            "70     \t [ 4.07645163 -0.94709585  3.96206366  3.97464145 -2.07703788 -1.81688107\n",
            " -2.62889343 -3.19627597]. \t  -300.18016117605384 \t -142.40664593163214\n",
            "71     \t [ 5.08324205 -3.31859501 -2.42121066  1.9263734   3.71395054 -3.53040851\n",
            "  2.94077025  4.80294147]. \t  -469.1286668177112 \t -142.40664593163214\n",
            "72     \t [ 0.31598456  3.16037684 -2.98551328  4.90273818 -4.56881814  3.78932614\n",
            "  4.6351738  -2.74113174]. \t  -543.991774954768 \t -142.40664593163214\n",
            "73     \t [ 3.73169927 -4.5448439   4.38255997  0.80715004 -1.29767338 -0.11671516\n",
            " -4.943175    4.91190426]. \t  -488.02404935068887 \t -142.40664593163214\n",
            "74     \t [ 4.38032626  4.23610528 -3.29378115  4.63055434  5.01435186  3.42361857\n",
            " -4.655676    5.08298144]. \t  -727.8579942857493 \t -142.40664593163214\n",
            "75     \t [ 3.89711881  3.28311077 -4.89044418 -3.46857118 -2.31279938 -4.98006757\n",
            "  5.01205919 -1.02465125]. \t  -516.414530858023 \t -142.40664593163214\n",
            "76     \t [ 1.9090335  -1.91041817  4.65466123 -1.48499895 -4.85097696  2.84584012\n",
            " -4.69017958 -4.92779474]. \t  -599.2648082866556 \t -142.40664593163214\n",
            "77     \t [ 2.68693991  4.61765103 -3.52851414  4.511651    0.08714797 -4.15269704\n",
            " -4.25449845 -2.27993051]. \t  -440.43355774846304 \t -142.40664593163214\n",
            "78     \t [ 3.42430656 -4.34322404  3.49896892 -1.85954888  3.76337864  4.0499692\n",
            "  3.13684697 -3.38506852]. \t  -429.7898750904436 \t -142.40664593163214\n",
            "79     \t [ 3.53676516e+00 -4.08065761e+00 -4.90437513e+00  4.36922598e+00\n",
            " -7.08736430e-01  2.17348491e-03  2.34988290e+00 -4.52655422e+00]. \t  -399.4142270574297 \t -142.40664593163214\n",
            "80     \t [-3.88265228  4.98542161  3.32219151  0.18063507  0.2351792  -4.40013063\n",
            "  4.20709355 -1.54978758]. \t  -357.5808603688001 \t -142.40664593163214\n",
            "81     \t [-1.18094563 -3.05063307  1.93350837  4.51526607 -4.84115051 -5.03762917\n",
            " -2.00324677  4.88392864]. \t  -601.1362239539291 \t -142.40664593163214\n",
            "82     \t [-1.67857451 -4.58293747  3.93145134 -5.09267815  4.9068033  -2.42679636\n",
            "  2.35643197 -4.74114137]. \t  -569.3510660361846 \t -142.40664593163214\n",
            "83     \t [-4.2236931   4.0458425   4.79828778 -3.8558337  -4.27157236  4.81384722\n",
            " -4.79478471  2.51666229]. \t  -620.9866151152478 \t -142.40664593163214\n",
            "84     \t [ 5.04191235 -3.34227153  1.90837542  2.02685655 -2.72909003  4.88863992\n",
            " -4.48757341 -0.41345615]. \t  -398.08895562394713 \t -142.40664593163214\n",
            "85     \t [-4.74227265  4.93379821  4.81993701  3.74902479  4.91108723  1.58685561\n",
            "  1.15537478  4.91904405]. \t  -535.7127500430391 \t -142.40664593163214\n",
            "86     \t [-1.96645941  1.49890556 -2.01266789  4.70259161  3.45115633  3.44673124\n",
            "  4.63677971  4.12804083]. \t  -526.6263542674585 \t -142.40664593163214\n",
            "87     \t [ 2.02980137  3.84056384 -0.50566451 -0.78323662 -3.38561911  3.72272539\n",
            " -0.11509655 -5.08637052]. \t  -384.3671235598706 \t -142.40664593163214\n",
            "88     \t [-0.4349599  -0.2574399  -2.10684031 -5.09454417 -3.2889131   1.28147565\n",
            "  2.02671477 -1.97829559]. \t  -241.45565310364356 \t -142.40664593163214\n",
            "89     \t [ 4.78099307  2.64343098 -1.42405995 -4.82525253  2.66242681 -4.73499063\n",
            " -0.32069739  0.0244797 ]. \t  -306.73755932136345 \t -142.40664593163214\n",
            "90     \t [ 1.07892068  4.58229581 -2.71908355 -2.82181652 -2.94666214 -1.81981864\n",
            " -4.01496845 -2.28883188]. \t  -315.2241203589291 \t -142.40664593163214\n",
            "91     \t [-3.58514913  4.13186759 -0.47744976  4.15260625  0.72639447 -4.60766293\n",
            "  4.68734529  3.42486315]. \t  -494.3159153126929 \t -142.40664593163214\n",
            "92     \t [-3.66820866 -2.70733964 -2.13692635 -3.78969175  4.16648055  4.46255637\n",
            " -3.79056677  3.88974679]. \t  -527.1656199040901 \t -142.40664593163214\n",
            "93     \t [-1.00813769 -3.41761432  4.6126152   4.99369014  3.41653628  0.52423263\n",
            "  0.79464314 -4.22706982]. \t  -395.33061664474496 \t -142.40664593163214\n",
            "94     \t [ 4.17661334 -4.35274166  2.14588014  5.02670555  4.57067159 -0.29956632\n",
            " -2.16142653  3.77354171]. \t  -421.8352202609274 \t -142.40664593163214\n",
            "95     \t [ 1.52689067 -2.40550149  3.95760241 -4.62323777  2.67761291  4.46384257\n",
            " -4.82558898 -4.74874493]. \t  -645.2016178860433 \t -142.40664593163214\n",
            "96     \t [-2.58633726  4.17760474  4.63676511  1.6041876   3.49917549 -4.43628752\n",
            " -2.96277562  2.59135608]. \t  -410.8586600762004 \t -142.40664593163214\n",
            "97     \t [ 0.40954033 -4.48459035  3.69033537 -1.84832565 -4.31054437 -1.11122226\n",
            "  4.01635642  0.87883452]. \t  -314.3212672427642 \t -142.40664593163214\n",
            "98     \t [ 4.6458484   5.03705394  3.08340115  2.51976125  3.33927598 -2.95919449\n",
            "  4.63770127 -4.38228085]. \t  -538.7344144856839 \t -142.40664593163214\n",
            "99     \t [-1.73209648 -3.0265361   1.53773617  1.46382176 -0.35072619  4.83963953\n",
            " -4.08562573 -4.54450624]. \t  -460.19936160086854 \t -142.40664593163214\n",
            "100    \t [ 5.09345027  4.65313815 -4.62077753  0.60007667 -1.38994809  5.00179588\n",
            "  4.76871598 -0.01903777]. \t  -453.69676274165573 \t -142.40664593163214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSj_CQIAuvk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd31cf35-c6b5-4bdc-e5a3-5a858288b6f6"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 11 \r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_winner_11 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_11 = dGPGO_stp(surrogate_winner_11, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.92580518  3.28957798  1.4939506  -0.78143474 -3.04833558 -0.08287467\n",
            " -3.70116269 -0.4861846 ]. \t  -199.328627991057 \t -199.328627991057\n",
            "init   \t [-3.95535741 -5.09005324  0.23988403 -3.17469533 -3.66878933 -1.68072836\n",
            "  0.85700801  4.66360642]. \t  -371.33373135563875 \t -199.328627991057\n",
            "init   \t [ 4.97602467 -3.51277821  1.50799121 -0.08432225  3.26374507  1.8591538\n",
            "  1.97393801 -3.23583363]. \t  -241.32944618066992 \t -199.328627991057\n",
            "init   \t [ 3.9633366   0.66475842  1.73406641 -4.83201623 -0.61553705  4.24424807\n",
            " -3.088857    4.67305641]. \t  -470.469518894517 \t -199.328627991057\n",
            "init   \t [-2.63594969  1.40305335 -1.97175977  1.69687477 -1.50561156  4.86926807\n",
            " -1.76401693  2.83643699]. \t  -273.80464224498314 \t -199.328627991057\n",
            "1      \t [ 2.27211609  2.02425273 -1.2017534   4.16140797 -1.81853031 -4.31745003\n",
            "  2.0394904   3.25603062]. \t  -329.2676500747198 \t -199.328627991057\n",
            "2      \t [-3.69480656 -2.83253806  3.2747732   5.02500578 -5.06179771  3.60408914\n",
            "  3.67571491  0.76998055]. \t  -468.2381428914773 \t -199.328627991057\n",
            "3      \t [-4.13596727 -1.0508567   1.75136576 -3.55868316  0.65420774  1.77056145\n",
            " -5.02292824  4.76010165]. \t  -458.0000388046471 \t -199.328627991057\n",
            "4      \t [-3.61752876  2.99909561  0.1754234  -4.49062742 -1.22212296  1.71872834\n",
            "  4.97691018 -5.01665075]. \t  -511.74472953719817 \t -199.328627991057\n",
            "5      \t [-3.33539955 -1.26268526  1.94599964  4.92721403  2.08546241  3.34953724\n",
            " -4.27127122 -2.52482762]. \t  -390.55064122727174 \t -199.328627991057\n",
            "6      \t [ 0.3203754   0.15634972  4.84020429  1.72889228  1.62378325 -2.44968773\n",
            " -2.33630337 -4.26979199]. \t  -315.6369003974118 \t -199.328627991057\n",
            "7      \t [ 2.21787863 -2.88552062 -0.77407512 -4.9246763  -3.43481049  3.95417761\n",
            "  3.49615334  4.10516905]. \t  -493.5624273808329 \t -199.328627991057\n",
            "8      \t [ 3.61739562 -0.72572306 -4.39576726  0.25459781  2.74571778 -3.88721073\n",
            " -3.12290975  1.68819358]. \t  -291.791700258221 \t -199.328627991057\n",
            "9      \t [ 1.84822825 -1.58025135  4.2708715  -4.70395687 -0.34828434 -3.15872902\n",
            "  1.01027634  1.66955706]. \t  -241.55610557955714 \t -199.328627991057\n",
            "10     \t [-2.15998023  3.85545002 -0.54053289  5.04117111 -2.63495086  1.56342599\n",
            "  4.20047587 -2.265158  ]. \t  -350.8608004276867 \t -199.328627991057\n",
            "11     \t [-1.47895719 -4.26158453 -3.99179746 -0.3229649   4.83917585  2.70663318\n",
            " -2.77916902  0.2142721 ]. \t  -302.2071427677263 \t -199.328627991057\n",
            "12     \t [ 0.77262228  3.35922916 -2.7130201   2.50729784  0.9153661  -4.69397989\n",
            " -2.46807739 -5.00773931]. \t  -450.04301459145205 \t -199.328627991057\n",
            "13     \t [-2.50634688 -0.777872    1.22243455 -3.46787027  3.06002545  4.5751336\n",
            "  4.8119627   3.96201758]. \t  -520.1549046345149 \t -199.328627991057\n",
            "14     \t [ 3.0504194  -4.39355043 -1.97567319  3.61335842 -4.20123562  4.8947748\n",
            " -3.46490789  1.45702944]. \t  -444.8743300822997 \t -199.328627991057\n",
            "15     \t [-1.33533273 -5.04061147 -1.93792846  3.5377157  -2.5941644  -3.61933378\n",
            " -0.29635047 -0.38459549]. \t  -227.97105286685064 \t -199.328627991057\n",
            "16     \t [ 2.71660935 -3.49506318 -3.22857155 -1.90698651 -1.40532494 -2.37770593\n",
            " -0.71239056 -4.70656311]. \t  -302.1903093641155 \t -199.328627991057\n",
            "17     \t [ 4.8960545   3.3017529  -3.18776844  4.37309421 -3.84111719  3.63244037\n",
            "  0.74989536  3.60283937]. \t  -413.4745672253348 \t -199.328627991057\n",
            "18     \t [ 3.23579495  4.81255367 -3.92346266  4.60479345  3.92222871  5.08407494\n",
            "  3.4718759   4.76100216]. \t  -685.5097707267493 \t -199.328627991057\n",
            "19     \t [ 4.38332568  3.95542661  1.00506254 -4.61028775 -2.97097197  3.96177287\n",
            "  4.665975   -0.36993258]. \t  -430.35510528931144 \t -199.328627991057\n",
            "20     \t [-3.37673576 -1.31681957  0.37656527  3.41495008  3.83347044 -4.91811502\n",
            " -3.51171693  3.30664288]. \t  -454.34411010858173 \t -199.328627991057\n",
            "21     \t [ 1.72379183 -3.64723036  4.09278674 -5.06005207  4.91015936 -4.67819038\n",
            " -1.9360076  -4.65445219]. \t  -633.6546505446174 \t -199.328627991057\n",
            "22     \t [ 5.04512834 -4.87504612 -5.07267826  2.78616273  4.4880482  -1.75812555\n",
            "  4.72918448 -4.23618597]. \t  -600.6098643591031 \t -199.328627991057\n",
            "23     \t [ 3.89048929  3.37721285 -5.10183403  4.2231121   4.76516682  4.46839842\n",
            "  2.5181604  -4.07598316]. \t  -598.0024877904641 \t -199.328627991057\n",
            "24     \t [-0.77031311  2.11166946 -4.19781621 -3.70693273 -0.42841756  2.2491252\n",
            " -4.86433571 -4.35802412]. \t  -466.1824825425966 \t -199.328627991057\n",
            "25     \t [-2.55901605  2.1439068   4.70375136 -4.76948846  4.56210452  2.28033808\n",
            " -4.01635705 -4.30076391]. \t  -569.2632158067031 \t -199.328627991057\n",
            "26     \t [-5.00625396  3.47732469 -4.45240401 -3.74080419  1.59674539 -1.53695118\n",
            "  4.26197943  3.98259193]. \t  -445.65320228227364 \t -199.328627991057\n",
            "27     \t [-4.72729063  2.11396643  2.66949756 -0.75208004  5.05875894 -2.55062273\n",
            "  3.61515158 -0.17863067]. \t  -313.6559195882461 \t -199.328627991057\n",
            "28     \t [-3.68843478 -4.21452729 -4.17599482 -0.15473508 -4.76024388  2.28811389\n",
            " -2.55245377 -4.12523699]. \t  -427.99978570877397 \t -199.328627991057\n",
            "29     \t [ 3.94143067 -1.65105669  4.99943591  3.6396259   3.14720944  2.43927453\n",
            " -4.605013    1.23286227]. \t  -394.7850429023689 \t -199.328627991057\n",
            "30     \t [-3.30769724  0.74822456  3.20852994  0.93183764 -4.70374045 -3.40186803\n",
            " -4.29722365  0.44868891]. \t  -357.35341869150153 \t -199.328627991057\n",
            "31     \t [ 2.36743685  4.30230317  4.33115074 -2.16958914 -3.5387015  -2.87203698\n",
            "  4.7884971  -3.19753453]. \t  -472.13481857973056 \t -199.328627991057\n",
            "32     \t [ 0.68149802  4.96341088 -4.84936281 -4.62101212  4.48186363 -1.02872019\n",
            "  1.13768069 -1.75242087]. \t  -346.1124580495231 \t -199.328627991057\n",
            "33     \t [-4.1799218  -4.45154706 -4.88585799  3.29992834  4.47766872  2.47713079\n",
            "  3.6427257   3.86577761]. \t  -521.781914997654 \t -199.328627991057\n",
            "34     \t [ 3.01301725  3.8553045  -3.88809554 -4.85834064 -2.61026854 -1.37342995\n",
            "  1.88295781  4.79520638]. \t  -432.7268868751215 \t -199.328627991057\n",
            "35     \t [ 5.07085485 -3.97401201 -1.25011231 -1.41735359  3.83756823 -3.50633235\n",
            "  5.07507291  4.52887276]. \t  -561.8039314122386 \t -199.328627991057\n",
            "36     \t [ 0.73691287  4.83728344  3.59236137  2.52724612  3.7011516   2.38717938\n",
            "  2.51664583 -2.98347072]. \t  -329.8324273540846 \t -199.328627991057\n",
            "37     \t [ 1.18773227  0.36275172 -0.17617903  0.07896681 -4.36296088  4.46521958\n",
            "  0.83734118 -3.63776064]. \t  -327.372600845528 \t -199.328627991057\n",
            "38     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -199.328627991057\n",
            "39     \t [ 2.06591497 -4.76555177 -4.59712746  5.10204255 -4.53941633  2.52291351\n",
            "  4.33294481 -2.24399416]. \t  -530.1400791695247 \t -199.328627991057\n",
            "40     \t [-5.10005384 -4.63471942  3.08745159 -4.36641863 -2.64255602  2.69213337\n",
            "  1.78075593 -4.07341222]. \t  -407.17145874187145 \t -199.328627991057\n",
            "41     \t [ 4.71819464  2.44326222 -4.59210083 -3.91811804  4.7421209   2.68869153\n",
            " -2.25401074  3.39731296]. \t  -442.5799474329874 \t -199.328627991057\n",
            "42     \t [ 4.15119801 -3.7890752  -2.23374744 -3.21545964 -5.01646683 -0.51183972\n",
            " -2.85320924  2.44461252]. \t  -334.46347232718404 \t -199.328627991057\n",
            "43     \t [ 1.80051668 -2.37043873  4.19066744 -2.81504586  4.76482724 -1.91618353\n",
            " -4.43112498  4.83297437]. \t  -558.7164924975589 \t -199.328627991057\n",
            "44     \t [ 4.9350003  -0.63196453  4.13809554  4.95799701  4.61197129  3.55826056\n",
            "  3.16923487  4.22185433]. \t  -570.0709122194698 \t -199.328627991057\n",
            "45     \t [-1.80278406 -3.10713211 -1.29921195 -4.15657307  3.22529045 -4.77341303\n",
            "  4.18214993  0.99904375]. \t  -415.8735015928293 \t -199.328627991057\n",
            "46     \t [ 4.96653493 -4.34431375  4.23314429 -0.45513806 -4.61037836  1.8478346\n",
            " -0.79723806 -0.34783974]. \t  -249.181686634616 \t -199.328627991057\n",
            "47     \t [ 1.59199623e+00 -4.87901809e+00  5.00488963e+00  4.31183546e+00\n",
            " -2.91789352e-03 -4.59860322e+00  5.07559909e+00 -2.58527189e+00]. \t  -560.3424885399099 \t -199.328627991057\n",
            "48     \t [-4.46445217 -4.0322638   4.90869089  3.45268067  1.94240314  2.60049792\n",
            " -4.62632097  4.70334496]. \t  -558.6511270487639 \t -199.328627991057\n",
            "49     \t [ 3.14246405 -1.67027081 -4.71375118  3.44554255  4.64057804  2.99674309\n",
            " -4.98679332 -4.68425843]. \t  -640.7727008629149 \t -199.328627991057\n",
            "50     \t [-2.28715658 -4.40950515 -3.56469343  4.96403235 -2.98980986  5.11656387\n",
            "  2.33950645  4.34118189]. \t  -571.6562276561119 \t -199.328627991057\n",
            "51     \t [-3.5662317   1.66658374  1.9450782   4.2719409   4.11751328  3.13864707\n",
            "  3.33476976  3.57783681]. \t  -426.7492808819816 \t -199.328627991057\n",
            "52     \t [ 4.43170882 -5.07336186  0.53145969  4.53817549  0.74519174 -2.83439688\n",
            " -4.38298542 -0.10924247]. \t  -339.8943272008297 \t -199.328627991057\n",
            "53     \t [-0.04792754  4.92155106  3.88300939 -1.57304052  4.33876639  3.65621114\n",
            " -4.94209472  2.7734198 ]. \t  -510.41344704227845 \t -199.328627991057\n",
            "54     \t [-5.0476453   0.73437813  2.98108543  1.15693311 -4.866035   -4.21871444\n",
            "  4.86617725 -1.67874315]. \t  -472.0519219010078 \t -199.328627991057\n",
            "55     \t [-3.07897172  2.77912862 -3.47344638 -4.57507988 -2.17899594 -4.35398892\n",
            " -5.02538371  0.36309739]. \t  -460.1666135501882 \t -199.328627991057\n",
            "56     \t [-5.047947   -4.80913947  0.36448085 -1.6514873   3.90044885 -2.3744302\n",
            " -1.50603573 -3.71798713]. \t  -319.40504466564266 \t -199.328627991057\n",
            "57     \t [-4.95852587  3.80412098  1.37301834 -3.45741374 -0.59058903 -3.35934167\n",
            " -0.63749823 -4.86721656]. \t  -368.81826922052926 \t -199.328627991057\n",
            "58     \t [ 4.29779224  3.54245489 -4.50008554  1.50172201 -4.44771386 -4.23901939\n",
            "  4.13388326 -3.80489858]. \t  -555.5094439737558 \t -199.328627991057\n",
            "59     \t [-2.38255813 -4.88455733  4.33519427 -3.25814628 -4.0375606  -0.16171717\n",
            " -4.43660803 -1.64019942]. \t  -393.2110423675102 \t -199.328627991057\n",
            "60     \t [ 3.67860301  3.07679856  3.78739418  0.39381822  1.72383422 -2.89603246\n",
            "  3.8301275   4.8179005 ]. \t  -429.6854389803915 \t -199.328627991057\n",
            "61     \t [-1.50892764 -4.76916303 -3.51952957 -3.14992723  3.65441859  3.28455813\n",
            "  3.67218108 -5.02737727]. \t  -552.710510242246 \t -199.328627991057\n",
            "62     \t [-4.96061865 -4.58279843  5.06892387  2.33768658 -3.92731122  4.74314861\n",
            " -3.57875972 -4.50251435]. \t  -629.4902533990743 \t -199.328627991057\n",
            "63     \t [ 4.08681338  4.52597132  4.58541041  3.95388408 -1.91632763  5.00602184\n",
            " -1.41789787  4.49532946]. \t  -527.7416616961839 \t -199.328627991057\n",
            "64     \t [ 1.2587082   4.72923661  2.55212315 -3.76151183 -1.24304387 -4.78694473\n",
            " -5.09010368 -4.36831635]. \t  -601.688006164632 \t -199.328627991057\n",
            "65     \t [-4.9093221   3.95686232 -0.02820251 -4.37283839 -3.74960752  4.00553274\n",
            "  5.0191188   3.91430908]. \t  -597.3831484747747 \t -199.328627991057\n",
            "66     \t [-1.43743485 -1.37431474  3.08033702  4.53151652 -5.00760099  3.46257964\n",
            " -4.90539759  2.18734924]. \t  -520.4812341763061 \t -199.328627991057\n",
            "67     \t [-3.98487473 -0.61185515 -3.96382011  4.71661086 -2.28835111 -1.8231433\n",
            " -2.90467103  4.81858231]. \t  -443.6847851585256 \t -199.328627991057\n",
            "68     \t [ 3.56164073  2.73276624 -3.46244499  4.79798202  4.63089512  3.19069711\n",
            " -4.87148042  4.01699684]. \t  -619.188004856918 \t -199.328627991057\n",
            "69     \t [-0.49525621  4.70899373  4.0124245   3.11914942  0.53539195 -2.61371903\n",
            " -3.1960275   5.10673198]. \t  -454.3637665030693 \t -199.328627991057\n",
            "70     \t [-2.40305199  2.03330348 -3.9890426  -1.3103285  -4.75168066 -0.73979775\n",
            "  3.82908871  1.49569702]. \t  -305.3549997755738 \t -199.328627991057\n",
            "71     \t [-4.32059948 -4.41228861  4.21101052  3.38020055  2.98496012 -3.29889541\n",
            "  4.1920448   3.31387264]. \t  -477.2179054088453 \t -199.328627991057\n",
            "72     \t [-5.02721283  2.45075925  5.08328172 -2.39961338 -1.95604883  1.59701205\n",
            "  1.63348986  1.76232782]. \t  -215.79488601717114 \t -199.328627991057\n",
            "73     \t [ 4.89746697 -2.36067047  4.8205116   3.24662386 -4.39853923 -3.66257636\n",
            "  2.93352382  2.55544651]. \t  -436.7088943980925 \t -199.328627991057\n",
            "74     \t [ 2.93038191 -2.17216974  5.07131518  3.81141188 -0.69069585  3.51492019\n",
            "  4.73739774 -3.07627304]. \t  -462.6074312396842 \t -199.328627991057\n",
            "75     \t [-3.67955454 -1.91512817 -4.62527774  3.00027009  1.22636994  0.77160078\n",
            "  3.94160305 -3.3233718 ]. \t  -329.26478435534136 \t -199.328627991057\n",
            "76     \t [ 3.89586341  1.19848015  0.32543765 -0.82487994  2.21325068 -3.37760393\n",
            "  3.51907909 -3.59383137]. \t  -304.04395540879915 \t -199.328627991057\n",
            "77     \t [-3.77782858  4.94870437 -4.68718767  2.89314165  2.63087839  3.4181164\n",
            " -4.81112493 -2.28956827]. \t  -471.315766379938 \t -199.328627991057\n",
            "78     \t [-4.92861738  0.06435866  2.02436918 -4.43418312 -1.82262917  4.6271283\n",
            " -4.04414411 -2.43494642]. \t  -422.23089184843786 \t -199.328627991057\n",
            "79     \t [ 4.47086745  2.79035832  3.77137198  4.5555697  -1.1268271  -2.57020651\n",
            "  2.95990399 -2.23136012]. \t  -308.3868864983688 \t -199.328627991057\n",
            "80     \t [-1.66307265  2.04507944  4.81678052 -4.47838541  4.4212288   4.87286339\n",
            "  4.3134704  -2.81011177]. \t  -594.5794975361712 \t -199.328627991057\n",
            "81     \t [-4.94260884  1.34010952 -1.12310903 -4.60571628  3.62919257  2.18669716\n",
            " -0.74979494 -0.36796488]. \t  -216.219373606773 \t -199.328627991057\n",
            "82     \t [ 0.01470008 -4.16392496  1.86349614  4.53650436  4.09937468  4.08055765\n",
            "  1.61786492 -5.07669954]. \t  -535.8496007148458 \t -199.328627991057\n",
            "83     \t [-5.00239327  2.58783774 -4.44430397  0.81560769  5.1102833  -4.68019072\n",
            " -4.14141158 -1.55456389]. \t  -501.7265923965957 \t -199.328627991057\n",
            "84     \t [ 0.99622906  2.67715634  1.00385478  4.53149417 -4.70944116  0.27144697\n",
            " -3.69858302 -5.07070801]. \t  -513.2772687387759 \t -199.328627991057\n",
            "85     \t [ 3.84979047  0.5293945  -3.32768717 -4.65328049  4.61514885  3.74408532\n",
            "  4.43767309 -3.0878092 ]. \t  -539.948153195241 \t -199.328627991057\n",
            "86     \t [ 2.41851517  4.60253757 -3.91476471  3.33542101  4.9830239  -3.14746539\n",
            "  2.15525861  0.62962371]. \t  -357.9714533215046 \t -199.328627991057\n",
            "87     \t [ 4.35659483  2.72779411 -4.8639666  -3.2972893  -5.06069813  0.86432839\n",
            " -4.66759621  1.79373378]. \t  -459.1053568780966 \t -199.328627991057\n",
            "88     \t [ 0.22758818 -0.08050004 -4.61491935  2.86065008 -3.9593124  -2.53073919\n",
            " -4.84256476 -2.36164116]. \t  -422.2709189379676 \t -199.328627991057\n",
            "89     \t [ 0.98855744 -3.93581416  3.43529283 -1.71777834  2.92233029  5.0043523\n",
            " -4.11678736 -4.04684525]. \t  -521.7778145076988 \t -199.328627991057\n",
            "90     \t [-4.57473383  3.62555094  4.52457254 -4.47785823  4.95684624 -3.16348504\n",
            " -3.99321507  4.23400099]. \t  -626.7694860057343 \t -199.328627991057\n",
            "91     \t [ 3.87543522 -0.95478336  4.2637513   1.38596011 -4.81266529 -3.53617468\n",
            " -4.61149492  4.22835268]. \t  -561.7933405326593 \t -199.328627991057\n",
            "92     \t [ 4.53418242 -4.98251913 -2.15833129  2.68477314 -2.3292842   1.56259462\n",
            " -4.68302592 -5.02993904]. \t  -510.7124658568896 \t -199.328627991057\n",
            "93     \t [ 2.11648248 -4.57645883 -2.93316045  2.1446837  -2.83479918 -1.55101891\n",
            "  4.13132088  4.17678939]. \t  -404.2300447148257 \t -199.328627991057\n",
            "94     \t [ 4.10480024 -1.48316851 -4.54250109  2.23758479 -3.86301329 -4.55447117\n",
            " -5.04733164  4.96110332]. \t  -677.4819251594753 \t -199.328627991057\n",
            "95     \t [ 4.92402351  3.19870291  3.85278409 -4.71096053  3.91646076  4.91870375\n",
            " -3.42445189 -2.59368856]. \t  -535.7749020633737 \t -199.328627991057\n",
            "96     \t [-3.11411413 -3.33227606 -3.43883211 -4.08202019  2.25784263 -4.14243647\n",
            " -3.84376437  2.4696527 ]. \t  -414.6971819602664 \t -199.328627991057\n",
            "97     \t [-0.63740329 -3.77715645 -4.89441468  4.49921769  4.06183859 -4.05731658\n",
            "  2.2988587   5.11135757]. \t  -609.0424685934337 \t -199.328627991057\n",
            "98     \t [ 3.1206735   5.04757192  1.09681649 -4.82756549  4.9270567  -3.691652\n",
            " -2.50709028  1.84591868]. \t  -431.93218506632456 \t -199.328627991057\n",
            "99     \t [ 0.69291507 -4.00742319 -2.9274178   2.27626332  3.04766781 -4.82023849\n",
            " -4.07333779 -4.42610951]. \t  -537.7515546667062 \t -199.328627991057\n",
            "100    \t [-5.05325178 -5.10031512  0.69911643 -1.1639846  -1.60326803  4.43932491\n",
            "  3.73980917  2.92536563]. \t  -381.9108103527982 \t -199.328627991057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goBGvUay_Y_k",
        "outputId": "bebd6e8a-293b-49bd-ace0-52c5f70a48c0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 12\r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_winner_12 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_12 = dGPGO_stp(surrogate_winner_12, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.15884083  1.25039382 -0.63766795  2.9220719   2.86695228 -2.32865172\n",
            " -2.28900603  3.0911711 ]. \t  -235.23146270653385 \t -119.61569010596395\n",
            "init   \t [ 4.69134698  3.84955018 -1.45595116  0.01019009  1.87866046  2.17806876\n",
            " -1.32863227  0.62664895]. \t  -119.61569010596395 \t -119.61569010596395\n",
            "init   \t [ 0.03157161 -4.97901108  2.79374461  3.91824579 -1.38356752  1.18165687\n",
            " -4.34809609 -1.34324218]. \t  -299.1328730459762 \t -119.61569010596395\n",
            "init   \t [ 4.43535464  1.55011219 -1.0526456   2.95659666 -1.87559811  0.6973302\n",
            "  3.77986447 -0.65358414]. \t  -186.70407348837227 \t -119.61569010596395\n",
            "init   \t [ 3.09399185 -3.64782772  2.09163234  2.0949126  -2.87956884  4.35064452\n",
            " -0.59247866  4.19139542]. \t  -364.893303476081 \t -119.61569010596395\n",
            "1      \t [ 2.97496712  5.03891421  4.69813004  2.98971275 -2.19903017  1.27914706\n",
            " -0.22431953 -3.11628617]. \t  -273.6406716394283 \t -119.61569010596395\n",
            "2      \t [-0.24180414 -2.21543246 -3.5449624   2.8387371  -4.51621751 -4.30978558\n",
            "  1.68180186  0.23905261]. \t  -313.49172527062245 \t -119.61569010596395\n",
            "3      \t [ 1.34642708  3.01603741  2.92575758 -3.6354322  -4.2241213  -2.49080909\n",
            "  1.4348023   0.71380879]. \t  -243.47904169319926 \t -119.61569010596395\n",
            "4      \t [ 0.86109473 -3.15275839  4.71621581 -0.93942814  3.2844691  -1.63986699\n",
            " -4.65618777  3.48889083]. \t  -410.0925653321129 \t -119.61569010596395\n",
            "5      \t [-5.0392713   1.28642045  0.78649942 -2.71140686  1.90152795  4.89785969\n",
            "  1.88625656 -3.78633376]. \t  -361.57621590745845 \t -119.61569010596395\n",
            "6      \t [-1.73037951 -4.1690811  -4.06246691 -4.6495486  -3.72257011  1.46777661\n",
            "  0.88706436  2.47126902]. \t  -310.32020543077647 \t -119.61569010596395\n",
            "7      \t [-4.48115473  4.69856248 -2.58544488  0.7519363  -3.12662811 -0.47930587\n",
            " -3.5600688  -4.48065658]. \t  -386.1352526901647 \t -119.61569010596395\n",
            "8      \t [ 2.07307859 -3.09035017  0.37745416 -2.94123437 -2.31053681 -3.39288785\n",
            " -1.0912393  -4.69515644]. \t  -338.88364085417396 \t -119.61569010596395\n",
            "9      \t [-2.63884853 -4.74823966 -4.72667146  0.53968904  2.55330202 -0.94153795\n",
            " -3.71978724 -4.39722242]. \t  -409.70236539299896 \t -119.61569010596395\n",
            "10     \t [ 2.00346449 -1.09148065  5.11892961 -4.2726464   4.11731509  3.93264314\n",
            "  1.21318876 -3.11611023]. \t  -423.5683225137209 \t -119.61569010596395\n",
            "11     \t [-4.99777619  3.54079835 -4.03410463 -2.99367945  5.08636374  3.52706711\n",
            " -4.2657072  -5.00335179]. \t  -666.361473147168 \t -119.61569010596395\n",
            "12     \t [ 4.18456152 -2.43313627  1.66811276  4.46499799  4.26605991  4.55246158\n",
            "  4.62909664  0.97949457]. \t  -490.46428928299486 \t -119.61569010596395\n",
            "13     \t [-2.62653652 -0.2206364   4.47978458  1.28741919  4.67219993  0.9389212\n",
            " -2.76078903 -4.09616054]. \t  -375.84989828682956 \t -119.61569010596395\n",
            "14     \t [ 1.9283171  -2.48042747  1.67965135  0.7074178  -0.26196646 -2.70227431\n",
            "  4.90874781  5.09965023]. \t  -447.36783977840696 \t -119.61569010596395\n",
            "15     \t [ 1.88737595 -3.75061764 -3.25828183 -1.738482   -1.06378709  5.06567904\n",
            " -4.54278396 -1.12817118]. \t  -389.90013761997153 \t -119.61569010596395\n",
            "16     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -119.61569010596395\n",
            "17     \t [ 2.2066092   4.72028097 -0.17834306 -3.35826476  0.05454814 -3.20219048\n",
            " -4.28144707 -5.09457459]. \t  -492.1304822375849 \t -119.61569010596395\n",
            "18     \t [-5.05511133  0.29818975 -4.7771362   2.10253213  1.84100063 -5.03393887\n",
            "  2.23816984 -3.10161592]. \t  -392.89330087974093 \t -119.61569010596395\n",
            "19     \t [ 1.54813289  3.14450572 -1.05288077 -4.74230646 -2.16535034  4.17208938\n",
            "  4.6513583   3.37198651]. \t  -485.7460754221071 \t -119.61569010596395\n",
            "20     \t [-4.88964196  3.8463487   0.82306425 -2.2179785   1.28984697  4.98121115\n",
            " -4.14516407  5.10901577]. \t  -561.4937603080291 \t -119.61569010596395\n",
            "21     \t [-3.49579749 -4.53396831 -0.06142374  1.25144705 -2.78717748  1.89527687\n",
            "  2.4387612  -2.55499805]. \t  -213.86138626084616 \t -119.61569010596395\n",
            "22     \t [-1.02913297  3.05654669 -4.77805609 -3.37768365 -4.09372401 -3.2770608\n",
            " -5.07939935  2.14153806]. \t  -499.38772957658125 \t -119.61569010596395\n",
            "23     \t [-1.94476667e+00  4.35313893e+00 -3.91396958e+00  2.34577227e+00\n",
            " -4.78904294e+00 -9.99104168e-05  4.60152852e+00 -4.84530698e+00]. \t  -560.358930861183 \t -119.61569010596395\n",
            "24     \t [ 4.55218172 -4.92133698 -4.80947918 -3.13791836  3.66924879 -4.22177678\n",
            " -2.46897693 -3.5962942 ]. \t  -498.3357843946825 \t -119.61569010596395\n",
            "25     \t [-2.34690635  0.41408083 -2.06700835  4.92542739 -3.1974964   4.86060871\n",
            "  1.08929342  4.74662173]. \t  -497.1300874013109 \t -119.61569010596395\n",
            "26     \t [ 5.04663954  3.35672373  4.31958814  2.7702407   0.28819888 -3.80267746\n",
            " -5.10019833  1.41368334]. \t  -419.9268124961101 \t -119.61569010596395\n",
            "27     \t [-4.06957082  3.07781431 -5.04564028 -4.63868102  4.5238576   0.09073362\n",
            " -3.8670247   3.63065877]. \t  -510.45865064750575 \t -119.61569010596395\n",
            "28     \t [ 3.83137915  2.46955649 -4.13832376  4.76995056 -4.05417157  3.24549292\n",
            " -3.47381587  2.05103212]. \t  -432.77028943630796 \t -119.61569010596395\n",
            "29     \t [ 4.86698847 -4.53021179 -4.96600432  4.39513996  3.98583518  2.34860751\n",
            " -4.75623567 -0.37634072]. \t  -488.001489146732 \t -119.61569010596395\n",
            "30     \t [-0.44720792  4.30582995 -4.04672944 -1.05179276  2.38559567 -3.788819\n",
            "  4.80093653  1.32439879]. \t  -380.79489585327235 \t -119.61569010596395\n",
            "31     \t [-1.51776197  2.32886686  2.72006487  1.44556497  4.79044927 -2.58496721\n",
            "  4.46864589 -4.40749841]. \t  -493.7299987837579 \t -119.61569010596395\n",
            "32     \t [ 2.6003205   4.89571569 -4.53008988 -4.65627315 -3.92988438  1.99241618\n",
            " -1.1893431  -3.00156511]. \t  -386.00158621979153 \t -119.61569010596395\n",
            "33     \t [-4.39438117 -3.31601208  3.50918488  1.68084875 -5.03221834 -4.68465139\n",
            "  0.75535839  3.0659118 ]. \t  -427.03094801058035 \t -119.61569010596395\n",
            "34     \t [-4.75751848  1.22824796  4.80051768  1.89165417  3.78471419 -2.1423962\n",
            "  5.03887888  3.90413793]. \t  -507.9294228221502 \t -119.61569010596395\n",
            "35     \t [-1.14161101  0.4287262   2.66577586 -2.24816089 -5.11953854  3.58940104\n",
            " -3.30200712 -3.01031686]. \t  -400.3768715559916 \t -119.61569010596395\n",
            "36     \t [-4.84221901 -3.4614988   4.80215635 -4.28950909  0.3726752  -1.35871651\n",
            " -0.46968575 -1.30732719]. \t  -217.18086774601292 \t -119.61569010596395\n",
            "37     \t [ 4.58389797  1.42426849  4.90273498 -2.07537653  4.65302224  2.62210961\n",
            "  2.4603855   3.74783547]. \t  -418.65885967484724 \t -119.61569010596395\n",
            "38     \t [ 0.58586851 -2.94437998  4.561808   -4.77113352 -4.35529467  4.78139081\n",
            "  3.91335712 -1.40046319]. \t  -526.0711971666101 \t -119.61569010596395\n",
            "39     \t [ 4.67775899 -1.99140585 -1.96895445  4.59805379  3.99967103 -4.26973217\n",
            " -1.54744303  1.51864418]. \t  -350.5943824041008 \t -119.61569010596395\n",
            "40     \t [-1.74789758 -4.58602859 -3.61319229  1.64332143  3.00998693  4.07861416\n",
            "  0.77043408  4.81973765]. \t  -430.1905755273003 \t -119.61569010596395\n",
            "41     \t [ 4.86812743 -3.61332722 -3.22371878 -4.74041688 -1.86285629 -4.8707853\n",
            "  0.26677496  4.22036275]. \t  -473.5625696622485 \t -119.61569010596395\n",
            "42     \t [-4.56320343  4.27462385  4.91400996  2.87007513 -2.13497759  4.26022915\n",
            " -4.39562268 -0.13826234]. \t  -429.85083432363854 \t -119.61569010596395\n",
            "43     \t [-4.00678166 -5.02703925  2.81888431 -3.36797491  4.50920547  4.80489422\n",
            " -4.59456991  2.26407755]. \t  -564.7734999702807 \t -119.61569010596395\n",
            "44     \t [ 4.68300896 -5.09764682  3.74151609  3.12566115 -0.67591516 -3.74048108\n",
            "  2.49653883 -2.65904451]. \t  -341.4030207466335 \t -119.61569010596395\n",
            "45     \t [-4.41805214  4.00245809 -2.93510097 -3.64968047 -4.34103186 -4.21730146\n",
            "  4.81189421  3.86715418]. \t  -613.3395601758556 \t -119.61569010596395\n",
            "46     \t [ 4.61082078  2.4875075  -2.51702414  2.79975735 -4.76863093 -3.65302392\n",
            " -3.54125757 -4.34176797]. \t  -516.3536882519304 \t -119.61569010596395\n",
            "47     \t [-3.35896803  2.29638973  4.64543696 -5.04885191  4.87332189  4.9024958\n",
            "  5.0780048   1.1169216 ]. \t  -641.9695161526813 \t -119.61569010596395\n",
            "48     \t [-2.59882387  1.21650903  5.10644339  2.24360444 -2.12492704  4.27522309\n",
            "  3.6531234   3.35171941]. \t  -423.60713732187355 \t -119.61569010596395\n",
            "49     \t [ 4.87604017 -3.89549963 -4.93033226  3.65708891  0.34171984  3.22019456\n",
            "  3.04678932 -3.93917358]. \t  -432.4662924337722 \t -119.61569010596395\n",
            "50     \t [-4.77445343  3.53698109  1.04205432 -3.7642153   3.45654636 -3.95889214\n",
            " -0.83902015 -0.18336627]. \t  -266.7229695706896 \t -119.61569010596395\n",
            "51     \t [-0.43008236 -1.56694046 -1.94574087 -4.7504723   4.85077624 -4.22108747\n",
            " -1.01361159  4.41890664]. \t  -494.6826199043031 \t -119.61569010596395\n",
            "52     \t [ 3.58798644  4.17182175  5.02132741  3.48903439  1.4815132  -4.46046567\n",
            "  3.42358888  2.99757436]. \t  -456.295744115184 \t -119.61569010596395\n",
            "53     \t [-0.85791143  3.81790521  0.79658212  2.82262165 -3.98177874 -0.87400618\n",
            " -1.55508627  3.22017662]. \t  -247.40169647843643 \t -119.61569010596395\n",
            "54     \t [-5.07507089  3.57398676  3.39224312  4.90007055  3.08466668  4.99674869\n",
            "  4.25039793 -4.14042069]. \t  -642.8544861954965 \t -119.61569010596395\n",
            "55     \t [-2.46015498 -4.75111412 -4.08193474  4.42597258 -4.11288791 -0.18166605\n",
            " -4.90122427  2.06028677]. \t  -466.4315380362501 \t -119.61569010596395\n",
            "56     \t [ 4.78814417  2.54222543 -4.69643517 -4.90911118  4.55580953 -4.68983276\n",
            " -5.11092906  2.36343119]. \t  -661.7009622462532 \t -119.61569010596395\n",
            "57     \t [ 4.89958131  4.8462347  -3.71519661 -4.83422941  4.61283229 -0.64523856\n",
            "  3.01914575  5.07236996]. \t  -584.3923212906969 \t -119.61569010596395\n",
            "58     \t [ 0.11130335  4.96719695 -5.10605507 -5.08875359  3.33974552  3.5274559\n",
            "  4.23351711 -2.89351758]. \t  -554.020920438892 \t -119.61569010596395\n",
            "59     \t [ 1.6706635  -4.54363587 -2.04418182 -3.12542023  4.15831533  0.4600055\n",
            "  1.95976533 -0.95283098]. \t  -217.56483312846123 \t -119.61569010596395\n",
            "60     \t [ 2.07839624  2.88614439 -3.76879187  3.71903075  4.67303152  0.97977287\n",
            "  3.34008443 -4.7580745 ]. \t  -493.0687040758986 \t -119.61569010596395\n",
            "61     \t [ 4.84188277  0.66620769  1.32422865  4.9365634   3.22296603  4.47301989\n",
            " -2.4871344  -4.5436847 ]. \t  -507.51729145120305 \t -119.61569010596395\n",
            "62     \t [-4.11826896  2.71191907 -4.79783108  4.68965678  3.52865034  2.20018279\n",
            "  4.66814349  3.60065913]. \t  -536.2588282888481 \t -119.61569010596395\n",
            "63     \t [-5.0912035   2.91828567 -4.56607276 -2.24639912  1.49323033  4.82745367\n",
            "  2.23691256  3.58362837]. \t  -414.42555345496976 \t -119.61569010596395\n",
            "64     \t [ 4.26483296  4.85624127  2.12298824 -2.69545986  4.32999409 -1.78910574\n",
            " -4.93791663  3.97710804]. \t  -518.1081034145167 \t -119.61569010596395\n",
            "65     \t [-3.01363237 -0.33356604 -2.28265103  4.61346219  2.56456966  4.2243148\n",
            " -4.01059172 -1.4682208 ]. \t  -379.86553453870425 \t -119.61569010596395\n",
            "66     \t [-2.30830527  4.34998862  4.21833921  2.75075991 -4.19466759 -3.61512681\n",
            " -3.9981206  -3.86006172]. \t  -524.3093748112951 \t -119.61569010596395\n",
            "67     \t [-0.03956994 -4.5262892   4.55960124 -4.25540786 -1.76247407  4.47669575\n",
            " -2.84594845  1.99076548]. \t  -399.95756727034484 \t -119.61569010596395\n",
            "68     \t [-4.92098352 -5.11753372 -1.89334865 -2.18845719 -3.94273322 -4.05398212\n",
            "  4.78896239  1.00849034]. \t  -451.51596787090716 \t -119.61569010596395\n",
            "69     \t [-2.04668385 -5.03552996  3.71185002  4.11367708  4.90930832  4.61874629\n",
            " -1.57963657  1.56124879]. \t  -449.39507580931314 \t -119.61569010596395\n",
            "70     \t [-1.20145452  4.59586557 -1.36625083  2.17475419  4.18479     4.75261403\n",
            " -1.10832968  2.05236395]. \t  -333.5883231708578 \t -119.61569010596395\n",
            "71     \t [ 4.61307037  4.23019934  3.34652422 -2.02835908 -2.97503499  3.12197206\n",
            " -4.0697201   4.50111347]. \t  -487.87718135289583 \t -119.61569010596395\n",
            "72     \t [ 4.79458611 -1.32968021 -4.14022564 -2.46976684 -2.46751438  3.84467004\n",
            "  2.05839472 -0.12383459]. \t  -251.2612169826972 \t -119.61569010596395\n",
            "73     \t [-4.95550642 -3.99664374  4.10428556  3.10896971 -4.60109208 -3.57815088\n",
            " -1.22344073 -4.80463174]. \t  -523.5243803410103 \t -119.61569010596395\n",
            "74     \t [ 2.02333463 -4.45047343 -3.96746597 -0.25808233 -4.59102426 -4.71563621\n",
            " -4.96702844  5.06401339]. \t  -707.8604157669331 \t -119.61569010596395\n",
            "75     \t [-4.32356719 -5.0660311   0.2461429  -4.56920997  3.93660365  1.94506585\n",
            "  4.03427129  3.43671557]. \t  -462.31450757745864 \t -119.61569010596395\n",
            "76     \t [-0.47699912  4.27851823  3.31575281 -5.03738759  2.07345583  2.20598403\n",
            " -5.08795016 -1.45302439]. \t  -420.1178947536827 \t -119.61569010596395\n",
            "77     \t [ 4.25330716 -1.13653418 -4.0345726  -4.78654119 -4.2022719  -5.05707867\n",
            "  4.84276709 -3.21831744]. \t  -649.9182790991416 \t -119.61569010596395\n",
            "78     \t [-4.50424512  4.968231    1.41296567 -0.6202619  -4.89791107 -4.89147132\n",
            "  2.48022735 -3.11352601]. \t  -461.3028401319146 \t -119.61569010596395\n",
            "79     \t [-3.54176325  5.002253   -2.80441001  0.35305916 -4.75344077  4.94456036\n",
            " -0.71920205 -0.38268097]. \t  -351.1422839182854 \t -119.61569010596395\n",
            "80     \t [ 3.82907685  3.12475399  5.06228022 -1.72960879  1.45083607 -3.7007238\n",
            "  4.12194676 -2.44934601]. \t  -382.6604829707443 \t -119.61569010596395\n",
            "81     \t [-0.32122573 -2.47806832 -3.84392524 -4.73270949 -0.42275451 -0.98780956\n",
            "  4.04421086 -4.81187647]. \t  -452.77721618608535 \t -119.61569010596395\n",
            "82     \t [-4.87761867  1.18782038  0.83390706 -4.37916295 -4.49155976 -5.01451002\n",
            " -3.46621035 -0.9499352 ]. \t  -448.47119834693416 \t -119.61569010596395\n",
            "83     \t [ 4.90962147  3.6406731   2.26649059  4.77802827  4.12003519 -3.1547146\n",
            " -3.56596834 -4.88897631]. \t  -582.1589605949364 \t -119.61569010596395\n",
            "84     \t [-3.98734284 -4.41840132  4.1888291   3.20467834  4.23902431 -2.9553085\n",
            "  1.08340133 -1.39956968]. \t  -314.79856141891105 \t -119.61569010596395\n",
            "85     \t [-3.99504014 -5.01734193  4.1852742  -4.30777797 -2.59269713  1.088131\n",
            "  2.0526925   4.93140311]. \t  -457.8444355993787 \t -119.61569010596395\n",
            "86     \t [-4.9619588  -1.93995357 -1.77562744 -5.11517945  0.4733362   4.82019142\n",
            " -4.56434509 -1.41832191]. \t  -448.71820302914887 \t -119.61569010596395\n",
            "87     \t [-4.81137533  5.07163659  4.28508698 -1.65960128 -1.57059261 -4.00193278\n",
            " -3.32907995  4.39027831]. \t  -480.8977089208625 \t -119.61569010596395\n",
            "88     \t [-4.40418477  0.59069985  2.03063856  5.0568018  -0.39799642  0.39195162\n",
            "  1.04693073 -2.43165914]. \t  -191.44009212995599 \t -119.61569010596395\n",
            "89     \t [ 4.7951598   2.14252526 -4.44605075 -4.78192979  1.42594865 -2.76902876\n",
            "  0.60907522 -5.07449584]. \t  -447.7165404776188 \t -119.61569010596395\n",
            "90     \t [ 2.4280269  -4.36970659 -4.42196584  1.35064904 -3.05364177 -1.71522398\n",
            " -5.11245683 -2.24477942]. \t  -397.5907241535862 \t -119.61569010596395\n",
            "91     \t [ 1.35713706  4.78144111 -3.86326492  1.48320135  3.331725   -4.71670523\n",
            " -2.25587509 -0.73078059]. \t  -330.02110765144084 \t -119.61569010596395\n",
            "92     \t [ 4.85605615 -1.70735945  4.81068094 -1.31290736 -2.34661974  2.82699816\n",
            "  1.11606884 -4.92846366]. \t  -384.256223253269 \t -119.61569010596395\n",
            "93     \t [ 1.45251257 -4.46352242 -4.01037204  4.72726268  2.81601702 -4.03056254\n",
            "  1.1478216  -4.55706167]. \t  -492.0724742447515 \t -119.61569010596395\n",
            "94     \t [ 3.66941472 -4.1960224   5.01828031 -4.37953847 -5.05466779 -2.78962036\n",
            "  1.60266347  1.30609286]. \t  -407.015615214959 \t -119.61569010596395\n",
            "95     \t [ 3.35563621  0.35727173 -0.88260405  2.43561154 -3.60152803  4.47841961\n",
            " -4.39818401 -4.49570851]. \t  -519.8731561182135 \t -119.61569010596395\n",
            "96     \t [-4.93675484  1.95487792  4.02003756 -1.90560612 -4.7538452   3.0902354\n",
            "  5.02904314 -4.91364181]. \t  -635.504569193655 \t -119.61569010596395\n",
            "97     \t [-1.1688348  -0.83046467  0.30217384  3.28678641  0.57048865 -4.212293\n",
            " -4.66929131 -4.60107623]. \t  -476.2942544128905 \t -119.61569010596395\n",
            "98     \t [ 3.45949197 -2.85183826  3.96941805 -2.1377705   4.40814463 -3.25317517\n",
            " -0.12373398 -3.12741314]. \t  -332.7935991644325 \t -119.61569010596395\n",
            "99     \t [-1.39384566 -1.70353842 -3.4553154  -4.88561014  3.13981128  5.07031391\n",
            " -2.54505993  4.65058873]. \t  -560.9469386664289 \t -119.61569010596395\n",
            "100    \t [-3.77646078  5.09737885 -3.70611482 -5.092573   -1.56595326 -3.89622964\n",
            " -0.52205896 -2.59371148]. \t  -370.24247159861125 \t -119.61569010596395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bpn-kmNuvqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6f5667-de67-41a1-9e8c-8ee343f01962"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 13 \r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_winner_13 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_13 = dGPGO_stp(surrogate_winner_13, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.64499773 -0.88472932  1.72137019 -2.76537936  3.15062616  1.40102108\n",
            " -3.35673495 -2.45364871]. \t  -232.19635670005127 \t -232.19635670005127\n",
            "init   \t [ 4.2528767  -0.38076919 -3.88924462  3.90026757 -2.80351794  3.18914893\n",
            " -0.55419986 -4.1015814 ]. \t  -361.66026260752943 \t -232.19635670005127\n",
            "init   \t [ 4.03920839  1.42981319  4.41130989  3.62084556  3.50044048  0.52242587\n",
            " -2.97909353  3.81846156]. \t  -372.8981589252669 \t -232.19635670005127\n",
            "init   \t [ 3.80219612  2.41871092 -4.9313143   3.0755089  -1.83535427 -0.17449361\n",
            "  2.95749718 -3.92317458]. \t  -338.32885418149425 \t -232.19635670005127\n",
            "init   \t [-2.96300648  4.98598367  2.14768853 -4.67440231  5.05344835  0.67544515\n",
            "  0.4351207  -3.01593487]. \t  -364.25359293813665 \t -232.19635670005127\n",
            "1      \t [ 4.80987456 -3.46820678  2.58262962 -0.28783238 -2.10049364 -0.26524925\n",
            " -0.19379678  0.5408205 ]. \t  \u001b[92m-92.61843242301455\u001b[0m \t -92.61843242301455\n",
            "2      \t [ 1.9543379   2.0934188  -0.94255966 -1.7405562   0.06261135 -4.8506502\n",
            "  3.45925627  2.40979353]. \t  -298.78210274080607 \t -92.61843242301455\n",
            "3      \t [-1.23180471 -1.94356327 -0.00824713  3.53112869  1.31592708 -0.83747358\n",
            "  3.10154041 -0.85011777]. \t  -144.93286693920209 \t -92.61843242301455\n",
            "5      \t [-4.68664521  1.70175046 -4.74500152 -1.92806708 -3.9301831   3.56090291\n",
            "  3.61185688 -1.52682267]. \t  -373.45138510689867 \t -92.61843242301455\n",
            "6      \t [-3.39709501 -0.75844229 -0.28988583  0.01269954  5.05807698  4.77249476\n",
            "  1.49596497  2.4718132 ]. \t  -342.06868330388926 \t -92.61843242301455\n",
            "7      \t [ 1.40063251 -0.43083079  1.21708151  3.95004302 -2.16375609  4.01670843\n",
            " -0.05043856  4.98652521]. \t  -388.3423826855039 \t -92.61843242301455\n",
            "8      \t [-2.71667671  0.56608726 -4.65744745  1.81555904  3.58337557  2.71601054\n",
            " -3.16488768 -4.56282399]. \t  -431.4153928965887 \t -92.61843242301455\n",
            "9      \t [-1.3712379   4.43342592 -2.34034832  1.15808497  4.58355243 -2.713087\n",
            " -3.48221122  4.82787565]. \t  -483.5446007985546 \t -92.61843242301455\n",
            "10     \t [ 0.55827506  3.56701067  0.69739806 -0.52643575 -3.62135875  4.01257402\n",
            " -0.926893   -1.26369398]. \t  -209.29142411765054 \t -92.61843242301455\n",
            "11     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -92.61843242301455\n",
            "12     \t [ 1.20673026 -1.89358767 -1.93268573 -3.73300418 -1.84005015 -2.43666024\n",
            " -4.28984156  3.94615516]. \t  -381.52376011944966 \t -92.61843242301455\n",
            "13     \t [ 4.94977688 -4.68277233 -1.33876797  2.9531957  -4.10073761 -4.88543912\n",
            " -2.67575729 -5.09230559]. \t  -593.4750491246078 \t -92.61843242301455\n",
            "14     \t [-0.41652349 -4.53064711 -2.60332916 -0.78582198 -2.75861119  3.95062035\n",
            "  4.17043797  3.20451546]. \t  -399.6223614635618 \t -92.61843242301455\n",
            "15     \t [-3.85042816  1.41046709  4.97664168  3.54390539  0.94631968 -4.40687672\n",
            " -4.11689158  2.38758432]. \t  -428.58960482287085 \t -92.61843242301455\n",
            "16     \t [-4.97110094  0.28733202  1.26531007  0.26463666 -3.92034586 -2.39177041\n",
            "  3.54721064 -4.13560123]. \t  -366.03357915512356 \t -92.61843242301455\n",
            "17     \t [ 3.98492677 -0.82572679 -4.31881527  0.83692829  3.96402232  4.4478775\n",
            "  1.85034518 -0.39119157]. \t  -298.46132057166074 \t -92.61843242301455\n",
            "18     \t [-4.33877585 -0.46941136  4.99224157  0.49748171  3.59173759 -1.7542332\n",
            "  4.08379355  4.95281274]. \t  -490.97436975790083 \t -92.61843242301455\n",
            "19     \t [ 1.64253049 -3.93872469 -3.42833038 -4.63449444  0.20357174 -0.95615576\n",
            "  0.79186068 -4.27655536]. \t  -311.2928329614486 \t -92.61843242301455\n",
            "20     \t [ 2.82550194  4.30172305 -4.85986814 -3.65740813  4.81102314 -0.4028026\n",
            "  0.91879643  1.83147431]. \t  -318.80150673084734 \t -92.61843242301455\n",
            "21     \t [-4.26256236  2.20180573 -3.88250667  4.64725405 -1.34128031  3.1159942\n",
            "  4.88884876  4.04286214]. \t  -524.7902427223751 \t -92.61843242301455\n",
            "22     \t [-1.74663734 -4.87617518 -3.6133213   2.82223463  2.49202577 -0.87298326\n",
            " -4.3198933   3.34715573]. \t  -377.51473576852595 \t -92.61843242301455\n",
            "23     \t [ 5.11002054  1.70729065 -4.37341998  0.55123828 -3.23966382  1.30027833\n",
            "  3.96065647  4.42190168]. \t  -419.3926184798777 \t -92.61843242301455\n",
            "24     \t [-3.41610139  2.7540363  -4.52229061 -3.95475925  3.42889359 -3.66940931\n",
            "  4.94971658 -4.61778596]. \t  -632.416381379151 \t -92.61843242301455\n",
            "25     \t [ 2.18662094 -2.51984916  3.14713159 -2.2904857   4.58521492 -3.47418769\n",
            "  4.2545655  -2.33035305]. \t  -415.87371746266956 \t -92.61843242301455\n",
            "26     \t [-4.82713991  4.31556158  3.57451684  1.02807856  4.76765004  4.49767619\n",
            " -5.04359259  1.79163218]. \t  -541.8800486402343 \t -92.61843242301455\n",
            "27     \t [ 0.81237977  2.90601183 -0.25933528 -5.03489465 -3.61275704 -3.95661515\n",
            " -4.22697307 -2.5917805 ]. \t  -457.15079785969925 \t -92.61843242301455\n",
            "28     \t [-4.88829526  2.64832431  2.13880944 -4.44431822 -2.34635149  5.05000617\n",
            "  0.29762488  3.43929378]. \t  -406.4462470964444 \t -92.61843242301455\n",
            "29     \t [-4.16629307 -2.89818882  3.97386188 -4.91684102  2.48155922  1.34014929\n",
            " -4.52409412  4.51540003]. \t  -526.1824058499537 \t -92.61843242301455\n",
            "30     \t [-3.76374974  4.38076595  0.9145554   2.5771412   1.60653691  3.63818437\n",
            "  4.86189429 -3.74321405]. \t  -451.5063357579247 \t -92.61843242301455\n",
            "31     \t [-1.80664145 -2.35007288  4.43378435 -1.72082173 -4.46234372  4.72698052\n",
            " -4.34230752 -3.68202005]. \t  -559.2061211928544 \t -92.61843242301455\n",
            "32     \t [ 3.33783062  4.93745923  4.47993774  2.46764311 -2.26135487 -3.61573921\n",
            "  1.13495538 -0.35794829]. \t  -258.51662825198724 \t -92.61843242301455\n",
            "33     \t [-4.01192713 -4.20629787 -2.64376671  4.74452692 -4.9106467  -4.38471798\n",
            " -0.51091478  2.30773331]. \t  -442.85115984787905 \t -92.61843242301455\n",
            "34     \t [-4.20240708 -4.3379147  -3.64259878 -4.33493758  2.70764992 -3.84493245\n",
            "  3.84589384  4.71418666]. \t  -576.9501630057957 \t -92.61843242301455\n",
            "35     \t [ 1.26146494  1.73632468 -3.84880665  3.24852481 -5.0032528  -4.71091774\n",
            " -3.96448792  1.11836436]. \t  -472.6177629999363 \t -92.61843242301455\n",
            "36     \t [-0.18586755  2.82976332  4.73509369  4.29501048  4.57800208 -4.62000798\n",
            "  4.98006118  0.10885609]. \t  -563.6606850302481 \t -92.61843242301455\n",
            "37     \t [ 3.12414101 -3.58892378 -1.38372145  4.83718558 -2.24756551 -2.56274114\n",
            "  5.09447137  4.45859528]. \t  -540.2301686720825 \t -92.61843242301455\n",
            "38     \t [ 2.27690887 -2.50824054 -4.75329065  2.71242431  4.1746703  -4.13912341\n",
            " -3.08322165 -4.63876085]. \t  -543.5991774802244 \t -92.61843242301455\n",
            "39     \t [-3.3602684  -1.65281082  3.73244419  4.79549319 -2.08975598  0.4050948\n",
            " -3.74298342 -4.69029098]. \t  -447.4155307012515 \t -92.61843242301455\n",
            "40     \t [-1.61198817  4.07593571  1.32108499  1.31842269  1.3058913  -2.11810397\n",
            " -3.81367376 -4.75733673]. \t  -366.3254814907367 \t -92.61843242301455\n",
            "41     \t [ 2.04452364  5.04520206 -1.24760379  4.77208668  4.92321545  1.79752958\n",
            "  3.29163715  1.67700857]. \t  -389.7689108946041 \t -92.61843242301455\n",
            "42     \t [ 4.44998884  4.83189181 -3.48850946  4.71549053  0.48593049  0.06889903\n",
            " -4.62393859  2.76595884]. \t  -404.0282640278795 \t -92.61843242301455\n",
            "43     \t [ 4.77241485  2.9143137   4.24893623  3.12063071 -3.29403863  3.2318535\n",
            "  4.67989025 -0.29916536]. \t  -403.8244367304283 \t -92.61843242301455\n",
            "44     \t [ 1.30602149  0.99528055  3.93122024 -2.42708411  0.48608673  4.33388996\n",
            "  4.1702001   4.01793171]. \t  -438.3744844596057 \t -92.61843242301455\n",
            "45     \t [-5.031867   -3.52852097  3.05148882 -4.18032025  3.98859454  1.67176189\n",
            "  1.0870498  -2.49473033]. \t  -302.43000280207525 \t -92.61843242301455\n",
            "46     \t [ 0.36848609 -4.97536301  4.49143081 -2.28187137  2.26556328 -4.99986844\n",
            " -2.07276342  2.54332337]. \t  -388.46923507795947 \t -92.61843242301455\n",
            "47     \t [ 3.84582711  1.11961907 -4.42950259 -4.84312616 -5.00527102  3.83690828\n",
            "  2.69424858 -2.82329363]. \t  -498.1580474301615 \t -92.61843242301455\n",
            "48     \t [ 1.95079555  4.33738499  5.1028963  -3.96958547 -4.20416601  4.80999719\n",
            " -4.41724853  4.54891915]. \t  -711.8979198917001 \t -92.61843242301455\n",
            "49     \t [-4.13980672  4.5698936  -2.56086151  4.76226719 -2.06732464  2.71820952\n",
            " -3.93775772  1.72508922]. \t  -367.3467924206076 \t -92.61843242301455\n",
            "50     \t [ 3.96461148 -1.02211002 -4.87039666 -1.80130428 -3.23055     4.82055135\n",
            " -4.59658249  2.74204923]. \t  -501.6078658536871 \t -92.61843242301455\n",
            "51     \t [ 4.48266562  3.23200429  0.70356907 -4.16644147  2.08805431  1.2452743\n",
            "  4.91729907 -4.99949793]. \t  -512.2307105321062 \t -92.61843242301455\n",
            "52     \t [ 0.81079588 -4.47843051 -4.64981392 -4.55893117  3.29643148  3.97676935\n",
            " -2.46764467  4.48189518]. \t  -541.3122276053964 \t -92.61843242301455\n",
            "53     \t [ 2.83803478  0.60206719 -4.77773543  4.43372848  4.77830384  3.98955078\n",
            " -3.40965668  5.11550666]. \t  -656.279080162272 \t -92.61843242301455\n",
            "54     \t [-4.90536144 -5.08431697  1.94203513  1.23838067 -4.2242366   1.9955568\n",
            " -1.81789781  2.6810529 ]. \t  -286.9639575005183 \t -92.61843242301455\n",
            "55     \t [-3.62322381 -4.66992365  3.81935234  0.46107536 -4.17170049 -2.51625505\n",
            "  4.95065842  4.73082454]. \t  -576.970243278578 \t -92.61843242301455\n",
            "56     \t [-4.04112439  4.914568    3.54979755  2.55876093 -1.62902072 -2.14983593\n",
            "  2.72878479  2.94406132]. \t  -291.0920127152447 \t -92.61843242301455\n",
            "57     \t [-2.12599379 -1.6853951  -3.97971478  4.89647477 -3.17948279  4.91564904\n",
            " -5.01062223 -1.23729683]. \t  -537.1359737110379 \t -92.61843242301455\n",
            "58     \t [ 4.74292299 -4.02537106 -5.05031241 -1.60637058  0.13830532 -4.9748861\n",
            "  2.89504535  1.28869337]. \t  -362.2886649924886 \t -92.61843242301455\n",
            "59     \t [ 3.27651698 -5.03946055  4.83522856  5.09356663  1.68856301  4.02643604\n",
            "  3.72953114  1.39987334]. \t  -460.0162075682083 \t -92.61843242301455\n",
            "60     \t [-4.1939416  -1.53129104 -2.94395702 -2.5220195   3.11546926 -4.35993142\n",
            " -2.55760555 -0.66372296]. \t  -285.62023290370126 \t -92.61843242301455\n",
            "61     \t [-3.85642589 -4.57569917  1.80710642 -5.08565046 -3.19584651  1.96558737\n",
            "  4.89146035 -4.24855894]. \t  -556.133421427285 \t -92.61843242301455\n",
            "62     \t [ 2.05836776 -3.41276076  3.58007086 -3.12478294 -0.16958368 -3.26534957\n",
            "  4.91636288  4.75479323]. \t  -519.2162226624273 \t -92.61843242301455\n",
            "63     \t [-1.97294043 -5.11418698 -0.49646405  4.92886776  4.43653202 -4.72334466\n",
            "  1.90319163  4.66265664]. \t  -585.6685843875551 \t -92.61843242301455\n",
            "64     \t [ 4.04046229  0.93539287  3.86102034  3.12478013  4.60395117  4.49804321\n",
            "  2.81217651 -2.46830376]. \t  -433.32942549626165 \t -92.61843242301455\n",
            "65     \t [ 0.83673002 -0.08924828  4.72034729 -3.87117094 -5.10244406 -4.08884173\n",
            "  2.26809571 -1.8184349 ]. \t  -420.45482868036544 \t -92.61843242301455\n",
            "66     \t [-4.90449578 -4.3302542  -3.94719694 -0.11466786  0.1097625   4.80622782\n",
            "  0.50319784 -2.20120978]. \t  -287.54421406858233 \t -92.61843242301455\n",
            "67     \t [ 3.18572877 -4.66548767  3.54627313 -2.59356589  4.04675139  2.02545835\n",
            "  0.85449581  4.86144024]. \t  -418.9927384010846 \t -92.61843242301455\n",
            "68     \t [-5.01062598 -3.72705038 -1.38398869  4.50358372  3.84444395 -3.47688911\n",
            " -0.78620514 -3.55176711]. \t  -391.44204153437477 \t -92.61843242301455\n",
            "69     \t [-4.59838958  2.91823801  4.96694637 -0.04404393 -5.09513632  4.86909646\n",
            "  3.98616191 -0.89154465]. \t  -501.83273657342056 \t -92.61843242301455\n",
            "70     \t [ 0.27173585  4.54771921  2.27652972 -4.90574711  2.15397225 -2.29717312\n",
            " -1.16406224  3.81805442]. \t  -334.216132609718 \t -92.61843242301455\n",
            "71     \t [ 5.07897127 -3.79808938 -1.62953612  2.69500199  5.11127207  4.12992008\n",
            " -3.96565249 -4.86233536]. \t  -623.8514112353189 \t -92.61843242301455\n",
            "72     \t [-0.48806298  4.63590795 -1.68243569 -4.95580525 -5.11819836 -0.1873465\n",
            "  2.44705896  1.92954077]. \t  -352.8453511859875 \t -92.61843242301455\n",
            "73     \t [-1.03921413  3.27232237 -4.72129036  3.9079879   3.70239066 -4.61659379\n",
            "  0.40489817 -2.35171477]. \t  -392.2655883838895 \t -92.61843242301455\n",
            "74     \t [ 4.80640793 -4.60672991 -1.15279129 -1.07000143 -3.70785535  4.37543099\n",
            "  2.47990113 -3.8238509 ]. \t  -417.7432613564136 \t -92.61843242301455\n",
            "75     \t [-3.99680206  5.01358411 -4.81320304 -3.99158302  1.28001891  2.24812128\n",
            " -2.35107609 -0.88812172]. \t  -282.9977192535723 \t -92.61843242301455\n",
            "76     \t [-1.43455725 -4.91317131  2.33611934 -0.56678951 -1.72347639 -4.30278685\n",
            " -1.3337615  -5.09198745]. \t  -413.80865133699535 \t -92.61843242301455\n",
            "77     \t [-1.59149386 -1.12839164 -3.0781761  -4.07742363 -5.04016113  1.88754326\n",
            " -2.74445587 -2.674817  ]. \t  -358.3608990839289 \t -92.61843242301455\n",
            "78     \t [ 3.17841528  5.02153575 -0.67914896  1.62957845  3.4512576   3.82401658\n",
            " -0.6375062  -4.48151797]. \t  -383.3512378584293 \t -92.61843242301455\n",
            "79     \t [-4.96194419  4.96099578 -4.66235295  4.27084072 -5.10354278 -1.61014855\n",
            "  2.61478131 -4.43137857]. \t  -562.7594873851715 \t -92.61843242301455\n",
            "80     \t [ 4.7177579  -1.66062259 -4.32962712  3.38236732  3.58909044 -1.7904497\n",
            "  3.73420099  1.81960785]. \t  -337.51091526719506 \t -92.61843242301455\n",
            "81     \t [-3.47229953  3.82146893 -0.85301284 -0.21070705  3.42494175 -0.44495702\n",
            "  3.77274675  1.34457807]. \t  -217.5620940851657 \t -92.61843242301455\n",
            "82     \t [ 4.67583202  3.22073732 -4.60827308 -0.72477249  3.36122517 -4.5256494\n",
            " -4.05052173 -0.15266752]. \t  -402.8311566803825 \t -92.61843242301455\n",
            "83     \t [-3.66283388 -1.18767279  4.30644268  4.92899595  4.26242939  1.9389561\n",
            "  0.82734281 -4.97201186]. \t  -485.01134944317766 \t -92.61843242301455\n",
            "84     \t [ 4.01762346 -0.4097422   2.05501122 -4.26782563  0.30753954  3.14642699\n",
            " -5.10504992  3.40570924]. \t  -437.0981372850091 \t -92.61843242301455\n",
            "85     \t [-3.28858235 -1.4971864  -3.36670488 -5.0980163   2.08013821  4.00219874\n",
            "  4.29742004 -4.35099518]. \t  -551.7255430392722 \t -92.61843242301455\n",
            "86     \t [ 1.84483641 -3.89010439  3.45258304  5.09311939  3.55877929 -1.76470053\n",
            " -3.44996549  0.24779875]. \t  -339.006320221849 \t -92.61843242301455\n",
            "87     \t [ 2.54280176 -3.75769985 -4.24285028 -0.02074904  4.96028033 -4.65707751\n",
            "  4.0640619  -4.60234269]. \t  -626.9343050826288 \t -92.61843242301455\n",
            "88     \t [-4.3285754   2.07807099  3.90705207 -4.00710826 -0.70060139  0.67081788\n",
            " -5.01987003 -3.75316292]. \t  -431.6338698071316 \t -92.61843242301455\n",
            "89     \t [ 2.40764434 -4.26574633  4.88330651  3.83199003 -1.94304663 -3.83865924\n",
            "  2.57491756 -2.01162842]. \t  -358.54014650723616 \t -92.61843242301455\n",
            "90     \t [ 4.74158065 -3.10871354 -3.77180576 -3.12710248 -3.33649742  0.38108683\n",
            " -4.40023074 -2.83128582]. \t  -379.80150941006445 \t -92.61843242301455\n",
            "91     \t [ 2.95379749  4.6566892   4.99785558 -4.37479472  3.05158958  4.0033307\n",
            " -2.98697352 -0.93991282]. \t  -415.827923838069 \t -92.61843242301455\n",
            "92     \t [ 0.58565475  4.2538263   2.01322639  2.94239074 -5.08453338 -0.25256215\n",
            "  4.16543081 -4.84490896]. \t  -522.2089257026767 \t -92.61843242301455\n",
            "93     \t [ 2.44197262  1.99306918  4.49989524 -0.32986724 -4.51176005 -3.86073225\n",
            " -4.97559309  3.11737914]. \t  -517.3418232946608 \t -92.61843242301455\n",
            "94     \t [ 3.69160771 -1.35127353  1.94429149 -3.76741628  4.27842944 -5.10559468\n",
            " -4.87645056  4.54404814]. \t  -664.9671104634215 \t -92.61843242301455\n",
            "95     \t [-0.49316721 -1.84877497 -1.7362148  -2.11761143 -4.54827257 -1.76569533\n",
            "  3.81185849  0.04627976]. \t  -257.92857705416475 \t -92.61843242301455\n",
            "96     \t [ 1.22570089 -4.34969229 -2.80193394 -1.10255021  3.018042    1.08266692\n",
            "  2.71361525  5.00791133]. \t  -372.5122125772226 \t -92.61843242301455\n",
            "97     \t [-3.30436432 -3.55971022  4.81829868 -0.72235573 -4.3028209   4.23583837\n",
            "  4.76027565  2.36642354]. \t  -511.6436461616882 \t -92.61843242301455\n",
            "98     \t [ 2.15726445 -4.76069428  0.02370025  2.54220517 -4.73029523  4.21098972\n",
            " -4.2845162   2.73495189]. \t  -482.44744342844956 \t -92.61843242301455\n",
            "99     \t [ 5.03100616 -1.74266424 -4.91132831 -3.98385117  3.21254429  3.11441159\n",
            " -4.38718064 -2.42975674]. \t  -458.9932797103463 \t -92.61843242301455\n",
            "100    \t [-3.36974441  1.49552301  2.22705405 -4.545044    0.47662919 -4.73691678\n",
            "  0.91235528 -2.2154116 ]. \t  -294.19465855463017 \t -92.61843242301455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHI3RrtS_cXk",
        "outputId": "44512413-136f-4017-cc6b-13c8620f880c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 14 \r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_winner_14 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_14 = dGPGO_stp(surrogate_winner_14, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.51092275  0.07321281  0.29021573  4.05796049  2.04790979  2.19440232\n",
            "  2.22554503 -2.83832871]. \t  -217.39677218415014 \t -198.56808439329558\n",
            "init   \t [-3.32641768 -0.44194316  4.39028154 -5.01876852 -4.19919673  3.58605074\n",
            " -0.14724036  3.85879646]. \t  -454.63061220313574 \t -198.56808439329558\n",
            "init   \t [-1.97290047 -1.14723281  0.83400441 -3.95584327  2.74309309 -1.91932375\n",
            "  1.49514711 -4.78516309]. \t  -329.7622575537801 \t -198.56808439329558\n",
            "init   \t [-3.41610929 -0.71369695 -2.78726175  4.77498845  4.14657954  3.74438823\n",
            " -4.79065311  3.06685697]. \t  -533.1877350004759 \t -198.56808439329558\n",
            "init   \t [ 4.15903244  2.08827731 -2.76774455 -0.90689946  4.90131417 -1.75056937\n",
            "  0.97821769  0.36706653]. \t  -198.56808439329558 \t -198.56808439329558\n",
            "1      \t [-0.39837742 -2.80781146  4.30646237  1.1348259  -2.86625872 -4.7177257\n",
            "  0.49038928 -4.19648802]. \t  -393.90076362444245 \t -198.56808439329558\n",
            "2      \t [-3.3024737   5.10871425  3.24433055  2.77252492  0.85991499 -4.37501503\n",
            " -2.86441234 -5.03829863]. \t  -504.48031361068513 \t -198.56808439329558\n",
            "3      \t [-0.92980509 -4.30040138 -3.26462577  4.56516629 -2.88753534  1.82743128\n",
            " -2.1548711   4.26696946]. \t  -393.0746043478335 \t -198.56808439329558\n",
            "4      \t [ 1.93719465  4.11526207 -4.74409348  3.27244601 -3.4769437  -1.96653854\n",
            "  4.8122042   1.00443915]. \t  -401.80004683381793 \t -198.56808439329558\n",
            "5      \t [-0.03181203  4.33805948 -0.44747142  4.58524543  3.88294289 -4.50476581\n",
            "  0.50355991  2.93073043]. \t  -389.96929911062045 \t -198.56808439329558\n",
            "6      \t [-0.23280524  3.38076193  2.95399104 -1.15474815 -2.80957564  3.85282213\n",
            " -1.60428625 -4.24105182]. \t  -344.8675748134268 \t -198.56808439329558\n",
            "7      \t [ 1.38106068  3.16171404  4.16653953 -1.97356742  0.05772626 -2.82596375\n",
            "  1.11439113  4.61957236]. \t  -316.90997981490364 \t -198.56808439329558\n",
            "8      \t [ 0.08142732  4.75140566  2.9963424  -3.23507203 -4.41345417 -4.6353535\n",
            "  0.39600985 -3.62437665]. \t  -446.45382608047237 \t -198.56808439329558\n",
            "9      \t [-2.94153297 -4.72197701 -2.5001437  -1.31967248 -1.05286925  3.04985223\n",
            "  3.82699485  0.59569556]. \t  -245.67735980151227 \t -198.56808439329558\n",
            "10     \t [ 3.21476598  0.26675137  0.35541205  5.0595921  -0.63462653  4.16544666\n",
            "  1.14058689  4.59524693]. \t  -397.4102282376962 \t -198.56808439329558\n",
            "11     \t [ 4.39589311 -2.63238916 -0.42473053  3.46291368 -4.45295055 -3.32856296\n",
            "  0.33154344  4.17398955]. \t  -387.45788340642343 \t -198.56808439329558\n",
            "12     \t [ 0.51678178 -4.33656642  2.73729925  1.0888125   2.57474767 -4.72429433\n",
            " -2.77048929  2.03866427]. \t  -319.1380140723573 \t -198.56808439329558\n",
            "13     \t [ 4.48673974  1.28088228  3.5687081  -3.90711571 -4.24765293  3.37900285\n",
            "  4.72749553 -2.13360407]. \t  -474.2627647473313 \t -198.56808439329558\n",
            "14     \t [-5.0813497  -3.80916529 -3.50982139  2.9269636   4.86626155 -1.05002318\n",
            "  4.28438133 -1.59529189]. \t  -399.9335101190047 \t -198.56808439329558\n",
            "15     \t [ 1.45625919  0.75649195 -3.95074262 -3.47785896 -2.63466893  1.78976944\n",
            "  2.29339112 -2.58523433]. \t  -242.6844064277512 \t -198.56808439329558\n",
            "16     \t [ 4.17858574  0.13084355 -1.97677267 -4.34579804 -3.9435953  -0.10839843\n",
            " -4.66255145  4.13078303]. \t  -471.27442234878765 \t -198.56808439329558\n",
            "17     \t [-5.03607337 -3.31066354 -3.57533661  0.94336117 -1.94858178 -5.0808589\n",
            "  4.86925197  4.51232175]. \t  -591.9231398927816 \t -198.56808439329558\n",
            "18     \t [ 4.73692332  4.43502402  4.28934205 -1.82748527  2.62076879 -2.09028139\n",
            "  0.87786496 -3.49659065]. \t  -294.0929943217344 \t -198.56808439329558\n",
            "19     \t [-3.75962742 -1.8832868   4.99001478 -3.41516484  3.66788389  4.61569466\n",
            "  4.00356515  3.16219069]. \t  -529.8725041011188 \t -198.56808439329558\n",
            "20     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -198.56808439329558\n",
            "21     \t [ 4.34441123  4.64364973  3.83852977  0.82484397 -4.68430816  1.23108874\n",
            " -4.85711954  4.08769748]. \t  -526.5479054849711 \t -198.56808439329558\n",
            "22     \t [-2.79958288  3.46339189  2.97214212  2.68023358 -3.07473051 -0.51534145\n",
            "  3.5216447   0.13823341]. \t  -222.8933624306999 \t -198.56808439329558\n",
            "23     \t [ 3.31163667 -4.0136498  -5.05745775  1.58273225 -3.38626979  1.64858821\n",
            " -2.25168731 -3.31960808]. \t  -327.22973580022676 \t -198.56808439329558\n",
            "24     \t [ 4.80955415 -3.81988491  0.89280586 -1.47074581  0.83072271  3.4310768\n",
            " -1.68976547  4.85483888]. \t  -345.9855974737528 \t -198.56808439329558\n",
            "25     \t [-3.73555349  4.72222462 -3.91807102 -4.12559843 -3.54038882  3.23908216\n",
            " -0.99136498  1.21623576]. \t  -317.02441309615034 \t -198.56808439329558\n",
            "26     \t [-0.96873921 -3.54339904  2.33821228 -1.28589214  1.51017269  3.64098048\n",
            " -4.0886066  -1.16231668]. \t  -267.833902338266 \t -198.56808439329558\n",
            "27     \t [-4.86206585  4.19479912  0.56702767 -4.37875675 -4.11352016 -4.83597036\n",
            " -2.65821153  4.69683412]. \t  -587.3604896621283 \t -198.56808439329558\n",
            "28     \t [-5.10953119 -3.10099531 -3.2860372  -4.65987239 -1.54838058 -1.18690914\n",
            " -5.01660376  1.24000125]. \t  -373.4963668118543 \t -198.56808439329558\n",
            "29     \t [-4.68186429  2.81164486  0.77693349 -1.9408878   4.69131273  4.00385963\n",
            " -4.97885143  1.50909596]. \t  -452.5787289744897 \t -198.56808439329558\n",
            "30     \t [-2.79561642  3.88200126 -4.77098212 -5.03009085  0.73941555 -4.0286816\n",
            "  2.93249537 -0.39626921]. \t  -369.0176730444112 \t -198.56808439329558\n",
            "31     \t [-4.65152108  4.54819638  4.40360338  3.65529756 -3.78024348  2.78660134\n",
            " -4.80636147  1.02756252]. \t  -462.82573574508604 \t -198.56808439329558\n",
            "32     \t [-2.93315587 -3.91698264  4.26708108  4.16165678 -1.42666648 -3.86242442\n",
            "  4.69421026  5.0262372 ]. \t  -619.2309746481867 \t -198.56808439329558\n",
            "33     \t [ 4.00555936  2.47137401  3.4548429   3.73466428  3.76952228  1.53597012\n",
            " -4.95271561  2.5974843 ]. \t  -430.7414297011274 \t -198.56808439329558\n",
            "34     \t [ 0.64450332  2.78800412  0.84961096 -3.35642335  3.93106189  4.80157943\n",
            "  3.98505476 -4.03022392]. \t  -519.8926427557718 \t -198.56808439329558\n",
            "35     \t [-3.98646707  1.77223493  3.51743109  4.1726324   5.11088186  4.5206381\n",
            " -2.94089353 -3.44371779]. \t  -537.572062950123 \t -198.56808439329558\n",
            "36     \t [-4.20740879  4.69228011 -4.45784794  1.86759681 -0.16871162 -1.1307125\n",
            " -5.04602514 -3.91661735]. \t  -444.0752722785177 \t -198.56808439329558\n",
            "37     \t [-1.2315927  -3.91859062  4.48505741  4.75257097 -3.06750343  3.88781753\n",
            " -4.57789345 -3.75741066]. \t  -580.3059438258515 \t -198.56808439329558\n",
            "38     \t [-2.45858473 -4.67201186 -4.92614085  2.51139494  3.98520921 -3.58242612\n",
            " -4.61107214  3.6799754 ]. \t  -561.3128165740434 \t -198.56808439329558\n",
            "39     \t [ 4.43800643  2.88084545 -2.43754497 -2.63930286  2.26256408  1.43907337\n",
            " -4.92603581 -4.61130546]. \t  -459.97847687873025 \t -198.56808439329558\n",
            "40     \t [-3.20684251 -4.02441766  4.57743747  3.88848167  4.84546842  3.72318783\n",
            " -1.44306191  4.09608143]. \t  -515.3813190298237 \t -198.56808439329558\n",
            "41     \t [ 4.5498858  -4.11713229 -5.05549999  0.59279448 -0.81915946 -2.7782831\n",
            "  4.68861331 -2.92149688]. \t  -404.5139473051788 \t -198.56808439329558\n",
            "42     \t [ 2.48848575 -4.06180833  3.97747981 -1.36221504 -4.8780301   1.20218184\n",
            "  4.78379628  4.86041038]. \t  -570.9016873999382 \t -198.56808439329558\n",
            "43     \t [-0.1164518  -4.50435891 -4.2250201  -4.72935561 -4.76089799  4.93770782\n",
            " -1.24627851  3.18986914]. \t  -535.502752769268 \t -198.56808439329558\n",
            "44     \t [ 4.63891619 -2.93890838 -2.94740736 -5.10608259  3.1589524   4.57275568\n",
            "  2.34370685 -0.70199954]. \t  -386.89248443101445 \t -198.56808439329558\n",
            "45     \t [-2.87495356  0.681258   -4.08025741 -0.65110223  2.87753489  5.04284483\n",
            " -2.21090747 -4.97475973]. \t  -487.0202179059493 \t -198.56808439329558\n",
            "46     \t [ 4.87761164 -3.28891546  4.12937009 -3.92093306 -3.10360652 -0.93044747\n",
            " -1.02131792 -1.7590136 ]. \t  -243.48590630388682 \t -198.56808439329558\n",
            "47     \t [-2.03753913 -1.51594691 -2.82374676 -4.77167945  4.9817286  -3.97070849\n",
            "  1.78031263  4.81905292]. \t  -550.4041069171739 \t -198.56808439329558\n",
            "48     \t [ 2.74412705 -3.56240197  1.71161485  5.07593912  4.95198976 -2.94711843\n",
            " -3.38885614 -4.73371515]. \t  -579.1401063440298 \t -198.56808439329558\n",
            "49     \t [ 3.63447856  3.9569385  -3.28913307  3.80123913 -0.31778341  4.84178928\n",
            " -3.54616749 -0.16525606]. \t  -364.1850993488297 \t -198.56808439329558\n",
            "50     \t [ 4.93338619 -4.32002578 -4.7965584  -2.70930512  4.61501121  2.02926584\n",
            " -4.96075735 -1.64677681]. \t  -485.2037459101324 \t -198.56808439329558\n",
            "51     \t [ 4.52752982  2.86971625  2.2608396   2.40243954 -1.80829102 -4.19829735\n",
            " -3.93928877 -1.18942683]. \t  -317.4377664471737 \t -198.56808439329558\n",
            "52     \t [-1.06199132  3.66948108 -0.39489794 -4.37867393  1.34047032 -4.57469064\n",
            " -4.44643856 -1.71796776]. \t  -401.77507029779855 \t -198.56808439329558\n",
            "53     \t [-3.78624862  1.2259509  -2.93690055  2.49538578  3.42750672  3.22026061\n",
            "  4.39731381  4.82671389]. \t  -510.81694408510066 \t -198.56808439329558\n",
            "54     \t [-4.96924393 -5.03144067 -3.36907996 -0.32793008 -4.61469836  4.18882812\n",
            " -5.00512139 -4.69826566]. \t  -673.509600468962 \t -198.56808439329558\n",
            "55     \t [-4.69612126 -3.74402938 -4.12821826  3.54454829 -5.03935695 -3.92637068\n",
            " -1.60738361 -3.74442595]. \t  -501.1964082102255 \t -198.56808439329558\n",
            "56     \t [ 4.44013244 -4.81936548 -4.53083105  4.6655052   4.64382385  4.36048038\n",
            " -1.6029142  -4.80458401]. \t  -639.3861808093668 \t -198.56808439329558\n",
            "57     \t [4.40813589 3.67067357 3.97199813 0.59398684 3.79381741 3.27582669\n",
            " 3.85238278 3.46679284]. \t  -431.5076283908052 \t -198.56808439329558\n",
            "58     \t [ 3.18402628 -3.43391688  3.31097767  1.00892544  4.75237426  0.7332114\n",
            "  4.97936946  1.21708102]. \t  -372.24106578380884 \t -198.56808439329558\n",
            "59     \t [-3.15554629 -4.19643382  2.53912025  1.87964509  5.05277064  4.8563878\n",
            "  3.56993121 -4.99662942]. \t  -636.752019753712 \t -198.56808439329558\n",
            "60     \t [-4.82583854  0.89699815 -4.07914845  5.01945998 -0.5076361  -3.92501355\n",
            " -1.15180548  4.13283943]. \t  -415.24854468297394 \t -198.56808439329558\n",
            "61     \t [-5.10306098  4.08416429  4.66652123  2.41580457  3.97039851  4.31037031\n",
            "  4.20597318  1.38310753]. \t  -477.5071745036735 \t -198.56808439329558\n",
            "62     \t [ 4.50453894 -3.98444764 -2.23044734 -1.92020309  4.38406644 -4.63930848\n",
            "  4.70260115  1.04984596]. \t  -470.57382985806976 \t -198.56808439329558\n",
            "63     \t [-3.73620971 -2.697818   -4.95586096 -4.76982156  4.80736852 -3.70678202\n",
            " -2.54106474 -4.89886925]. \t  -628.3879587117306 \t -198.56808439329558\n",
            "64     \t [-4.65118641 -0.62649883  4.89597294 -4.78462462 -3.6582474  -3.19246165\n",
            "  3.5503176  -0.09426453]. \t  -402.26983090818044 \t -198.56808439329558\n",
            "65     \t [ 2.96432403  5.01632163  3.8119136  -2.21291383  4.46051716  4.30178442\n",
            " -2.64036303 -2.97300007]. \t  -452.3178042630862 \t -198.56808439329558\n",
            "66     \t [-4.70368461 -4.419649    1.83208068  3.13136728 -4.98661818 -1.55891797\n",
            " -4.81177585  4.19015036]. \t  -551.926989854671 \t -198.56808439329558\n",
            "67     \t [-2.99347369 -2.73616585  2.11977514  4.47376222 -3.59525027  4.10956996\n",
            "  4.77345358 -1.86788433]. \t  -470.84608815896524 \t -198.56808439329558\n",
            "68     \t [ 4.95507037  0.38140294 -0.95715578 -2.61718718 -3.07893663 -3.66231118\n",
            "  4.50466506  4.09996157]. \t  -459.38669820742894 \t -198.56808439329558\n",
            "69     \t [-4.43783733  3.59215899 -4.84499999 -0.56419833  2.42990766  1.21182217\n",
            "  4.61190679 -4.90155913]. \t  -496.62034506226286 \t -198.56808439329558\n",
            "71     \t [ 4.24444888  4.29184113 -1.58911321 -1.48859082 -3.79729201  4.7519821\n",
            "  1.80209033  3.21708493]. \t  -384.4095265776475 \t -198.56808439329558\n",
            "72     \t [ 1.22699496 -0.03296917 -1.03660128  5.09285063 -4.94780184 -2.14429923\n",
            "  0.45167683 -3.03462023]. \t  -333.5711013094411 \t -198.56808439329558\n",
            "73     \t [ 4.61750798  0.02555327  4.9980392   4.51568266  2.22054165 -4.25660231\n",
            "  3.36175117  3.60901184]. \t  -494.50476633533503 \t -198.56808439329558\n",
            "74     \t [ 4.82605798  4.72569188 -4.04742982  0.56557042  3.3856823   4.64416941\n",
            "  4.69358106  2.82190075]. \t  -523.0167000844631 \t -198.56808439329558\n",
            "75     \t [-0.56095558  2.73947793 -3.72514189 -4.89826176  0.64251343  3.38225417\n",
            "  4.70623175  4.39164645]. \t  -532.9608357150238 \t -198.56808439329558\n",
            "76     \t [-4.12091691  4.36522133  4.29832731 -4.96691011  4.7781163  -5.09776635\n",
            " -3.25871837  3.64389889]. \t  -659.8339259529573 \t -198.56808439329558\n",
            "77     \t [ 4.79913783  3.20508879 -5.11600711  4.6195374   5.04894524  4.91270602\n",
            "  3.03214638 -3.85154372]. \t  -662.7578187047255 \t -198.56808439329558\n",
            "78     \t [ 1.61049696  3.22535674 -4.5285837  -3.4687495  -4.66322214 -3.85565468\n",
            " -3.76588096 -1.5544685 ]. \t  -449.58129201133556 \t -198.56808439329558\n",
            "79     \t [-1.08321839 -3.35360854  1.78757403 -4.61950707 -2.88852841  3.68666317\n",
            "  1.85359649 -5.0915276 ]. \t  -473.3192479602471 \t -198.56808439329558\n",
            "80     \t [-2.25410079 -0.68261127 -4.93057703 -2.12354912  3.99268777  0.76629303\n",
            " -4.63765602  5.08823919]. \t  -537.8899053167679 \t -198.56808439329558\n",
            "81     \t [-3.10289388 -1.58838637  3.95925894 -2.36824868 -4.55089036 -1.00439072\n",
            " -4.32923105 -0.629521  ]. \t  -328.1073780181682 \t -198.56808439329558\n",
            "82     \t [ 3.39388629 -4.34340584 -4.18068175  1.29291398  1.68294011  3.08031608\n",
            "  3.13764084  2.68178784]. \t  -305.9105568119322 \t -198.56808439329558\n",
            "83     \t [ 0.62258051 -2.16845972  3.32742252  4.21147931 -0.59304659  2.71147368\n",
            " -5.08188197  4.48936009]. \t  -501.8380561122679 \t -198.56808439329558\n",
            "84     \t [-0.51269847 -3.5926666  -2.8039256  -0.13177771  0.38633701 -3.31201412\n",
            " -4.81054582 -5.04493282]. \t  -481.89596612471684 \t -198.56808439329558\n",
            "85     \t [-4.26603633 -3.48137301  2.3081636  -4.72316487 -2.24654213 -4.58118615\n",
            " -1.07309246  4.63462926]. \t  -478.7123406297537 \t -198.56808439329558\n",
            "86     \t [-1.8397362   4.76773026  4.07077587  3.61585204 -0.56895197  4.68348682\n",
            "  3.79305499 -4.3814801 ]. \t  -538.3769560029468 \t -198.56808439329558\n",
            "87     \t [ 3.95930156  4.21453564  1.32721035  2.32607135 -4.27420888  3.09705999\n",
            "  3.76144106 -4.76689651]. \t  -507.8480656191363 \t -198.56808439329558\n",
            "88     \t [-2.3634252   2.07439774 -0.98811104 -0.20999046 -4.39073101  4.92437588\n",
            " -4.96792433  4.05397677]. \t  -563.4266913176839 \t -198.56808439329558\n",
            "89     \t [ 3.68790869 -4.80755725  4.87007889  2.64063977 -2.73436728  2.83608659\n",
            "  1.03131313 -0.2033593 ]. \t  -252.29103508543682 \t -198.56808439329558\n",
            "90     \t [ 1.68165428 -3.39338667  2.20831178 -4.37959208  0.99354527 -5.01415999\n",
            "  3.58249294  4.66434266]. \t  -536.8863299779498 \t -198.56808439329558\n",
            "91     \t [ 4.88978142 -5.07088065  2.14478107  1.9033811  -3.76094397 -4.46123084\n",
            " -4.88804593 -3.33041835]. \t  -549.752743130797 \t -198.56808439329558\n",
            "92     \t [-4.52716778  0.76366962  3.4995259   3.05638833  3.88560854 -2.59376324\n",
            " -4.22035013  4.09329074]. \t  -470.34284820949625 \t -198.56808439329558\n",
            "93     \t [-0.46746069 -2.03141175 -1.73554952 -1.40375005 -4.79678249 -3.92068303\n",
            "  2.48505697 -1.16251402]. \t  -286.7064517802671 \t -198.56808439329558\n",
            "94     \t [ 4.62893912  1.73444535 -4.75375189  5.07622843 -4.80719864  4.80532157\n",
            "  4.56921527 -2.02809013]. \t  -631.4523108470972 \t -198.56808439329558\n",
            "95     \t [ 3.51392049  4.45060611  2.94930242 -4.64837857 -1.81892929  0.09994889\n",
            " -2.72940591  0.54671125]. \t  -235.62947366245487 \t -198.56808439329558\n",
            "96     \t [ 0.41553896  3.8018216   4.87068592 -4.60800636  4.00440344  3.52068508\n",
            "  0.85311276  4.77674434]. \t  -527.3664791358706 \t -198.56808439329558\n",
            "97     \t [ 4.21380439 -1.97112679 -0.20260376 -3.87387504  4.67210826 -3.62391355\n",
            " -4.14245857  1.40740929]. \t  -409.58322801971343 \t -198.56808439329558\n",
            "98     \t [-4.448026   -4.36002003  0.39060396  2.65534952  2.72543283 -1.74154332\n",
            " -5.00528021 -0.90595139]. \t  -323.7392758315598 \t -198.56808439329558\n",
            "99     \t [ 4.83549962  4.99614372  4.02230942  4.88981188 -4.86514471 -1.48072256\n",
            "  1.71412992  3.5798398 ]. \t  -472.0760352707883 \t -198.56808439329558\n",
            "100    \t [-2.91171588  1.51237654 -3.32116021  4.34735429 -0.54835685 -4.17983525\n",
            "  2.63981739 -3.30264357]. \t  -364.1106272498971 \t -198.56808439329558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d86panpOuvum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db32ccf-4a7c-4cd0-ceb6-3805c3d7094b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 15 \r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_winner_15 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_15 = dGPGO_stp(surrogate_winner_15, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.79751023 -2.50366638 -2.53412486  2.14942059 -0.5370638  -2.79610411\n",
            " -1.00649405  3.91431921]. \t  -228.93586258775446 \t -111.84379356128198\n",
            "init   \t [-0.6429341   3.87507385  2.87260414  0.35035432 -4.99985399 -2.39865368\n",
            " -1.72857241  1.17580582]. \t  -247.18214418832017 \t -111.84379356128198\n",
            "init   \t [ 3.84255585 -0.47241396 -1.33929378  0.83608715  1.37927538 -3.11654164\n",
            " -0.55786658  1.52017343]. \t  -111.84379356128198 \t -111.84379356128198\n",
            "init   \t [ 3.74892071 -4.8478471  -1.40433719  2.34767012  1.9855191   0.6647632\n",
            " -3.76057172  2.51723021]. \t  -261.0681305251046 \t -111.84379356128198\n",
            "init   \t [-0.55198121 -0.67596996 -3.19596718 -4.19216237 -1.4139613  -0.32482896\n",
            " -2.05442948  4.53772941]. \t  -307.060259396398 \t -111.84379356128198\n",
            "1      \t [-2.51367588  4.67420708 -3.8466322   2.6958628  -4.79133558  0.76305254\n",
            " -3.96072329 -1.11140926]. \t  -361.4465579486143 \t -111.84379356128198\n",
            "2      \t [ 3.59564778  4.51509721 -4.2532918   4.88423533  4.69189145 -1.53762576\n",
            "  3.6493151   3.60248043]. \t  -524.695792395735 \t -111.84379356128198\n",
            "3      \t [ 3.65838953 -3.65540232  1.39373299  4.45739924 -1.19556836  4.65675434\n",
            "  2.52730654  0.40442687]. \t  -308.68737481626977 \t -111.84379356128198\n",
            "4      \t [ 2.48921905 -4.28456967 -4.18815068 -4.61310118  4.61587021 -3.20488727\n",
            " -3.26093515 -3.56527486]. \t  -524.9403830688307 \t -111.84379356128198\n",
            "5      \t [-4.85272535 -3.89403078 -1.74722506  1.60991698 -1.61244735 -1.07631829\n",
            "  2.57851766 -1.60150022]. \t  -160.41200738036034 \t -111.84379356128198\n",
            "6      \t [ 2.79915823 -3.07535343  1.54915144 -0.34951671 -4.50840015 -1.23683184\n",
            "  2.16201081 -1.55016968]. \t  -197.19026348252453 \t -111.84379356128198\n",
            "7      \t [ 1.65019235  2.35098964  4.69224662 -1.82231264 -3.68344442  4.79839766\n",
            " -0.42656071 -4.35238171]. \t  -451.9182931973306 \t -111.84379356128198\n",
            "8      \t [ 0.79082105  2.60068887 -2.91245761 -4.56326894  0.33392464 -1.15580396\n",
            "  4.38251909 -1.17562895]. \t  -276.96845239212325 \t -111.84379356128198\n",
            "9      \t [-2.11419656 -1.8595311  -1.2839357  -0.82536408  4.73413653  4.36129594\n",
            " -4.47917065  4.84092933]. \t  -573.1591344477459 \t -111.84379356128198\n",
            "10     \t [-0.50861462  4.54634625  1.23674036  3.14491108  0.02016445 -3.03349437\n",
            "  4.21594032 -4.60806421]. \t  -435.2553374375713 \t -111.84379356128198\n",
            "11     \t [ 5.02549587  1.117597    1.81591151 -2.3410321  -1.93506609  3.81286408\n",
            " -4.19099904  2.61844649]. \t  -343.3193897552946 \t -111.84379356128198\n",
            "12     \t [ 4.93363299  4.48978022 -4.38227625 -4.3243733   1.10704141 -2.47487453\n",
            " -4.42887446 -2.58872651]. \t  -430.86510992728455 \t -111.84379356128198\n",
            "13     \t [-4.84455795  5.05557046  1.39191514 -0.67776501  0.57833434  0.63764304\n",
            " -4.81805196 -3.76182711]. \t  -362.055075415231 \t -111.84379356128198\n",
            "14     \t [ 1.73207257  2.80211546  2.63827927  4.85084842  2.23263983 -4.99828222\n",
            " -3.15026573 -3.28967883]. \t  -464.57371882184043 \t -111.84379356128198\n",
            "15     \t [-0.06275868 -1.49206096  4.92357368 -3.93162222  1.40240418 -4.80515805\n",
            "  2.53928826 -2.48481135]. \t  -381.9129211511174 \t -111.84379356128198\n",
            "16     \t [ 3.95202796  2.89890031 -2.06960118  5.04611886  3.12153692  3.76895063\n",
            " -1.25525191 -3.04033094]. \t  -366.0571764911808 \t -111.84379356128198\n",
            "17     \t [-1.67323843 -1.53222513 -2.29205179 -4.76151903 -3.60925852  3.33289607\n",
            "  0.18410779 -3.08209368]. \t  -321.9585065995703 \t -111.84379356128198\n",
            "18     \t [-2.62074694 -0.6651476   1.33916835  4.22680282  3.44461177 -2.44176334\n",
            "  5.09716405  3.19404009]. \t  -443.1794278980911 \t -111.84379356128198\n",
            "19     \t [ 4.36158291 -4.76136398 -2.87131935  1.4968818   1.83061472  0.48253276\n",
            "  4.60342068 -4.97948697]. \t  -462.91610031085645 \t -111.84379356128198\n",
            "20     \t [-3.62730296  5.06213126  3.96295947 -4.00657858 -1.81150384  0.35353853\n",
            "  4.12825919 -2.1946686 ]. \t  -350.7214007916615 \t -111.84379356128198\n",
            "21     \t [ 0.66724801 -5.08452759 -0.26814339 -2.96727225  4.74243336  0.19151948\n",
            "  2.69611193  1.43048091]. \t  -267.5113738406144 \t -111.84379356128198\n",
            "22     \t [ 4.18152986  2.95842792  4.40888794 -1.79232775 -0.87044097  0.92961068\n",
            "  4.28021128  1.61043031]. \t  -264.1171576482146 \t -111.84379356128198\n",
            "23     \t [ 2.7066243  -4.45402929  2.28531539 -3.75988673  0.15354481  2.81283276\n",
            " -4.08910522 -3.19615049]. \t  -365.5761042740721 \t -111.84379356128198\n",
            "24     \t [-4.85510476 -3.25836235 -0.80743445 -0.49862365  1.22711993  2.44796042\n",
            " -4.75835124 -3.47646374]. \t  -346.42017084890404 \t -111.84379356128198\n",
            "25     \t [-3.12981896 -4.99756621  4.43287495  5.01439348  3.38924395 -3.13211226\n",
            "  2.93149432 -3.16912081]. \t  -476.07267386240176 \t -111.84379356128198\n",
            "26     \t [ 2.34833021 -5.11988695  5.07172838 -4.85377777 -0.17599614 -3.46856202\n",
            " -5.06975064  4.89663465]. \t  -673.4183168441568 \t -111.84379356128198\n",
            "27     \t [-2.00000023 -0.81495266  4.49760997  3.28881191  3.54424783  3.90729007\n",
            "  1.51080874 -1.44599762]. \t  -296.3939498335501 \t -111.84379356128198\n",
            "28     \t [-4.81805155  0.0115909  -1.43691086  2.0486301  -2.2113821   3.48500506\n",
            " -1.3279297   4.39860158]. \t  -310.6435325587016 \t -111.84379356128198\n",
            "29     \t [ 4.85079083  4.64412604 -4.15759924  4.82219914 -3.38839773 -2.40164379\n",
            " -1.03143843 -3.34308883]. \t  -400.40785132499394 \t -111.84379356128198\n",
            "30     \t [-4.18817978 -3.72735542  4.99635087 -2.60688816  0.7679042   0.30301961\n",
            "  0.70786071  3.72497235]. \t  -265.4113652712485 \t -111.84379356128198\n",
            "31     \t [ 1.21095792  2.43944823  4.95355413 -4.75000364 -1.2375098  -4.78910738\n",
            " -4.70406039 -2.20862898]. \t  -516.4235423907713 \t -111.84379356128198\n",
            "32     \t [-3.66342288  1.73178429 -3.53423948  2.93862028  4.833024    0.67724226\n",
            " -0.26626077 -0.1640545 ]. \t  -211.68744585204743 \t -111.84379356128198\n",
            "33     \t [-5.00785916 -5.0581811  -4.98586355 -4.91353134 -4.8897871  -4.74620317\n",
            " -5.03876562 -5.07857729]. \t  -886.1651594962531 \t -111.84379356128198\n",
            "34     \t [ 1.42584053 -4.98846896 -5.04382224 -0.17873995 -4.81602368 -5.08607429\n",
            " -1.69609334 -2.82190647]. \t  -483.27259440141745 \t -111.84379356128198\n",
            "35     \t [ 4.68100986  3.05554182  4.37799914 -0.66645653  4.90810767 -4.34437706\n",
            "  1.53546479  4.37096722]. \t  -502.8974886633654 \t -111.84379356128198\n",
            "36     \t [ 2.00063202  4.21622079  2.64684132  5.11962267  1.29812438  4.16455218\n",
            " -1.22531778  3.63261179]. \t  -393.9783924356984 \t -111.84379356128198\n",
            "37     \t [-3.74607364 -4.48132481  1.23528608  4.95953601 -2.35467191 -3.34919366\n",
            " -4.085666    0.39577349]. \t  -370.29014435590517 \t -111.84379356128198\n",
            "38     \t [-4.25782814 -2.54345745  3.74204407 -4.53531218  4.51431498  3.06938843\n",
            "  3.55670687 -4.13762389]. \t  -539.2850282441663 \t -111.84379356128198\n",
            "39     \t [ 4.45482303 -2.10731163  4.4518349   1.20262824  4.88618034 -0.17515968\n",
            " -2.40844545 -1.99186687]. \t  -285.8711457905021 \t -111.84379356128198\n",
            "40     \t [-3.35575805  4.20876834 -4.4405628  -3.27861663  3.45224717 -2.95133823\n",
            " -4.83884272  2.08845583]. \t  -459.4880864749046 \t -111.84379356128198\n",
            "41     \t [-3.36658269  2.35700824 -4.24291999  4.11536469 -5.07904712 -0.10391665\n",
            "  3.8045435  -3.94888634]. \t  -499.31674672937356 \t -111.84379356128198\n",
            "42     \t [ 2.72559146  5.03017876 -0.48616408 -3.12944939 -4.97165254  4.20611814\n",
            "  4.31171077  0.36607525]. \t  -458.8603864402666 \t -111.84379356128198\n",
            "43     \t [ 4.93471441  0.82412531  3.29501043  2.15461001 -4.42200329 -0.9642858\n",
            " -3.62661336 -4.59040274]. \t  -440.84072757354824 \t -111.84379356128198\n",
            "44     \t [-4.70933529  0.54159936 -3.67520372  4.9384419  -4.43557641 -3.6718543\n",
            "  1.18922347  3.14022493]. \t  -428.8933419537889 \t -111.84379356128198\n",
            "45     \t [ 4.04914508  2.72802405 -3.46929666  3.14871586 -4.21971758  2.2448761\n",
            "  4.16599646  4.96843663]. \t  -545.2839911018008 \t -111.84379356128198\n",
            "46     \t [ 5.03304524 -2.30475718  4.33972276  4.52452446 -0.93357245 -3.83326765\n",
            "  4.52434991  4.47454235]. \t  -570.3220840114686 \t -111.84379356128198\n",
            "47     \t [-4.34043319  3.63154674  4.28618004  2.41266227 -0.85255622  1.24782929\n",
            "  3.66571077  4.34058004]. \t  -381.3772555503027 \t -111.84379356128198\n",
            "48     \t [ 4.64828515 -3.95150786  5.04167123  4.78585402  0.27595253 -4.62602404\n",
            "  1.80562507 -3.90677003]. \t  -494.4144538658944 \t -111.84379356128198\n",
            "49     \t [ 0.78749311  3.7830172   2.80966919 -3.23004847  4.96319691  3.37689927\n",
            " -0.63282578 -0.82582851]. \t  -294.5046902167816 \t -111.84379356128198\n",
            "50     \t [ 3.09630592 -3.77719345  4.96037087 -1.90079422 -3.04421034  4.16781055\n",
            "  1.35936662  4.44552012]. \t  -447.98569130963114 \t -111.84379356128198\n",
            "51     \t [-4.98513187  2.47523987 -4.33288093 -4.24099008 -3.36309749 -3.85484717\n",
            " -2.44745955 -2.3787199 ]. \t  -398.27880218622204 \t -111.84379356128198\n",
            "52     \t [-4.05452717 -3.85219092  2.56203156 -2.81475976 -4.57097018 -2.42355804\n",
            " -2.44575405 -1.17525791]. \t  -290.1339305642247 \t -111.84379356128198\n",
            "53     \t [ 4.14098834  3.68338582  0.76421304 -1.69000311  3.90433278 -2.98585754\n",
            "  0.37871471 -4.98877285]. \t  -387.2769072527343 \t -111.84379356128198\n",
            "54     \t [ 0.34370218 -0.85814232 -5.06873043  4.88029071 -4.20597297  4.95258503\n",
            " -2.11976086 -0.28101069]. \t  -441.6410543584494 \t -111.84379356128198\n",
            "55     \t [-3.05083688 -1.60816064  4.15313833 -2.50913105  3.6033683  -3.65775071\n",
            " -4.91387156 -4.80068413]. \t  -590.0002328578703 \t -111.84379356128198\n",
            "56     \t [-4.88768133  3.29570613  2.09412092 -2.14074906  2.69844291 -3.74738741\n",
            "  0.35657769  4.68206425]. \t  -374.0293232792685 \t -111.84379356128198\n",
            "57     \t [ 1.62046483  4.35237479  1.88716379 -4.3040567  -4.15775755 -4.5300245\n",
            "  2.79406742 -4.72112814]. \t  -567.8175839722142 \t -111.84379356128198\n",
            "58     \t [-3.36224788  3.9744885  -3.64422845 -4.61498564  4.778964    4.3424576\n",
            "  1.66722271  1.74514012]. \t  -439.0870473002398 \t -111.84379356128198\n",
            "59     \t [ 5.11116707  4.67987244 -4.56288268 -4.2464596   3.41418859  4.91633696\n",
            "  1.34541238  2.60420866]. \t  -474.7476093297524 \t -111.84379356128198\n",
            "60     \t [-2.828024   -0.51887756  4.61153321 -4.94897517 -2.38701365  3.59365564\n",
            " -2.62661722  0.10615489]. \t  -324.6636371946109 \t -111.84379356128198\n",
            "61     \t [ 5.10543846 -1.67019775 -3.63797596 -3.46517951 -4.56016951  3.63385945\n",
            "  3.15710461  2.44272592]. \t  -420.0908885500898 \t -111.84379356128198\n",
            "62     \t [-0.62615271 -4.48289363 -4.39819964  2.03805512 -2.91772018  3.35477771\n",
            "  4.40723974 -0.5197243 ]. \t  -363.4517907202569 \t -111.84379356128198\n",
            "63     \t [ 3.47428488  5.03541325  0.22180637  4.26004929 -2.28504834 -5.11230615\n",
            " -0.08705     4.54188002]. \t  -483.52481361115497 \t -111.84379356128198\n",
            "64     \t [ 0.17344329 -1.53598671  3.52981782  3.51487094 -0.34719123  2.2044257\n",
            " -4.13665124  0.71091624]. \t  -245.1307696521949 \t -111.84379356128198\n",
            "65     \t [-4.22579324 -4.49738877 -3.30500583 -3.51809207  4.57238274 -2.98275492\n",
            "  1.17620888 -3.04512418]. \t  -382.3683204798107 \t -111.84379356128198\n",
            "66     \t [-0.49396015 -3.72301906 -4.94829631 -3.69967489 -0.10474981 -4.36467388\n",
            "  4.82985959  1.81833452]. \t  -460.2736854445637 \t -111.84379356128198\n",
            "67     \t [ 2.72827422 -3.86887931 -3.31944909  1.18118615  4.82201159  4.64212594\n",
            " -1.29312772 -4.53849564]. \t  -498.0607390288718 \t -111.84379356128198\n",
            "68     \t [ 2.61174095  3.99266617  2.75716316  4.18871359 -4.28773962  2.12467516\n",
            "  3.18384054 -2.19086589]. \t  -360.05714251453844 \t -111.84379356128198\n",
            "69     \t [ 0.18908828 -0.92140198 -4.30803247  0.92772146  2.04306213  3.24398199\n",
            "  1.83496246  4.98200742]. \t  -366.9976405492453 \t -111.84379356128198\n",
            "70     \t [-4.05516868  3.48911801 -4.9555899  -2.5126909   4.98995879 -0.36038673\n",
            " -2.54726044 -4.97679526]. \t  -508.56575199417273 \t -111.84379356128198\n",
            "71     \t [-3.35680408  3.13121704 -0.14111465  3.81038501  2.70032247 -3.59166121\n",
            " -4.82683279  4.09255751]. \t  -499.9523571487148 \t -111.84379356128198\n",
            "72     \t [-2.55691975  3.48737527 -4.7376207  -1.65925927 -5.05517871 -3.1832294\n",
            "  1.49332729  4.85083626]. \t  -501.63606577886577 \t -111.84379356128198\n",
            "73     \t [-4.56197848 -0.86663745  3.36407686 -2.91185916 -5.04540774 -3.45255604\n",
            "  2.43655697  4.8993994 ]. \t  -522.5726431581137 \t -111.84379356128198\n",
            "74     \t [-4.48134113  2.63908144  3.25790194  2.39944995 -4.46792582  0.91222415\n",
            "  3.46835163 -4.42135255]. \t  -434.28096716948767 \t -111.84379356128198\n",
            "75     \t [ 0.26411705  5.09176606 -5.03143595 -3.35651539 -0.61300259  4.29650022\n",
            " -1.08250851 -3.93305928]. \t  -417.5255069890516 \t -111.84379356128198\n",
            "76     \t [-4.67713792  3.39659925  1.95417148  5.05241469 -4.10243776 -3.42805633\n",
            " -4.7644036  -4.11326319]. \t  -607.4209909284011 \t -111.84379356128198\n",
            "77     \t [-2.27107276 -1.53598922 -1.5330107  -3.41272979 -2.75812335  4.85310615\n",
            "  5.06754425  2.64714538]. \t  -478.6846810786384 \t -111.84379356128198\n",
            "78     \t [-1.06561646 -3.0239988  -3.71880757  4.77374945  0.90848951 -0.92967804\n",
            " -2.74714388 -2.67518282]. \t  -271.4609954000052 \t -111.84379356128198\n",
            "79     \t [-0.76154725 -0.83842706 -2.99023145  4.57336121  3.52084614  3.66127753\n",
            "  4.00882821 -5.03233314]. \t  -569.974303877478 \t -111.84379356128198\n",
            "80     \t [-9.41319237e-01  4.77281939e+00  2.97194314e-04 -1.89009203e+00\n",
            "  3.29577845e-01  3.59761269e+00 -7.51576486e-02  4.49212034e+00]. \t  -300.4081959825444 \t -111.84379356128198\n",
            "81     \t [ 2.68387463 -4.27091083  3.22834967 -1.49711893  2.61535433 -4.67798928\n",
            "  2.68904453  4.54092065]. \t  -464.9950269004206 \t -111.84379356128198\n",
            "82     \t [ 4.25369862 -1.21309605 -1.7464494  -4.06678386 -3.50126264 -0.86979736\n",
            " -2.97550474 -3.45553946]. \t  -319.6772443725448 \t -111.84379356128198\n",
            "83     \t [-1.3711068  -3.35517963 -4.59772095 -4.3736465   2.30796838  4.59199097\n",
            "  4.83242232 -2.14435934]. \t  -517.7308739649797 \t -111.84379356128198\n",
            "84     \t [-1.94347113  4.81922375 -4.40071169  2.63372878  4.68595972  2.85049292\n",
            " -5.09192297  4.11448639]. \t  -611.5405088156442 \t -111.84379356128198\n",
            "85     \t [-0.07545681  2.65362958  4.41054894 -2.79114446  4.50363623 -2.10537028\n",
            " -4.78813391  2.80068333]. \t  -454.85337101353116 \t -111.84379356128198\n",
            "86     \t [-3.13828024  4.3162847   5.09121346  4.35883762  1.16997678 -0.88728428\n",
            " -1.68992168  0.7228624 ]. \t  -236.6076113737336 \t -111.84379356128198\n",
            "87     \t [-5.10623451 -4.43276908 -4.65799891 -1.66530535  2.15405724 -4.2092087\n",
            " -0.83294647  4.27586481]. \t  -422.181541184769 \t -111.84379356128198\n",
            "88     \t [ 3.40254174  4.40385022  4.89191724 -4.352711   -2.68888507 -3.31601326\n",
            " -0.69927811  3.60477064]. \t  -407.44609703141816 \t -111.84379356128198\n",
            "89     \t [ 4.86454233  0.84017586  3.24284407  3.94947604  2.71115558  2.75201683\n",
            "  4.29583778 -4.31437964]. \t  -479.3010518369314 \t -111.84379356128198\n",
            "90     \t [-3.15657963 -4.1487322   2.73411297  3.75448292 -4.50994011  2.09907766\n",
            " -5.11951377 -3.75699749]. \t  -547.7193929834791 \t -111.84379356128198\n",
            "91     \t [-4.38450457  4.06464434  0.51774448 -1.08868747  4.86856932 -3.61927643\n",
            "  0.83715685 -2.3683954 ]. \t  -304.701689785126 \t -111.84379356128198\n",
            "92     \t [ 3.2371991  -2.52788842 -2.48012289 -3.86695592  4.50803834 -0.82732722\n",
            " -4.96129304  4.95715762]. \t  -576.1334836829162 \t -111.84379356128198\n",
            "93     \t [ 4.75931559  1.14300116 -3.6882072   1.7566011  -4.59956057  3.7472642\n",
            "  1.51048547 -4.79592023]. \t  -468.424686809656 \t -111.84379356128198\n",
            "94     \t [-0.7934346   1.35662251  0.43600253 -2.07985137  1.51807806  4.1873137\n",
            "  3.91188237 -3.72843303]. \t  -357.23765935201664 \t -111.84379356128198\n",
            "95     \t [-3.3509565  -4.04867641  4.28640132  3.54003725  4.17378256 -3.87987531\n",
            " -0.94354641  4.46241542]. \t  -492.21970358132444 \t -111.84379356128198\n",
            "96     \t [-0.47336107  4.36609799  1.10564312 -2.67527992 -4.28340239  4.0801874\n",
            " -5.04837139 -1.04239836]. \t  -449.3659106975835 \t -111.84379356128198\n",
            "97     \t [ 1.18256771  4.9638901  -4.21212328  1.08891071  4.83728625  1.19470548\n",
            "  3.57521868 -3.51341536]. \t  -422.43636837901954 \t -111.84379356128198\n",
            "98     \t [ 1.93094854 -2.32888778 -2.58291769  4.89241242  4.42080361 -4.30469298\n",
            "  3.7912727  -0.98473907]. \t  -447.6069287783593 \t -111.84379356128198\n",
            "99     \t [ 0.85191325  4.00820567 -5.01901821 -1.83019206  4.23555191 -5.02292177\n",
            "  0.47877007 -1.59159646]. \t  -384.7751629714559 \t -111.84379356128198\n",
            "100    \t [-4.03501209  4.37894494  0.13489956  0.46462596 -3.85683718  5.11778542\n",
            "  2.01031698  0.50089373]. \t  -317.37285020198095 \t -111.84379356128198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "any0xrgYuvxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8810b59e-3665-4388-dee5-84e1ce878190"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 16 \r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_winner_16 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_16 = dGPGO_stp(surrogate_winner_16, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.72683092 -1.88041214  1.76282397  0.08101548  2.88420277 -2.21509961\n",
            " -2.72682205  0.65330879]. \t  -156.8066019097497 \t -156.8066019097497\n",
            "init   \t [ 3.84024949  2.2419755  -3.25497095 -2.62348378 -4.23877911  0.35067282\n",
            "  3.47852441 -0.5561546 ]. \t  -261.8650591886947 \t -156.8066019097497\n",
            "init   \t [ 0.26105361  3.64645501 -0.31006696  0.15828746  1.76956804 -4.75312845\n",
            " -1.21380639  1.33368774]. \t  -202.8033628398822 \t -156.8066019097497\n",
            "init   \t [ 1.67575729 -3.93174065 -4.05292123 -2.2111691  -3.83176859  3.19394297\n",
            " -2.91057129  0.66405444]. \t  -300.0085240682813 \t -156.8066019097497\n",
            "init   \t [-1.33059735  4.11084689 -1.25252503 -4.4633888  -4.89127772 -0.62411111\n",
            " -2.74874149  4.74659878]. \t  -475.05316372608854 \t -156.8066019097497\n",
            "1      \t [-4.38660667  1.62450493 -1.22519012  1.94388211  1.6423205   4.26907265\n",
            "  2.26974299  0.96861339]. \t  -210.5421323027258 \t -156.8066019097497\n",
            "2      \t [-4.78868719 -2.56736811  3.95271621  0.27973843  0.90924496  0.89094332\n",
            " -1.31633494  1.29485454]. \t  \u001b[92m-117.73785589110597\u001b[0m \t -117.73785589110597\n",
            "3      \t [-2.6753072   4.31716614  3.07622603  2.68213022  4.9079513   0.56893367\n",
            "  3.69165981 -4.94981533]. \t  -515.3837876856595 \t -117.73785589110597\n",
            "4      \t [-0.97028195  3.34594568  3.89388743  2.84798818 -4.09339045  3.51762285\n",
            " -3.93575248  2.3554368 ]. \t  -412.10031930740945 \t -117.73785589110597\n",
            "5      \t [-3.38781748  1.37235268  4.27771436  2.51930944 -4.84209936 -4.02519981\n",
            "  2.00846157 -4.51188899]. \t  -501.0658069129778 \t -117.73785589110597\n",
            "6      \t [ 3.08840881  1.09355518 -2.27221671  0.20362313  5.04563824  3.88780797\n",
            "  4.45226401  4.09078879]. \t  -518.2023890662198 \t -117.73785589110597\n",
            "7      \t [-3.45080578 -0.25583992 -4.55940953  4.95107863  3.06665401  1.69508879\n",
            " -4.47638998 -1.93280567]. \t  -406.8704959003774 \t -117.73785589110597\n",
            "8      \t [-3.46240387 -2.00909558 -2.51403845  0.58022984  4.16791614 -3.02806887\n",
            "  1.25327079 -1.73619207]. \t  -217.3515534416787 \t -117.73785589110597\n",
            "9      \t [-4.24124606  3.86550676 -1.57866608 -4.10052331 -2.28994953  0.52178909\n",
            " -0.787546   -2.50793079]. \t  -205.11844165852588 \t -117.73785589110597\n",
            "10     \t [ 2.96119612 -2.48799036  3.29814556  4.51889823 -3.76513681  3.14873152\n",
            " -5.03645634 -2.38470571]. \t  -488.888086848498 \t -117.73785589110597\n",
            "11     \t [-1.74419421 -2.97566387 -2.51770045 -0.22404063 -2.57004044 -3.18775746\n",
            "  2.26407505  4.33743539]. \t  -320.3539300741578 \t -117.73785589110597\n",
            "12     \t [ 4.18696991  3.365974   -2.54364089 -3.36838534 -1.45864595  1.08365408\n",
            " -4.60653562 -4.51818089]. \t  -434.52162334900993 \t -117.73785589110597\n",
            "13     \t [ 3.13596545  0.88316232  4.792607   -3.27713072  2.8861456   1.94236798\n",
            "  5.0311476  -0.13901156]. \t  -364.8874783478433 \t -117.73785589110597\n",
            "14     \t [ 2.64171498  2.88899805  4.77261749  4.04294004 -0.27164042 -5.07791904\n",
            "  3.3474683   0.68662433]. \t  -394.67731233605815 \t -117.73785589110597\n",
            "15     \t [-1.31218668 -3.9184267  -3.54034996 -4.92513616  4.71252513 -3.37533384\n",
            " -4.66971746 -1.34930083]. \t  -513.6655342720869 \t -117.73785589110597\n",
            "16     \t [-4.49837844 -3.57809253 -4.64732576 -0.37844856  3.02548022 -0.61761383\n",
            " -4.27377256  4.28930233]. \t  -434.3038777075816 \t -117.73785589110597\n",
            "17     \t [-1.59156241 -3.81184279  4.65017504 -3.4073155  -4.34539835 -4.09224959\n",
            " -2.10328815  2.03453059]. \t  -401.87768084752315 \t -117.73785589110597\n",
            "18     \t [ 1.19847408 -4.81665388  3.19260034 -0.13902353 -3.93813554  2.36046234\n",
            "  3.20403718 -2.53039654]. \t  -312.55153510407445 \t -117.73785589110597\n",
            "19     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -117.73785589110597\n",
            "20     \t [ 0.33706497  4.8454218  -3.99882541  3.67352063 -4.41082736  4.02070541\n",
            " -1.31646008 -4.56976066]. \t  -522.4872586728911 \t -117.73785589110597\n",
            "21     \t [ 2.09042562  4.99718894  2.41684062 -2.43981311 -3.15047351 -5.01581687\n",
            " -1.85611452 -4.97647902]. \t  -518.4645867894133 \t -117.73785589110597\n",
            "22     \t [ 4.99758685  0.24573481 -4.44491465  3.57308703 -4.51711192 -4.19008374\n",
            " -1.12675733  4.79196793]. \t  -535.3892869970293 \t -117.73785589110597\n",
            "23     \t [ 3.93387708  0.15985446 -4.11580197  0.9979959   3.8163165  -1.46824571\n",
            "  3.78534691 -3.77030722]. \t  -370.10947781714486 \t -117.73785589110597\n",
            "24     \t [-4.59056799 -3.38081711 -2.90183201  1.97333331 -2.89656159 -4.10948834\n",
            " -4.89151801 -1.28072159]. \t  -408.6595603321545 \t -117.73785589110597\n",
            "25     \t [ 0.1302977   3.40487396 -1.99470876 -4.03747961  4.89478187  2.14159484\n",
            "  2.69089617 -2.55115513]. \t  -350.4114802352062 \t -117.73785589110597\n",
            "26     \t [ 4.8552635  -3.84324687 -2.44558913  4.21382836 -1.31777993  3.10811545\n",
            "  1.4321615   3.84450068]. \t  -341.3268922674117 \t -117.73785589110597\n",
            "27     \t [-4.54420098  4.89547877 -5.09489697  2.95793517 -1.03406976 -4.57905458\n",
            " -2.37816959  4.31242752]. \t  -500.9716637417185 \t -117.73785589110597\n",
            "28     \t [-4.79842584  4.27181323  3.73461017  4.54149778 -4.32376144 -0.22810643\n",
            "  4.59276194  4.53183714]. \t  -589.6057935015588 \t -117.73785589110597\n",
            "29     \t [ 1.17845865 -4.9554146   3.73674354  5.11099538  4.45985352  1.19760374\n",
            "  1.2511522   4.83217463]. \t  -502.6938458434294 \t -117.73785589110597\n",
            "30     \t [-4.56269521 -1.86136786  4.51214993  5.10332947  0.70283726 -3.41416917\n",
            "  4.72202888 -0.67381507]. \t  -425.1262649266657 \t -117.73785589110597\n",
            "31     \t [ 3.67722984 -1.34725562  4.69347553 -3.12990734 -1.27457825  4.27064453\n",
            " -2.37102419  0.697062  ]. \t  -283.2162622924733 \t -117.73785589110597\n",
            "32     \t [-0.65878145 -3.31045371  3.55494697 -3.91169375  4.26592386  4.96784998\n",
            " -4.55981022 -5.08724753]. \t  -713.1220531581514 \t -117.73785589110597\n",
            "33     \t [-4.96253445 -4.71591949 -1.90758981  0.78252477 -3.78338675  4.87812828\n",
            "  1.37107881 -1.52787655]. \t  -328.6537610628858 \t -117.73785589110597\n",
            "34     \t [-4.15048978  2.00841566 -3.90811624 -3.43065885  4.94679223  1.0296555\n",
            "  1.61346696  4.63329723]. \t  -436.8692158150179 \t -117.73785589110597\n",
            "35     \t [ 4.87781392 -3.27687728 -1.52548253 -3.256436    2.3554773   4.10568693\n",
            " -4.41169292  4.23677047]. \t  -503.39210088739617 \t -117.73785589110597\n",
            "36     \t [-4.44703603  4.54410352  4.11500256 -1.08286348  4.70679157  0.0671524\n",
            "  1.95659366  2.65975533]. \t  -310.7526839529857 \t -117.73785589110597\n",
            "37     \t [-4.23961553  2.8661218   4.72951994 -3.27940208  0.44756815 -2.90163427\n",
            " -4.88665966  0.44874183]. \t  -364.81216403857525 \t -117.73785589110597\n",
            "38     \t [ 1.3548442  -2.91936959 -4.94113698  1.85642339 -4.29252603  4.0108326\n",
            "  5.01849823 -3.59974832]. \t  -574.5231178189481 \t -117.73785589110597\n",
            "39     \t [ 3.42067318  4.55042167 -2.70746041  4.12711395  1.28985058 -1.85708075\n",
            "  4.57025558  3.32485592]. \t  -406.89603781782597 \t -117.73785589110597\n",
            "40     \t [-2.16840619 -3.33755656 -0.15954269 -4.83748641  0.18122897 -0.08762663\n",
            "  3.76656999 -4.07113921]. \t  -352.77504593757027 \t -117.73785589110597\n",
            "41     \t [-0.89065945  1.4356561   4.63437254  4.93324663  2.12728538  1.30934584\n",
            " -3.04468305 -3.83861497]. \t  -382.37882411615556 \t -117.73785589110597\n",
            "42     \t [ 3.04327099  1.18575409 -4.78871301  4.10643835 -3.43922091 -4.32362425\n",
            "  3.62262634 -3.00315003]. \t  -483.63897844462275 \t -117.73785589110597\n",
            "43     \t [ 4.21070171 -2.28692957  4.63482251  4.60057566 -4.96438013 -4.27338855\n",
            " -0.30063325  4.82718161]. \t  -597.1385974793302 \t -117.73785589110597\n",
            "44     \t [-0.88230239  4.65638834  4.58797094 -1.22641326 -3.98226427  3.20295183\n",
            "  1.89689245 -3.35838474]. \t  -369.57008972293806 \t -117.73785589110597\n",
            "45     \t [ 4.67558399 -4.55428235  4.72742331  4.97910776  3.09857891 -1.84867635\n",
            "  4.62670044 -2.3638087 ]. \t  -492.61252401513116 \t -117.73785589110597\n",
            "46     \t [ 3.40236921 -4.11869625  0.22971092  0.53788587 -4.82949746 -4.11293012\n",
            " -1.02864356 -2.78624305]. \t  -334.4483697344649 \t -117.73785589110597\n",
            "47     \t [-0.63478582  4.8312724  -2.35568359 -0.41674687  3.93472211  2.29421882\n",
            " -4.83770365 -0.02902685]. \t  -337.24899355098694 \t -117.73785589110597\n",
            "48     \t [-2.04916815 -4.88783407  0.72846699  4.46036762 -3.73290522  2.51245331\n",
            " -2.07989721  5.01887934]. \t  -472.49488583941354 \t -117.73785589110597\n",
            "49     \t [-2.6642034   3.01656193 -4.40218102  2.14777482 -1.4398163   2.66693079\n",
            " -4.69875222  4.57871718]. \t  -477.1922001657348 \t -117.73785589110597\n",
            "50     \t [-0.99272171 -3.22855369  5.11075153 -2.32071924 -3.87876423  1.12706129\n",
            "  3.18807188  4.42966387]. \t  -432.7025640501191 \t -117.73785589110597\n",
            "51     \t [ 4.80817781  3.85751992 -1.37863086  4.421246    1.28321146  3.58672983\n",
            " -2.62732362 -1.21858967]. \t  -282.39146300704806 \t -117.73785589110597\n",
            "52     \t [-3.95536443  2.50480283 -1.27900249 -4.90303368 -4.42865558 -5.07509093\n",
            "  4.09504294  0.80789091]. \t  -504.4708588663581 \t -117.73785589110597\n",
            "53     \t [ 2.88671911  3.27637723  3.28667612  4.6728313   5.04865881  3.97040508\n",
            "  4.73848015 -0.60686072]. \t  -531.6986481545669 \t -117.73785589110597\n",
            "54     \t [ 0.67973788 -0.25806626  3.59338351 -4.65670532  5.10453878 -5.00484153\n",
            "  2.73604524 -4.69569034]. \t  -635.4419532885289 \t -117.73785589110597\n",
            "55     \t [-3.68164684 -0.02453809  4.47183333  2.4102999   3.36042369 -5.03386025\n",
            " -1.8569878   5.06894121]. \t  -534.9786667284723 \t -117.73785589110597\n",
            "56     \t [-3.08656764 -1.15803033 -4.64316667 -3.39674231  1.78552177  4.70555175\n",
            " -1.17886009 -4.96048474]. \t  -478.4103838188424 \t -117.73785589110597\n",
            "57     \t [-4.94613384  3.1336446   2.86146533 -3.32764294 -1.5282281   4.45888878\n",
            " -2.84550592  4.88241573]. \t  -491.3102132711778 \t -117.73785589110597\n",
            "58     \t [-1.64800738 -1.10272652  4.86297083 -4.44107681  2.68026523 -4.74175379\n",
            "  4.3409091   3.16110084]. \t  -537.6554420481806 \t -117.73785589110597\n",
            "59     \t [ 2.84818722 -3.90221884  2.01968991  2.45874044  4.62156312  3.80948294\n",
            " -0.36125748 -5.01320405]. \t  -470.8243117044938 \t -117.73785589110597\n",
            "60     \t [ 3.65739737 -4.33649187 -1.09696817 -4.86901199  4.40209653 -3.68221565\n",
            "  3.4123857   1.4057571 ]. \t  -424.99040659942136 \t -117.73785589110597\n",
            "61     \t [4.15629992 0.47444428 4.41860992 4.20568195 0.06581134 3.09550068\n",
            " 0.31384155 4.2862439 ]. \t  -352.2273800224795 \t -117.73785589110597\n",
            "62     \t [ 4.96345953  4.51198931  4.96852858  1.84589141  4.97661164 -3.36863299\n",
            "  0.03380845 -2.14056182]. \t  -381.6236013221256 \t -117.73785589110597\n",
            "63     \t [ 3.41385663 -3.68770101 -1.62949244 -4.86873635  4.10309929  4.72857145\n",
            "  4.59378451 -3.57374295]. \t  -609.8633545301722 \t -117.73785589110597\n",
            "64     \t [ 4.99698708  1.92266627  0.79574025 -2.88895451 -2.89857773 -3.7070597\n",
            "  5.08850119  4.64443653]. \t  -545.9257611564904 \t -117.73785589110597\n",
            "65     \t [-2.58306752 -3.99053603  2.89333682  3.58578072  4.42016552 -2.83194717\n",
            " -5.09915531 -1.91402886]. \t  -472.1930911250166 \t -117.73785589110597\n",
            "66     \t [ 4.9873039   4.5801764  -1.19544913 -4.59885216  1.04509742  4.40340608\n",
            " -1.1538206   2.06023722]. \t  -320.7910790578681 \t -117.73785589110597\n",
            "67     \t [ 2.16875472  0.22721717 -1.35926645  5.05593408  2.1604286  -2.51846482\n",
            " -4.69786784 -2.63287743]. \t  -383.9387788909533 \t -117.73785589110597\n",
            "68     \t [-0.01246799  5.01907757 -2.40078927  2.24103151 -4.65281573  2.31621474\n",
            "  3.16121786  4.04249119]. \t  -428.88223522043336 \t -117.73785589110597\n",
            "69     \t [ 4.07789256  0.94138031  1.66205745 -1.37196685 -2.43039571 -3.47496882\n",
            " -4.85853176  4.06199774]. \t  -433.440566301039 \t -117.73785589110597\n",
            "70     \t [-2.77299158 -3.47307972  2.51087566 -4.52023661  3.62846963  4.64675671\n",
            "  4.02123483  3.77361926]. \t  -554.9546658069055 \t -117.73785589110597\n",
            "71     \t [ 1.03156022 -4.52749394  3.82702437 -4.656528   -1.57677841 -1.56612476\n",
            " -1.96411366 -4.71726424]. \t  -404.9043618897126 \t -117.73785589110597\n",
            "72     \t [ 1.81281995 -0.84686494 -5.08764029 -2.75023302  3.39163776 -3.04250294\n",
            " -1.13078714  3.69941788]. \t  -344.12133122540484 \t -117.73785589110597\n",
            "73     \t [ 4.6674457   3.57456028 -0.91317413  4.67636635 -4.07670262  4.44093558\n",
            "  4.88645416 -4.11897124]. \t  -641.6136884978539 \t -117.73785589110597\n",
            "74     \t [ 4.16890139 -2.59448748 -3.87431049 -3.82999448  3.0694267   3.57025093\n",
            " -3.08435176 -3.01418755]. \t  -397.41098988952285 \t -117.73785589110597\n",
            "75     \t [ 2.01820543  4.89364052  4.53431323 -0.74318897 -4.17296084  0.33323307\n",
            "  3.39141732  3.78965768]. \t  -398.9961959394856 \t -117.73785589110597\n",
            "76     \t [ 5.00601522  3.15505457  3.37130099 -2.56404302  4.78635606 -4.38217185\n",
            "  1.84524298  3.63052256]. \t  -464.4098111176261 \t -117.73785589110597\n",
            "77     \t [-4.92926094  2.22052502 -3.79570519  4.19479146 -0.01595398 -4.896653\n",
            "  4.68036849 -0.45726723]. \t  -446.64453857608163 \t -117.73785589110597\n",
            "78     \t [ 4.25416187 -4.66137062  4.14053243  5.10519263 -0.58689922 -0.15969953\n",
            " -4.87940179  4.75870798]. \t  -566.9362617345502 \t -117.73785589110597\n",
            "79     \t [ 4.65885261  4.72028968  4.12431482  0.52862603 -3.33088573  2.66991378\n",
            " -4.57255548 -3.51233546]. \t  -461.7093617268231 \t -117.73785589110597\n",
            "80     \t [-0.86262972  4.5741383   4.75968151 -1.67660802  3.66887655  2.74970279\n",
            " -3.81305266 -3.70172006]. \t  -445.86328821230626 \t -117.73785589110597\n",
            "81     \t [ 2.6625347  -2.82277578 -3.63612977  5.09960615  3.72991123  4.12741549\n",
            " -1.92089592 -0.10116875]. \t  -364.3987777466257 \t -117.73785589110597\n",
            "82     \t [ 3.69069373  5.03179346  5.09352277  3.97808174 -0.05159456 -4.64712968\n",
            " -4.00524272  4.670035  ]. \t  -621.7473669465957 \t -117.73785589110597\n",
            "83     \t [-4.25167978  4.65469243  2.22069625  4.55644664  5.02231669  0.17278159\n",
            " -4.83861862  1.05240318]. \t  -458.29187996727217 \t -117.73785589110597\n",
            "84     \t [-3.72470503  0.25930417 -0.71816963  1.98149142 -4.09516693  2.37440385\n",
            " -4.59444188 -3.99702894]. \t  -424.51135946330453 \t -117.73785589110597\n",
            "85     \t [ 2.44501185 -4.97365588 -4.63218054 -4.26579793 -5.07363774 -4.5723603\n",
            " -2.45442215  1.26720439]. \t  -501.77565042483496 \t -117.73785589110597\n",
            "86     \t [ 3.65175671  4.92080501 -3.55665505  2.66808762 -3.92268694 -4.99803802\n",
            " -4.04007847 -5.02252361]. \t  -671.0693771770107 \t -117.73785589110597\n",
            "87     \t [ 0.13649047  2.22382126 -3.162174   -2.51518327  3.86859007 -3.53145776\n",
            " -1.65844369 -4.63015487]. \t  -405.62884249599534 \t -117.73785589110597\n",
            "88     \t [-3.52763176 -0.96572224  2.46750904 -1.46165518  4.63352251  3.129943\n",
            "  4.97265812 -3.07459676]. \t  -455.96434736571894 \t -117.73785589110597\n",
            "89     \t [-4.78289531 -4.23761    -4.85901696  3.47486778  2.10390228  2.18377799\n",
            "  1.06241423  1.2284295 ]. \t  -248.63844858091727 \t -117.73785589110597\n",
            "90     \t [-0.6982644   3.74795405 -0.88962747  4.14483126  5.08736881  4.68167728\n",
            " -3.50797399 -5.00578697]. \t  -647.1943238881397 \t -117.73785589110597\n",
            "91     \t [-2.92516463 -4.14214912 -3.32335656 -1.93432379 -4.53144671 -3.62940736\n",
            "  2.55292045 -2.97998056]. \t  -389.34164322975727 \t -117.73785589110597\n",
            "92     \t [-2.97670559  4.46794386  3.18523429  0.40255763  2.11894554 -4.99997657\n",
            " -1.06491429 -4.61422104]. \t  -430.5860128140305 \t -117.73785589110597\n",
            "93     \t [-2.5198818   1.07164519 -3.88854199 -4.77485719 -4.21931995  2.64593383\n",
            "  4.22048817 -4.4611322 ]. \t  -560.1263181463627 \t -117.73785589110597\n",
            "94     \t [-4.60814259  4.74818525  2.13563895 -1.07770594 -0.53426838 -1.36957796\n",
            "  5.08555413 -1.22559663]. \t  -290.3925646970471 \t -117.73785589110597\n",
            "95     \t [-4.91072464  0.88493216 -4.65515387  3.56097571 -4.52936389 -0.83351412\n",
            "  2.13889084 -4.47016227]. \t  -440.04193586503175 \t -117.73785589110597\n",
            "96     \t [-0.51076038 -1.86396178  4.45362956 -4.81427684  0.59712694  0.27146243\n",
            " -4.30831438  4.77786554]. \t  -474.2030346429683 \t -117.73785589110597\n",
            "97     \t [ 0.10821692  0.24283574  4.37231061  0.79507675  2.60918292  3.97963699\n",
            " -5.06390274  4.76102484]. \t  -549.914415816483 \t -117.73785589110597\n",
            "98     \t [ 3.65117855 -4.94014869 -1.27152034 -5.09608233 -2.60445226 -0.21613057\n",
            "  2.69914467  4.76523091]. \t  -437.72496646620164 \t -117.73785589110597\n",
            "99     \t [ 3.01339203  2.14502498 -1.43540873  1.15190419 -4.87235662  0.40995634\n",
            " -2.83503528 -0.27868175]. \t  -206.3624876719815 \t -117.73785589110597\n",
            "100    \t [ 4.9340902   3.62900328  4.85349798 -1.37209557 -0.51923843 -0.14824022\n",
            "  1.19000523 -4.89477118]. \t  -331.9474492992618 \t -117.73785589110597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reLyKt6Quvzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327d06ab-9337-440b-d950-f1536f5a18d3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 17 \r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_winner_17 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_17 = dGPGO_stp(surrogate_winner_17, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.55467805  2.36052095 -3.13991821  0.20149492  1.80616465  3.1175155\n",
            "  0.34317173  4.17827   ]. \t  -258.41326242861834 \t -235.79782281711795\n",
            "init   \t [-0.57875324 -2.49884457 -2.26647022 -4.67638414 -0.31769608  4.52212527\n",
            "  1.02815985  3.77559691]. \t  -360.3515407216042 \t -235.79782281711795\n",
            "init   \t [-1.56342663  0.20561354 -4.2801447   1.05706761 -4.41947127 -0.8235598\n",
            "  0.12249555 -4.00962754]. \t  -292.4074163867352 \t -235.79782281711795\n",
            "init   \t [ 4.87253618  0.77758176  1.94038044  4.01713279  4.85251496 -0.60490047\n",
            " -0.9483114   1.04745517]. \t  -235.79782281711795 \t -235.79782281711795\n",
            "init   \t [-1.91993985 -0.06178726  4.23457571  3.73427573  1.95047484 -4.92945438\n",
            "  2.09212815 -3.62478353]. \t  -413.83828931150714 \t -235.79782281711795\n",
            "1      \t [4.51401957 4.23400766 4.83433318 3.1296932  0.24588569 1.21802929\n",
            " 4.61282793 1.4098879 ]. \t  -339.57567715308704 \t -235.79782281711795\n",
            "2      \t [ 4.34613475  0.09909698 -3.33092813  2.82766181 -2.84562198  4.50627157\n",
            " -0.1584268  -1.6809663 ]. \t  -269.2840576493786 \t -235.79782281711795\n",
            "3      \t [ 4.09497634 -4.75974532 -3.00272806 -0.06611657 -4.33996548 -0.09387773\n",
            " -4.44896948 -0.0285772 ]. \t  -321.93501465656647 \t -235.79782281711795\n",
            "4      \t [-4.99925133 -4.18488405 -1.85934976  4.24459381  2.84233518  4.72679143\n",
            "  0.94643919  5.11383892]. \t  -532.3875812684558 \t -235.79782281711795\n",
            "5      \t [-4.32324557  4.16008425  0.73400626  1.37941964  2.39241189  1.2191708\n",
            "  4.5820686   2.43094463]. \t  -294.3103842772912 \t -235.79782281711795\n",
            "6      \t [ 4.42595181  0.54614973  2.56689034 -3.13851565  1.0307697   2.47296272\n",
            " -4.33428986  0.81887648]. \t  -258.2261564362497 \t -235.79782281711795\n",
            "7      \t [ 0.66447238 -3.91103033  4.17858658  0.21711608 -4.3397492   4.31302174\n",
            " -1.5125309  -0.58820395]. \t  -308.1663286769472 \t -235.79782281711795\n",
            "8      \t [-4.87547998 -1.56374704 -3.87137333  4.60172558 -3.46813326  4.51981227\n",
            " -4.67560113 -2.98692641]. \t  -565.4415383736457 \t -235.79782281711795\n",
            "9      \t [-1.0296616   3.11959071  2.37143083 -4.00631249 -3.69364403  2.99630416\n",
            "  0.3118283  -0.27779663]. \t  \u001b[92m-224.97719563161542\u001b[0m \t -224.97719563161542\n",
            "10     \t [-0.42337672  4.61669406 -0.68144138 -2.40854511 -2.2300071  -3.18869405\n",
            "  2.38569872  4.45204396]. \t  -351.6821701601855 \t -224.97719563161542\n",
            "11     \t [ 2.67117625  0.41299568  4.43883274  0.14211974 -1.31876413 -4.67433041\n",
            " -3.51524601 -1.16802904]. \t  -303.8717125415504 \t -224.97719563161542\n",
            "12     \t [-2.39912946 -0.40391774  1.50089901  3.98167608 -0.07684324  3.31681758\n",
            "  4.55010235 -3.45206108]. \t  -382.5502155884982 \t -224.97719563161542\n",
            "13     \t [-4.91803505  2.43422197  4.33040501  1.77553571  4.65284727  0.77129538\n",
            " -2.87632152 -3.95852696]. \t  -399.9916545335009 \t -224.97719563161542\n",
            "14     \t [ 4.11175318  2.80801549 -1.26863971 -3.37463256  3.64211405 -4.6463789\n",
            " -3.17780536  3.49343491]. \t  -447.2371585411927 \t -224.97719563161542\n",
            "15     \t [ 2.71173551 -4.48883927 -1.17375609 -2.07466    -2.88595299 -1.60420718\n",
            "  4.66211335 -4.86499068]. \t  -467.57952055289456 \t -224.97719563161542\n",
            "16     \t [-3.99721755 -4.89643028  0.24902574  4.98268391  0.87508303 -1.69873076\n",
            " -4.24816469 -2.56365359]. \t  -363.4722531738524 \t -224.97719563161542\n",
            "17     \t [-0.97395561 -1.58591984  3.27776365 -4.32329374  3.33488848 -2.96973725\n",
            "  2.04826637 -3.35315313]. \t  -340.8138469903375 \t -224.97719563161542\n",
            "18     \t [-0.1582644  -4.53980592  3.77882912 -0.95929499  4.72375042 -4.78249914\n",
            " -5.0138651  -2.75891631]. \t  -573.432093961146 \t -224.97719563161542\n",
            "19     \t [-0.90152942  4.09186072  4.98192051  4.53977312  3.03038167  4.42184699\n",
            " -3.14089371  4.02928056]. \t  -553.3659171503199 \t -224.97719563161542\n",
            "20     \t [ 1.36183914 -3.95264993  0.5964067   1.60673003  2.84621685 -4.96563471\n",
            "  3.28290177  4.95002935]. \t  -504.4092696086917 \t -224.97719563161542\n",
            "21     \t [-2.08177508 -2.23587536 -4.69274887  4.87939164  0.25276699 -0.23102108\n",
            "  4.29444994  1.66268476]. \t  -327.4835389316838 \t -224.97719563161542\n",
            "22     \t [ 4.23861552 -2.48393227 -4.57403057 -3.16960581  3.99046815  1.43977106\n",
            " -4.21569061  2.14353763]. \t  -386.4757558417865 \t -224.97719563161542\n",
            "23     \t [-4.2956962   2.33694966 -3.23021314  2.66925593  4.73924811 -1.40828798\n",
            " -4.02964557  2.62745726]. \t  -382.2747833250679 \t -224.97719563161542\n",
            "24     \t [-0.42896627  3.06413379 -4.55801291 -4.72935142  3.32813782 -3.45929822\n",
            "  4.60756347 -3.04775083]. \t  -520.8560892476327 \t -224.97719563161542\n",
            "25     \t [-5.04556993 -4.5814586   4.63018096  4.03567194 -4.20159207  2.81635396\n",
            "  1.59623998  4.5404559 ]. \t  -515.5193907559262 \t -224.97719563161542\n",
            "26     \t [-2.94601882 -0.88392029 -1.05231614 -3.00444486  4.9702821   3.39218985\n",
            " -3.58068651 -3.52587805]. \t  -431.43449211034044 \t -224.97719563161542\n",
            "27     \t [ 0.38019758  4.71884629  4.85862344 -0.33636536  3.56042973 -4.99211481\n",
            " -0.18818033  2.52571136]. \t  -380.14298948509673 \t -224.97719563161542\n",
            "28     \t [-0.83512656 -4.9031669   4.59254125  2.90106204  2.47815275  3.56326116\n",
            " -4.36337063  2.83296984]. \t  -450.08443044477997 \t -224.97719563161542\n",
            "29     \t [-3.31908315 -5.03030536  1.18061385 -2.75290743 -4.02728928 -1.70130076\n",
            "  0.91179534  0.27319729]. \t  \u001b[92m-200.99833115161596\u001b[0m \t -200.99833115161596\n",
            "30     \t [ 4.1413604   4.07719096 -3.59055524 -2.14740099  1.89158076  4.29791614\n",
            "  0.37890409 -4.95701934]. \t  -433.82361525327997 \t -200.99833115161596\n",
            "31     \t [-0.89543456  2.27886115  0.95963657  3.74243552 -4.30676707  5.05628436\n",
            " -1.36187373  2.83196312]. \t  -393.2545245218831 \t -200.99833115161596\n",
            "32     \t [-3.24965401 -4.87134067 -3.36610593 -2.64182318  0.20386318  2.17216865\n",
            "  1.51233768 -4.45333259]. \t  -323.1143241467338 \t -200.99833115161596\n",
            "33     \t [-3.32478137  4.41125147  3.15404398  5.10324725 -4.62562668 -3.74753996\n",
            "  1.24071878  4.99298375]. \t  -585.4501812564552 \t -200.99833115161596\n",
            "34     \t [ 4.2393102   1.27307906  4.88831422 -3.80009043 -0.13200775 -4.26968953\n",
            "  4.3216533   1.27030179]. \t  -403.7775742657542 \t -200.99833115161596\n",
            "35     \t [-2.96954285 -2.92558     4.90987685 -3.19545698  2.0966794  -1.77960537\n",
            " -0.74596167  3.62067124]. \t  -288.85226230032816 \t -200.99833115161596\n",
            "36     \t [ 4.10680057  0.29597613  4.84746179 -4.30778906  3.20605188  4.62870634\n",
            "  3.03834261 -1.52396206]. \t  -424.9065997925308 \t -200.99833115161596\n",
            "37     \t [ 3.2388431   4.68892488  0.06419265  4.55343367 -3.67688702 -3.69956067\n",
            "  1.96500398 -1.57070058]. \t  -333.89300509758795 \t -200.99833115161596\n",
            "38     \t [ 5.00984969 -4.75358018  3.67958593 -3.9664102  -2.97441938 -0.6986476\n",
            " -2.76115774 -3.70203639]. \t  -384.0123759912306 \t -200.99833115161596\n",
            "39     \t [-2.39965645 -3.87504649  4.80955219  3.05166243  4.98203402 -0.47402268\n",
            "  4.38354446  1.43731987]. \t  -418.92311471963916 \t -200.99833115161596\n",
            "40     \t [ 1.94290847  4.12612482 -2.84348525 -2.87900641 -4.41763246  3.14215175\n",
            " -4.44917031  0.84291858]. \t  -396.30163967010014 \t -200.99833115161596\n",
            "41     \t [-2.93654602 -1.42330592 -1.67539101  3.15211522 -1.2096753  -4.67257911\n",
            " -4.77045439  4.71256002]. \t  -536.119995018724 \t -200.99833115161596\n",
            "42     \t [ 4.69111627 -3.53101094  0.28170453  5.04092375 -4.56267124 -2.40663405\n",
            "  3.40909526  0.46123862]. \t  -370.72098046770805 \t -200.99833115161596\n",
            "43     \t [ 0.14207989 -4.16734201 -3.9231274   4.33583303  3.71040455  4.02109106\n",
            " -4.3760546   1.60196226]. \t  -476.5540347176991 \t -200.99833115161596\n",
            "44     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -200.99833115161596\n",
            "45     \t [-4.35948625  3.55313159  4.00380107  0.20814197 -3.98672602 -3.01662016\n",
            "  4.74778346 -1.99278162]. \t  -416.1486378692074 \t -200.99833115161596\n",
            "46     \t [ 4.78980614 -4.78015147  4.69514666  3.09370548  2.78784976 -4.57333187\n",
            "  2.52515842 -1.33038845]. \t  -396.2063603686764 \t -200.99833115161596\n",
            "47     \t [ 3.69038638 -3.60507036  0.67591945  0.75823951  4.9508242   2.93791524\n",
            "  4.11835308  2.20827505]. \t  -375.361357479491 \t -200.99833115161596\n",
            "48     \t [ 3.02371722  4.64041477  2.25997476  4.33535225 -4.10610989  1.58210572\n",
            " -4.47321992 -4.2107176 ]. \t  -523.9413984261104 \t -200.99833115161596\n",
            "49     \t [-4.74154813  3.44558122  5.11444234 -4.86875511 -0.52472458 -2.26284615\n",
            " -3.42916004  0.46949369]. \t  -335.6948851886345 \t -200.99833115161596\n",
            "50     \t [ 0.94272769 -2.52054987 -4.41825923 -1.66833676  3.15976055 -3.79338516\n",
            "  0.10877699 -0.60626828]. \t  -222.57388898601613 \t -200.99833115161596\n",
            "51     \t [ 3.55972427  1.1001323  -2.9817366   3.64506894  0.95608296 -2.47454836\n",
            " -3.98064685 -5.09137903]. \t  -454.5173679278165 \t -200.99833115161596\n",
            "52     \t [ 3.85315718 -4.76982924  1.27741473  4.644834   -0.56684401  4.16109384\n",
            " -3.88965638 -4.14799093]. \t  -500.5900488104906 \t -200.99833115161596\n",
            "53     \t [ 0.53015676 -4.17351728 -2.43226136  4.52207796  0.42167391 -4.72545259\n",
            "  2.48940599 -4.47370745]. \t  -473.0229205971543 \t -200.99833115161596\n",
            "54     \t [ 3.57201324 -5.07991833  2.73964124 -4.76085227 -4.13058937  3.4234442\n",
            "  3.52110796  3.62533945]. \t  -525.1109404328613 \t -200.99833115161596\n",
            "55     \t [ 4.52673038  0.81328718 -2.14888224  4.11613796  4.95007934  3.27027657\n",
            "  0.87571938 -4.69198333]. \t  -471.6081433586031 \t -200.99833115161596\n",
            "56     \t [-4.56260671 -1.73328229 -3.83262315 -2.52035075  4.83170919 -5.03594516\n",
            "  5.03294558  3.98537698]. \t  -669.5727429846723 \t -200.99833115161596\n",
            "57     \t [-4.83617349  2.35578855 -1.55925826 -4.45152927 -2.26349438 -4.14723966\n",
            " -0.40733697 -3.46238972]. \t  -346.9275826315857 \t -200.99833115161596\n",
            "58     \t [ 5.01294029  4.43078465  0.66675486 -4.80069846 -4.78779884 -1.54983127\n",
            "  0.93312558 -3.0990618 ]. \t  -369.8692706852889 \t -200.99833115161596\n",
            "59     \t [-4.61914149  2.24108251 -1.80158714 -4.37651943  0.95145479  4.89044218\n",
            "  4.80895592 -2.94569514]. \t  -497.0584451287923 \t -200.99833115161596\n",
            "60     \t [ 4.56341006 -3.70480144  2.29512498  3.67753885 -3.73768805  4.79578193\n",
            "  4.74189564  4.5422685 ]. \t  -648.4811335585395 \t -200.99833115161596\n",
            "61     \t [ 4.91420782 -4.49725829  0.08629989 -0.31611053 -1.33910004  4.15445806\n",
            " -2.94468413  5.00594308]. \t  -438.71910543783093 \t -200.99833115161596\n",
            "62     \t [-2.73897691  4.91950407 -1.37026923 -4.16840439 -2.88773815 -3.8515979\n",
            " -5.11978756  1.72687126]. \t  -469.0865722344169 \t -200.99833115161596\n",
            "63     \t [-3.38645982 -3.93279769 -3.79556795 -5.08322387 -4.27897994 -2.9913212\n",
            " -3.76362655  4.77725616]. \t  -615.9455408955137 \t -200.99833115161596\n",
            "64     \t [-4.84050927 -3.67630575  3.08952663 -5.10271817 -0.68440265  4.13542233\n",
            " -4.23747942  4.55070742]. \t  -579.56490251009 \t -200.99833115161596\n",
            "65     \t [ 4.28273394 -0.21918968  2.78487533 -4.79375839 -4.18986546 -2.76124552\n",
            " -3.43650881  3.9992659 ]. \t  -477.7668631075229 \t -200.99833115161596\n",
            "66     \t [ 2.64907632 -4.89003889 -1.70313374  2.80278114  2.86168224 -4.66143795\n",
            " -4.78753965  1.15823477]. \t  -437.46285057802856 \t -200.99833115161596\n",
            "67     \t [ 0.12445425  3.83679128 -1.19627223  0.80896538  3.89103496 -3.92005976\n",
            "  0.93804854 -4.5726706 ]. \t  -377.70437835495227 \t -200.99833115161596\n",
            "68     \t [ 0.24513486  4.7228398   1.10025392  5.01791889 -0.12826607 -2.28957605\n",
            " -3.46972307  0.89286433]. \t  -271.2059512479371 \t -200.99833115161596\n",
            "69     \t [-4.54724981 -1.37948467 -5.09590997 -0.87163641 -1.22077002 -3.92928897\n",
            " -5.05458181 -0.95823093]. \t  -391.70183332931913 \t -200.99833115161596\n",
            "70     \t [ 4.52707993 -3.86678494 -5.05490781 -3.66636342  1.21810632  1.21325323\n",
            "  5.08597916  1.95879247]. \t  -408.83971347676527 \t -200.99833115161596\n",
            "71     \t [ 3.43643853  4.86561813 -2.82830931  2.35804048  1.257945   -4.63762292\n",
            "  4.69455667  4.30983671]. \t  -545.2239916608052 \t -200.99833115161596\n",
            "72     \t [ 5.06928509  2.4266353  -4.91904907  1.23426309 -4.10391231 -2.05925418\n",
            " -4.85808634  3.89874544]. \t  -512.6219175987422 \t -200.99833115161596\n",
            "73     \t [-3.91609078  4.93539131 -4.09681164 -2.90362741  4.3958853  -3.18762264\n",
            " -4.30692775 -3.0484357 ]. \t  -509.90348212271005 \t -200.99833115161596\n",
            "74     \t [ 1.98644632  0.43258677 -4.93978106 -5.06522396 -4.14735352 -4.8650203\n",
            "  3.63348669 -2.59279363]. \t  -554.3599683503475 \t -200.99833115161596\n",
            "75     \t [-3.36570282  2.80018089 -4.00857349  4.82944874  4.47821945  4.79164122\n",
            "  2.19220655 -4.45283431]. \t  -598.8037209885565 \t -200.99833115161596\n",
            "76     \t [-3.70033362  3.09235811  0.93610651 -1.53062249  2.28785528  4.75148954\n",
            " -4.15173357  3.13498138]. \t  -405.7323673176027 \t -200.99833115161596\n",
            "77     \t [-3.03182367 -3.87592135 -3.10522361  1.05015    -4.50916599  4.50318357\n",
            " -5.06412894  3.52010755]. \t  -574.5579228153925 \t -200.99833115161596\n",
            "78     \t [-3.44952062  1.75044505  3.83483538  2.5045381  -4.96752657  3.86108928\n",
            "  5.11176534  3.86896095]. \t  -602.7275881952725 \t -200.99833115161596\n",
            "79     \t [-4.60527794  3.53585134 -3.57497982  2.27056368 -2.23132375 -4.41475909\n",
            "  4.80411673 -0.70611909]. \t  -412.5565653949465 \t -200.99833115161596\n",
            "80     \t [-4.81331951 -3.04905195 -4.12351686 -1.38496986  5.0177192   4.53159866\n",
            " -3.51822253  4.40201877]. \t  -591.2114517002171 \t -200.99833115161596\n",
            "81     \t [-0.84971768 -0.63044286 -3.54556918  1.97709535 -5.09994153 -0.11637113\n",
            "  0.92028736  4.92131649]. \t  -384.67736388046984 \t -200.99833115161596\n",
            "82     \t [-4.29167576  3.29080091  3.27852772  2.36837542 -1.60790481  4.96645279\n",
            " -4.39674688 -2.19277236]. \t  -429.4666582909185 \t -200.99833115161596\n",
            "83     \t [ 4.24054336  4.86732567  0.19885329 -3.10189148  2.79797745 -0.6630878\n",
            "  2.08329469  0.92531307]. \t  \u001b[92m-182.9814303884602\u001b[0m \t -182.9814303884602\n",
            "84     \t [ 2.04104089  0.97464656  0.3874591  -5.08511988 -2.99627124 -1.39377989\n",
            " -4.84859833 -3.19756146]. \t  -412.85134574446585 \t -182.9814303884602\n",
            "85     \t [ 0.50406446 -4.94261379  3.4802338   3.79446528 -3.8101912  -3.26585342\n",
            " -1.60779726  1.43513559]. \t  -314.1954657690812 \t -182.9814303884602\n",
            "86     \t [-4.32371967 -4.53270158  4.61547257 -4.72141999  2.1262934   0.58581821\n",
            " -3.35067192 -2.74183972]. \t  -376.255519603654 \t -182.9814303884602\n",
            "87     \t [-3.98500877  4.96963753 -3.63670621  3.74135637 -1.97690418 -4.87112277\n",
            " -4.45640057 -2.25003456]. \t  -502.3683345711294 \t -182.9814303884602\n",
            "88     \t [-1.02165372  0.03412216  4.79013013  2.12676276 -0.83824054 -0.75060813\n",
            "  2.0437267   3.77813049]. \t  -238.3002275502049 \t -182.9814303884602\n",
            "89     \t [ 3.70658639 -2.52231928 -3.76122132 -3.94875732 -4.64258328  4.75056288\n",
            " -3.04953011 -3.86700076]. \t  -559.1760469977015 \t -182.9814303884602\n",
            "90     \t [-4.99348971 -3.37970472  4.34703657 -4.64302241 -1.50930312  4.89159348\n",
            "  4.35421513  0.31434525]. \t  -479.1614861084114 \t -182.9814303884602\n",
            "91     \t [-4.67974089  4.83937804  4.2516176   1.22682902  5.04408485 -3.26813891\n",
            "  2.85488902 -1.41057782]. \t  -393.25725823272194 \t -182.9814303884602\n",
            "92     \t [-4.77735319  4.04414258 -2.5334635   2.66927273 -4.02986687  4.92818197\n",
            "  4.68689733 -2.93829773]. \t  -553.0474560941333 \t -182.9814303884602\n",
            "93     \t [-3.58033345 -1.78427799  2.14564006 -0.8141816  -3.89065017  0.18518801\n",
            " -3.76734901 -3.46569252]. \t  -306.9791519781397 \t -182.9814303884602\n",
            "94     \t [ 4.78815676  1.01952672  1.28062913 -4.27070776  4.84997387  0.06051907\n",
            " -4.85376103 -4.71992551]. \t  -563.6488820046261 \t -182.9814303884602\n",
            "95     \t [-2.95317364  3.77739479  3.70785463 -2.93038224  4.14204565 -5.06876145\n",
            " -4.01675845 -4.52136431]. \t  -629.2708632134819 \t -182.9814303884602\n",
            "96     \t [ 2.22986204  3.43470413  2.78095832 -0.27070384  4.22620155  4.44743122\n",
            " -1.97198568 -3.39678197]. \t  -379.568859242849 \t -182.9814303884602\n",
            "97     \t [ 3.58637285  0.29798007  3.49560705  2.62905142 -2.10545795 -0.50167521\n",
            "  3.80721991 -4.92146772]. \t  -396.2511598578161 \t -182.9814303884602\n",
            "98     \t [ 3.85532902  3.53195856 -4.28842356  1.81728513  3.90972638  0.28366408\n",
            " -4.48968571  0.55666291]. \t  -328.687381859241 \t -182.9814303884602\n",
            "99     \t [-5.09682525e+00 -1.39062357e-03 -3.45047477e+00  4.52736287e+00\n",
            "  2.25862338e+00 -3.62551639e+00 -4.17984506e-01 -4.41246012e+00]. \t  -405.03754257808725 \t -182.9814303884602\n",
            "100    \t [-4.20539422  1.89173259 -4.04191761 -0.50695078 -0.95838059  0.6452236\n",
            " -4.42530327  4.72645012]. \t  -397.77009171428807 \t -182.9814303884602\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3pFfqLIyfec",
        "outputId": "240f5d6f-f139-4803-fa9d-60e15f4f4a1f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 18 \r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_winner_18 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_18 = dGPGO_stp(surrogate_winner_18, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.82391708  4.79785639  3.78055209  0.31596228 -2.73686192 -5.00327624\n",
            " -0.7119993  -0.99992207]. \t  -303.134303896496 \t -81.06401370190679\n",
            "init   \t [ 0.23218863 -0.22126801  0.56685029  0.44427282  2.67157069  2.17471564\n",
            "  1.22554466 -0.75682027]. \t  -81.06401370190679 \t -81.06401370190679\n",
            "init   \t [-2.15987171  4.85227767 -1.70215377 -2.87947714 -4.44612211  4.9445944\n",
            " -3.8107575  -1.82138068]. \t  -467.3384008943868 \t -81.06401370190679\n",
            "init   \t [-4.39354527 -2.81835582 -1.08917847  4.05652485 -1.58247309  4.96383424\n",
            " -4.82578382 -1.5187483 ]. \t  -446.39910875588674 \t -81.06401370190679\n",
            "init   \t [-1.21898097  2.70499975  4.49335207 -1.84637648 -0.69144645 -2.35370761\n",
            "  3.08281228  1.41556537]. \t  -208.5138761485756 \t -81.06401370190679\n",
            "1      \t [-4.72153807 -0.54862943 -3.19311344  1.30104982 -2.91514573 -3.5740661\n",
            "  0.3701177  -4.09203923]. \t  -314.305007357293 \t -81.06401370190679\n",
            "2      \t [ 4.75749964  2.50666145  1.4600848   4.10414325  4.79668006  1.14293188\n",
            " -1.90940471  5.05737721]. \t  -461.98777226929315 \t -81.06401370190679\n",
            "3      \t [ 3.06126016 -5.03739926  1.34009691 -2.83917989  0.15922462 -3.0285552\n",
            "  1.53342461 -0.79266576]. \t  -174.39937676687128 \t -81.06401370190679\n",
            "4      \t [ 0.42370315  2.76051631 -4.28684083 -1.00813757  0.23910174 -4.20360952\n",
            " -5.10789117  4.0388014 ]. \t  -494.0538487164447 \t -81.06401370190679\n",
            "5      \t [-1.31381342  1.34414963 -1.47029586 -3.19585654  3.99004733 -3.77203562\n",
            "  4.83680135 -3.53343442]. \t  -481.29459380418626 \t -81.06401370190679\n",
            "6      \t [ 3.87143811  4.99112582 -2.67262829  3.59590374 -0.99582885 -1.3363236\n",
            " -3.17576347 -2.26273187]. \t  -265.1925272704262 \t -81.06401370190679\n",
            "7      \t [ 3.6239736  -2.07083955  3.38746594  0.9570053  -4.24943996 -3.40232466\n",
            " -1.03826705  4.48450426]. \t  -387.9739458792113 \t -81.06401370190679\n",
            "8      \t [ 4.11717363  3.03178758  2.01395375  1.63361829  4.47315693 -4.65011712\n",
            "  2.84599778 -3.76540159]. \t  -458.0885710056757 \t -81.06401370190679\n",
            "9      \t [-2.91800834  4.94512966 -4.26505397  1.08038774  3.72853718  4.88835747\n",
            " -3.05806134 -0.86423166]. \t  -400.9879197183122 \t -81.06401370190679\n",
            "10     \t [-2.64600344 -3.81202872 -2.09543011 -2.96220218  3.44003821  0.42606833\n",
            " -5.02260132  0.26824148]. \t  -321.7553250826761 \t -81.06401370190679\n",
            "11     \t [-2.87613589 -2.36204857  3.86377212  4.81924511 -2.69254788 -0.09132169\n",
            "  3.3245157  -2.45169484]. \t  -318.8698045732099 \t -81.06401370190679\n",
            "12     \t [-1.22014713  1.35461272  3.80622469  3.76586181 -1.33734579  4.32559537\n",
            "  3.27711706  4.80301625]. \t  -486.28292551430087 \t -81.06401370190679\n",
            "13     \t [-3.90330747  3.55185923  0.83728002  3.61324973  4.59515387 -4.97165056\n",
            " -0.44420214 -2.14083268]. \t  -386.7202012156301 \t -81.06401370190679\n",
            "14     \t [ 4.58687136  0.49663519  2.34372153 -4.81848485 -2.91478721  1.75500613\n",
            "  4.36332002 -2.93468603]. \t  -394.01214854280374 \t -81.06401370190679\n",
            "15     \t [-4.20465375  2.28645463 -3.79995443  4.47434475 -4.85720159  0.30519263\n",
            "  4.60159528  5.11821644]. \t  -627.8456290261904 \t -81.06401370190679\n",
            "16     \t [-4.88682301 -3.99155186 -4.74673714  1.01004651  4.07950327  3.68229071\n",
            "  3.24983814 -1.84439949]. \t  -393.1332631565087 \t -81.06401370190679\n",
            "17     \t [ 3.52157776 -4.85901561 -0.7743586  -4.99596051  1.1542038   5.03552961\n",
            " -1.7038783  -2.12853273]. \t  -376.62685910896926 \t -81.06401370190679\n",
            "18     \t [ 4.2630053  -1.32637586 -4.98225395  1.23955078 -0.22202057  4.16810733\n",
            " -3.64249584  1.147865  ]. \t  -310.2066300432564 \t -81.06401370190679\n",
            "19     \t [ 4.3255579   2.43208629  2.80901089 -0.74812327 -1.71656587  2.37303961\n",
            " -4.9186684   3.78925884]. \t  -389.192764740545 \t -81.06401370190679\n",
            "20     \t [-4.1558945  -2.73328753 -4.40569961 -3.37161887 -1.55874088  0.25645336\n",
            "  0.91485     4.36972202]. \t  -307.07239638706864 \t -81.06401370190679\n",
            "21     \t [-4.5267117   2.77190971  2.60208934  3.86844599  4.32092749  4.28810044\n",
            "  4.94262214 -2.83787841]. \t  -555.1441205944673 \t -81.06401370190679\n",
            "22     \t [ 3.46150681 -0.48951566 -1.22139911  3.97244198 -4.4624104   0.6228863\n",
            "  4.61059839  0.59927521]. \t  -333.6277347326167 \t -81.06401370190679\n",
            "23     \t [ 2.21706055 -2.3224231   1.15363882 -3.72728923  3.59582213 -4.72364805\n",
            " -4.20096102 -4.60843508]. \t  -567.2307371945125 \t -81.06401370190679\n",
            "24     \t [ 0.58744873 -3.25281218  0.92292964 -2.22116378 -4.78104134  4.46414427\n",
            " -2.01867263  4.90425328]. \t  -498.59850339148016 \t -81.06401370190679\n",
            "25     \t [-0.09940172 -3.7593408   0.72934153 -2.34892622 -4.85248507 -4.4733624\n",
            " -3.91123637 -3.70722472]. \t  -506.77219607313873 \t -81.06401370190679\n",
            "26     \t [ 0.5305035  -2.40387146 -3.76947124  3.21663621  2.98389133 -2.09566893\n",
            " -3.69003782 -4.68456234]. \t  -437.5970195478538 \t -81.06401370190679\n",
            "27     \t [-0.03729814  5.0643191  -1.05274149  2.45123197  2.71246937 -2.66558307\n",
            "  3.60833072  4.33506523]. \t  -399.5571213573778 \t -81.06401370190679\n",
            "28     \t [-3.46350391  4.76172687  0.8113278   4.39629572 -1.36463868  3.12673806\n",
            " -4.47399674  2.39792175]. \t  -390.71526392067415 \t -81.06401370190679\n",
            "29     \t [-0.04004013  3.35646926  4.93659394  5.0856631  -3.38555396  4.70906769\n",
            " -1.67086226 -4.3527928 ]. \t  -560.577826054646 \t -81.06401370190679\n",
            "30     \t [-0.18795831 -5.09944139  4.93045625 -0.99469197 -1.30187725  3.25909789\n",
            " -4.46567453 -1.50483582]. \t  -358.8465040209822 \t -81.06401370190679\n",
            "31     \t [-1.12836081  4.69959827 -2.01832734 -3.58443072 -4.38360641  0.45474381\n",
            "  4.09898035 -1.18589722]. \t  -335.2422306188787 \t -81.06401370190679\n",
            "32     \t [ 4.68037188  5.11583228  0.07506883 -3.99002422  3.38709454  0.48009482\n",
            " -0.5755943   3.447589  ]. \t  -294.0985542725962 \t -81.06401370190679\n",
            "33     \t [-0.26460403 -4.99961506 -3.44103422  3.76456573  4.15666939 -2.38897627\n",
            "  3.93047942  4.13429371]. \t  -507.7847899313499 \t -81.06401370190679\n",
            "34     \t [ 1.23226657  3.27913603  1.57479164  5.04364353  3.38429487  3.59627499\n",
            " -5.08183044 -4.85930989]. \t  -636.7617810644904 \t -81.06401370190679\n",
            "35     \t [ 3.31576885 -4.77868122  4.46468119 -5.0446848   5.0903975   0.71111716\n",
            " -2.6282192   4.89269898]. \t  -590.7170633026457 \t -81.06401370190679\n",
            "36     \t [ 2.56887241 -4.63577684 -4.92640661 -0.76498397 -1.23438738  4.77524762\n",
            "  2.8771215   4.48280853]. \t  -487.8750832118572 \t -81.06401370190679\n",
            "37     \t [-4.60179965 -3.15807307  4.72435448 -2.57124812  3.77690678 -4.38187575\n",
            "  0.38279297  4.45779594]. \t  -481.05865944266355 \t -81.06401370190679\n",
            "38     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -81.06401370190679\n",
            "39     \t [-2.44351324 -4.27534621  5.05601371 -5.05925586 -3.45054224 -0.43082563\n",
            "  2.77014506 -2.89815142]. \t  -403.1570824755569 \t -81.06401370190679\n",
            "40     \t [-0.13123501  4.88371503  0.31448912  4.46739834 -3.56249046  0.50361639\n",
            "  4.21219606 -4.79961502]. \t  -501.3129419249598 \t -81.06401370190679\n",
            "41     \t [-3.67645232  4.32580657  3.06154823 -3.52178551 -2.38709048  4.53482223\n",
            " -2.30462682  4.87352415]. \t  -507.7403472036432 \t -81.06401370190679\n",
            "42     \t [ 4.7831904   1.258516    4.75191963 -3.77408499  3.52474327  3.64596322\n",
            " -4.41334133 -4.87581385]. \t  -619.1726458444527 \t -81.06401370190679\n",
            "43     \t [ 3.25279673 -2.99730334 -3.70714357 -4.91243286 -1.80754352 -2.97296401\n",
            "  0.00841377  5.09092879]. \t  -443.0131689756873 \t -81.06401370190679\n",
            "44     \t [-4.91807469  4.18777875 -1.38627993 -5.09450641  4.5373401  -3.30171963\n",
            " -4.17475826 -1.41847061]. \t  -475.2858463073255 \t -81.06401370190679\n",
            "45     \t [-2.18456297 -4.53639129  1.25858833  4.61483024 -0.91100653 -4.91821825\n",
            " -4.14146324  2.15537693]. \t  -442.3788846454878 \t -81.06401370190679\n",
            "46     \t [ 3.95156247 -1.97163235  4.21594487  3.97267539 -4.7170807  -2.27474538\n",
            " -4.83731292 -1.95985731]. \t  -476.6672367560901 \t -81.06401370190679\n",
            "47     \t [ 2.02940315 -2.31639312 -0.45340637  0.79911077 -4.30538585  4.85017928\n",
            " -0.98922682 -3.63596564]. \t  -364.46000318716744 \t -81.06401370190679\n",
            "48     \t [ 2.07226183e+00 -4.44302497e+00 -4.99460197e+00  3.03735663e+00\n",
            "  8.76434789e-01 -2.48803936e-04  4.26523539e+00 -4.99397929e+00]. \t  -486.2204519720578 \t -81.06401370190679\n",
            "49     \t [-0.39717097 -0.64538509  4.931228    4.73593264  4.6050523   4.41312371\n",
            " -4.58266512  3.37636978]. \t  -624.7492683233748 \t -81.06401370190679\n",
            "50     \t [ 4.87922706  3.75295175 -3.60587812 -2.6709506   2.27780989  1.28831097\n",
            "  1.30528719 -4.63460948]. \t  -339.18295341376813 \t -81.06401370190679\n",
            "51     \t [ 3.84855428  3.51726439  2.72884973 -2.91947549 -2.25912324  2.46870496\n",
            "  4.95723305  5.02634915]. \t  -532.2046960390614 \t -81.06401370190679\n",
            "52     \t [-4.71978439  3.75083258 -4.68450782 -4.51153026 -0.100094    0.53716969\n",
            " -3.9071865   4.54797144]. \t  -471.77981644675367 \t -81.06401370190679\n",
            "53     \t [ 1.0477616   5.09976267 -4.83435174 -4.54466429 -0.05609386 -4.2131076\n",
            " -5.01503146 -4.93532119]. \t  -683.2720592494293 \t -81.06401370190679\n",
            "54     \t [ 2.33737497 -4.47733289  4.01104794  3.86543269  4.2596995   1.37612534\n",
            "  2.81595253  2.50354072]. \t  -361.32451190936973 \t -81.06401370190679\n",
            "55     \t [-4.6948849   2.32813946 -4.36041575  1.99251658 -3.95399876  4.94323526\n",
            "  2.34430887 -4.18657832]. \t  -509.27654923463666 \t -81.06401370190679\n",
            "56     \t [-3.49587941  4.83923578  4.05200559 -3.13446374 -0.6277142  -0.50193202\n",
            " -2.89765245 -3.04135422]. \t  -283.8684305295335 \t -81.06401370190679\n",
            "57     \t [-2.60472785  4.55549764  5.0566844   1.97181432  4.68069177 -0.76047237\n",
            " -1.64366313  4.96687994]. \t  -469.8369598183293 \t -81.06401370190679\n",
            "58     \t [-4.6497895   1.35934327 -3.82187911 -4.63984064  4.00675026  2.47393753\n",
            "  4.84779427  3.39410218]. \t  -528.9085765826711 \t -81.06401370190679\n",
            "59     \t [-4.9828632  -1.19522556 -4.07039595  2.81607842 -3.45048605 -1.24995082\n",
            " -4.98040154  4.78504904]. \t  -534.8194976540077 \t -81.06401370190679\n",
            "61     \t [-3.94526016 -4.3663181   3.94188299 -2.98093814 -4.51080595  1.25453177\n",
            "  4.44818211  4.61226408]. \t  -555.7218976015747 \t -81.06401370190679\n",
            "62     \t [-3.24649713  2.17313763 -2.98006031  4.49624811  4.20249944 -1.30940163\n",
            " -4.97532666  1.7009591 ]. \t  -422.5074904585082 \t -81.06401370190679\n",
            "63     \t [ 4.36195638 -4.54839719  2.95758862  4.99352551  2.91075086 -3.90778976\n",
            " -2.23051896 -3.65922404]. \t  -462.31882275917286 \t -81.06401370190679\n",
            "64     \t [-0.53476343  0.57081205 -1.65514107 -4.28852159  4.94722844 -4.16158605\n",
            "  4.81359251  4.40562242]. \t  -626.4806883848486 \t -81.06401370190679\n",
            "65     \t [ 0.56449686  3.82784697 -3.78733219 -2.62097106 -1.08824111  4.40587462\n",
            "  2.14221032  4.49681384]. \t  -416.4189580258907 \t -81.06401370190679\n",
            "66     \t [-5.01568163 -1.37669592  4.46799587  0.84531964  0.57272578 -3.72825084\n",
            " -1.42249903 -1.79965491]. \t  -216.80865447414718 \t -81.06401370190679\n",
            "67     \t [ 2.59500292  3.82730869 -0.90909902 -4.82871123 -4.44540489 -5.0779435\n",
            " -1.0020734   4.01665416]. \t  -521.3941422292799 \t -81.06401370190679\n",
            "68     \t [-4.87806763  4.48605381  2.94410498  3.30247658 -4.68447048 -1.37863478\n",
            " -1.65864145 -2.51119692]. \t  -324.50521155595555 \t -81.06401370190679\n",
            "69     \t [ 4.1556955  -0.84850763 -5.08231477 -1.41117405 -3.28345203 -3.36755468\n",
            "  1.75474785 -4.15802859]. \t  -385.98058256600757 \t -81.06401370190679\n",
            "70     \t [ 4.48438671  3.72980338 -3.68670335  4.33706856  0.75645832  4.38481119\n",
            "  3.0468733  -1.23899927]. \t  -359.4341629546412 \t -81.06401370190679\n",
            "71     \t [ 4.57206291 -4.89011883  1.09997503  0.90165521  4.08054771  3.71668926\n",
            "  4.78091866 -3.03386537]. \t  -475.38406524329616 \t -81.06401370190679\n",
            "72     \t [-3.76130606 -1.07172936  0.16509534  2.47614284  1.36401926 -1.64941552\n",
            "  1.27732692  3.97654112]. \t  -204.60168860204652 \t -81.06401370190679\n",
            "73     \t [ 3.04194856  3.1027606   2.53782048  0.2486137   3.14889879 -4.7313867\n",
            " -4.54927601  4.2494379 ]. \t  -521.3036353414842 \t -81.06401370190679\n",
            "74     \t [ 4.19693252 -3.85580846 -4.35036687  2.93927826 -2.71963414 -2.58612162\n",
            " -0.1427993   4.6771161 ]. \t  -390.93952380884343 \t -81.06401370190679\n",
            "75     \t [ 1.29480856  4.50649088  2.95241317 -4.95817138  4.38324039 -0.72295391\n",
            "  0.67270903 -3.04922507]. \t  -343.52743911319067 \t -81.06401370190679\n",
            "76     \t [ 3.53165218  4.13279214 -4.66850382  5.07475731  2.49716901 -3.86879919\n",
            "  3.29588151 -4.12255954]. \t  -548.0186701987557 \t -81.06401370190679\n",
            "77     \t [-4.40000315 -3.95546383 -0.45425772  1.61876916  4.45401756 -1.37439321\n",
            " -0.07420012 -2.14823323]. \t  -209.23501047110224 \t -81.06401370190679\n",
            "78     \t [-4.24382251 -4.30389324 -1.06849138 -1.41259713 -4.76067493  3.5170315\n",
            "  2.89046506 -0.47992475]. \t  -314.3270999217142 \t -81.06401370190679\n",
            "79     \t [-1.00094775 -1.92644165  4.92088795 -4.55315363  4.3430194   4.97977381\n",
            "  2.0895649   5.04226956]. \t  -641.0522974657667 \t -81.06401370190679\n",
            "80     \t [ 2.47437617  0.1844736   4.26674257  5.09015301 -2.94964593 -4.77064012\n",
            "  4.70440575  1.78312195]. \t  -524.8568297496628 \t -81.06401370190679\n",
            "81     \t [-3.89078546 -1.87502601  0.93280175 -4.82878086  1.23714032  5.07054194\n",
            " -0.25483251 -3.22905397]. \t  -363.83236021017274 \t -81.06401370190679\n",
            "82     \t [ 0.22379786 -1.46441441 -4.15609285 -4.28509075 -0.07263705  0.36969361\n",
            "  4.19258886 -1.24660523]. \t  -265.92966605106216 \t -81.06401370190679\n",
            "83     \t [-2.56712251 -2.06648101  1.12705218 -4.57458062 -3.38744515 -4.67648158\n",
            "  0.89992942  3.40527222]. \t  -389.6756416462688 \t -81.06401370190679\n",
            "84     \t [-0.17409384  5.09062087  1.19802024  3.16546121 -4.85723605 -4.38507484\n",
            "  3.48243891  4.519258  ]. \t  -577.8636930055811 \t -81.06401370190679\n",
            "85     \t [-2.22524433 -5.1078244  -3.72924499  4.23231622 -2.48725023  2.02935507\n",
            "  3.18016389  4.74792396]. \t  -477.28137194295203 \t -81.06401370190679\n",
            "86     \t [-0.73111808 -2.60984744  3.5923223   3.07680869  4.40836094 -5.11080228\n",
            "  3.17485914 -0.30486769]. \t  -415.93018534990904 \t -81.06401370190679\n",
            "87     \t [ 5.0397215  -3.3051518  -2.82834428  2.71887331  4.89426702  4.22916341\n",
            "  1.93722702  4.63989968]. \t  -526.398011041466 \t -81.06401370190679\n",
            "88     \t [ 1.02168115  1.08372792 -4.6374748   0.70456655 -2.66461956 -5.07969131\n",
            "  4.00941651  4.13898397]. \t  -509.7949603603971 \t -81.06401370190679\n",
            "89     \t [ 3.10147518  4.82704895  4.92704107 -4.58450518 -3.17090038  2.2974675\n",
            " -2.5611166  -1.68906185]. \t  -363.7997582447187 \t -81.06401370190679\n",
            "90     \t [-3.62838319  3.48654051  4.95158631  4.93882915  1.17558652 -4.85060405\n",
            "  4.96739457  3.48144146]. \t  -626.3685637829486 \t -81.06401370190679\n",
            "91     \t [-3.43237087 -3.65362625  1.39470203 -5.08261437  2.42450644  0.42547184\n",
            "  4.65690425  2.16451436]. \t  -367.41219049414616 \t -81.06401370190679\n",
            "92     \t [ 3.5245454  -3.27138721 -2.04718444  0.35555596  3.31357027 -2.36471648\n",
            " -4.13948318  2.68475099]. \t  -312.965335229751 \t -81.06401370190679\n",
            "93     \t [-3.91976914 -4.60050504  4.12973738  0.96760655  4.81420259  4.33827178\n",
            "  2.8571282  -2.21377859]. \t  -437.7582666780822 \t -81.06401370190679\n",
            "94     \t [ 2.54434993 -0.68324182 -2.12343118 -5.06066659  3.61334714  3.28112635\n",
            " -3.42755773  4.25475971]. \t  -480.31265482668493 \t -81.06401370190679\n",
            "95     \t [-3.66360132  1.69270726 -4.03853078 -2.28937013  5.05895109  4.76730106\n",
            "  2.04463091 -4.73235915]. \t  -561.799826569921 \t -81.06401370190679\n",
            "96     \t [-4.48208088  2.50370226  1.42325976 -2.32747355 -4.64582504  4.96345554\n",
            "  1.82578525 -1.75039297]. \t  -363.9508803555571 \t -81.06401370190679\n",
            "97     \t [ 4.45874562 -4.35838558  4.91841746  4.13434128 -2.31462041  3.40998555\n",
            " -0.61453639 -1.86766583]. \t  -325.91940117422297 \t -81.06401370190679\n",
            "98     \t [ 4.9984231   3.39942768  3.10602992 -0.70325472  4.11217282  1.43320106\n",
            "  5.07266018 -0.68329634]. \t  -359.74952366282747 \t -81.06401370190679\n",
            "99     \t [ 4.55643271  4.65764355 -3.67296164 -4.08713718  4.23748938 -4.98052938\n",
            " -0.72971518 -0.2357779 ]. \t  -414.22680684740254 \t -81.06401370190679\n",
            "100    \t [-4.3238846   3.00818106 -2.80062841 -3.48727298 -0.37422976 -3.76953061\n",
            "  4.92421467  3.08266455]. \t  -440.68333677658825 \t -81.06401370190679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YT-CgKvuv4q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3668cb2-64ee-411f-bcf0-e32593d467f1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 19 \r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_winner_19 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_19 = dGPGO_stp(surrogate_winner_19, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.60872271  2.67767798 -2.61599688  2.78210017 -1.49020588  3.03818137\n",
            " -1.57695977 -0.57472578]. \t  -152.73804339453181 \t -152.73804339453181\n",
            "init   \t [-2.01417124 -0.59275346  0.74966386 -4.44760047 -4.87332982  3.28317578\n",
            " -1.38099049  2.2742428 ]. \t  -323.7197488227736 \t -152.73804339453181\n",
            "init   \t [-1.01293527  0.56350397 -2.8300206   3.21862419  2.65507157  2.99837476\n",
            "  1.85657419  0.54493065]. \t  -182.81852961404186 \t -152.73804339453181\n",
            "init   \t [ 2.7452723   4.7291508   4.64956866  0.49623227 -2.52475319 -2.84587614\n",
            "  1.92234127  1.96987691]. \t  -255.4837579570394 \t -152.73804339453181\n",
            "init   \t [-4.14230197  2.55639339 -5.00090869 -3.49701125 -2.12620717  3.13206479\n",
            "  2.96251747  5.00628454]. \t  -497.5739847629385 \t -152.73804339453181\n",
            "1      \t [-4.8562831   2.5202371   0.65818482  1.85973564 -3.16121357  4.05790202\n",
            "  3.22145623 -3.32687085]. \t  -361.375551583699 \t -152.73804339453181\n",
            "2      \t [-4.77552039 -1.68941064  4.9572144   1.36923121  0.74443524 -0.86130392\n",
            " -4.11036966 -2.93642896]. \t  -304.20378932332414 \t -152.73804339453181\n",
            "3      \t [ 2.03295518 -3.75539881  1.44540034 -0.22722052 -3.20263597 -1.71487982\n",
            "  0.81219779 -4.07442271]. \t  -245.16729287500243 \t -152.73804339453181\n",
            "4      \t [ 3.58035418  1.95072496 -3.71863885 -3.78036017  4.54723818  0.04750952\n",
            " -1.80309397 -3.09559193]. \t  -321.89887702560833 \t -152.73804339453181\n",
            "5      \t [-4.90125363 -4.48066987  0.6215702  -4.11322459  2.5725056   4.56065263\n",
            " -3.11784557  2.13903663]. \t  -395.5453956718856 \t -152.73804339453181\n",
            "6      \t [-3.59204616  2.01157128 -1.37932814 -3.91230147  0.87501658 -2.67283951\n",
            " -1.30867742  2.09829245]. \t  -181.83148528143957 \t -152.73804339453181\n",
            "7      \t [ 5.0368601  -1.56669821  3.14670899  2.96383245  1.34472085  2.5478463\n",
            " -3.84363162  0.61363107]. \t  -249.538958127328 \t -152.73804339453181\n",
            "8      \t [-1.2792895  -0.33035848 -3.01935532  4.43322669 -0.21223861 -4.92463399\n",
            "  1.19087856  1.01683709]. \t  -271.75471960043285 \t -152.73804339453181\n",
            "9      \t [ 4.77036283  3.48142752 -4.39667926  5.10135878  2.29876507 -3.00277116\n",
            " -1.83978411 -3.57242556]. \t  -415.3976941563825 \t -152.73804339453181\n",
            "10     \t [-2.82245111 -0.10482037 -3.06230048 -4.85865626 -0.26692326  3.86122801\n",
            " -3.92070535 -3.16551209]. \t  -408.1253983365439 \t -152.73804339453181\n",
            "11     \t [-2.74511363  3.76685972  4.4246735   4.38496769  4.91433138 -4.6635153\n",
            "  2.73141886 -4.00045557]. \t  -603.0563016476349 \t -152.73804339453181\n",
            "12     \t [-4.14009729  0.56822166  4.99581164  4.00735471  4.17428007  2.28250328\n",
            " -1.75656808  2.89454946]. \t  -363.9041769748305 \t -152.73804339453181\n",
            "13     \t [ 3.02880458  5.00302092  3.38575986 -2.78758691  0.68090204 -4.410365\n",
            " -4.87902353 -0.4338765 ]. \t  -411.8729054727788 \t -152.73804339453181\n",
            "14     \t [ 1.39844523 -4.24153617 -2.81632605 -4.17346218  2.17898134 -2.31017175\n",
            "  4.98822782 -2.7563534 ]. \t  -422.12108009728513 \t -152.73804339453181\n",
            "15     \t [ 0.53896904 -4.45741272  3.14519144 -4.01813576 -1.95697437  4.84904002\n",
            "  4.14976278 -4.43621621]. \t  -572.4976011451986 \t -152.73804339453181\n",
            "16     \t [-3.55630932  4.95453312  0.2449662  -1.82321095 -4.83449408 -4.39921768\n",
            "  1.64070992 -3.42458482]. \t  -420.8646659728716 \t -152.73804339453181\n",
            "17     \t [ 4.43521243 -4.13363668  2.48883659  4.56370907  4.23935255 -0.77298898\n",
            "  3.29683439  4.40225426]. \t  -480.30588019101543 \t -152.73804339453181\n",
            "18     \t [ 4.41187953  0.87313913  4.48110574 -0.01597955  4.06675153 -0.70648342\n",
            "  3.29504565 -2.55397191]. \t  -295.1018861139921 \t -152.73804339453181\n",
            "19     \t [-3.88652504 -4.89704157  4.60009126 -4.05566084  0.87564413 -2.77372175\n",
            "  1.94801258 -4.79740835]. \t  -453.02241109067313 \t -152.73804339453181\n",
            "20     \t [-4.61948412 -4.85587688 -3.07057751 -3.75915602 -3.69236167 -2.64717453\n",
            "  4.55145547  2.98572713]. \t  -479.84870046839177 \t -152.73804339453181\n",
            "21     \t [ 4.7182966   4.97198316  4.83518785 -1.40684216 -0.98052487  4.59920889\n",
            "  4.8176904   1.63963918]. \t  -465.459298136093 \t -152.73804339453181\n",
            "22     \t [-1.26201712 -4.79081925  3.32667155 -0.16136122 -2.63763288 -4.59610699\n",
            " -2.3793456   3.77913422]. \t  -396.21554112356716 \t -152.73804339453181\n",
            "23     \t [ 3.87280287 -4.66630273 -4.13777053 -0.77482852  3.61635662 -4.96966346\n",
            " -4.54761957  3.81614065]. \t  -587.1570836493127 \t -152.73804339453181\n",
            "24     \t [-4.91635692 -1.37091199 -2.35739104 -4.34758503 -4.4180418  -4.7474707\n",
            " -2.50608597 -4.12534468]. \t  -533.1445775156103 \t -152.73804339453181\n",
            "25     \t [-2.37583917 -2.9593471  -4.84673418  3.48088978  4.07798772 -4.91814349\n",
            " -2.76741901 -4.20682374]. \t  -565.5668690566243 \t -152.73804339453181\n",
            "26     \t [-4.67859684 -3.89407969  4.36056936  2.35976092 -0.0743924  -0.253316\n",
            "  4.47374995  2.7689999 ]. \t  -333.38720259556754 \t -152.73804339453181\n",
            "27     \t [ 3.77190588  4.38786184  0.92931912 -4.62898058 -2.63845626 -4.45771883\n",
            "  4.95751945 -4.45939184]. \t  -626.1978826869462 \t -152.73804339453181\n",
            "28     \t [-4.93475194  1.02087206  2.80710477  2.93129208 -4.4511647  -3.11282345\n",
            " -0.09928233  1.48619718]. \t  -259.38715093736266 \t -152.73804339453181\n",
            "29     \t [ 1.75718185  5.08549935 -3.74406226 -3.76696377 -1.22203607  3.08834127\n",
            "  2.76891424 -3.64485881]. \t  -378.2685063141948 \t -152.73804339453181\n",
            "30     \t [-3.69969164  4.21476188  2.29680419 -4.65501674  3.76558113  3.63662027\n",
            " -2.60089654 -0.31205118]. \t  -350.09850121196047 \t -152.73804339453181\n",
            "31     \t [ 4.42349682  2.89455612 -2.87184574 -3.56416125 -1.29979838  0.86962266\n",
            " -5.01470655  2.86156351]. \t  -366.4038883644979 \t -152.73804339453181\n",
            "32     \t [ 4.86887667 -5.08404749 -3.7144335   0.1951142  -1.64091153  4.03523736\n",
            "  1.36267315 -4.46338572]. \t  -400.47880516139946 \t -152.73804339453181\n",
            "33     \t [-2.34727446  0.82203791  5.02370658 -4.37854904  5.09779246 -5.06523037\n",
            " -3.11678968  2.26146628]. \t  -552.0521150649304 \t -152.73804339453181\n",
            "34     \t [ 1.73465174 -4.73127806  1.24358175  2.30827041 -2.51127741  3.99212755\n",
            "  1.49253409  4.15340388]. \t  -354.4857186055027 \t -152.73804339453181\n",
            "35     \t [ 4.32558214 -3.39915787 -0.86404156 -3.16895149  1.63839594  2.27241598\n",
            "  4.85459903  4.14254653]. \t  -430.8883364889266 \t -152.73804339453181\n",
            "36     \t [ 4.51853171  0.33657841 -5.07610242  1.39242635  3.85768842 -3.99792127\n",
            "  3.91066185  2.45310297]. \t  -431.2032436484022 \t -152.73804339453181\n",
            "37     \t [ 0.68019692  3.69234855  5.06527081  2.61861867 -5.10265611  2.55984269\n",
            " -0.95573547 -4.99061685]. \t  -507.2754322132708 \t -152.73804339453181\n",
            "38     \t [-4.66840919 -4.1915628  -3.02965181  2.17131028  5.01840233  1.03446615\n",
            "  4.24088501 -4.15459968]. \t  -499.6510240228034 \t -152.73804339453181\n",
            "39     \t [ 5.08772786  3.9729796  -3.09617592 -0.92643727 -0.44126397  1.58019448\n",
            "  3.72164864  4.01851611]. \t  -331.7442797109178 \t -152.73804339453181\n",
            "40     \t [-1.96773188 -4.89093859 -1.34968342  2.73429545  4.94831998  1.58578599\n",
            " -4.59386688  3.08382867]. \t  -448.40789257826947 \t -152.73804339453181\n",
            "41     \t [-2.48934263 -0.02595662 -2.9393393   1.72789122 -3.06411128 -1.32487259\n",
            " -4.80833989  5.02269756]. \t  -465.19622072536936 \t -152.73804339453181\n",
            "42     \t [ 3.42403359  4.69122933  4.19955021  4.73300506  4.82773243 -1.2640517\n",
            " -2.68246719  2.21332726]. \t  -413.93519918872954 \t -152.73804339453181\n",
            "43     \t [ 4.55928366  4.81049067 -0.61775329  5.03191528 -4.81113242 -4.16264321\n",
            "  0.0653753  -1.85002272]. \t  -416.6054081357776 \t -152.73804339453181\n",
            "44     \t [ 3.30849522  4.23356622 -2.76316193  2.39032775  4.04670138  4.85550612\n",
            " -3.89720563  4.69259755]. \t  -598.3680194498068 \t -152.73804339453181\n",
            "45     \t [ 3.68055211 -4.47295612  1.66590762 -3.58029949  4.55605478  4.27730489\n",
            " -2.40650413  3.01958435]. \t  -440.20321021425605 \t -152.73804339453181\n",
            "46     \t [ 4.40152656 -4.50622807 -2.69419436  3.9181091   2.21156571 -2.37089721\n",
            "  2.22237185 -3.53466554]. \t  -335.8734606202589 \t -152.73804339453181\n",
            "47     \t [ 2.27566813  2.59158335 -5.05100689  1.30126852 -1.76076339 -2.8160475\n",
            "  5.0934644  -4.95584431]. \t  -543.0914643193091 \t -152.73804339453181\n",
            "48     \t [ 2.85780519 -4.02217593  4.72574273  4.44999789 -3.58511639  3.68372651\n",
            "  4.69134269 -2.2567066 ]. \t  -527.2177222171783 \t -152.73804339453181\n",
            "49     \t [-4.93592507 -4.99796226 -4.77415104 -2.1238525   3.61410101  3.22530684\n",
            "  4.86006102  3.53076071]. \t  -553.5389387363554 \t -152.73804339453181\n",
            "50     \t [ 0.96070274 -3.93914274  5.06555839 -4.59871493 -0.89701245 -1.03539644\n",
            "  3.7807451   1.84796309]. \t  -331.3624091283552 \t -152.73804339453181\n",
            "51     \t [-3.03335562  2.6981789   4.6216064  -2.27584402 -3.42278419  4.19897645\n",
            "  4.95144455  4.77350696]. \t  -626.831435384851 \t -152.73804339453181\n",
            "52     \t [ 5.11590783 -4.4110851  -3.18966968 -1.12691048 -3.72937011  0.09791993\n",
            " -5.00086203 -0.76450899]. \t  -350.0242194239989 \t -152.73804339453181\n",
            "53     \t [-0.88404708 -4.43023147 -3.84853406  3.31244421  0.01971194  2.24923258\n",
            " -3.70209426 -3.93965788]. \t  -378.82020368397855 \t -152.73804339453181\n",
            "54     \t [-0.82322435  4.82912461  2.98314053  3.96901118 -0.37808183  4.79222621\n",
            "  1.95742106  4.28818615]. \t  -449.46429364822967 \t -152.73804339453181\n",
            "55     \t [ 4.58341526  4.98774821  0.19800884 -5.10047613 -4.55996401 -3.45777359\n",
            "  2.76987472  4.94891377]. \t  -600.2829791219883 \t -152.73804339453181\n",
            "56     \t [-3.95054637 -4.4494467   0.38265906  0.33101922  4.62572926 -4.00264715\n",
            "  2.307373    0.00882974]. \t  -296.46192292645554 \t -152.73804339453181\n",
            "57     \t [-3.49161818  5.09829727 -1.86823008  0.78998141  4.25053285 -3.81010835\n",
            "  3.24249598  2.08986967]. \t  -363.11740590278026 \t -152.73804339453181\n",
            "58     \t [-1.23977628  4.54633101  3.84924946  4.46794698  4.54267307  3.73311723\n",
            "  4.18468181 -4.13729135]. \t  -613.4904111784153 \t -152.73804339453181\n",
            "59     \t [ 4.63137231 -0.65816234  1.14968587  3.86779329 -4.92462401 -1.56379484\n",
            "  3.04234437  4.69869773]. \t  -463.46602904083454 \t -152.73804339453181\n",
            "60     \t [-4.7969004  -4.19384685  0.77801521  4.50669943 -2.29011512 -0.93967522\n",
            "  1.50655366 -4.26838899]. \t  -334.40639548279324 \t -152.73804339453181\n",
            "61     \t [ 3.11301536 -3.9547939   1.05620263 -2.4413357   4.56923854 -4.14996101\n",
            " -1.34300583 -3.41073647]. \t  -381.5722272409541 \t -152.73804339453181\n",
            "62     \t [ 2.53914359  3.34156057  3.16985518 -0.86003954  4.55567803  1.55744586\n",
            "  1.955789    5.09824189]. \t  -414.9190959362047 \t -152.73804339453181\n",
            "63     \t [ 5.04502582 -4.72712546  3.2925176   4.7262779   4.73560192 -3.78604194\n",
            " -4.62285477 -4.24546783]. \t  -683.9383332050049 \t -152.73804339453181\n",
            "64     \t [-1.89169554 -0.55376852 -3.28225313  0.58136138  5.06027621 -4.47374932\n",
            " -2.32061876  4.5632755 ]. \t  -490.2666533739248 \t -152.73804339453181\n",
            "65     \t [-4.92737514 -1.13893886  3.38514403  4.97043516  0.97635144 -3.84776772\n",
            " -4.13874261  4.3481735 ]. \t  -524.8273371265932 \t -152.73804339453181\n",
            "66     \t [-4.68381713  2.23574265  4.6750858  -1.09808184  1.58101045 -3.8800558\n",
            "  2.64611441  0.4925462 ]. \t  -256.1088826341661 \t -152.73804339453181\n",
            "67     \t [-3.94262707  3.81717702 -4.58992245  4.34373392  4.18958338  5.0867427\n",
            " -3.65478166 -4.09504011]. \t  -654.029834487611 \t -152.73804339453181\n",
            "68     \t [ 2.27042285  0.29971219  0.67426274 -4.86575354 -4.16832383  0.4797981\n",
            " -4.33438079 -4.99260846]. \t  -520.5735624995721 \t -152.73804339453181\n",
            "69     \t [-3.34766093  4.9062631  -0.14574755  4.1557658  -2.63645871 -1.26128873\n",
            "  4.65137251  5.08538369]. \t  -531.1305033051497 \t -152.73804339453181\n",
            "70     \t [-0.45068167  4.40361616  3.71761504  4.30216029 -4.75980659  0.63386636\n",
            " -3.63128424  4.1421852 ]. \t  -499.73777804068436 \t -152.73804339453181\n",
            "71     \t [-0.10554859  1.28383565  4.77331849  4.1959283  -2.86456556 -4.95299555\n",
            "  3.87088791 -4.12387409]. \t  -571.2433551613806 \t -152.73804339453181\n",
            "72     \t [-1.63334057 -3.51515182 -3.70756441  1.12257023 -4.74329112  3.72666889\n",
            " -0.12664702 -0.13151457]. \t  -269.73220755797416 \t -152.73804339453181\n",
            "73     \t [ 3.66951971 -1.47236747  3.30332462 -2.05406113  4.31684766  3.69055648\n",
            " -3.30502509 -4.54309323]. \t  -483.8906516033669 \t -152.73804339453181\n",
            "74     \t [-4.67852801  2.56060547 -2.24528147  1.35695405  0.01101725 -2.89395035\n",
            " -3.84231976 -3.33300803]. \t  -299.9569757824602 \t -152.73804339453181\n",
            "75     \t [ 0.95839469  1.18262403 -3.37891316 -0.20171595 -4.85388861 -1.49043942\n",
            "  1.44479633  2.75666014]. \t  -244.66472653477922 \t -152.73804339453181\n",
            "76     \t [ 5.0731576  -4.22705006  2.22076897 -5.04093049 -1.36671422 -0.04573141\n",
            " -5.11652693  4.88526473]. \t  -561.4427107064403 \t -152.73804339453181\n",
            "77     \t [ 0.48651044 -3.34772144 -3.4336444  -2.92564006 -0.52889335  3.44709723\n",
            " -2.76447125  4.87124789]. \t  -408.28046472720916 \t -152.73804339453181\n",
            "78     \t [-2.51144249 -0.77924678  0.14168081 -0.79563775  4.19211413  4.35022212\n",
            "  0.45834238 -4.87461628]. \t  -403.095487300567 \t -152.73804339453181\n",
            "79     \t [-3.39734088  1.69127831 -4.49504675  3.40001553  2.15675472  4.73804903\n",
            " -4.99509396  3.43218945]. \t  -550.9682756203476 \t -152.73804339453181\n",
            "80     \t [-4.46490769 -0.85164152  4.02525952 -0.65411922  3.87536977  4.68223505\n",
            "  3.19023393  0.32966534]. \t  -350.4506041349525 \t -152.73804339453181\n",
            "81     \t [ 3.36913519  3.81114881 -1.81682287  5.05504152  1.62275189 -5.04118055\n",
            " -4.53118289  3.88692638]. \t  -582.7516267051113 \t -152.73804339453181\n",
            "82     \t [-3.95274868  3.34846517 -4.2294089  -3.29819595  3.86264671  0.27560214\n",
            "  2.83581468 -5.11314852]. \t  -475.727899004582 \t -152.73804339453181\n",
            "83     \t [ 5.0393965  -4.94645913 -4.70663694  4.51896217  4.63292873  2.95553998\n",
            " -1.28543382  1.61538035]. \t  -414.6452558557022 \t -152.73804339453181\n",
            "84     \t [ 3.41920633 -2.28512198 -4.5149784   4.91848121 -2.2219503  -0.89095796\n",
            " -2.68117429  2.25417822]. \t  -300.4750332364825 \t -152.73804339453181\n",
            "85     \t [ 3.66971001 -2.2010496   4.55199129  2.40681903  0.59441659 -4.21665669\n",
            " -0.82845997  0.43248328]. \t  -223.23756877302756 \t -152.73804339453181\n",
            "86     \t [-4.61985418  4.44738307  3.93362753 -5.01944483  4.7746835   3.62797169\n",
            "  3.98701418 -3.95573741]. \t  -637.5189934560657 \t -152.73804339453181\n",
            "87     \t [-1.80788556  4.86398883  2.81321551  1.71357925  0.46141199 -3.02504808\n",
            " -4.89538868  4.93818072]. \t  -504.8820282357045 \t -152.73804339453181\n",
            "88     \t [ 2.8531422   0.34583378  4.79182865 -5.10563852 -1.96482629  4.78494598\n",
            " -4.20981941  0.34501238]. \t  -463.22195109012324 \t -152.73804339453181\n",
            "89     \t [-1.66031474  1.10252398 -0.83859894 -4.46089995  3.99792367  3.8780892\n",
            "  3.7767139   4.45821126]. \t  -515.9006010885103 \t -152.73804339453181\n",
            "90     \t [-0.82251244 -4.94900966 -3.52249526 -3.67526391  4.93615239 -0.42587218\n",
            "  0.45188928  2.88827918]. \t  -331.9989830463752 \t -152.73804339453181\n",
            "91     \t [-4.9271561  -2.39295151  4.24831213  2.44293102 -3.38349084  2.78000749\n",
            " -4.33020873  4.85925556]. \t  -537.5099883614339 \t -152.73804339453181\n",
            "92     \t [-1.3065696  -3.57403613  5.08411676  4.74920303 -4.68099166 -0.01488374\n",
            " -4.50558851 -3.10860889]. \t  -523.9886721095849 \t -152.73804339453181\n",
            "93     \t [-4.52792719  2.61985878  4.57301022 -4.91892028 -5.09913638  1.82126547\n",
            "  0.02226916 -2.68958448]. \t  -401.5322146248567 \t -152.73804339453181\n",
            "94     \t [-1.3503254   4.35574594 -4.8286849  -3.23966224 -4.80974408  1.58745305\n",
            " -3.77712906 -4.80809513]. \t  -567.296055500477 \t -152.73804339453181\n",
            "95     \t [-4.66295191 -4.60472649 -2.99536054  4.1786046  -1.39787533 -4.47667508\n",
            " -4.67276349  0.13010913]. \t  -443.9020858080789 \t -152.73804339453181\n",
            "96     \t [-3.67814165 -4.48114656 -0.93008137 -5.0512932   2.74466742 -1.67837573\n",
            " -4.03978332 -2.7327235 ]. \t  -386.89631413823463 \t -152.73804339453181\n",
            "97     \t [-2.99186386  4.93845972  4.29180457  4.26420515  3.19136619 -2.89224088\n",
            "  1.55216153  4.16087504]. \t  -442.20248111910655 \t -152.73804339453181\n",
            "98     \t [ 1.61825543  5.02395818  3.73003353  0.42610241  2.6731522   2.39762344\n",
            " -1.69000916 -3.53977248]. \t  -286.01789844406954 \t -152.73804339453181\n",
            "99     \t [-4.78655393  4.88501047 -1.19280746  0.31685449 -2.30976759  3.11446073\n",
            " -2.35136812  2.40079534]. \t  -244.99510478792712 \t -152.73804339453181\n",
            "100    \t [ 3.21690089  0.37835115 -3.09818922  5.11702878  3.83854365  3.7790976\n",
            " -4.89117694 -2.58020023]. \t  -524.2533214584012 \t -152.73804339453181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g8G9pNE4iYY",
        "outputId": "370ff756-814e-44fa-c6bc-c2ac26b0e885"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 20 \r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_winner_20 = dtStudentProcess(d_cov_func, nu = df)\r\n",
        "\r\n",
        "winner_20 = dGPGO_stp(surrogate_winner_20, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.722097    0.66077445 -0.11835563 -1.6744678  -1.27110986  0.3280473\n",
            " -4.42259161  0.86557758]. \t  -164.28536719065698 \t -132.28213531381235\n",
            "init   \t [-2.6839269  -3.47385261 -3.56229991 -3.8188112  -1.76700246  1.98813566\n",
            " -1.44418335  4.00758432]. \t  -310.1550894686203 \t -132.28213531381235\n",
            "init   \t [-3.05275003 -3.98743036  0.28218124  3.76479057 -2.43840637 -0.00619396\n",
            " -0.73150053  0.30723982]. \t  -132.28213531381235 \t -132.28213531381235\n",
            "init   \t [ 0.75721546 -1.10739814 -4.30577546  3.76095755 -3.43548334  3.1076518\n",
            " -2.17161474 -2.36983115]. \t  -310.1222484793693 \t -132.28213531381235\n",
            "init   \t [ 2.22697488  3.90559391  5.0393091  -0.42649562  2.91972373  2.4442259\n",
            " -0.2705103  -0.15529262]. \t  -191.55277957356324 \t -132.28213531381235\n",
            "1      \t [ 4.30728864  2.61813474 -2.20410079  4.60389393  3.48040036  3.22508805\n",
            "  2.4952604   4.24826238]. \t  -442.5587609971722 \t -132.28213531381235\n",
            "2      \t [-3.67810551 -4.48116665 -0.74199632 -3.37059583 -3.9425506  -2.29259788\n",
            "  4.31213333 -3.89016012]. \t  -461.26828963432035 \t -132.28213531381235\n",
            "3      \t [ 1.56366458  1.97029779 -1.88321714 -2.27776188  3.1870926  -3.83192746\n",
            " -0.64438653  4.95979293]. \t  -380.19432108174544 \t -132.28213531381235\n",
            "4      \t [-4.79386159 -1.23325986 -3.19321875  1.42012973 -0.76680564  4.49919162\n",
            "  3.54009581 -0.08523908]. \t  -276.86036064062404 \t -132.28213531381235\n",
            "5      \t [ 5.09982097  3.31399616  1.2914979  -2.21995516  3.17197923 -4.72587319\n",
            " -0.04913458 -3.0906311 ]. \t  -333.43344861063383 \t -132.28213531381235\n",
            "6      \t [-2.29089101  0.96324983 -3.67061926  2.56765292  4.17925858 -2.88542368\n",
            "  2.46704165 -4.5907166 ]. \t  -422.3821079805308 \t -132.28213531381235\n",
            "7      \t [-2.60318915  4.91446954 -3.68630877 -3.57702537  4.36703787 -3.54053091\n",
            " -4.06260887 -1.76682508]. \t  -458.10183104301075 \t -132.28213531381235\n",
            "8      \t [-1.3660865   4.41521204  3.40253855 -4.85484974 -2.7320969  -5.02809654\n",
            " -2.46778548  2.94861325]. \t  -471.0610700186468 \t -132.28213531381235\n",
            "9      \t [ 3.44669653 -5.04747822  2.63711296 -4.46744958 -4.59315593 -3.41243311\n",
            "  3.34615084  3.91770876]. \t  -540.0475264259259 \t -132.28213531381235\n",
            "10     \t [ 3.81508618 -5.04446628 -3.700409    4.36649921  0.54330584  3.96256502\n",
            "  4.38942842  0.57567637]. \t  -416.00073903197176 \t -132.28213531381235\n",
            "11     \t [-4.38116271  0.73020784  4.29591436 -1.62840433 -4.42223406 -2.56027981\n",
            "  4.61469652  2.97026294]. \t  -442.991067169615 \t -132.28213531381235\n",
            "12     \t [ 4.3201642   2.20704124 -0.95603605 -2.14067184 -4.98861162  3.3441296\n",
            "  4.8115412  -3.51809955]. \t  -502.08094121787286 \t -132.28213531381235\n",
            "13     \t [ 4.20555709 -4.82045106  1.25009295  1.96171827  2.4155117  -0.22004755\n",
            "  0.77474469  3.87191752]. \t  -237.84133559148316 \t -132.28213531381235\n",
            "14     \t [-3.42035991 -4.06347631  3.32616539 -1.12285169 -0.33952557 -2.82385236\n",
            " -4.72968589 -2.60736314]. \t  -342.3533348582342 \t -132.28213531381235\n",
            "15     \t [-3.20096227  1.92278847  4.32557445  0.6946986  -3.0725153   3.80122673\n",
            " -0.59874594  3.32161848]. \t  -300.3749688488301 \t -132.28213531381235\n",
            "16     \t [-0.77941715 -4.96947151 -2.86473006 -2.40486458  4.25734728 -2.01508581\n",
            "  3.63414579  3.33295283]. \t  -394.0584748324677 \t -132.28213531381235\n",
            "17     \t [ 1.90823429  4.7086659   4.6202126   4.46782142 -5.10559227  1.16873665\n",
            " -2.85462602 -2.66855376]. \t  -444.41192925556794 \t -132.28213531381235\n",
            "18     \t [-3.98507415  2.59664872  1.44992385  1.70632584  4.74497442  0.45937653\n",
            "  0.11811558  3.88947827]. \t  -282.28107439482346 \t -132.28213531381235\n",
            "19     \t [-5.07606234  0.9638008  -4.14526419 -2.07942412 -2.32555821 -2.47158545\n",
            " -4.72345959 -4.0008729 ]. \t  -444.3967745335917 \t -132.28213531381235\n",
            "20     \t [ 2.1989529   4.94772477  3.759214   -2.35330117 -3.55495063  4.70668155\n",
            "  5.04008614  4.72263982]. \t  -670.6919001433469 \t -132.28213531381235\n",
            "21     \t [ 3.64895343 -1.14523591 -4.56359329 -0.40949733  4.51385526  1.65187603\n",
            " -1.52282001 -0.95149928]. \t  -220.81018046431072 \t -132.28213531381235\n",
            "22     \t [ 0.61505324 -2.23383853  0.89237124  4.07004063  4.98427924 -5.04819691\n",
            " -4.11143005 -4.89688224]. \t  -666.2918574743164 \t -132.28213531381235\n",
            "23     \t [-4.97431192 -3.34444973  0.37337155 -3.75951157  4.94108708 -3.1438911\n",
            "  3.03040635 -3.50354189]. \t  -447.9263949242355 \t -132.28213531381235\n",
            "24     \t [-3.50330685 -4.62422704  4.19650669 -4.87523307  0.40772878  0.9126899\n",
            "  2.73784607  1.58736283]. \t  -281.40131003513744 \t -132.28213531381235\n",
            "25     \t [ 0.0664636  -4.46560177  2.98276541  4.35067882 -4.27750334  2.85424965\n",
            "  5.0078218  -3.43849786]. \t  -552.7916240574951 \t -132.28213531381235\n",
            "26     \t [-4.73358359  0.35401167  1.08036012 -5.09279157  0.85489432  3.80346997\n",
            "  4.43695619 -4.22235364]. \t  -500.7898477309751 \t -132.28213531381235\n",
            "27     \t [ 1.25321795  4.62044155  0.98879821  4.56622348  0.97698919  3.97846405\n",
            "  3.40058774 -3.97462134]. \t  -437.67276252407237 \t -132.28213531381235\n",
            "28     \t [ 0.69073152  3.29692216  4.10923677  2.83649169 -1.34164311 -4.13077039\n",
            "  4.27763755 -2.4989649 ]. \t  -394.482223434535 \t -132.28213531381235\n",
            "29     \t [-4.7866435   2.40630859  4.2481415   0.0877344   2.66564125  3.24349491\n",
            " -3.51681512 -3.50699296]. \t  -372.28119460627954 \t -132.28213531381235\n",
            "30     \t [-2.97651883  4.16932961 -4.5273907  -3.55673881  3.77315654  4.47810203\n",
            "  2.75580802  1.19915438]. \t  -411.88869963691997 \t -132.28213531381235\n",
            "31     \t [ 3.86006283 -4.95599307  3.99849373 -3.59191    -4.05123019  1.706878\n",
            " -3.32632447  2.60582995]. \t  -394.91171075921056 \t -132.28213531381235\n",
            "32     \t [ 5.06799526 -3.38734556  3.3282687  -3.11389257  4.06746539  2.33745256\n",
            " -4.76229199  0.30578138]. \t  -395.6576946528338 \t -132.28213531381235\n",
            "33     \t [ 3.72564259 -4.42229391 -0.73183333  3.92957908 -4.43617246 -0.01104371\n",
            " -3.53047065  3.86925813]. \t  -421.7845778547189 \t -132.28213531381235\n",
            "34     \t [-0.03363581  2.01501905 -4.87535381 -4.45208286 -4.45344882 -3.66551545\n",
            "  1.29894014  2.48577125]. \t  -399.7383677921997 \t -132.28213531381235\n",
            "35     \t [-4.04534117  3.83576578 -4.117545    3.35379295 -0.56643574  2.32033582\n",
            " -2.53071041  4.42437285]. \t  -376.985286933148 \t -132.28213531381235\n",
            "36     \t [-1.43648001  4.26862717  3.43247115  3.40931072 -2.94764362 -4.62608606\n",
            " -4.92901031  2.89080183]. \t  -529.1119314258874 \t -132.28213531381235\n",
            "37     \t [ 5.00957273  4.85049722  0.61224844  0.98971922  5.01678331  4.64337691\n",
            " -4.42020538  3.80846055]. \t  -585.2019383760982 \t -132.28213531381235\n",
            "38     \t [-4.24144278  4.78154039 -0.39467365 -4.83069721 -3.87453583 -1.80984516\n",
            "  4.36996008 -5.00156089]. \t  -586.0400629375663 \t -132.28213531381235\n",
            "39     \t [ 3.66445481 -1.72112613 -2.37248683 -1.9542025  -3.81005192 -4.70053713\n",
            " -0.63977977 -3.81998357]. \t  -376.2706871350887 \t -132.28213531381235\n",
            "40     \t [ 1.90402261 -4.61050828 -1.62646645 -3.68538965  0.02283698  4.62216172\n",
            "  3.48585813 -3.16033404]. \t  -401.5524615142508 \t -132.28213531381235\n",
            "41     \t [-2.20602362 -2.48378462 -4.25260202  2.24103891 -2.59245815 -4.36528352\n",
            " -4.56172326  3.82971507]. \t  -502.4851771943737 \t -132.28213531381235\n",
            "42     \t [-4.37870696  4.26848611 -0.57345016 -4.82760743 -2.33934006  4.2324473\n",
            " -2.41618765 -3.10511312]. \t  -402.6665109547 \t -132.28213531381235\n",
            "43     \t [ 1.68342958  4.79973719 -4.39784826  4.7330888  -3.59084344 -2.41110438\n",
            " -4.19918667  0.33427574]. \t  -420.21804778316874 \t -132.28213531381235\n",
            "44     \t [ 3.61240984  4.30873864 -0.45779934  1.28331872 -4.66629075 -3.75553734\n",
            "  4.41228801  3.71199431]. \t  -497.4012543881045 \t -132.28213531381235\n",
            "45     \t [ 4.17175157  1.18194705 -5.10012835  4.61004252  2.93367911 -4.59137688\n",
            "  3.39265514  0.66236577]. \t  -436.83880964730787 \t -132.28213531381235\n",
            "46     \t [-1.76115443 -1.80720033  3.2035144  -1.50741772 -5.03197188  2.66234462\n",
            " -1.41510283 -4.48332896]. \t  -393.4620554402112 \t -132.28213531381235\n",
            "47     \t [-2.17195944 -0.13587423 -0.93429613  5.08448639 -0.35276657 -3.42227469\n",
            "  3.64412334  4.42905462]. \t  -431.5647147916196 \t -132.28213531381235\n",
            "48     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -132.28213531381235\n",
            "49     \t [ 2.77970533 -3.29703967 -3.68240051 -4.50282609  4.52993869 -4.11724705\n",
            "  4.30120567 -3.91561679]. \t  -607.7207875123738 \t -132.28213531381235\n",
            "50     \t [-3.77693777  0.62902152 -2.62002009  4.7378269   4.13308159  4.72027284\n",
            " -2.11287804 -4.68956696]. \t  -551.721878363435 \t -132.28213531381235\n",
            "51     \t [ 4.80549537 -4.49500578  3.68826367  0.3166382  -0.08520491 -2.10660002\n",
            "  0.28637515 -4.93283989]. \t  -326.61407682351 \t -132.28213531381235\n",
            "52     \t [-4.01209246 -3.5573335  -3.37294897 -4.03755273  3.43852213  4.15159508\n",
            " -2.96688514 -3.16321948]. \t  -444.93994630488487 \t -132.28213531381235\n",
            "53     \t [ 1.30992772 -4.37159763  4.85666223  3.91079283 -4.58673809 -1.43025613\n",
            "  3.43114122  3.58588279]. \t  -474.61852928153206 \t -132.28213531381235\n",
            "54     \t [ 0.02493316 -2.17010193  4.63745183  1.15050673  4.94558214  3.03674203\n",
            "  2.58874774  1.50974601]. \t  -322.00254245230514 \t -132.28213531381235\n",
            "55     \t [ 3.85912738  4.78573428  3.65319033  4.5324051   4.93281694 -2.43710169\n",
            "  5.00119717 -0.80946439]. \t  -520.5334276543307 \t -132.28213531381235\n",
            "56     \t [-2.65953024  2.02939096  4.9793024  -2.36774876  4.63630132 -4.28345606\n",
            " -1.65389341 -0.75084297]. \t  -353.337339712082 \t -132.28213531381235\n",
            "57     \t [-4.50328468  5.06710399  4.98266276 -2.79406775  4.57190333  4.18540077\n",
            " -4.20137133  3.94600751]. \t  -635.0841289825212 \t -132.28213531381235\n",
            "58     \t [ 4.88543496 -2.73206853  2.84759643  3.89960903 -2.00186503  4.46517731\n",
            " -1.47120403 -3.8546616 ]. \t  -397.6326764906346 \t -132.28213531381235\n",
            "59     \t [ 4.3911269  -0.68998891  4.64416565 -5.02367222  2.28312721 -3.22796775\n",
            "  2.39804721  2.01628663]. \t  -347.2478303103264 \t -132.28213531381235\n",
            "60     \t [ 2.5859763  -3.43766436 -2.0723411   0.80990962 -4.22333739  2.20073099\n",
            "  3.40727022  4.80792905]. \t  -430.26803451528383 \t -132.28213531381235\n",
            "61     \t [-2.60455793 -2.04428548  5.06832595 -3.41435029  1.90636737  4.94440174\n",
            " -2.91348159  4.21990672]. \t  -505.570224792251 \t -132.28213531381235\n",
            "62     \t [-1.2494911  -2.14937754  0.41137956  2.8420512   3.13018154 -2.50145393\n",
            " -4.07589757  1.95899134]. \t  -277.1431714381756 \t -132.28213531381235\n",
            "63     \t [-4.5144129  -4.57000251  5.06518704  4.69685279  0.13923226  4.86332875\n",
            " -3.84267044 -2.01849806]. \t  -505.32604880423185 \t -132.28213531381235\n",
            "64     \t [ 4.82990773  3.10222829  4.18825631 -4.22643055 -2.81216447  0.99126217\n",
            " -3.6574171  -4.18483058]. \t  -445.8272866538779 \t -132.28213531381235\n",
            "65     \t [-3.88253763 -1.55071724  3.65164374  3.15405572  3.48169458 -3.70781779\n",
            "  3.40092501 -4.46274484]. \t  -483.0705531728214 \t -132.28213531381235\n",
            "66     \t [ 2.05877424  1.77013698 -2.07983437 -3.96071712  4.76525026  3.65122718\n",
            "  4.74110262 -3.81019671]. \t  -553.2455544063938 \t -132.28213531381235\n",
            "67     \t [-5.10418792 -3.08310129 -3.95446642 -4.49492198  2.63832864 -3.90746182\n",
            " -2.69545068 -0.58921226]. \t  -352.843456731507 \t -132.28213531381235\n",
            "68     \t [-2.39582837  4.81939473 -0.43187149 -4.19285568  0.04317381 -1.56944466\n",
            "  4.80364588  3.0761807 ]. \t  -375.08927540273856 \t -132.28213531381235\n",
            "69     \t [ 4.13511112 -0.2175337   4.62851386 -1.88616792  4.8936848   0.2303731\n",
            "  3.6131991  -3.70366131]. \t  -416.87622137447937 \t -132.28213531381235\n",
            "70     \t [-4.82793132  2.4045387   0.43265132  1.93137142 -4.56382744 -5.01613956\n",
            "  2.56052581 -4.78126714]. \t  -534.2455894978028 \t -132.28213531381235\n",
            "71     \t [ 3.85958298  3.91409973 -3.74482098 -4.41116707 -5.11007121  2.51704618\n",
            " -1.71120411  3.24145714]. \t  -438.57252549938215 \t -132.28213531381235\n",
            "72     \t [ 3.91947348  2.08550456  5.09687495 -4.14552846 -2.14616279 -2.37842629\n",
            "  4.57617096 -4.66096058]. \t  -548.0943145833191 \t -132.28213531381235\n",
            "73     \t [ 2.24726686  1.74675799 -4.63518311 -3.97693001 -0.38508139  4.44603391\n",
            "  3.90865225  4.29952019]. \t  -513.0458632217446 \t -132.28213531381235\n",
            "74     \t [ 0.59689007 -0.54432524  4.96153229  1.73827222  3.60202171 -4.94278231\n",
            "  4.6165071   4.73361594]. \t  -626.786934360891 \t -132.28213531381235\n",
            "75     \t [ 4.64537219  2.59910943  4.09585564 -0.43955209 -1.83963162 -3.33009248\n",
            " -1.23390942  4.28205018]. \t  -326.99482235092785 \t -132.28213531381235\n",
            "76     \t [ 3.23073637  3.32021034  4.82894513  3.59150184  3.19883164 -4.48278326\n",
            " -3.84008882  0.36519439]. \t  -430.0625306567547 \t -132.28213531381235\n",
            "77     \t [ 3.97799686 -4.67601103 -3.58668466  4.73473385  2.50051783 -0.75034701\n",
            " -2.29173938 -4.05413395]. \t  -390.7119294731326 \t -132.28213531381235\n",
            "78     \t [-0.47430387 -4.45345123 -0.18681857 -3.26121006 -4.95617845 -4.78596924\n",
            " -4.90853482  1.10827633]. \t  -521.2718309169541 \t -132.28213531381235\n",
            "79     \t [ 3.76034264 -3.9853637  -2.38264784 -4.94932687  0.64178436 -3.65998019\n",
            " -2.59383318  1.07815733]. \t  -299.74814817547065 \t -132.28213531381235\n",
            "80     \t [-0.52274755 -4.51752492 -3.88508289  4.63232635  3.08949141  4.6106891\n",
            " -3.08606069  1.94200183]. \t  -444.3175971317949 \t -132.28213531381235\n",
            "81     \t [ 4.37986841  3.2286018  -0.31194045  4.52326907  4.95799461  3.77860518\n",
            " -2.67312951 -3.20841288]. \t  -463.1091104374658 \t -132.28213531381235\n",
            "82     \t [ 5.09969687  4.30522912 -4.65091812 -2.71808242 -1.62144252 -5.0081474\n",
            "  2.97476088 -1.63029828]. \t  -404.3639272811418 \t -132.28213531381235\n",
            "83     \t [-3.40810781  4.03463749 -3.12791325  1.92124675 -1.72686296  2.38787706\n",
            "  4.64024906  4.56292157]. \t  -454.6955033817877 \t -132.28213531381235\n",
            "84     \t [-3.75584724 -3.75204053 -4.8505412   1.69550834 -4.82661859 -4.20067028\n",
            "  3.55584845  2.34235293]. \t  -479.10061450498955 \t -132.28213531381235\n",
            "85     \t [-4.94299606 -4.07501613  3.85263262 -0.21764713  4.2731227  -4.03011501\n",
            "  0.7024103   5.05797546]. \t  -499.22997602822716 \t -132.28213531381235\n",
            "86     \t [ 0.50764127 -3.43287843  3.20671121  0.39682134  2.8145274   4.01388523\n",
            "  0.39814862 -5.01310962]. \t  -393.7411386986218 \t -132.28213531381235\n",
            "87     \t [-0.98949338 -4.98055278  3.95494968 -1.81110671 -4.77915125 -3.48532952\n",
            "  1.12381893 -0.80207789]. \t  -311.7101993239841 \t -132.28213531381235\n",
            "88     \t [ 4.58301144 -3.49347167 -3.7461192  -3.01711901 -2.89519986  2.65397634\n",
            " -4.5055157   2.82664366]. \t  -414.11440902338967 \t -132.28213531381235\n",
            "89     \t [-4.23118182  4.39659473  0.79237902  2.43646844 -1.56613248 -3.17177634\n",
            " -3.85171146 -3.76753548]. \t  -372.2212999739959 \t -132.28213531381235\n",
            "90     \t [-4.1766955   2.27234115  4.40681069  0.05893855 -4.25829352  2.75633063\n",
            "  4.39821293 -4.09165636]. \t  -491.6383131002136 \t -132.28213531381235\n",
            "91     \t [ 3.06808859  4.57068816 -4.31608556  4.08442299 -4.40713196  2.4377541\n",
            "  3.75213691  0.98169199]. \t  -412.8407806047796 \t -132.28213531381235\n",
            "92     \t [-0.08482687 -0.78908666 -5.02155557 -1.83042911  3.78025629  4.75354272\n",
            " -5.04212612  3.10230257]. \t  -552.2866537259431 \t -132.28213531381235\n",
            "93     \t [ 4.76519943  3.86866581 -3.17252272 -1.25620944 -3.10382443  2.83550891\n",
            " -4.33469214 -4.56698909]. \t  -483.942527390412 \t -132.28213531381235\n",
            "94     \t [ 1.37217877 -2.58487736 -2.12017791  3.48921754 -1.12220396 -3.75411444\n",
            "  4.72192693 -3.43902313]. \t  -418.978234160697 \t -132.28213531381235\n",
            "95     \t [-4.71334462  4.1848252   2.42771973  4.70253722  4.34980275  4.32558717\n",
            "  2.45641987 -2.25628446]. \t  -453.21072811232887 \t -132.28213531381235\n",
            "96     \t [-4.39170848  4.92943441  5.04139136  4.90564059  4.39442586 -2.74962542\n",
            "  1.50749846 -1.76507405]. \t  -423.1431546157039 \t -132.28213531381235\n",
            "97     \t [-4.87631495  2.18396126  4.7498359  -5.00175063 -0.75082619  0.97211809\n",
            " -1.00425587  1.07776123]. \t  -225.9117261693178 \t -132.28213531381235\n",
            "98     \t [-0.95068226 -0.04151344  0.5519865  -4.6147166   0.8845725  -3.13381374\n",
            " -0.53298662 -4.61439211]. \t  -322.1702614163268 \t -132.28213531381235\n",
            "99     \t [-5.06135137 -4.87753649 -4.98949642 -0.13144877 -2.7281292   4.35820451\n",
            " -1.70810012 -2.98990723]. \t  -391.0690686292137 \t -132.28213531381235\n",
            "100    \t [-2.76888451 -0.29122423 -4.45937596  4.53324079  0.09482229 -3.98778426\n",
            " -4.0084058  -3.81871446]. \t  -474.2868917686936 \t -132.28213531381235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUnhsKpCuv9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f71110-9787-47ea-95f1-1815dbb19112"
      },
      "source": [
        "end_win = time.time()\r\n",
        "end_win\r\n",
        "\r\n",
        "time_win = end_win - start_win\r\n",
        "time_win"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16990.071573972702"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJG0SLpwuwAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa58ea8e-b0a5-491c-bcc9-c17cdcf3ae3b"
      },
      "source": [
        "### Training regret minimization: run number = 1\r\n",
        "\r\n",
        "loser_output_1 = np.append(np.max(loser_1.GP.y[0:n_init]),loser_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_1 = np.append(np.max(winner_1.GP.y[0:n_init]),winner_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_1 = np.log(y_global_orig - loser_output_1)\r\n",
        "regret_winner_1 = np.log(y_global_orig - winner_output_1)\r\n",
        "\r\n",
        "train_regret_loser_1 = min_max_array(regret_loser_1)\r\n",
        "train_regret_winner_1 = min_max_array(regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1 = min(train_regret_loser_1)\r\n",
        "min_train_regret_winner_1 = min(train_regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1, min_train_regret_winner_1"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.185168623851889, 5.061622502430507)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lA9eZf0uwCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f71a64a-fc9e-4c54-a90a-e3ac85fbef2e"
      },
      "source": [
        "### Training regret minimization: run number = 2\r\n",
        "\r\n",
        "loser_output_2 = np.append(np.max(loser_2.GP.y[0:n_init]),loser_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_2 = np.append(np.max(winner_2.GP.y[0:n_init]),winner_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_2 = np.log(y_global_orig - loser_output_2)\r\n",
        "regret_winner_2 = np.log(y_global_orig - winner_output_2)\r\n",
        "\r\n",
        "train_regret_loser_2 = min_max_array(regret_loser_2)\r\n",
        "train_regret_winner_2 = min_max_array(regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2 = min(train_regret_loser_2)\r\n",
        "min_train_regret_winner_2 = min(train_regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2, min_train_regret_winner_2"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.264080017248812, 5.131750129144026)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glrTGcpAuwFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dddcf96-be41-4d1f-b35a-07d30156b3bb"
      },
      "source": [
        "### Training regret minimization: run number = 3\r\n",
        "\r\n",
        "loser_output_3 = np.append(np.max(loser_3.GP.y[0:n_init]),loser_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_3 = np.append(np.max(winner_3.GP.y[0:n_init]),winner_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_3 = np.log(y_global_orig - loser_output_3)\r\n",
        "regret_winner_3 = np.log(y_global_orig - winner_output_3)\r\n",
        "\r\n",
        "train_regret_loser_3 = min_max_array(regret_loser_3)\r\n",
        "train_regret_winner_3 = min_max_array(regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3 = min(train_regret_loser_3)\r\n",
        "min_train_regret_winner_3 = min(train_regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3, min_train_regret_winner_3"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.109665301060218, 5.016686733856197)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaRwfbxeuwIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e0751f-9032-4983-b82d-41e0caa01cc9"
      },
      "source": [
        "### Training regret minimization: run number = 4\r\n",
        "\r\n",
        "loser_output_4 = np.append(np.max(loser_4.GP.y[0:n_init]),loser_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_4 = np.append(np.max(winner_4.GP.y[0:n_init]),winner_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_4 = np.log(y_global_orig - loser_output_4)\r\n",
        "regret_winner_4 = np.log(y_global_orig - winner_output_4)\r\n",
        "\r\n",
        "train_regret_loser_4 = min_max_array(regret_loser_4)\r\n",
        "train_regret_winner_4 = min_max_array(regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4 = min(train_regret_loser_4)\r\n",
        "min_train_regret_winner_4 = min(train_regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4, min_train_regret_winner_4"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.109733786005427, 4.985673966280516)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nb5NkfyuwKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97075ae9-0cc1-4360-fe3d-b00fa13b533b"
      },
      "source": [
        "### Training regret minimization: run number = 5\r\n",
        "\r\n",
        "loser_output_5 = np.append(np.max(loser_5.GP.y[0:n_init]),loser_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_5 = np.append(np.max(winner_5.GP.y[0:n_init]),winner_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_5 = np.log(y_global_orig - loser_output_5)\r\n",
        "regret_winner_5 = np.log(y_global_orig - winner_output_5)\r\n",
        "\r\n",
        "train_regret_loser_5 = min_max_array(regret_loser_5)\r\n",
        "train_regret_winner_5 = min_max_array(regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5 = min(train_regret_loser_5)\r\n",
        "min_train_regret_winner_5 = min(train_regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5, min_train_regret_winner_5"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.139102336415449, 5.156918080131978)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Q-WfXbuwNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653b39e8-6453-4b70-d447-173c9d8a6d58"
      },
      "source": [
        "### Training regret minimization: run number = 6\r\n",
        "\r\n",
        "loser_output_6 = np.append(np.max(loser_6.GP.y[0:n_init]),loser_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_6 = np.append(np.max(winner_6.GP.y[0:n_init]),winner_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_6 = np.log(y_global_orig - loser_output_6)\r\n",
        "regret_winner_6 = np.log(y_global_orig - winner_output_6)\r\n",
        "\r\n",
        "train_regret_loser_6 = min_max_array(regret_loser_6)\r\n",
        "train_regret_winner_6 = min_max_array(regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6 = min(train_regret_loser_6)\r\n",
        "min_train_regret_winner_6 = min(train_regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6, min_train_regret_winner_6"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.10459496818004, 5.307975358934126)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqqS7VLcuwPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2623c21-2f27-4fe9-860f-c14228974ef6"
      },
      "source": [
        "### Training regret minimization: run number = 7\r\n",
        "\r\n",
        "loser_output_7 = np.append(np.max(loser_7.GP.y[0:n_init]),loser_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_7 = np.append(np.max(winner_7.GP.y[0:n_init]),winner_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_7 = np.log(y_global_orig - loser_output_7)\r\n",
        "regret_winner_7 = np.log(y_global_orig - winner_output_7)\r\n",
        "\r\n",
        "train_regret_loser_7 = min_max_array(regret_loser_7)\r\n",
        "train_regret_winner_7 = min_max_array(regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7 = min(train_regret_loser_7)\r\n",
        "min_train_regret_winner_7 = min(train_regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7, min_train_regret_winner_7"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.836780871006718, 4.836780871006718)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOi5iX8guwSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd974b99-711f-4821-8e48-5ae5eed2c8b7"
      },
      "source": [
        "### Training regret minimization: run number = 8\r\n",
        "\r\n",
        "loser_output_8 = np.append(np.max(loser_8.GP.y[0:n_init]),loser_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_8 = np.append(np.max(winner_8.GP.y[0:n_init]),winner_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_8 = np.log(y_global_orig - loser_output_8)\r\n",
        "regret_winner_8 = np.log(y_global_orig - winner_output_8)\r\n",
        "\r\n",
        "train_regret_loser_8 = min_max_array(regret_loser_8)\r\n",
        "train_regret_winner_8 = min_max_array(regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8 = min(train_regret_loser_8)\r\n",
        "min_train_regret_winner_8 = min(train_regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8, min_train_regret_winner_8"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.195836937766768, 4.6927457405126525)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFVApeazuwU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d466637f-1c11-4c77-dbae-3685bb414682"
      },
      "source": [
        "### Training regret minimization: run number = 9\r\n",
        "\r\n",
        "loser_output_9 = np.append(np.max(loser_9.GP.y[0:n_init]),loser_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_9 = np.append(np.max(winner_9.GP.y[0:n_init]),winner_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_9 = np.log(y_global_orig - loser_output_9)\r\n",
        "regret_winner_9 = np.log(y_global_orig - winner_output_9)\r\n",
        "\r\n",
        "train_regret_loser_9 = min_max_array(regret_loser_9)\r\n",
        "train_regret_winner_9 = min_max_array(regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9 = min(train_regret_loser_9)\r\n",
        "min_train_regret_winner_9 = min(train_regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9, min_train_regret_winner_9"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.168530738268499, 5.08259074943662)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g92jk9WJuwXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63f5cd28-3e97-4b48-e1ca-22fb64e8f715"
      },
      "source": [
        "### Training regret minimization: run number = 10\r\n",
        "\r\n",
        "loser_output_10 = np.append(np.max(loser_10.GP.y[0:n_init]),loser_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_10 = np.append(np.max(winner_10.GP.y[0:n_init]),winner_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_10 = np.log(y_global_orig - loser_output_10)\r\n",
        "regret_winner_10 = np.log(y_global_orig - winner_output_10)\r\n",
        "\r\n",
        "train_regret_loser_10 = min_max_array(regret_loser_10)\r\n",
        "train_regret_winner_10 = min_max_array(regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10 = min(train_regret_loser_10)\r\n",
        "min_train_regret_winner_10 = min(train_regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10, min_train_regret_winner_10"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.105519060338369, 4.958686668757028)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmcF1x-NuwZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c3d3b5-b1ce-43c3-f0a2-bbef0242b41b"
      },
      "source": [
        "### Training regret minimization: run number = 11\r\n",
        "\r\n",
        "loser_output_11 = np.append(np.max(loser_11.GP.y[0:n_init]),loser_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_11 = np.append(np.max(winner_11.GP.y[0:n_init]),winner_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_11 = np.log(y_global_orig - loser_output_11)\r\n",
        "regret_winner_11 = np.log(y_global_orig - winner_output_11)\r\n",
        "\r\n",
        "train_regret_loser_11 = min_max_array(regret_loser_11)\r\n",
        "train_regret_winner_11 = min_max_array(regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11 = min(train_regret_loser_11)\r\n",
        "min_train_regret_winner_11 = min(train_regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11, min_train_regret_winner_11"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.294954859607875, 5.294954859607875)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8axVhb6uwcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf2dcb3-a5a1-4299-82be-f454b46cdac4"
      },
      "source": [
        "### Training regret minimization: run number = 12\r\n",
        "\r\n",
        "loser_output_12 = np.append(np.max(loser_12.GP.y[0:n_init]),loser_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_12 = np.append(np.max(winner_12.GP.y[0:n_init]),winner_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_12 = np.log(y_global_orig - loser_output_12)\r\n",
        "regret_winner_12 = np.log(y_global_orig - winner_output_12)\r\n",
        "\r\n",
        "train_regret_loser_12 = min_max_array(regret_loser_12)\r\n",
        "train_regret_winner_12 = min_max_array(regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12 = min(train_regret_loser_12)\r\n",
        "min_train_regret_winner_12 = min(train_regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12, min_train_regret_winner_12"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.784284021089071, 4.784284021089071)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzlrL8XFuwfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a3bc6e-41fc-4722-e7d9-79d1402376d1"
      },
      "source": [
        "### Training regret minimization: run number = 13\r\n",
        "\r\n",
        "loser_output_13 = np.append(np.max(loser_13.GP.y[0:n_init]),loser_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_13 = np.append(np.max(winner_13.GP.y[0:n_init]),winner_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_13 = np.log(y_global_orig - loser_output_13)\r\n",
        "regret_winner_13 = np.log(y_global_orig - winner_output_13)\r\n",
        "\r\n",
        "train_regret_loser_13 = min_max_array(regret_loser_13)\r\n",
        "train_regret_winner_13 = min_max_array(regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13 = min(train_regret_loser_13)\r\n",
        "min_train_regret_winner_13 = min(train_regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13, min_train_regret_winner_13"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.388682173250253, 4.528488176087684)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uZlLJ1quwh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0823d930-7f3a-4991-f1e3-6901e2ca7eda"
      },
      "source": [
        "### Training regret minimization: run number = 14\r\n",
        "\r\n",
        "loser_output_14 = np.append(np.max(loser_14.GP.y[0:n_init]),loser_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_14 = np.append(np.max(winner_14.GP.y[0:n_init]),winner_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_14 = np.log(y_global_orig - loser_output_14)\r\n",
        "regret_winner_14 = np.log(y_global_orig - winner_output_14)\r\n",
        "\r\n",
        "train_regret_loser_14 = min_max_array(regret_loser_14)\r\n",
        "train_regret_winner_14 = min_max_array(regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14 = min(train_regret_loser_14)\r\n",
        "min_train_regret_winner_14 = min(train_regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14, min_train_regret_winner_14"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.188190270709808, 5.291132035742767)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVBcHRiMuwjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec06076e-4cd0-4679-8b25-455a1df40a97"
      },
      "source": [
        "### Training regret minimization: run number = 15\r\n",
        "\r\n",
        "loser_output_15 = np.append(np.max(loser_15.GP.y[0:n_init]),loser_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_15 = np.append(np.max(winner_15.GP.y[0:n_init]),winner_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_15 = np.log(y_global_orig - loser_output_15)\r\n",
        "regret_winner_15 = np.log(y_global_orig - winner_output_15)\r\n",
        "\r\n",
        "train_regret_loser_15 = min_max_array(regret_loser_15)\r\n",
        "train_regret_winner_15 = min_max_array(regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15 = min(train_regret_loser_15)\r\n",
        "min_train_regret_winner_15 = min(train_regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15, min_train_regret_winner_15"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.717103197449605, 4.717103197449605)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8nZ_DrKuwnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e56482-88c4-4f24-cffb-c1c6c8c39e02"
      },
      "source": [
        "### Training regret minimization: run number = 16\r\n",
        "\r\n",
        "loser_output_16 = np.append(np.max(loser_16.GP.y[0:n_init]),loser_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_16 = np.append(np.max(winner_16.GP.y[0:n_init]),winner_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_16 = np.log(y_global_orig - loser_output_16)\r\n",
        "regret_winner_16 = np.log(y_global_orig - winner_output_16)\r\n",
        "\r\n",
        "train_regret_loser_16 = min_max_array(regret_loser_16)\r\n",
        "train_regret_winner_16 = min_max_array(regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16 = min(train_regret_loser_16)\r\n",
        "min_train_regret_winner_16 = min(train_regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16, min_train_regret_winner_16"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.055013211046219, 4.768460592895028)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg6qzzQFuwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76857c78-d4db-4d59-e81d-208429f58dd0"
      },
      "source": [
        "### Training regret minimization: run number = 17\r\n",
        "\r\n",
        "loser_output_17 = np.append(np.max(loser_17.GP.y[0:n_init]),loser_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_17 = np.append(np.max(winner_17.GP.y[0:n_init]),winner_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_17 = np.log(y_global_orig - loser_output_17)\r\n",
        "regret_winner_17 = np.log(y_global_orig - winner_output_17)\r\n",
        "\r\n",
        "train_regret_loser_17 = min_max_array(regret_loser_17)\r\n",
        "train_regret_winner_17 = min_max_array(regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17 = min(train_regret_loser_17)\r\n",
        "min_train_regret_winner_17 = min(train_regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17, min_train_regret_winner_17"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.042343049744377, 5.209384674405556)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrRtDLMFuwsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "777d0ffc-cc6c-43c3-8ed4-a14f6354628c"
      },
      "source": [
        "### Training regret minimization: run number = 18\r\n",
        "\r\n",
        "loser_output_18 = np.append(np.max(loser_18.GP.y[0:n_init]),loser_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_18 = np.append(np.max(winner_18.GP.y[0:n_init]),winner_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_18 = np.log(y_global_orig - loser_output_18)\r\n",
        "regret_winner_18 = np.log(y_global_orig - winner_output_18)\r\n",
        "\r\n",
        "train_regret_loser_18 = min_max_array(regret_loser_18)\r\n",
        "train_regret_winner_18 = min_max_array(regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18 = min(train_regret_loser_18)\r\n",
        "min_train_regret_winner_18 = min(train_regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18, min_train_regret_winner_18"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.395239135171794, 4.395239135171794)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkmSu4CUuwuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ccd197-a69b-48aa-a685-5398ad91f27f"
      },
      "source": [
        "### Training regret minimization: run number = 19\r\n",
        "\r\n",
        "loser_output_19 = np.append(np.max(loser_19.GP.y[0:n_init]),loser_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_19 = np.append(np.max(winner_19.GP.y[0:n_init]),winner_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_19 = np.log(y_global_orig - loser_output_19)\r\n",
        "regret_winner_19 = np.log(y_global_orig - winner_output_19)\r\n",
        "\r\n",
        "train_regret_loser_19 = min_max_array(regret_loser_19)\r\n",
        "train_regret_winner_19 = min_max_array(regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19 = min(train_regret_loser_19)\r\n",
        "min_train_regret_winner_19 = min(train_regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19, min_train_regret_winner_19"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.02872431933846, 5.02872431933846)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eymecjwkuwxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14e38c8-0101-44f0-82da-f34fad34ece8"
      },
      "source": [
        "### Training regret minimization: run number = 20\r\n",
        "\r\n",
        "loser_output_20 = np.append(np.max(loser_20.GP.y[0:n_init]),loser_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_20 = np.append(np.max(winner_20.GP.y[0:n_init]),winner_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_20 = np.log(y_global_orig - loser_output_20)\r\n",
        "regret_winner_20 = np.log(y_global_orig - winner_output_20)\r\n",
        "\r\n",
        "train_regret_loser_20 = min_max_array(regret_loser_20)\r\n",
        "train_regret_winner_20 = min_max_array(regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20 = min(train_regret_loser_20)\r\n",
        "min_train_regret_winner_20 = min(train_regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20, min_train_regret_winner_20"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.884937030361687, 4.884937030361687)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5P6kq2Kuw0d"
      },
      "source": [
        "# Iteration1 :\r\n",
        "\r\n",
        "slice1 = 0\r\n",
        "\r\n",
        "loser1 = [train_regret_loser_1[slice1],\r\n",
        "       train_regret_loser_2[slice1],\r\n",
        "       train_regret_loser_3[slice1],\r\n",
        "       train_regret_loser_4[slice1],\r\n",
        "       train_regret_loser_5[slice1],\r\n",
        "       train_regret_loser_6[slice1],\r\n",
        "       train_regret_loser_7[slice1],\r\n",
        "       train_regret_loser_8[slice1],\r\n",
        "       train_regret_loser_9[slice1],\r\n",
        "       train_regret_loser_10[slice1],\r\n",
        "       train_regret_loser_11[slice1],\r\n",
        "       train_regret_loser_12[slice1],\r\n",
        "       train_regret_loser_13[slice1],\r\n",
        "       train_regret_loser_14[slice1],\r\n",
        "       train_regret_loser_15[slice1],\r\n",
        "       train_regret_loser_16[slice1],\r\n",
        "       train_regret_loser_17[slice1],\r\n",
        "       train_regret_loser_18[slice1],\r\n",
        "       train_regret_loser_19[slice1],\r\n",
        "       train_regret_loser_20[slice1]]\r\n",
        "\r\n",
        "winner1 = [train_regret_winner_1[slice1],\r\n",
        "       train_regret_winner_2[slice1],\r\n",
        "       train_regret_winner_3[slice1],\r\n",
        "       train_regret_winner_4[slice1],\r\n",
        "       train_regret_winner_5[slice1],\r\n",
        "       train_regret_winner_6[slice1],\r\n",
        "       train_regret_winner_7[slice1],\r\n",
        "       train_regret_winner_8[slice1],\r\n",
        "       train_regret_winner_9[slice1],\r\n",
        "       train_regret_winner_10[slice1],\r\n",
        "       train_regret_winner_11[slice1],\r\n",
        "       train_regret_winner_12[slice1],\r\n",
        "       train_regret_winner_13[slice1],\r\n",
        "       train_regret_winner_14[slice1],\r\n",
        "       train_regret_winner_15[slice1],\r\n",
        "       train_regret_winner_16[slice1],\r\n",
        "       train_regret_winner_17[slice1],\r\n",
        "       train_regret_winner_18[slice1],\r\n",
        "       train_regret_winner_19[slice1],\r\n",
        "       train_regret_winner_20[slice1]]\r\n",
        "\r\n",
        "loser1_results = pd.DataFrame(loser1).sort_values(by=[0], ascending=False)\r\n",
        "winner1_results = pd.DataFrame(winner1).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser1 = np.asarray(loser1_results[4:5][0])[0]\r\n",
        "median_loser1 = np.asarray(loser1_results[9:10][0])[0]\r\n",
        "upper_loser1 = np.asarray(loser1_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner1 = np.asarray(winner1_results[4:5][0])[0]\r\n",
        "median_winner1 = np.asarray(winner1_results[9:10][0])[0]\r\n",
        "upper_winner1 = np.asarray(winner1_results[14:15][0])[0]"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXcnj2pNuw3X"
      },
      "source": [
        "# Iteration11 :\r\n",
        "\r\n",
        "slice11 = 10\r\n",
        "\r\n",
        "loser11 = [train_regret_loser_1[slice11],\r\n",
        "       train_regret_loser_2[slice11],\r\n",
        "       train_regret_loser_3[slice11],\r\n",
        "       train_regret_loser_4[slice11],\r\n",
        "       train_regret_loser_5[slice11],\r\n",
        "       train_regret_loser_6[slice11],\r\n",
        "       train_regret_loser_7[slice11],\r\n",
        "       train_regret_loser_8[slice11],\r\n",
        "       train_regret_loser_9[slice11],\r\n",
        "       train_regret_loser_10[slice11],\r\n",
        "       train_regret_loser_11[slice11],\r\n",
        "       train_regret_loser_12[slice11],\r\n",
        "       train_regret_loser_13[slice11],\r\n",
        "       train_regret_loser_14[slice11],\r\n",
        "       train_regret_loser_15[slice11],\r\n",
        "       train_regret_loser_16[slice11],\r\n",
        "       train_regret_loser_17[slice11],\r\n",
        "       train_regret_loser_18[slice11],\r\n",
        "       train_regret_loser_19[slice11],\r\n",
        "       train_regret_loser_20[slice11]]\r\n",
        "\r\n",
        "winner11 = [train_regret_winner_1[slice11],\r\n",
        "       train_regret_winner_2[slice11],\r\n",
        "       train_regret_winner_3[slice11],\r\n",
        "       train_regret_winner_4[slice11],\r\n",
        "       train_regret_winner_5[slice11],\r\n",
        "       train_regret_winner_6[slice11],\r\n",
        "       train_regret_winner_7[slice11],\r\n",
        "       train_regret_winner_8[slice11],\r\n",
        "       train_regret_winner_9[slice11],\r\n",
        "       train_regret_winner_10[slice11],\r\n",
        "       train_regret_winner_11[slice11],\r\n",
        "       train_regret_winner_12[slice11],\r\n",
        "       train_regret_winner_13[slice11],\r\n",
        "       train_regret_winner_14[slice11],\r\n",
        "       train_regret_winner_15[slice11],\r\n",
        "       train_regret_winner_16[slice11],\r\n",
        "       train_regret_winner_17[slice11],\r\n",
        "       train_regret_winner_18[slice11],\r\n",
        "       train_regret_winner_19[slice11],\r\n",
        "       train_regret_winner_20[slice11]]\r\n",
        "\r\n",
        "loser11_results = pd.DataFrame(loser11).sort_values(by=[0], ascending=False)\r\n",
        "winner11_results = pd.DataFrame(winner11).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser11 = np.asarray(loser11_results[4:5][0])[0]\r\n",
        "median_loser11 = np.asarray(loser11_results[9:10][0])[0]\r\n",
        "upper_loser11 = np.asarray(loser11_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner11 = np.asarray(winner11_results[4:5][0])[0]\r\n",
        "median_winner11 = np.asarray(winner11_results[9:10][0])[0]\r\n",
        "upper_winner11 = np.asarray(winner11_results[14:15][0])[0]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxQa6BAVuw6L"
      },
      "source": [
        "# Iteration21 :\r\n",
        "\r\n",
        "slice21 = 20\r\n",
        "\r\n",
        "loser21 = [train_regret_loser_1[slice21],\r\n",
        "       train_regret_loser_2[slice21],\r\n",
        "       train_regret_loser_3[slice21],\r\n",
        "       train_regret_loser_4[slice21],\r\n",
        "       train_regret_loser_5[slice21],\r\n",
        "       train_regret_loser_6[slice21],\r\n",
        "       train_regret_loser_7[slice21],\r\n",
        "       train_regret_loser_8[slice21],\r\n",
        "       train_regret_loser_9[slice21],\r\n",
        "       train_regret_loser_10[slice21],\r\n",
        "       train_regret_loser_11[slice21],\r\n",
        "       train_regret_loser_12[slice21],\r\n",
        "       train_regret_loser_13[slice21],\r\n",
        "       train_regret_loser_14[slice21],\r\n",
        "       train_regret_loser_15[slice21],\r\n",
        "       train_regret_loser_16[slice21],\r\n",
        "       train_regret_loser_17[slice21],\r\n",
        "       train_regret_loser_18[slice21],\r\n",
        "       train_regret_loser_19[slice21],\r\n",
        "       train_regret_loser_20[slice21]]\r\n",
        "\r\n",
        "winner21 = [train_regret_winner_1[slice21],\r\n",
        "       train_regret_winner_2[slice21],\r\n",
        "       train_regret_winner_3[slice21],\r\n",
        "       train_regret_winner_4[slice21],\r\n",
        "       train_regret_winner_5[slice21],\r\n",
        "       train_regret_winner_6[slice21],\r\n",
        "       train_regret_winner_7[slice21],\r\n",
        "       train_regret_winner_8[slice21],\r\n",
        "       train_regret_winner_9[slice21],\r\n",
        "       train_regret_winner_10[slice21],\r\n",
        "       train_regret_winner_11[slice21],\r\n",
        "       train_regret_winner_12[slice21],\r\n",
        "       train_regret_winner_13[slice21],\r\n",
        "       train_regret_winner_14[slice21],\r\n",
        "       train_regret_winner_15[slice21],\r\n",
        "       train_regret_winner_16[slice21],\r\n",
        "       train_regret_winner_17[slice21],\r\n",
        "       train_regret_winner_18[slice21],\r\n",
        "       train_regret_winner_19[slice21],\r\n",
        "       train_regret_winner_20[slice21]]\r\n",
        "\r\n",
        "loser21_results = pd.DataFrame(loser21).sort_values(by=[0], ascending=False)\r\n",
        "winner21_results = pd.DataFrame(winner21).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser21 = np.asarray(loser21_results[4:5][0])[0]\r\n",
        "median_loser21 = np.asarray(loser21_results[9:10][0])[0]\r\n",
        "upper_loser21 = np.asarray(loser21_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner21 = np.asarray(winner21_results[4:5][0])[0]\r\n",
        "median_winner21 = np.asarray(winner21_results[9:10][0])[0]\r\n",
        "upper_winner21 = np.asarray(winner21_results[14:15][0])[0]"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wdJdIsWuw8r"
      },
      "source": [
        "# Iteration31 :\r\n",
        "\r\n",
        "slice31 = 30\r\n",
        "\r\n",
        "loser31 = [train_regret_loser_1[slice31],\r\n",
        "       train_regret_loser_2[slice31],\r\n",
        "       train_regret_loser_3[slice31],\r\n",
        "       train_regret_loser_4[slice31],\r\n",
        "       train_regret_loser_5[slice31],\r\n",
        "       train_regret_loser_6[slice31],\r\n",
        "       train_regret_loser_7[slice31],\r\n",
        "       train_regret_loser_8[slice31],\r\n",
        "       train_regret_loser_9[slice31],\r\n",
        "       train_regret_loser_10[slice31],\r\n",
        "       train_regret_loser_11[slice31],\r\n",
        "       train_regret_loser_12[slice31],\r\n",
        "       train_regret_loser_13[slice31],\r\n",
        "       train_regret_loser_14[slice31],\r\n",
        "       train_regret_loser_15[slice31],\r\n",
        "       train_regret_loser_16[slice31],\r\n",
        "       train_regret_loser_17[slice31],\r\n",
        "       train_regret_loser_18[slice31],\r\n",
        "       train_regret_loser_19[slice31],\r\n",
        "       train_regret_loser_20[slice31]]\r\n",
        "\r\n",
        "winner31 = [train_regret_winner_1[slice31],\r\n",
        "       train_regret_winner_2[slice31],\r\n",
        "       train_regret_winner_3[slice31],\r\n",
        "       train_regret_winner_4[slice31],\r\n",
        "       train_regret_winner_5[slice31],\r\n",
        "       train_regret_winner_6[slice31],\r\n",
        "       train_regret_winner_7[slice31],\r\n",
        "       train_regret_winner_8[slice31],\r\n",
        "       train_regret_winner_9[slice31],\r\n",
        "       train_regret_winner_10[slice31],\r\n",
        "       train_regret_winner_11[slice31],\r\n",
        "       train_regret_winner_12[slice31],\r\n",
        "       train_regret_winner_13[slice31],\r\n",
        "       train_regret_winner_14[slice31],\r\n",
        "       train_regret_winner_15[slice31],\r\n",
        "       train_regret_winner_16[slice31],\r\n",
        "       train_regret_winner_17[slice31],\r\n",
        "       train_regret_winner_18[slice31],\r\n",
        "       train_regret_winner_19[slice31],\r\n",
        "       train_regret_winner_20[slice31]]\r\n",
        "\r\n",
        "loser31_results = pd.DataFrame(loser31).sort_values(by=[0], ascending=False)\r\n",
        "winner31_results = pd.DataFrame(winner31).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser31 = np.asarray(loser31_results[4:5][0])[0]\r\n",
        "median_loser31 = np.asarray(loser31_results[9:10][0])[0]\r\n",
        "upper_loser31 = np.asarray(loser31_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner31 = np.asarray(winner31_results[4:5][0])[0]\r\n",
        "median_winner31 = np.asarray(winner31_results[9:10][0])[0]\r\n",
        "upper_winner31 = np.asarray(winner31_results[14:15][0])[0]"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vWZBDufuw_Z"
      },
      "source": [
        "# Iteration41 :\r\n",
        "\r\n",
        "slice41 = 40\r\n",
        "\r\n",
        "loser41 = [train_regret_loser_1[slice41],\r\n",
        "       train_regret_loser_2[slice41],\r\n",
        "       train_regret_loser_3[slice41],\r\n",
        "       train_regret_loser_4[slice41],\r\n",
        "       train_regret_loser_5[slice41],\r\n",
        "       train_regret_loser_6[slice41],\r\n",
        "       train_regret_loser_7[slice41],\r\n",
        "       train_regret_loser_8[slice41],\r\n",
        "       train_regret_loser_9[slice41],\r\n",
        "       train_regret_loser_10[slice41],\r\n",
        "       train_regret_loser_11[slice41],\r\n",
        "       train_regret_loser_12[slice41],\r\n",
        "       train_regret_loser_13[slice41],\r\n",
        "       train_regret_loser_14[slice41],\r\n",
        "       train_regret_loser_15[slice41],\r\n",
        "       train_regret_loser_16[slice41],\r\n",
        "       train_regret_loser_17[slice41],\r\n",
        "       train_regret_loser_18[slice41],\r\n",
        "       train_regret_loser_19[slice41],\r\n",
        "       train_regret_loser_20[slice41]]\r\n",
        "\r\n",
        "winner41 = [train_regret_winner_1[slice41],\r\n",
        "       train_regret_winner_2[slice41],\r\n",
        "       train_regret_winner_3[slice41],\r\n",
        "       train_regret_winner_4[slice41],\r\n",
        "       train_regret_winner_5[slice41],\r\n",
        "       train_regret_winner_6[slice41],\r\n",
        "       train_regret_winner_7[slice41],\r\n",
        "       train_regret_winner_8[slice41],\r\n",
        "       train_regret_winner_9[slice41],\r\n",
        "       train_regret_winner_10[slice41],\r\n",
        "       train_regret_winner_11[slice41],\r\n",
        "       train_regret_winner_12[slice41],\r\n",
        "       train_regret_winner_13[slice41],\r\n",
        "       train_regret_winner_14[slice41],\r\n",
        "       train_regret_winner_15[slice41],\r\n",
        "       train_regret_winner_16[slice41],\r\n",
        "       train_regret_winner_17[slice41],\r\n",
        "       train_regret_winner_18[slice41],\r\n",
        "       train_regret_winner_19[slice41],\r\n",
        "       train_regret_winner_20[slice41]]\r\n",
        "\r\n",
        "loser41_results = pd.DataFrame(loser41).sort_values(by=[0], ascending=False)\r\n",
        "winner41_results = pd.DataFrame(winner41).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser41 = np.asarray(loser41_results[4:5][0])[0]\r\n",
        "median_loser41 = np.asarray(loser41_results[9:10][0])[0]\r\n",
        "upper_loser41 = np.asarray(loser41_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner41 = np.asarray(winner41_results[4:5][0])[0]\r\n",
        "median_winner41 = np.asarray(winner41_results[9:10][0])[0]\r\n",
        "upper_winner41 = np.asarray(winner41_results[14:15][0])[0]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwi_GzjiuxB6"
      },
      "source": [
        "# Iteration51 :\r\n",
        "\r\n",
        "slice51 = 50\r\n",
        "\r\n",
        "loser51 = [train_regret_loser_1[slice51],\r\n",
        "       train_regret_loser_2[slice51],\r\n",
        "       train_regret_loser_3[slice51],\r\n",
        "       train_regret_loser_4[slice51],\r\n",
        "       train_regret_loser_5[slice51],\r\n",
        "       train_regret_loser_6[slice51],\r\n",
        "       train_regret_loser_7[slice51],\r\n",
        "       train_regret_loser_8[slice51],\r\n",
        "       train_regret_loser_9[slice51],\r\n",
        "       train_regret_loser_10[slice51],\r\n",
        "       train_regret_loser_11[slice51],\r\n",
        "       train_regret_loser_12[slice51],\r\n",
        "       train_regret_loser_13[slice51],\r\n",
        "       train_regret_loser_14[slice51],\r\n",
        "       train_regret_loser_15[slice51],\r\n",
        "       train_regret_loser_16[slice51],\r\n",
        "       train_regret_loser_17[slice51],\r\n",
        "       train_regret_loser_18[slice51],\r\n",
        "       train_regret_loser_19[slice51],\r\n",
        "       train_regret_loser_20[slice51]]\r\n",
        "\r\n",
        "winner51 = [train_regret_winner_1[slice51],\r\n",
        "       train_regret_winner_2[slice51],\r\n",
        "       train_regret_winner_3[slice51],\r\n",
        "       train_regret_winner_4[slice51],\r\n",
        "       train_regret_winner_5[slice51],\r\n",
        "       train_regret_winner_6[slice51],\r\n",
        "       train_regret_winner_7[slice51],\r\n",
        "       train_regret_winner_8[slice51],\r\n",
        "       train_regret_winner_9[slice51],\r\n",
        "       train_regret_winner_10[slice51],\r\n",
        "       train_regret_winner_11[slice51],\r\n",
        "       train_regret_winner_12[slice51],\r\n",
        "       train_regret_winner_13[slice51],\r\n",
        "       train_regret_winner_14[slice51],\r\n",
        "       train_regret_winner_15[slice51],\r\n",
        "       train_regret_winner_16[slice51],\r\n",
        "       train_regret_winner_17[slice51],\r\n",
        "       train_regret_winner_18[slice51],\r\n",
        "       train_regret_winner_19[slice51],\r\n",
        "       train_regret_winner_20[slice51]]\r\n",
        "\r\n",
        "loser51_results = pd.DataFrame(loser51).sort_values(by=[0], ascending=False)\r\n",
        "winner51_results = pd.DataFrame(winner51).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser51 = np.asarray(loser51_results[4:5][0])[0]\r\n",
        "median_loser51 = np.asarray(loser51_results[9:10][0])[0]\r\n",
        "upper_loser51 = np.asarray(loser51_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner51 = np.asarray(winner51_results[4:5][0])[0]\r\n",
        "median_winner51 = np.asarray(winner51_results[9:10][0])[0]\r\n",
        "upper_winner51 = np.asarray(winner51_results[14:15][0])[0]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk9nlS6puxFZ"
      },
      "source": [
        "# Iteration61 :\r\n",
        "\r\n",
        "slice61 = 60\r\n",
        "\r\n",
        "loser61 = [train_regret_loser_1[slice61],\r\n",
        "       train_regret_loser_2[slice61],\r\n",
        "       train_regret_loser_3[slice61],\r\n",
        "       train_regret_loser_4[slice61],\r\n",
        "       train_regret_loser_5[slice61],\r\n",
        "       train_regret_loser_6[slice61],\r\n",
        "       train_regret_loser_7[slice61],\r\n",
        "       train_regret_loser_8[slice61],\r\n",
        "       train_regret_loser_9[slice61],\r\n",
        "       train_regret_loser_10[slice61],\r\n",
        "       train_regret_loser_11[slice61],\r\n",
        "       train_regret_loser_12[slice61],\r\n",
        "       train_regret_loser_13[slice61],\r\n",
        "       train_regret_loser_14[slice61],\r\n",
        "       train_regret_loser_15[slice61],\r\n",
        "       train_regret_loser_16[slice61],\r\n",
        "       train_regret_loser_17[slice61],\r\n",
        "       train_regret_loser_18[slice61],\r\n",
        "       train_regret_loser_19[slice61],\r\n",
        "       train_regret_loser_20[slice61]]\r\n",
        "\r\n",
        "winner61 = [train_regret_winner_1[slice61],\r\n",
        "       train_regret_winner_2[slice61],\r\n",
        "       train_regret_winner_3[slice61],\r\n",
        "       train_regret_winner_4[slice61],\r\n",
        "       train_regret_winner_5[slice61],\r\n",
        "       train_regret_winner_6[slice61],\r\n",
        "       train_regret_winner_7[slice61],\r\n",
        "       train_regret_winner_8[slice61],\r\n",
        "       train_regret_winner_9[slice61],\r\n",
        "       train_regret_winner_10[slice61],\r\n",
        "       train_regret_winner_11[slice61],\r\n",
        "       train_regret_winner_12[slice61],\r\n",
        "       train_regret_winner_13[slice61],\r\n",
        "       train_regret_winner_14[slice61],\r\n",
        "       train_regret_winner_15[slice61],\r\n",
        "       train_regret_winner_16[slice61],\r\n",
        "       train_regret_winner_17[slice61],\r\n",
        "       train_regret_winner_18[slice61],\r\n",
        "       train_regret_winner_19[slice61],\r\n",
        "       train_regret_winner_20[slice61]]\r\n",
        "\r\n",
        "loser61_results = pd.DataFrame(loser61).sort_values(by=[0], ascending=False)\r\n",
        "winner61_results = pd.DataFrame(winner61).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser61 = np.asarray(loser61_results[4:5][0])[0]\r\n",
        "median_loser61 = np.asarray(loser61_results[9:10][0])[0]\r\n",
        "upper_loser61 = np.asarray(loser61_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner61 = np.asarray(winner61_results[4:5][0])[0]\r\n",
        "median_winner61 = np.asarray(winner61_results[9:10][0])[0]\r\n",
        "upper_winner61 = np.asarray(winner61_results[14:15][0])[0]"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMus9vDpuxHN"
      },
      "source": [
        "# Iteration71 :\r\n",
        "\r\n",
        "slice71 = 70\r\n",
        "\r\n",
        "loser71 = [train_regret_loser_1[slice71],\r\n",
        "       train_regret_loser_2[slice71],\r\n",
        "       train_regret_loser_3[slice71],\r\n",
        "       train_regret_loser_4[slice71],\r\n",
        "       train_regret_loser_5[slice71],\r\n",
        "       train_regret_loser_6[slice71],\r\n",
        "       train_regret_loser_7[slice71],\r\n",
        "       train_regret_loser_8[slice71],\r\n",
        "       train_regret_loser_9[slice71],\r\n",
        "       train_regret_loser_10[slice71],\r\n",
        "       train_regret_loser_11[slice71],\r\n",
        "       train_regret_loser_12[slice71],\r\n",
        "       train_regret_loser_13[slice71],\r\n",
        "       train_regret_loser_14[slice71],\r\n",
        "       train_regret_loser_15[slice71],\r\n",
        "       train_regret_loser_16[slice71],\r\n",
        "       train_regret_loser_17[slice71],\r\n",
        "       train_regret_loser_18[slice71],\r\n",
        "       train_regret_loser_19[slice71],\r\n",
        "       train_regret_loser_20[slice71]]\r\n",
        "\r\n",
        "winner71 = [train_regret_winner_1[slice71],\r\n",
        "       train_regret_winner_2[slice71],\r\n",
        "       train_regret_winner_3[slice71],\r\n",
        "       train_regret_winner_4[slice71],\r\n",
        "       train_regret_winner_5[slice71],\r\n",
        "       train_regret_winner_6[slice71],\r\n",
        "       train_regret_winner_7[slice71],\r\n",
        "       train_regret_winner_8[slice71],\r\n",
        "       train_regret_winner_9[slice71],\r\n",
        "       train_regret_winner_10[slice71],\r\n",
        "       train_regret_winner_11[slice71],\r\n",
        "       train_regret_winner_12[slice71],\r\n",
        "       train_regret_winner_13[slice71],\r\n",
        "       train_regret_winner_14[slice71],\r\n",
        "       train_regret_winner_15[slice71],\r\n",
        "       train_regret_winner_16[slice71],\r\n",
        "       train_regret_winner_17[slice71],\r\n",
        "       train_regret_winner_18[slice71],\r\n",
        "       train_regret_winner_19[slice71],\r\n",
        "       train_regret_winner_20[slice71]]\r\n",
        "\r\n",
        "loser71_results = pd.DataFrame(loser71).sort_values(by=[0], ascending=False)\r\n",
        "winner71_results = pd.DataFrame(winner71).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser71 = np.asarray(loser71_results[4:5][0])[0]\r\n",
        "median_loser71 = np.asarray(loser71_results[9:10][0])[0]\r\n",
        "upper_loser71 = np.asarray(loser71_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner71 = np.asarray(winner71_results[4:5][0])[0]\r\n",
        "median_winner71 = np.asarray(winner71_results[9:10][0])[0]\r\n",
        "upper_winner71 = np.asarray(winner71_results[14:15][0])[0]"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Mg0x9vuxL4"
      },
      "source": [
        "# Iteration81 :\r\n",
        "\r\n",
        "slice81 = 80\r\n",
        "\r\n",
        "loser81 = [train_regret_loser_1[slice81],\r\n",
        "       train_regret_loser_2[slice81],\r\n",
        "       train_regret_loser_3[slice81],\r\n",
        "       train_regret_loser_4[slice81],\r\n",
        "       train_regret_loser_5[slice81],\r\n",
        "       train_regret_loser_6[slice81],\r\n",
        "       train_regret_loser_7[slice81],\r\n",
        "       train_regret_loser_8[slice81],\r\n",
        "       train_regret_loser_9[slice81],\r\n",
        "       train_regret_loser_10[slice81],\r\n",
        "       train_regret_loser_11[slice81],\r\n",
        "       train_regret_loser_12[slice81],\r\n",
        "       train_regret_loser_13[slice81],\r\n",
        "       train_regret_loser_14[slice81],\r\n",
        "       train_regret_loser_15[slice81],\r\n",
        "       train_regret_loser_16[slice81],\r\n",
        "       train_regret_loser_17[slice81],\r\n",
        "       train_regret_loser_18[slice81],\r\n",
        "       train_regret_loser_19[slice81],\r\n",
        "       train_regret_loser_20[slice81]]\r\n",
        "\r\n",
        "winner81 = [train_regret_winner_1[slice81],\r\n",
        "       train_regret_winner_2[slice81],\r\n",
        "       train_regret_winner_3[slice81],\r\n",
        "       train_regret_winner_4[slice81],\r\n",
        "       train_regret_winner_5[slice81],\r\n",
        "       train_regret_winner_6[slice81],\r\n",
        "       train_regret_winner_7[slice81],\r\n",
        "       train_regret_winner_8[slice81],\r\n",
        "       train_regret_winner_9[slice81],\r\n",
        "       train_regret_winner_10[slice81],\r\n",
        "       train_regret_winner_11[slice81],\r\n",
        "       train_regret_winner_12[slice81],\r\n",
        "       train_regret_winner_13[slice81],\r\n",
        "       train_regret_winner_14[slice81],\r\n",
        "       train_regret_winner_15[slice81],\r\n",
        "       train_regret_winner_16[slice81],\r\n",
        "       train_regret_winner_17[slice81],\r\n",
        "       train_regret_winner_18[slice81],\r\n",
        "       train_regret_winner_19[slice81],\r\n",
        "       train_regret_winner_20[slice81]]\r\n",
        "\r\n",
        "loser81_results = pd.DataFrame(loser81).sort_values(by=[0], ascending=False)\r\n",
        "winner81_results = pd.DataFrame(winner81).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser81 = np.asarray(loser81_results[4:5][0])[0]\r\n",
        "median_loser81 = np.asarray(loser81_results[9:10][0])[0]\r\n",
        "upper_loser81 = np.asarray(loser81_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner81 = np.asarray(winner81_results[4:5][0])[0]\r\n",
        "median_winner81 = np.asarray(winner81_results[9:10][0])[0]\r\n",
        "upper_winner81 = np.asarray(winner81_results[14:15][0])[0]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gu9K8XlteV4"
      },
      "source": [
        "# Iteration91 :\r\n",
        "\r\n",
        "slice91 = 90\r\n",
        "\r\n",
        "loser91 = [train_regret_loser_1[slice91],\r\n",
        "       train_regret_loser_2[slice91],\r\n",
        "       train_regret_loser_3[slice91],\r\n",
        "       train_regret_loser_4[slice91],\r\n",
        "       train_regret_loser_5[slice91],\r\n",
        "       train_regret_loser_6[slice91],\r\n",
        "       train_regret_loser_7[slice91],\r\n",
        "       train_regret_loser_8[slice91],\r\n",
        "       train_regret_loser_9[slice91],\r\n",
        "       train_regret_loser_10[slice91],\r\n",
        "       train_regret_loser_11[slice91],\r\n",
        "       train_regret_loser_12[slice91],\r\n",
        "       train_regret_loser_13[slice91],\r\n",
        "       train_regret_loser_14[slice91],\r\n",
        "       train_regret_loser_15[slice91],\r\n",
        "       train_regret_loser_16[slice91],\r\n",
        "       train_regret_loser_17[slice91],\r\n",
        "       train_regret_loser_18[slice91],\r\n",
        "       train_regret_loser_19[slice91],\r\n",
        "       train_regret_loser_20[slice91]]\r\n",
        "\r\n",
        "winner91 = [train_regret_winner_1[slice91],\r\n",
        "       train_regret_winner_2[slice91],\r\n",
        "       train_regret_winner_3[slice91],\r\n",
        "       train_regret_winner_4[slice91],\r\n",
        "       train_regret_winner_5[slice91],\r\n",
        "       train_regret_winner_6[slice91],\r\n",
        "       train_regret_winner_7[slice91],\r\n",
        "       train_regret_winner_8[slice91],\r\n",
        "       train_regret_winner_9[slice91],\r\n",
        "       train_regret_winner_10[slice91],\r\n",
        "       train_regret_winner_11[slice91],\r\n",
        "       train_regret_winner_12[slice91],\r\n",
        "       train_regret_winner_13[slice91],\r\n",
        "       train_regret_winner_14[slice91],\r\n",
        "       train_regret_winner_15[slice91],\r\n",
        "       train_regret_winner_16[slice91],\r\n",
        "       train_regret_winner_17[slice91],\r\n",
        "       train_regret_winner_18[slice91],\r\n",
        "       train_regret_winner_19[slice91],\r\n",
        "       train_regret_winner_20[slice91]]\r\n",
        "\r\n",
        "loser91_results = pd.DataFrame(loser91).sort_values(by=[0], ascending=False)\r\n",
        "winner91_results = pd.DataFrame(winner91).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser91 = np.asarray(loser91_results[4:5][0])[0]\r\n",
        "median_loser91 = np.asarray(loser91_results[9:10][0])[0]\r\n",
        "upper_loser91 = np.asarray(loser91_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner91 = np.asarray(winner91_results[4:5][0])[0]\r\n",
        "median_winner91 = np.asarray(winner91_results[9:10][0])[0]\r\n",
        "upper_winner91 = np.asarray(winner91_results[14:15][0])[0]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVVeft6steXv"
      },
      "source": [
        "# Iteration101 :\r\n",
        "\r\n",
        "slice101 = 100\r\n",
        "\r\n",
        "loser101 = [train_regret_loser_1[slice101],\r\n",
        "       train_regret_loser_2[slice101],\r\n",
        "       train_regret_loser_3[slice101],\r\n",
        "       train_regret_loser_4[slice101],\r\n",
        "       train_regret_loser_5[slice101],\r\n",
        "       train_regret_loser_6[slice101],\r\n",
        "       train_regret_loser_7[slice101],\r\n",
        "       train_regret_loser_8[slice101],\r\n",
        "       train_regret_loser_9[slice101],\r\n",
        "       train_regret_loser_10[slice101],\r\n",
        "       train_regret_loser_11[slice101],\r\n",
        "       train_regret_loser_12[slice101],\r\n",
        "       train_regret_loser_13[slice101],\r\n",
        "       train_regret_loser_14[slice101],\r\n",
        "       train_regret_loser_15[slice101],\r\n",
        "       train_regret_loser_16[slice101],\r\n",
        "       train_regret_loser_17[slice101],\r\n",
        "       train_regret_loser_18[slice101],\r\n",
        "       train_regret_loser_19[slice101],\r\n",
        "       train_regret_loser_20[slice101]]\r\n",
        "\r\n",
        "winner101 = [train_regret_winner_1[slice101],\r\n",
        "       train_regret_winner_2[slice101],\r\n",
        "       train_regret_winner_3[slice101],\r\n",
        "       train_regret_winner_4[slice101],\r\n",
        "       train_regret_winner_5[slice101],\r\n",
        "       train_regret_winner_6[slice101],\r\n",
        "       train_regret_winner_7[slice101],\r\n",
        "       train_regret_winner_8[slice101],\r\n",
        "       train_regret_winner_9[slice101],\r\n",
        "       train_regret_winner_10[slice101],\r\n",
        "       train_regret_winner_11[slice101],\r\n",
        "       train_regret_winner_12[slice101],\r\n",
        "       train_regret_winner_13[slice101],\r\n",
        "       train_regret_winner_14[slice101],\r\n",
        "       train_regret_winner_15[slice101],\r\n",
        "       train_regret_winner_16[slice101],\r\n",
        "       train_regret_winner_17[slice101],\r\n",
        "       train_regret_winner_18[slice101],\r\n",
        "       train_regret_winner_19[slice101],\r\n",
        "       train_regret_winner_20[slice101]]\r\n",
        "\r\n",
        "loser101_results = pd.DataFrame(loser101).sort_values(by=[0], ascending=False)\r\n",
        "winner101_results = pd.DataFrame(winner101).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser101 = np.asarray(loser101_results[4:5][0])[0]\r\n",
        "median_loser101 = np.asarray(loser101_results[9:10][0])[0]\r\n",
        "upper_loser101 = np.asarray(loser101_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner101 = np.asarray(winner101_results[4:5][0])[0]\r\n",
        "median_winner101 = np.asarray(winner101_results[9:10][0])[0]\r\n",
        "upper_winner101 = np.asarray(winner101_results[14:15][0])[0]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maqbtTXXtebT"
      },
      "source": [
        "# Iteration2 :\r\n",
        "\r\n",
        "slice2 = 1\r\n",
        "\r\n",
        "loser2 = [train_regret_loser_1[slice2],\r\n",
        "       train_regret_loser_2[slice2],\r\n",
        "       train_regret_loser_3[slice2],\r\n",
        "       train_regret_loser_4[slice2],\r\n",
        "       train_regret_loser_5[slice2],\r\n",
        "       train_regret_loser_6[slice2],\r\n",
        "       train_regret_loser_7[slice2],\r\n",
        "       train_regret_loser_8[slice2],\r\n",
        "       train_regret_loser_9[slice2],\r\n",
        "       train_regret_loser_10[slice2],\r\n",
        "       train_regret_loser_11[slice2],\r\n",
        "       train_regret_loser_12[slice2],\r\n",
        "       train_regret_loser_13[slice2],\r\n",
        "       train_regret_loser_14[slice2],\r\n",
        "       train_regret_loser_15[slice2],\r\n",
        "       train_regret_loser_16[slice2],\r\n",
        "       train_regret_loser_17[slice2],\r\n",
        "       train_regret_loser_18[slice2],\r\n",
        "       train_regret_loser_19[slice2],\r\n",
        "       train_regret_loser_20[slice2]]\r\n",
        "\r\n",
        "winner2 = [train_regret_winner_1[slice2],\r\n",
        "       train_regret_winner_2[slice2],\r\n",
        "       train_regret_winner_3[slice2],\r\n",
        "       train_regret_winner_4[slice2],\r\n",
        "       train_regret_winner_5[slice2],\r\n",
        "       train_regret_winner_6[slice2],\r\n",
        "       train_regret_winner_7[slice2],\r\n",
        "       train_regret_winner_8[slice2],\r\n",
        "       train_regret_winner_9[slice2],\r\n",
        "       train_regret_winner_10[slice2],\r\n",
        "       train_regret_winner_11[slice2],\r\n",
        "       train_regret_winner_12[slice2],\r\n",
        "       train_regret_winner_13[slice2],\r\n",
        "       train_regret_winner_14[slice2],\r\n",
        "       train_regret_winner_15[slice2],\r\n",
        "       train_regret_winner_16[slice2],\r\n",
        "       train_regret_winner_17[slice2],\r\n",
        "       train_regret_winner_18[slice2],\r\n",
        "       train_regret_winner_19[slice2],\r\n",
        "       train_regret_winner_20[slice2]]\r\n",
        "\r\n",
        "loser2_results = pd.DataFrame(loser2).sort_values(by=[0], ascending=False)\r\n",
        "winner2_results = pd.DataFrame(winner2).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser2 = np.asarray(loser2_results[4:5][0])[0]\r\n",
        "median_loser2 = np.asarray(loser2_results[9:10][0])[0]\r\n",
        "upper_loser2 = np.asarray(loser2_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner2 = np.asarray(winner2_results[4:5][0])[0]\r\n",
        "median_winner2 = np.asarray(winner2_results[9:10][0])[0]\r\n",
        "upper_winner2 = np.asarray(winner2_results[14:15][0])[0]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWIBh0dQw-ZM"
      },
      "source": [
        "# Iteration12 :\r\n",
        "\r\n",
        "slice12 = 11\r\n",
        "\r\n",
        "loser12 = [train_regret_loser_1[slice12],\r\n",
        "       train_regret_loser_2[slice12],\r\n",
        "       train_regret_loser_3[slice12],\r\n",
        "       train_regret_loser_4[slice12],\r\n",
        "       train_regret_loser_5[slice12],\r\n",
        "       train_regret_loser_6[slice12],\r\n",
        "       train_regret_loser_7[slice12],\r\n",
        "       train_regret_loser_8[slice12],\r\n",
        "       train_regret_loser_9[slice12],\r\n",
        "       train_regret_loser_10[slice12],\r\n",
        "       train_regret_loser_11[slice12],\r\n",
        "       train_regret_loser_12[slice12],\r\n",
        "       train_regret_loser_13[slice12],\r\n",
        "       train_regret_loser_14[slice12],\r\n",
        "       train_regret_loser_15[slice12],\r\n",
        "       train_regret_loser_16[slice12],\r\n",
        "       train_regret_loser_17[slice12],\r\n",
        "       train_regret_loser_18[slice12],\r\n",
        "       train_regret_loser_19[slice12],\r\n",
        "       train_regret_loser_20[slice12]]\r\n",
        "\r\n",
        "winner12 = [train_regret_winner_1[slice12],\r\n",
        "       train_regret_winner_2[slice12],\r\n",
        "       train_regret_winner_3[slice12],\r\n",
        "       train_regret_winner_4[slice12],\r\n",
        "       train_regret_winner_5[slice12],\r\n",
        "       train_regret_winner_6[slice12],\r\n",
        "       train_regret_winner_7[slice12],\r\n",
        "       train_regret_winner_8[slice12],\r\n",
        "       train_regret_winner_9[slice12],\r\n",
        "       train_regret_winner_10[slice12],\r\n",
        "       train_regret_winner_11[slice12],\r\n",
        "       train_regret_winner_12[slice12],\r\n",
        "       train_regret_winner_13[slice12],\r\n",
        "       train_regret_winner_14[slice12],\r\n",
        "       train_regret_winner_15[slice12],\r\n",
        "       train_regret_winner_16[slice12],\r\n",
        "       train_regret_winner_17[slice12],\r\n",
        "       train_regret_winner_18[slice12],\r\n",
        "       train_regret_winner_19[slice12],\r\n",
        "       train_regret_winner_20[slice12]]\r\n",
        "\r\n",
        "loser12_results = pd.DataFrame(loser12).sort_values(by=[0], ascending=False)\r\n",
        "winner12_results = pd.DataFrame(winner12).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser12 = np.asarray(loser12_results[4:5][0])[0]\r\n",
        "median_loser12 = np.asarray(loser12_results[9:10][0])[0]\r\n",
        "upper_loser12 = np.asarray(loser12_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner12 = np.asarray(winner12_results[4:5][0])[0]\r\n",
        "median_winner12 = np.asarray(winner12_results[9:10][0])[0]\r\n",
        "upper_winner12 = np.asarray(winner12_results[14:15][0])[0]"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjIhsei3w-cV"
      },
      "source": [
        "# Iteration22 :\r\n",
        "\r\n",
        "slice22 = 21\r\n",
        "\r\n",
        "loser22 = [train_regret_loser_1[slice22],\r\n",
        "       train_regret_loser_2[slice22],\r\n",
        "       train_regret_loser_3[slice22],\r\n",
        "       train_regret_loser_4[slice22],\r\n",
        "       train_regret_loser_5[slice22],\r\n",
        "       train_regret_loser_6[slice22],\r\n",
        "       train_regret_loser_7[slice22],\r\n",
        "       train_regret_loser_8[slice22],\r\n",
        "       train_regret_loser_9[slice22],\r\n",
        "       train_regret_loser_10[slice22],\r\n",
        "       train_regret_loser_11[slice22],\r\n",
        "       train_regret_loser_12[slice22],\r\n",
        "       train_regret_loser_13[slice22],\r\n",
        "       train_regret_loser_14[slice22],\r\n",
        "       train_regret_loser_15[slice22],\r\n",
        "       train_regret_loser_16[slice22],\r\n",
        "       train_regret_loser_17[slice22],\r\n",
        "       train_regret_loser_18[slice22],\r\n",
        "       train_regret_loser_19[slice22],\r\n",
        "       train_regret_loser_20[slice22]]\r\n",
        "\r\n",
        "winner22 = [train_regret_winner_1[slice22],\r\n",
        "       train_regret_winner_2[slice22],\r\n",
        "       train_regret_winner_3[slice22],\r\n",
        "       train_regret_winner_4[slice22],\r\n",
        "       train_regret_winner_5[slice22],\r\n",
        "       train_regret_winner_6[slice22],\r\n",
        "       train_regret_winner_7[slice22],\r\n",
        "       train_regret_winner_8[slice22],\r\n",
        "       train_regret_winner_9[slice22],\r\n",
        "       train_regret_winner_10[slice22],\r\n",
        "       train_regret_winner_11[slice22],\r\n",
        "       train_regret_winner_12[slice22],\r\n",
        "       train_regret_winner_13[slice22],\r\n",
        "       train_regret_winner_14[slice22],\r\n",
        "       train_regret_winner_15[slice22],\r\n",
        "       train_regret_winner_16[slice22],\r\n",
        "       train_regret_winner_17[slice22],\r\n",
        "       train_regret_winner_18[slice22],\r\n",
        "       train_regret_winner_19[slice22],\r\n",
        "       train_regret_winner_20[slice22]]\r\n",
        "\r\n",
        "loser22_results = pd.DataFrame(loser22).sort_values(by=[0], ascending=False)\r\n",
        "winner22_results = pd.DataFrame(winner22).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser22 = np.asarray(loser22_results[4:5][0])[0]\r\n",
        "median_loser22 = np.asarray(loser22_results[9:10][0])[0]\r\n",
        "upper_loser22 = np.asarray(loser22_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner22 = np.asarray(winner22_results[4:5][0])[0]\r\n",
        "median_winner22 = np.asarray(winner22_results[9:10][0])[0]\r\n",
        "upper_winner22 = np.asarray(winner22_results[14:15][0])[0]"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur9p9GkHw-fq"
      },
      "source": [
        "# Iteration32 :\r\n",
        "\r\n",
        "slice32 = 31\r\n",
        "\r\n",
        "loser32 = [train_regret_loser_1[slice32],\r\n",
        "       train_regret_loser_2[slice32],\r\n",
        "       train_regret_loser_3[slice32],\r\n",
        "       train_regret_loser_4[slice32],\r\n",
        "       train_regret_loser_5[slice32],\r\n",
        "       train_regret_loser_6[slice32],\r\n",
        "       train_regret_loser_7[slice32],\r\n",
        "       train_regret_loser_8[slice32],\r\n",
        "       train_regret_loser_9[slice32],\r\n",
        "       train_regret_loser_10[slice32],\r\n",
        "       train_regret_loser_11[slice32],\r\n",
        "       train_regret_loser_12[slice32],\r\n",
        "       train_regret_loser_13[slice32],\r\n",
        "       train_regret_loser_14[slice32],\r\n",
        "       train_regret_loser_15[slice32],\r\n",
        "       train_regret_loser_16[slice32],\r\n",
        "       train_regret_loser_17[slice32],\r\n",
        "       train_regret_loser_18[slice32],\r\n",
        "       train_regret_loser_19[slice32],\r\n",
        "       train_regret_loser_20[slice32]]\r\n",
        "\r\n",
        "winner32 = [train_regret_winner_1[slice32],\r\n",
        "       train_regret_winner_2[slice32],\r\n",
        "       train_regret_winner_3[slice32],\r\n",
        "       train_regret_winner_4[slice32],\r\n",
        "       train_regret_winner_5[slice32],\r\n",
        "       train_regret_winner_6[slice32],\r\n",
        "       train_regret_winner_7[slice32],\r\n",
        "       train_regret_winner_8[slice32],\r\n",
        "       train_regret_winner_9[slice32],\r\n",
        "       train_regret_winner_10[slice32],\r\n",
        "       train_regret_winner_11[slice32],\r\n",
        "       train_regret_winner_12[slice32],\r\n",
        "       train_regret_winner_13[slice32],\r\n",
        "       train_regret_winner_14[slice32],\r\n",
        "       train_regret_winner_15[slice32],\r\n",
        "       train_regret_winner_16[slice32],\r\n",
        "       train_regret_winner_17[slice32],\r\n",
        "       train_regret_winner_18[slice32],\r\n",
        "       train_regret_winner_19[slice32],\r\n",
        "       train_regret_winner_20[slice32]]\r\n",
        "\r\n",
        "loser32_results = pd.DataFrame(loser32).sort_values(by=[0], ascending=False)\r\n",
        "winner32_results = pd.DataFrame(winner32).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser32 = np.asarray(loser32_results[4:5][0])[0]\r\n",
        "median_loser32 = np.asarray(loser32_results[9:10][0])[0]\r\n",
        "upper_loser32 = np.asarray(loser32_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner32 = np.asarray(winner32_results[4:5][0])[0]\r\n",
        "median_winner32 = np.asarray(winner32_results[9:10][0])[0]\r\n",
        "upper_winner32 = np.asarray(winner32_results[14:15][0])[0]"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_rzHB8w-hy"
      },
      "source": [
        "# Iteration42 :\r\n",
        "\r\n",
        "slice42 = 41\r\n",
        "\r\n",
        "loser42 = [train_regret_loser_1[slice42],\r\n",
        "       train_regret_loser_2[slice42],\r\n",
        "       train_regret_loser_3[slice42],\r\n",
        "       train_regret_loser_4[slice42],\r\n",
        "       train_regret_loser_5[slice42],\r\n",
        "       train_regret_loser_6[slice42],\r\n",
        "       train_regret_loser_7[slice42],\r\n",
        "       train_regret_loser_8[slice42],\r\n",
        "       train_regret_loser_9[slice42],\r\n",
        "       train_regret_loser_10[slice42],\r\n",
        "       train_regret_loser_11[slice42],\r\n",
        "       train_regret_loser_12[slice42],\r\n",
        "       train_regret_loser_13[slice42],\r\n",
        "       train_regret_loser_14[slice42],\r\n",
        "       train_regret_loser_15[slice42],\r\n",
        "       train_regret_loser_16[slice42],\r\n",
        "       train_regret_loser_17[slice42],\r\n",
        "       train_regret_loser_18[slice42],\r\n",
        "       train_regret_loser_19[slice42],\r\n",
        "       train_regret_loser_20[slice42]]\r\n",
        "\r\n",
        "winner42 = [train_regret_winner_1[slice42],\r\n",
        "       train_regret_winner_2[slice42],\r\n",
        "       train_regret_winner_3[slice42],\r\n",
        "       train_regret_winner_4[slice42],\r\n",
        "       train_regret_winner_5[slice42],\r\n",
        "       train_regret_winner_6[slice42],\r\n",
        "       train_regret_winner_7[slice42],\r\n",
        "       train_regret_winner_8[slice42],\r\n",
        "       train_regret_winner_9[slice42],\r\n",
        "       train_regret_winner_10[slice42],\r\n",
        "       train_regret_winner_11[slice42],\r\n",
        "       train_regret_winner_12[slice42],\r\n",
        "       train_regret_winner_13[slice42],\r\n",
        "       train_regret_winner_14[slice42],\r\n",
        "       train_regret_winner_15[slice42],\r\n",
        "       train_regret_winner_16[slice42],\r\n",
        "       train_regret_winner_17[slice42],\r\n",
        "       train_regret_winner_18[slice42],\r\n",
        "       train_regret_winner_19[slice42],\r\n",
        "       train_regret_winner_20[slice42]]\r\n",
        "\r\n",
        "loser42_results = pd.DataFrame(loser42).sort_values(by=[0], ascending=False)\r\n",
        "winner42_results = pd.DataFrame(winner42).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser42 = np.asarray(loser42_results[4:5][0])[0]\r\n",
        "median_loser42 = np.asarray(loser42_results[9:10][0])[0]\r\n",
        "upper_loser42 = np.asarray(loser42_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner42 = np.asarray(winner42_results[4:5][0])[0]\r\n",
        "median_winner42 = np.asarray(winner42_results[9:10][0])[0]\r\n",
        "upper_winner42 = np.asarray(winner42_results[14:15][0])[0]"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKUUG6vAw-kz"
      },
      "source": [
        "# Iteration52 :\r\n",
        "\r\n",
        "slice52 = 51\r\n",
        "\r\n",
        "loser52 = [train_regret_loser_1[slice52],\r\n",
        "       train_regret_loser_2[slice52],\r\n",
        "       train_regret_loser_3[slice52],\r\n",
        "       train_regret_loser_4[slice52],\r\n",
        "       train_regret_loser_5[slice52],\r\n",
        "       train_regret_loser_6[slice52],\r\n",
        "       train_regret_loser_7[slice52],\r\n",
        "       train_regret_loser_8[slice52],\r\n",
        "       train_regret_loser_9[slice52],\r\n",
        "       train_regret_loser_10[slice52],\r\n",
        "       train_regret_loser_11[slice52],\r\n",
        "       train_regret_loser_12[slice52],\r\n",
        "       train_regret_loser_13[slice52],\r\n",
        "       train_regret_loser_14[slice52],\r\n",
        "       train_regret_loser_15[slice52],\r\n",
        "       train_regret_loser_16[slice52],\r\n",
        "       train_regret_loser_17[slice52],\r\n",
        "       train_regret_loser_18[slice52],\r\n",
        "       train_regret_loser_19[slice52],\r\n",
        "       train_regret_loser_20[slice52]]\r\n",
        "\r\n",
        "winner52 = [train_regret_winner_1[slice52],\r\n",
        "       train_regret_winner_2[slice52],\r\n",
        "       train_regret_winner_3[slice52],\r\n",
        "       train_regret_winner_4[slice52],\r\n",
        "       train_regret_winner_5[slice52],\r\n",
        "       train_regret_winner_6[slice52],\r\n",
        "       train_regret_winner_7[slice52],\r\n",
        "       train_regret_winner_8[slice52],\r\n",
        "       train_regret_winner_9[slice52],\r\n",
        "       train_regret_winner_10[slice52],\r\n",
        "       train_regret_winner_11[slice52],\r\n",
        "       train_regret_winner_12[slice52],\r\n",
        "       train_regret_winner_13[slice52],\r\n",
        "       train_regret_winner_14[slice52],\r\n",
        "       train_regret_winner_15[slice52],\r\n",
        "       train_regret_winner_16[slice52],\r\n",
        "       train_regret_winner_17[slice52],\r\n",
        "       train_regret_winner_18[slice52],\r\n",
        "       train_regret_winner_19[slice52],\r\n",
        "       train_regret_winner_20[slice52]]\r\n",
        "\r\n",
        "loser52_results = pd.DataFrame(loser52).sort_values(by=[0], ascending=False)\r\n",
        "winner52_results = pd.DataFrame(winner52).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser52 = np.asarray(loser52_results[4:5][0])[0]\r\n",
        "median_loser52 = np.asarray(loser52_results[9:10][0])[0]\r\n",
        "upper_loser52 = np.asarray(loser52_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner52 = np.asarray(winner52_results[4:5][0])[0]\r\n",
        "median_winner52 = np.asarray(winner52_results[9:10][0])[0]\r\n",
        "upper_winner52 = np.asarray(winner52_results[14:15][0])[0]"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-9cJNkew-nY"
      },
      "source": [
        "# Iteration62 :\r\n",
        "\r\n",
        "slice62 = 61\r\n",
        "\r\n",
        "loser62 = [train_regret_loser_1[slice62],\r\n",
        "       train_regret_loser_2[slice62],\r\n",
        "       train_regret_loser_3[slice62],\r\n",
        "       train_regret_loser_4[slice62],\r\n",
        "       train_regret_loser_5[slice62],\r\n",
        "       train_regret_loser_6[slice62],\r\n",
        "       train_regret_loser_7[slice62],\r\n",
        "       train_regret_loser_8[slice62],\r\n",
        "       train_regret_loser_9[slice62],\r\n",
        "       train_regret_loser_10[slice62],\r\n",
        "       train_regret_loser_11[slice62],\r\n",
        "       train_regret_loser_12[slice62],\r\n",
        "       train_regret_loser_13[slice62],\r\n",
        "       train_regret_loser_14[slice62],\r\n",
        "       train_regret_loser_15[slice62],\r\n",
        "       train_regret_loser_16[slice62],\r\n",
        "       train_regret_loser_17[slice62],\r\n",
        "       train_regret_loser_18[slice62],\r\n",
        "       train_regret_loser_19[slice62],\r\n",
        "       train_regret_loser_20[slice62]]\r\n",
        "\r\n",
        "winner62 = [train_regret_winner_1[slice62],\r\n",
        "       train_regret_winner_2[slice62],\r\n",
        "       train_regret_winner_3[slice62],\r\n",
        "       train_regret_winner_4[slice62],\r\n",
        "       train_regret_winner_5[slice62],\r\n",
        "       train_regret_winner_6[slice62],\r\n",
        "       train_regret_winner_7[slice62],\r\n",
        "       train_regret_winner_8[slice62],\r\n",
        "       train_regret_winner_9[slice62],\r\n",
        "       train_regret_winner_10[slice62],\r\n",
        "       train_regret_winner_11[slice62],\r\n",
        "       train_regret_winner_12[slice62],\r\n",
        "       train_regret_winner_13[slice62],\r\n",
        "       train_regret_winner_14[slice62],\r\n",
        "       train_regret_winner_15[slice62],\r\n",
        "       train_regret_winner_16[slice62],\r\n",
        "       train_regret_winner_17[slice62],\r\n",
        "       train_regret_winner_18[slice62],\r\n",
        "       train_regret_winner_19[slice62],\r\n",
        "       train_regret_winner_20[slice62]]\r\n",
        "\r\n",
        "loser62_results = pd.DataFrame(loser62).sort_values(by=[0], ascending=False)\r\n",
        "winner62_results = pd.DataFrame(winner62).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser62 = np.asarray(loser62_results[4:5][0])[0]\r\n",
        "median_loser62 = np.asarray(loser62_results[9:10][0])[0]\r\n",
        "upper_loser62 = np.asarray(loser62_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner62 = np.asarray(winner62_results[4:5][0])[0]\r\n",
        "median_winner62 = np.asarray(winner62_results[9:10][0])[0]\r\n",
        "upper_winner62 = np.asarray(winner62_results[14:15][0])[0]"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DZ8kHHmw-qK"
      },
      "source": [
        "# Iteration72 :\r\n",
        "\r\n",
        "slice72 = 71\r\n",
        "\r\n",
        "loser72 = [train_regret_loser_1[slice72],\r\n",
        "       train_regret_loser_2[slice72],\r\n",
        "       train_regret_loser_3[slice72],\r\n",
        "       train_regret_loser_4[slice72],\r\n",
        "       train_regret_loser_5[slice72],\r\n",
        "       train_regret_loser_6[slice72],\r\n",
        "       train_regret_loser_7[slice72],\r\n",
        "       train_regret_loser_8[slice72],\r\n",
        "       train_regret_loser_9[slice72],\r\n",
        "       train_regret_loser_10[slice72],\r\n",
        "       train_regret_loser_11[slice72],\r\n",
        "       train_regret_loser_12[slice72],\r\n",
        "       train_regret_loser_13[slice72],\r\n",
        "       train_regret_loser_14[slice72],\r\n",
        "       train_regret_loser_15[slice72],\r\n",
        "       train_regret_loser_16[slice72],\r\n",
        "       train_regret_loser_17[slice72],\r\n",
        "       train_regret_loser_18[slice72],\r\n",
        "       train_regret_loser_19[slice72],\r\n",
        "       train_regret_loser_20[slice72]]\r\n",
        "\r\n",
        "winner72 = [train_regret_winner_1[slice72],\r\n",
        "       train_regret_winner_2[slice72],\r\n",
        "       train_regret_winner_3[slice72],\r\n",
        "       train_regret_winner_4[slice72],\r\n",
        "       train_regret_winner_5[slice72],\r\n",
        "       train_regret_winner_6[slice72],\r\n",
        "       train_regret_winner_7[slice72],\r\n",
        "       train_regret_winner_8[slice72],\r\n",
        "       train_regret_winner_9[slice72],\r\n",
        "       train_regret_winner_10[slice72],\r\n",
        "       train_regret_winner_11[slice72],\r\n",
        "       train_regret_winner_12[slice72],\r\n",
        "       train_regret_winner_13[slice72],\r\n",
        "       train_regret_winner_14[slice72],\r\n",
        "       train_regret_winner_15[slice72],\r\n",
        "       train_regret_winner_16[slice72],\r\n",
        "       train_regret_winner_17[slice72],\r\n",
        "       train_regret_winner_18[slice72],\r\n",
        "       train_regret_winner_19[slice72],\r\n",
        "       train_regret_winner_20[slice72]]\r\n",
        "\r\n",
        "loser72_results = pd.DataFrame(loser72).sort_values(by=[0], ascending=False)\r\n",
        "winner72_results = pd.DataFrame(winner72).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser72 = np.asarray(loser72_results[4:5][0])[0]\r\n",
        "median_loser72 = np.asarray(loser72_results[9:10][0])[0]\r\n",
        "upper_loser72 = np.asarray(loser72_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner72 = np.asarray(winner72_results[4:5][0])[0]\r\n",
        "median_winner72 = np.asarray(winner72_results[9:10][0])[0]\r\n",
        "upper_winner72 = np.asarray(winner72_results[14:15][0])[0]"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBzBvnVyw-sz"
      },
      "source": [
        "# Iteration82 :\r\n",
        "\r\n",
        "slice82 = 81\r\n",
        "\r\n",
        "loser82 = [train_regret_loser_1[slice82],\r\n",
        "       train_regret_loser_2[slice82],\r\n",
        "       train_regret_loser_3[slice82],\r\n",
        "       train_regret_loser_4[slice82],\r\n",
        "       train_regret_loser_5[slice82],\r\n",
        "       train_regret_loser_6[slice82],\r\n",
        "       train_regret_loser_7[slice82],\r\n",
        "       train_regret_loser_8[slice82],\r\n",
        "       train_regret_loser_9[slice82],\r\n",
        "       train_regret_loser_10[slice82],\r\n",
        "       train_regret_loser_11[slice82],\r\n",
        "       train_regret_loser_12[slice82],\r\n",
        "       train_regret_loser_13[slice82],\r\n",
        "       train_regret_loser_14[slice82],\r\n",
        "       train_regret_loser_15[slice82],\r\n",
        "       train_regret_loser_16[slice82],\r\n",
        "       train_regret_loser_17[slice82],\r\n",
        "       train_regret_loser_18[slice82],\r\n",
        "       train_regret_loser_19[slice82],\r\n",
        "       train_regret_loser_20[slice82]]\r\n",
        "\r\n",
        "winner82 = [train_regret_winner_1[slice82],\r\n",
        "       train_regret_winner_2[slice82],\r\n",
        "       train_regret_winner_3[slice82],\r\n",
        "       train_regret_winner_4[slice82],\r\n",
        "       train_regret_winner_5[slice82],\r\n",
        "       train_regret_winner_6[slice82],\r\n",
        "       train_regret_winner_7[slice82],\r\n",
        "       train_regret_winner_8[slice82],\r\n",
        "       train_regret_winner_9[slice82],\r\n",
        "       train_regret_winner_10[slice82],\r\n",
        "       train_regret_winner_11[slice82],\r\n",
        "       train_regret_winner_12[slice82],\r\n",
        "       train_regret_winner_13[slice82],\r\n",
        "       train_regret_winner_14[slice82],\r\n",
        "       train_regret_winner_15[slice82],\r\n",
        "       train_regret_winner_16[slice82],\r\n",
        "       train_regret_winner_17[slice82],\r\n",
        "       train_regret_winner_18[slice82],\r\n",
        "       train_regret_winner_19[slice82],\r\n",
        "       train_regret_winner_20[slice82]]\r\n",
        "\r\n",
        "loser82_results = pd.DataFrame(loser82).sort_values(by=[0], ascending=False)\r\n",
        "winner82_results = pd.DataFrame(winner82).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser82 = np.asarray(loser82_results[4:5][0])[0]\r\n",
        "median_loser82 = np.asarray(loser82_results[9:10][0])[0]\r\n",
        "upper_loser82 = np.asarray(loser82_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner82 = np.asarray(winner82_results[4:5][0])[0]\r\n",
        "median_winner82 = np.asarray(winner82_results[9:10][0])[0]\r\n",
        "upper_winner82 = np.asarray(winner82_results[14:15][0])[0]"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qj--n6Bw-y2"
      },
      "source": [
        "# Iteration92 :\r\n",
        "\r\n",
        "slice92 = 91\r\n",
        "\r\n",
        "loser92 = [train_regret_loser_1[slice92],\r\n",
        "       train_regret_loser_2[slice92],\r\n",
        "       train_regret_loser_3[slice92],\r\n",
        "       train_regret_loser_4[slice92],\r\n",
        "       train_regret_loser_5[slice92],\r\n",
        "       train_regret_loser_6[slice92],\r\n",
        "       train_regret_loser_7[slice92],\r\n",
        "       train_regret_loser_8[slice92],\r\n",
        "       train_regret_loser_9[slice92],\r\n",
        "       train_regret_loser_10[slice92],\r\n",
        "       train_regret_loser_11[slice92],\r\n",
        "       train_regret_loser_12[slice92],\r\n",
        "       train_regret_loser_13[slice92],\r\n",
        "       train_regret_loser_14[slice92],\r\n",
        "       train_regret_loser_15[slice92],\r\n",
        "       train_regret_loser_16[slice92],\r\n",
        "       train_regret_loser_17[slice92],\r\n",
        "       train_regret_loser_18[slice92],\r\n",
        "       train_regret_loser_19[slice92],\r\n",
        "       train_regret_loser_20[slice92]]\r\n",
        "\r\n",
        "winner92 = [train_regret_winner_1[slice92],\r\n",
        "       train_regret_winner_2[slice92],\r\n",
        "       train_regret_winner_3[slice92],\r\n",
        "       train_regret_winner_4[slice92],\r\n",
        "       train_regret_winner_5[slice92],\r\n",
        "       train_regret_winner_6[slice92],\r\n",
        "       train_regret_winner_7[slice92],\r\n",
        "       train_regret_winner_8[slice92],\r\n",
        "       train_regret_winner_9[slice92],\r\n",
        "       train_regret_winner_10[slice92],\r\n",
        "       train_regret_winner_11[slice92],\r\n",
        "       train_regret_winner_12[slice92],\r\n",
        "       train_regret_winner_13[slice92],\r\n",
        "       train_regret_winner_14[slice92],\r\n",
        "       train_regret_winner_15[slice92],\r\n",
        "       train_regret_winner_16[slice92],\r\n",
        "       train_regret_winner_17[slice92],\r\n",
        "       train_regret_winner_18[slice92],\r\n",
        "       train_regret_winner_19[slice92],\r\n",
        "       train_regret_winner_20[slice92]]\r\n",
        "\r\n",
        "loser92_results = pd.DataFrame(loser92).sort_values(by=[0], ascending=False)\r\n",
        "winner92_results = pd.DataFrame(winner92).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser92 = np.asarray(loser92_results[4:5][0])[0]\r\n",
        "median_loser92 = np.asarray(loser92_results[9:10][0])[0]\r\n",
        "upper_loser92 = np.asarray(loser92_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner92 = np.asarray(winner92_results[4:5][0])[0]\r\n",
        "median_winner92 = np.asarray(winner92_results[9:10][0])[0]\r\n",
        "upper_winner92 = np.asarray(winner92_results[14:15][0])[0]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaJ5KqLdw-0L"
      },
      "source": [
        "# Iteration3 :\r\n",
        "\r\n",
        "slice3 = 2\r\n",
        "\r\n",
        "loser3 = [train_regret_loser_1[slice3],\r\n",
        "       train_regret_loser_2[slice3],\r\n",
        "       train_regret_loser_3[slice3],\r\n",
        "       train_regret_loser_4[slice3],\r\n",
        "       train_regret_loser_5[slice3],\r\n",
        "       train_regret_loser_6[slice3],\r\n",
        "       train_regret_loser_7[slice3],\r\n",
        "       train_regret_loser_8[slice3],\r\n",
        "       train_regret_loser_9[slice3],\r\n",
        "       train_regret_loser_10[slice3],\r\n",
        "       train_regret_loser_11[slice3],\r\n",
        "       train_regret_loser_12[slice3],\r\n",
        "       train_regret_loser_13[slice3],\r\n",
        "       train_regret_loser_14[slice3],\r\n",
        "       train_regret_loser_15[slice3],\r\n",
        "       train_regret_loser_16[slice3],\r\n",
        "       train_regret_loser_17[slice3],\r\n",
        "       train_regret_loser_18[slice3],\r\n",
        "       train_regret_loser_19[slice3],\r\n",
        "       train_regret_loser_20[slice3]]\r\n",
        "\r\n",
        "winner3 = [train_regret_winner_1[slice3],\r\n",
        "       train_regret_winner_2[slice3],\r\n",
        "       train_regret_winner_3[slice3],\r\n",
        "       train_regret_winner_4[slice3],\r\n",
        "       train_regret_winner_5[slice3],\r\n",
        "       train_regret_winner_6[slice3],\r\n",
        "       train_regret_winner_7[slice3],\r\n",
        "       train_regret_winner_8[slice3],\r\n",
        "       train_regret_winner_9[slice3],\r\n",
        "       train_regret_winner_10[slice3],\r\n",
        "       train_regret_winner_11[slice3],\r\n",
        "       train_regret_winner_12[slice3],\r\n",
        "       train_regret_winner_13[slice3],\r\n",
        "       train_regret_winner_14[slice3],\r\n",
        "       train_regret_winner_15[slice3],\r\n",
        "       train_regret_winner_16[slice3],\r\n",
        "       train_regret_winner_17[slice3],\r\n",
        "       train_regret_winner_18[slice3],\r\n",
        "       train_regret_winner_19[slice3],\r\n",
        "       train_regret_winner_20[slice3]]\r\n",
        "\r\n",
        "loser3_results = pd.DataFrame(loser3).sort_values(by=[0], ascending=False)\r\n",
        "winner3_results = pd.DataFrame(winner3).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser3 = np.asarray(loser3_results[4:5][0])[0]\r\n",
        "median_loser3 = np.asarray(loser3_results[9:10][0])[0]\r\n",
        "upper_loser3 = np.asarray(loser3_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner3 = np.asarray(winner3_results[4:5][0])[0]\r\n",
        "median_winner3 = np.asarray(winner3_results[9:10][0])[0]\r\n",
        "upper_winner3 = np.asarray(winner3_results[14:15][0])[0]"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkaoT1dyw-16"
      },
      "source": [
        "# Iteration13 :\r\n",
        "\r\n",
        "slice13 = 12\r\n",
        "\r\n",
        "loser13 = [train_regret_loser_1[slice13],\r\n",
        "       train_regret_loser_2[slice13],\r\n",
        "       train_regret_loser_3[slice13],\r\n",
        "       train_regret_loser_4[slice13],\r\n",
        "       train_regret_loser_5[slice13],\r\n",
        "       train_regret_loser_6[slice13],\r\n",
        "       train_regret_loser_7[slice13],\r\n",
        "       train_regret_loser_8[slice13],\r\n",
        "       train_regret_loser_9[slice13],\r\n",
        "       train_regret_loser_10[slice13],\r\n",
        "       train_regret_loser_11[slice13],\r\n",
        "       train_regret_loser_12[slice13],\r\n",
        "       train_regret_loser_13[slice13],\r\n",
        "       train_regret_loser_14[slice13],\r\n",
        "       train_regret_loser_15[slice13],\r\n",
        "       train_regret_loser_16[slice13],\r\n",
        "       train_regret_loser_17[slice13],\r\n",
        "       train_regret_loser_18[slice13],\r\n",
        "       train_regret_loser_19[slice13],\r\n",
        "       train_regret_loser_20[slice13]]\r\n",
        "\r\n",
        "winner13 = [train_regret_winner_1[slice13],\r\n",
        "       train_regret_winner_2[slice13],\r\n",
        "       train_regret_winner_3[slice13],\r\n",
        "       train_regret_winner_4[slice13],\r\n",
        "       train_regret_winner_5[slice13],\r\n",
        "       train_regret_winner_6[slice13],\r\n",
        "       train_regret_winner_7[slice13],\r\n",
        "       train_regret_winner_8[slice13],\r\n",
        "       train_regret_winner_9[slice13],\r\n",
        "       train_regret_winner_10[slice13],\r\n",
        "       train_regret_winner_11[slice13],\r\n",
        "       train_regret_winner_12[slice13],\r\n",
        "       train_regret_winner_13[slice13],\r\n",
        "       train_regret_winner_14[slice13],\r\n",
        "       train_regret_winner_15[slice13],\r\n",
        "       train_regret_winner_16[slice13],\r\n",
        "       train_regret_winner_17[slice13],\r\n",
        "       train_regret_winner_18[slice13],\r\n",
        "       train_regret_winner_19[slice13],\r\n",
        "       train_regret_winner_20[slice13]]\r\n",
        "\r\n",
        "loser13_results = pd.DataFrame(loser12).sort_values(by=[0], ascending=False)\r\n",
        "winner13_results = pd.DataFrame(winner12).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser13 = np.asarray(loser13_results[4:5][0])[0]\r\n",
        "median_loser13 = np.asarray(loser13_results[9:10][0])[0]\r\n",
        "upper_loser13 = np.asarray(loser13_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner13 = np.asarray(winner13_results[4:5][0])[0]\r\n",
        "median_winner13 = np.asarray(winner13_results[9:10][0])[0]\r\n",
        "upper_winner13 = np.asarray(winner13_results[14:15][0])[0]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZbVMrBaw-4B"
      },
      "source": [
        "# Iteration23 :\r\n",
        "\r\n",
        "slice23 = 22\r\n",
        "\r\n",
        "loser23 = [train_regret_loser_1[slice23],\r\n",
        "       train_regret_loser_2[slice23],\r\n",
        "       train_regret_loser_3[slice23],\r\n",
        "       train_regret_loser_4[slice23],\r\n",
        "       train_regret_loser_5[slice23],\r\n",
        "       train_regret_loser_6[slice23],\r\n",
        "       train_regret_loser_7[slice23],\r\n",
        "       train_regret_loser_8[slice23],\r\n",
        "       train_regret_loser_9[slice23],\r\n",
        "       train_regret_loser_10[slice23],\r\n",
        "       train_regret_loser_11[slice23],\r\n",
        "       train_regret_loser_12[slice23],\r\n",
        "       train_regret_loser_13[slice23],\r\n",
        "       train_regret_loser_14[slice23],\r\n",
        "       train_regret_loser_15[slice23],\r\n",
        "       train_regret_loser_16[slice23],\r\n",
        "       train_regret_loser_17[slice23],\r\n",
        "       train_regret_loser_18[slice23],\r\n",
        "       train_regret_loser_19[slice23],\r\n",
        "       train_regret_loser_20[slice23]]\r\n",
        "\r\n",
        "winner23 = [train_regret_winner_1[slice23],\r\n",
        "       train_regret_winner_2[slice23],\r\n",
        "       train_regret_winner_3[slice23],\r\n",
        "       train_regret_winner_4[slice23],\r\n",
        "       train_regret_winner_5[slice23],\r\n",
        "       train_regret_winner_6[slice23],\r\n",
        "       train_regret_winner_7[slice23],\r\n",
        "       train_regret_winner_8[slice23],\r\n",
        "       train_regret_winner_9[slice23],\r\n",
        "       train_regret_winner_10[slice23],\r\n",
        "       train_regret_winner_11[slice23],\r\n",
        "       train_regret_winner_12[slice23],\r\n",
        "       train_regret_winner_13[slice23],\r\n",
        "       train_regret_winner_14[slice23],\r\n",
        "       train_regret_winner_15[slice23],\r\n",
        "       train_regret_winner_16[slice23],\r\n",
        "       train_regret_winner_17[slice23],\r\n",
        "       train_regret_winner_18[slice23],\r\n",
        "       train_regret_winner_19[slice23],\r\n",
        "       train_regret_winner_20[slice23]]\r\n",
        "\r\n",
        "loser23_results = pd.DataFrame(loser23).sort_values(by=[0], ascending=False)\r\n",
        "winner23_results = pd.DataFrame(winner23).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser23 = np.asarray(loser23_results[4:5][0])[0]\r\n",
        "median_loser23 = np.asarray(loser23_results[9:10][0])[0]\r\n",
        "upper_loser23 = np.asarray(loser23_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner23 = np.asarray(winner23_results[4:5][0])[0]\r\n",
        "median_winner23 = np.asarray(winner23_results[9:10][0])[0]\r\n",
        "upper_winner23 = np.asarray(winner23_results[14:15][0])[0]"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUa6HRCUw-7G"
      },
      "source": [
        "# Iteration33 :\r\n",
        "\r\n",
        "slice33 = 32\r\n",
        "\r\n",
        "loser33 = [train_regret_loser_1[slice33],\r\n",
        "       train_regret_loser_2[slice33],\r\n",
        "       train_regret_loser_3[slice33],\r\n",
        "       train_regret_loser_4[slice33],\r\n",
        "       train_regret_loser_5[slice33],\r\n",
        "       train_regret_loser_6[slice33],\r\n",
        "       train_regret_loser_7[slice33],\r\n",
        "       train_regret_loser_8[slice33],\r\n",
        "       train_regret_loser_9[slice33],\r\n",
        "       train_regret_loser_10[slice33],\r\n",
        "       train_regret_loser_11[slice33],\r\n",
        "       train_regret_loser_12[slice33],\r\n",
        "       train_regret_loser_13[slice33],\r\n",
        "       train_regret_loser_14[slice33],\r\n",
        "       train_regret_loser_15[slice33],\r\n",
        "       train_regret_loser_16[slice33],\r\n",
        "       train_regret_loser_17[slice33],\r\n",
        "       train_regret_loser_18[slice33],\r\n",
        "       train_regret_loser_19[slice33],\r\n",
        "       train_regret_loser_20[slice33]]\r\n",
        "\r\n",
        "winner33 = [train_regret_winner_1[slice33],\r\n",
        "       train_regret_winner_2[slice33],\r\n",
        "       train_regret_winner_3[slice33],\r\n",
        "       train_regret_winner_4[slice33],\r\n",
        "       train_regret_winner_5[slice33],\r\n",
        "       train_regret_winner_6[slice33],\r\n",
        "       train_regret_winner_7[slice33],\r\n",
        "       train_regret_winner_8[slice33],\r\n",
        "       train_regret_winner_9[slice33],\r\n",
        "       train_regret_winner_10[slice33],\r\n",
        "       train_regret_winner_11[slice33],\r\n",
        "       train_regret_winner_12[slice33],\r\n",
        "       train_regret_winner_13[slice33],\r\n",
        "       train_regret_winner_14[slice33],\r\n",
        "       train_regret_winner_15[slice33],\r\n",
        "       train_regret_winner_16[slice33],\r\n",
        "       train_regret_winner_17[slice33],\r\n",
        "       train_regret_winner_18[slice33],\r\n",
        "       train_regret_winner_19[slice33],\r\n",
        "       train_regret_winner_20[slice33]]\r\n",
        "\r\n",
        "loser33_results = pd.DataFrame(loser33).sort_values(by=[0], ascending=False)\r\n",
        "winner33_results = pd.DataFrame(winner33).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser33 = np.asarray(loser33_results[4:5][0])[0]\r\n",
        "median_loser33 = np.asarray(loser33_results[9:10][0])[0]\r\n",
        "upper_loser33 = np.asarray(loser33_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner33 = np.asarray(winner33_results[4:5][0])[0]\r\n",
        "median_winner33 = np.asarray(winner33_results[9:10][0])[0]\r\n",
        "upper_winner33 = np.asarray(winner33_results[14:15][0])[0]"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EVxQwsxw-9n"
      },
      "source": [
        "# Iteration43 :\r\n",
        "\r\n",
        "slice43 = 42\r\n",
        "\r\n",
        "loser43 = [train_regret_loser_1[slice43],\r\n",
        "       train_regret_loser_2[slice43],\r\n",
        "       train_regret_loser_3[slice43],\r\n",
        "       train_regret_loser_4[slice43],\r\n",
        "       train_regret_loser_5[slice43],\r\n",
        "       train_regret_loser_6[slice43],\r\n",
        "       train_regret_loser_7[slice43],\r\n",
        "       train_regret_loser_8[slice43],\r\n",
        "       train_regret_loser_9[slice43],\r\n",
        "       train_regret_loser_10[slice43],\r\n",
        "       train_regret_loser_11[slice43],\r\n",
        "       train_regret_loser_12[slice43],\r\n",
        "       train_regret_loser_13[slice43],\r\n",
        "       train_regret_loser_14[slice43],\r\n",
        "       train_regret_loser_15[slice43],\r\n",
        "       train_regret_loser_16[slice43],\r\n",
        "       train_regret_loser_17[slice43],\r\n",
        "       train_regret_loser_18[slice43],\r\n",
        "       train_regret_loser_19[slice43],\r\n",
        "       train_regret_loser_20[slice43]]\r\n",
        "\r\n",
        "winner43 = [train_regret_winner_1[slice43],\r\n",
        "       train_regret_winner_2[slice43],\r\n",
        "       train_regret_winner_3[slice43],\r\n",
        "       train_regret_winner_4[slice43],\r\n",
        "       train_regret_winner_5[slice43],\r\n",
        "       train_regret_winner_6[slice43],\r\n",
        "       train_regret_winner_7[slice43],\r\n",
        "       train_regret_winner_8[slice43],\r\n",
        "       train_regret_winner_9[slice43],\r\n",
        "       train_regret_winner_10[slice43],\r\n",
        "       train_regret_winner_11[slice43],\r\n",
        "       train_regret_winner_12[slice43],\r\n",
        "       train_regret_winner_13[slice43],\r\n",
        "       train_regret_winner_14[slice43],\r\n",
        "       train_regret_winner_15[slice43],\r\n",
        "       train_regret_winner_16[slice43],\r\n",
        "       train_regret_winner_17[slice43],\r\n",
        "       train_regret_winner_18[slice43],\r\n",
        "       train_regret_winner_19[slice43],\r\n",
        "       train_regret_winner_20[slice43]]\r\n",
        "\r\n",
        "loser43_results = pd.DataFrame(loser43).sort_values(by=[0], ascending=False)\r\n",
        "winner43_results = pd.DataFrame(winner43).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser43 = np.asarray(loser43_results[4:5][0])[0]\r\n",
        "median_loser43 = np.asarray(loser43_results[9:10][0])[0]\r\n",
        "upper_loser43 = np.asarray(loser43_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner43 = np.asarray(winner43_results[4:5][0])[0]\r\n",
        "median_winner43 = np.asarray(winner43_results[9:10][0])[0]\r\n",
        "upper_winner43 = np.asarray(winner43_results[14:15][0])[0]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQtRyMv-w_AZ"
      },
      "source": [
        "# Iteration53 :\r\n",
        "\r\n",
        "slice53 = 52\r\n",
        "\r\n",
        "loser53 = [train_regret_loser_1[slice53],\r\n",
        "       train_regret_loser_2[slice53],\r\n",
        "       train_regret_loser_3[slice53],\r\n",
        "       train_regret_loser_4[slice53],\r\n",
        "       train_regret_loser_5[slice53],\r\n",
        "       train_regret_loser_6[slice53],\r\n",
        "       train_regret_loser_7[slice53],\r\n",
        "       train_regret_loser_8[slice53],\r\n",
        "       train_regret_loser_9[slice53],\r\n",
        "       train_regret_loser_10[slice53],\r\n",
        "       train_regret_loser_11[slice53],\r\n",
        "       train_regret_loser_12[slice53],\r\n",
        "       train_regret_loser_13[slice53],\r\n",
        "       train_regret_loser_14[slice53],\r\n",
        "       train_regret_loser_15[slice53],\r\n",
        "       train_regret_loser_16[slice53],\r\n",
        "       train_regret_loser_17[slice53],\r\n",
        "       train_regret_loser_18[slice53],\r\n",
        "       train_regret_loser_19[slice53],\r\n",
        "       train_regret_loser_20[slice53]]\r\n",
        "\r\n",
        "winner53 = [train_regret_winner_1[slice53],\r\n",
        "       train_regret_winner_2[slice53],\r\n",
        "       train_regret_winner_3[slice53],\r\n",
        "       train_regret_winner_4[slice53],\r\n",
        "       train_regret_winner_5[slice53],\r\n",
        "       train_regret_winner_6[slice53],\r\n",
        "       train_regret_winner_7[slice53],\r\n",
        "       train_regret_winner_8[slice53],\r\n",
        "       train_regret_winner_9[slice53],\r\n",
        "       train_regret_winner_10[slice53],\r\n",
        "       train_regret_winner_11[slice53],\r\n",
        "       train_regret_winner_12[slice53],\r\n",
        "       train_regret_winner_13[slice53],\r\n",
        "       train_regret_winner_14[slice53],\r\n",
        "       train_regret_winner_15[slice53],\r\n",
        "       train_regret_winner_16[slice53],\r\n",
        "       train_regret_winner_17[slice53],\r\n",
        "       train_regret_winner_18[slice53],\r\n",
        "       train_regret_winner_19[slice53],\r\n",
        "       train_regret_winner_20[slice53]]\r\n",
        "\r\n",
        "loser53_results = pd.DataFrame(loser53).sort_values(by=[0], ascending=False)\r\n",
        "winner53_results = pd.DataFrame(winner53).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser53 = np.asarray(loser53_results[4:5][0])[0]\r\n",
        "median_loser53 = np.asarray(loser53_results[9:10][0])[0]\r\n",
        "upper_loser53 = np.asarray(loser53_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner53 = np.asarray(winner53_results[4:5][0])[0]\r\n",
        "median_winner53 = np.asarray(winner53_results[9:10][0])[0]\r\n",
        "upper_winner53 = np.asarray(winner53_results[14:15][0])[0]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CIMEXXYw_DR"
      },
      "source": [
        "# Iteration63 :\r\n",
        "\r\n",
        "slice63 = 62\r\n",
        "\r\n",
        "loser63 = [train_regret_loser_1[slice63],\r\n",
        "       train_regret_loser_2[slice63],\r\n",
        "       train_regret_loser_3[slice63],\r\n",
        "       train_regret_loser_4[slice63],\r\n",
        "       train_regret_loser_5[slice63],\r\n",
        "       train_regret_loser_6[slice63],\r\n",
        "       train_regret_loser_7[slice63],\r\n",
        "       train_regret_loser_8[slice63],\r\n",
        "       train_regret_loser_9[slice63],\r\n",
        "       train_regret_loser_10[slice63],\r\n",
        "       train_regret_loser_11[slice63],\r\n",
        "       train_regret_loser_12[slice63],\r\n",
        "       train_regret_loser_13[slice63],\r\n",
        "       train_regret_loser_14[slice63],\r\n",
        "       train_regret_loser_15[slice63],\r\n",
        "       train_regret_loser_16[slice63],\r\n",
        "       train_regret_loser_17[slice63],\r\n",
        "       train_regret_loser_18[slice63],\r\n",
        "       train_regret_loser_19[slice63],\r\n",
        "       train_regret_loser_20[slice63]]\r\n",
        "\r\n",
        "winner63 = [train_regret_winner_1[slice63],\r\n",
        "       train_regret_winner_2[slice63],\r\n",
        "       train_regret_winner_3[slice63],\r\n",
        "       train_regret_winner_4[slice63],\r\n",
        "       train_regret_winner_5[slice63],\r\n",
        "       train_regret_winner_6[slice63],\r\n",
        "       train_regret_winner_7[slice63],\r\n",
        "       train_regret_winner_8[slice63],\r\n",
        "       train_regret_winner_9[slice63],\r\n",
        "       train_regret_winner_10[slice63],\r\n",
        "       train_regret_winner_11[slice63],\r\n",
        "       train_regret_winner_12[slice63],\r\n",
        "       train_regret_winner_13[slice63],\r\n",
        "       train_regret_winner_14[slice63],\r\n",
        "       train_regret_winner_15[slice63],\r\n",
        "       train_regret_winner_16[slice63],\r\n",
        "       train_regret_winner_17[slice63],\r\n",
        "       train_regret_winner_18[slice63],\r\n",
        "       train_regret_winner_19[slice63],\r\n",
        "       train_regret_winner_20[slice63]]\r\n",
        "\r\n",
        "loser63_results = pd.DataFrame(loser63).sort_values(by=[0], ascending=False)\r\n",
        "winner63_results = pd.DataFrame(winner63).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser63 = np.asarray(loser63_results[4:5][0])[0]\r\n",
        "median_loser63 = np.asarray(loser63_results[9:10][0])[0]\r\n",
        "upper_loser63 = np.asarray(loser63_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner63 = np.asarray(winner63_results[4:5][0])[0]\r\n",
        "median_winner63 = np.asarray(winner63_results[9:10][0])[0]\r\n",
        "upper_winner63 = np.asarray(winner63_results[14:15][0])[0]"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg4GfwU_w_GF"
      },
      "source": [
        "# Iteration73 :\r\n",
        "\r\n",
        "slice73 = 72\r\n",
        "\r\n",
        "loser73 = [train_regret_loser_1[slice73],\r\n",
        "       train_regret_loser_2[slice73],\r\n",
        "       train_regret_loser_3[slice73],\r\n",
        "       train_regret_loser_4[slice73],\r\n",
        "       train_regret_loser_5[slice73],\r\n",
        "       train_regret_loser_6[slice73],\r\n",
        "       train_regret_loser_7[slice73],\r\n",
        "       train_regret_loser_8[slice73],\r\n",
        "       train_regret_loser_9[slice73],\r\n",
        "       train_regret_loser_10[slice73],\r\n",
        "       train_regret_loser_11[slice73],\r\n",
        "       train_regret_loser_12[slice73],\r\n",
        "       train_regret_loser_13[slice73],\r\n",
        "       train_regret_loser_14[slice73],\r\n",
        "       train_regret_loser_15[slice73],\r\n",
        "       train_regret_loser_16[slice73],\r\n",
        "       train_regret_loser_17[slice73],\r\n",
        "       train_regret_loser_18[slice73],\r\n",
        "       train_regret_loser_19[slice73],\r\n",
        "       train_regret_loser_20[slice73]]\r\n",
        "\r\n",
        "winner73 = [train_regret_winner_1[slice73],\r\n",
        "       train_regret_winner_2[slice73],\r\n",
        "       train_regret_winner_3[slice73],\r\n",
        "       train_regret_winner_4[slice73],\r\n",
        "       train_regret_winner_5[slice73],\r\n",
        "       train_regret_winner_6[slice73],\r\n",
        "       train_regret_winner_7[slice73],\r\n",
        "       train_regret_winner_8[slice73],\r\n",
        "       train_regret_winner_9[slice73],\r\n",
        "       train_regret_winner_10[slice73],\r\n",
        "       train_regret_winner_11[slice73],\r\n",
        "       train_regret_winner_12[slice73],\r\n",
        "       train_regret_winner_13[slice73],\r\n",
        "       train_regret_winner_14[slice73],\r\n",
        "       train_regret_winner_15[slice73],\r\n",
        "       train_regret_winner_16[slice73],\r\n",
        "       train_regret_winner_17[slice73],\r\n",
        "       train_regret_winner_18[slice73],\r\n",
        "       train_regret_winner_19[slice73],\r\n",
        "       train_regret_winner_20[slice73]]\r\n",
        "\r\n",
        "loser73_results = pd.DataFrame(loser73).sort_values(by=[0], ascending=False)\r\n",
        "winner73_results = pd.DataFrame(winner73).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser73 = np.asarray(loser73_results[4:5][0])[0]\r\n",
        "median_loser73 = np.asarray(loser73_results[9:10][0])[0]\r\n",
        "upper_loser73 = np.asarray(loser73_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner73 = np.asarray(winner73_results[4:5][0])[0]\r\n",
        "median_winner73 = np.asarray(winner73_results[9:10][0])[0]\r\n",
        "upper_winner73 = np.asarray(winner73_results[14:15][0])[0]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WmpcEV4w_I9"
      },
      "source": [
        "# Iteration83 :\r\n",
        "\r\n",
        "slice83 = 82\r\n",
        "\r\n",
        "loser83 = [train_regret_loser_1[slice83],\r\n",
        "       train_regret_loser_2[slice83],\r\n",
        "       train_regret_loser_3[slice83],\r\n",
        "       train_regret_loser_4[slice83],\r\n",
        "       train_regret_loser_5[slice83],\r\n",
        "       train_regret_loser_6[slice83],\r\n",
        "       train_regret_loser_7[slice83],\r\n",
        "       train_regret_loser_8[slice83],\r\n",
        "       train_regret_loser_9[slice83],\r\n",
        "       train_regret_loser_10[slice83],\r\n",
        "       train_regret_loser_11[slice83],\r\n",
        "       train_regret_loser_12[slice83],\r\n",
        "       train_regret_loser_13[slice83],\r\n",
        "       train_regret_loser_14[slice83],\r\n",
        "       train_regret_loser_15[slice83],\r\n",
        "       train_regret_loser_16[slice83],\r\n",
        "       train_regret_loser_17[slice83],\r\n",
        "       train_regret_loser_18[slice83],\r\n",
        "       train_regret_loser_19[slice83],\r\n",
        "       train_regret_loser_20[slice83]]\r\n",
        "\r\n",
        "winner83 = [train_regret_winner_1[slice83],\r\n",
        "       train_regret_winner_2[slice83],\r\n",
        "       train_regret_winner_3[slice83],\r\n",
        "       train_regret_winner_4[slice83],\r\n",
        "       train_regret_winner_5[slice83],\r\n",
        "       train_regret_winner_6[slice83],\r\n",
        "       train_regret_winner_7[slice83],\r\n",
        "       train_regret_winner_8[slice83],\r\n",
        "       train_regret_winner_9[slice83],\r\n",
        "       train_regret_winner_10[slice83],\r\n",
        "       train_regret_winner_11[slice83],\r\n",
        "       train_regret_winner_12[slice83],\r\n",
        "       train_regret_winner_13[slice83],\r\n",
        "       train_regret_winner_14[slice83],\r\n",
        "       train_regret_winner_15[slice83],\r\n",
        "       train_regret_winner_16[slice83],\r\n",
        "       train_regret_winner_17[slice83],\r\n",
        "       train_regret_winner_18[slice83],\r\n",
        "       train_regret_winner_19[slice83],\r\n",
        "       train_regret_winner_20[slice83]]\r\n",
        "\r\n",
        "loser83_results = pd.DataFrame(loser83).sort_values(by=[0], ascending=False)\r\n",
        "winner83_results = pd.DataFrame(winner83).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser83 = np.asarray(loser83_results[4:5][0])[0]\r\n",
        "median_loser83 = np.asarray(loser83_results[9:10][0])[0]\r\n",
        "upper_loser83 = np.asarray(loser83_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner83 = np.asarray(winner83_results[4:5][0])[0]\r\n",
        "median_winner83 = np.asarray(winner83_results[9:10][0])[0]\r\n",
        "upper_winner83 = np.asarray(winner83_results[14:15][0])[0]"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPwoBZyw_MF"
      },
      "source": [
        "# Iteration93 :\r\n",
        "\r\n",
        "slice93 = 92\r\n",
        "\r\n",
        "loser93 = [train_regret_loser_1[slice93],\r\n",
        "       train_regret_loser_2[slice93],\r\n",
        "       train_regret_loser_3[slice93],\r\n",
        "       train_regret_loser_4[slice93],\r\n",
        "       train_regret_loser_5[slice93],\r\n",
        "       train_regret_loser_6[slice93],\r\n",
        "       train_regret_loser_7[slice93],\r\n",
        "       train_regret_loser_8[slice93],\r\n",
        "       train_regret_loser_9[slice93],\r\n",
        "       train_regret_loser_10[slice93],\r\n",
        "       train_regret_loser_11[slice93],\r\n",
        "       train_regret_loser_12[slice93],\r\n",
        "       train_regret_loser_13[slice93],\r\n",
        "       train_regret_loser_14[slice93],\r\n",
        "       train_regret_loser_15[slice93],\r\n",
        "       train_regret_loser_16[slice93],\r\n",
        "       train_regret_loser_17[slice93],\r\n",
        "       train_regret_loser_18[slice93],\r\n",
        "       train_regret_loser_19[slice93],\r\n",
        "       train_regret_loser_20[slice93]]\r\n",
        "\r\n",
        "winner93 = [train_regret_winner_1[slice93],\r\n",
        "       train_regret_winner_2[slice93],\r\n",
        "       train_regret_winner_3[slice93],\r\n",
        "       train_regret_winner_4[slice93],\r\n",
        "       train_regret_winner_5[slice93],\r\n",
        "       train_regret_winner_6[slice93],\r\n",
        "       train_regret_winner_7[slice93],\r\n",
        "       train_regret_winner_8[slice93],\r\n",
        "       train_regret_winner_9[slice93],\r\n",
        "       train_regret_winner_10[slice93],\r\n",
        "       train_regret_winner_11[slice93],\r\n",
        "       train_regret_winner_12[slice93],\r\n",
        "       train_regret_winner_13[slice93],\r\n",
        "       train_regret_winner_14[slice93],\r\n",
        "       train_regret_winner_15[slice93],\r\n",
        "       train_regret_winner_16[slice93],\r\n",
        "       train_regret_winner_17[slice93],\r\n",
        "       train_regret_winner_18[slice93],\r\n",
        "       train_regret_winner_19[slice93],\r\n",
        "       train_regret_winner_20[slice93]]\r\n",
        "\r\n",
        "loser93_results = pd.DataFrame(loser93).sort_values(by=[0], ascending=False)\r\n",
        "winner93_results = pd.DataFrame(winner93).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser93 = np.asarray(loser93_results[4:5][0])[0]\r\n",
        "median_loser93 = np.asarray(loser93_results[9:10][0])[0]\r\n",
        "upper_loser93 = np.asarray(loser93_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner93 = np.asarray(winner93_results[4:5][0])[0]\r\n",
        "median_winner93 = np.asarray(winner93_results[9:10][0])[0]\r\n",
        "upper_winner93 = np.asarray(winner93_results[14:15][0])[0]"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_ghdGzPw_Oq"
      },
      "source": [
        "# Iteration4 :\r\n",
        "\r\n",
        "slice4 = 3\r\n",
        "\r\n",
        "loser4 = [train_regret_loser_1[slice4],\r\n",
        "       train_regret_loser_2[slice4],\r\n",
        "       train_regret_loser_3[slice4],\r\n",
        "       train_regret_loser_4[slice4],\r\n",
        "       train_regret_loser_5[slice4],\r\n",
        "       train_regret_loser_6[slice4],\r\n",
        "       train_regret_loser_7[slice4],\r\n",
        "       train_regret_loser_8[slice4],\r\n",
        "       train_regret_loser_9[slice4],\r\n",
        "       train_regret_loser_10[slice4],\r\n",
        "       train_regret_loser_11[slice4],\r\n",
        "       train_regret_loser_12[slice4],\r\n",
        "       train_regret_loser_13[slice4],\r\n",
        "       train_regret_loser_14[slice4],\r\n",
        "       train_regret_loser_15[slice4],\r\n",
        "       train_regret_loser_16[slice4],\r\n",
        "       train_regret_loser_17[slice4],\r\n",
        "       train_regret_loser_18[slice4],\r\n",
        "       train_regret_loser_19[slice4],\r\n",
        "       train_regret_loser_20[slice4]]\r\n",
        "\r\n",
        "winner4 = [train_regret_winner_1[slice4],\r\n",
        "       train_regret_winner_2[slice4],\r\n",
        "       train_regret_winner_3[slice4],\r\n",
        "       train_regret_winner_4[slice4],\r\n",
        "       train_regret_winner_5[slice4],\r\n",
        "       train_regret_winner_6[slice4],\r\n",
        "       train_regret_winner_7[slice4],\r\n",
        "       train_regret_winner_8[slice4],\r\n",
        "       train_regret_winner_9[slice4],\r\n",
        "       train_regret_winner_10[slice4],\r\n",
        "       train_regret_winner_11[slice4],\r\n",
        "       train_regret_winner_12[slice4],\r\n",
        "       train_regret_winner_13[slice4],\r\n",
        "       train_regret_winner_14[slice4],\r\n",
        "       train_regret_winner_15[slice4],\r\n",
        "       train_regret_winner_16[slice4],\r\n",
        "       train_regret_winner_17[slice4],\r\n",
        "       train_regret_winner_18[slice4],\r\n",
        "       train_regret_winner_19[slice4],\r\n",
        "       train_regret_winner_20[slice4]]\r\n",
        "\r\n",
        "loser4_results = pd.DataFrame(loser4).sort_values(by=[0], ascending=False)\r\n",
        "winner4_results = pd.DataFrame(winner4).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser4 = np.asarray(loser4_results[4:5][0])[0]\r\n",
        "median_loser4 = np.asarray(loser4_results[9:10][0])[0]\r\n",
        "upper_loser4 = np.asarray(loser4_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner4 = np.asarray(winner4_results[4:5][0])[0]\r\n",
        "median_winner4 = np.asarray(winner4_results[9:10][0])[0]\r\n",
        "upper_winner4 = np.asarray(winner4_results[14:15][0])[0]"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNvDt4QMw_Rz"
      },
      "source": [
        "# Iteration14 :\r\n",
        "\r\n",
        "slice14 = 13\r\n",
        "\r\n",
        "loser14 = [train_regret_loser_1[slice14],\r\n",
        "       train_regret_loser_2[slice14],\r\n",
        "       train_regret_loser_3[slice14],\r\n",
        "       train_regret_loser_4[slice14],\r\n",
        "       train_regret_loser_5[slice14],\r\n",
        "       train_regret_loser_6[slice14],\r\n",
        "       train_regret_loser_7[slice14],\r\n",
        "       train_regret_loser_8[slice14],\r\n",
        "       train_regret_loser_9[slice14],\r\n",
        "       train_regret_loser_10[slice14],\r\n",
        "       train_regret_loser_11[slice14],\r\n",
        "       train_regret_loser_12[slice14],\r\n",
        "       train_regret_loser_13[slice14],\r\n",
        "       train_regret_loser_14[slice14],\r\n",
        "       train_regret_loser_15[slice14],\r\n",
        "       train_regret_loser_16[slice14],\r\n",
        "       train_regret_loser_17[slice14],\r\n",
        "       train_regret_loser_18[slice14],\r\n",
        "       train_regret_loser_19[slice14],\r\n",
        "       train_regret_loser_20[slice14]]\r\n",
        "\r\n",
        "winner14 = [train_regret_winner_1[slice14],\r\n",
        "       train_regret_winner_2[slice14],\r\n",
        "       train_regret_winner_3[slice14],\r\n",
        "       train_regret_winner_4[slice14],\r\n",
        "       train_regret_winner_5[slice14],\r\n",
        "       train_regret_winner_6[slice14],\r\n",
        "       train_regret_winner_7[slice14],\r\n",
        "       train_regret_winner_8[slice14],\r\n",
        "       train_regret_winner_9[slice14],\r\n",
        "       train_regret_winner_10[slice14],\r\n",
        "       train_regret_winner_11[slice14],\r\n",
        "       train_regret_winner_12[slice14],\r\n",
        "       train_regret_winner_13[slice14],\r\n",
        "       train_regret_winner_14[slice14],\r\n",
        "       train_regret_winner_15[slice14],\r\n",
        "       train_regret_winner_16[slice14],\r\n",
        "       train_regret_winner_17[slice14],\r\n",
        "       train_regret_winner_18[slice14],\r\n",
        "       train_regret_winner_19[slice14],\r\n",
        "       train_regret_winner_20[slice14]]\r\n",
        "\r\n",
        "loser14_results = pd.DataFrame(loser14).sort_values(by=[0], ascending=False)\r\n",
        "winner14_results = pd.DataFrame(winner14).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser14 = np.asarray(loser14_results[4:5][0])[0]\r\n",
        "median_loser14 = np.asarray(loser14_results[9:10][0])[0]\r\n",
        "upper_loser14 = np.asarray(loser14_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner14 = np.asarray(winner14_results[4:5][0])[0]\r\n",
        "median_winner14 = np.asarray(winner14_results[9:10][0])[0]\r\n",
        "upper_winner14 = np.asarray(winner14_results[14:15][0])[0]"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx3kMQV0w_Ua"
      },
      "source": [
        "# Iteration24 :\r\n",
        "\r\n",
        "slice24 = 23\r\n",
        "\r\n",
        "loser24 = [train_regret_loser_1[slice24],\r\n",
        "       train_regret_loser_2[slice24],\r\n",
        "       train_regret_loser_3[slice24],\r\n",
        "       train_regret_loser_4[slice24],\r\n",
        "       train_regret_loser_5[slice24],\r\n",
        "       train_regret_loser_6[slice24],\r\n",
        "       train_regret_loser_7[slice24],\r\n",
        "       train_regret_loser_8[slice24],\r\n",
        "       train_regret_loser_9[slice24],\r\n",
        "       train_regret_loser_10[slice24],\r\n",
        "       train_regret_loser_11[slice24],\r\n",
        "       train_regret_loser_12[slice24],\r\n",
        "       train_regret_loser_13[slice24],\r\n",
        "       train_regret_loser_14[slice24],\r\n",
        "       train_regret_loser_15[slice24],\r\n",
        "       train_regret_loser_16[slice24],\r\n",
        "       train_regret_loser_17[slice24],\r\n",
        "       train_regret_loser_18[slice24],\r\n",
        "       train_regret_loser_19[slice24],\r\n",
        "       train_regret_loser_20[slice24]]\r\n",
        "\r\n",
        "winner24 = [train_regret_winner_1[slice24],\r\n",
        "       train_regret_winner_2[slice24],\r\n",
        "       train_regret_winner_3[slice24],\r\n",
        "       train_regret_winner_4[slice24],\r\n",
        "       train_regret_winner_5[slice24],\r\n",
        "       train_regret_winner_6[slice24],\r\n",
        "       train_regret_winner_7[slice24],\r\n",
        "       train_regret_winner_8[slice24],\r\n",
        "       train_regret_winner_9[slice24],\r\n",
        "       train_regret_winner_10[slice24],\r\n",
        "       train_regret_winner_11[slice24],\r\n",
        "       train_regret_winner_12[slice24],\r\n",
        "       train_regret_winner_13[slice24],\r\n",
        "       train_regret_winner_14[slice24],\r\n",
        "       train_regret_winner_15[slice24],\r\n",
        "       train_regret_winner_16[slice24],\r\n",
        "       train_regret_winner_17[slice24],\r\n",
        "       train_regret_winner_18[slice24],\r\n",
        "       train_regret_winner_19[slice24],\r\n",
        "       train_regret_winner_20[slice24]]\r\n",
        "\r\n",
        "loser24_results = pd.DataFrame(loser24).sort_values(by=[0], ascending=False)\r\n",
        "winner24_results = pd.DataFrame(winner24).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser24 = np.asarray(loser24_results[4:5][0])[0]\r\n",
        "median_loser24 = np.asarray(loser24_results[9:10][0])[0]\r\n",
        "upper_loser24 = np.asarray(loser24_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner24 = np.asarray(winner24_results[4:5][0])[0]\r\n",
        "median_winner24 = np.asarray(winner24_results[9:10][0])[0]\r\n",
        "upper_winner24 = np.asarray(winner24_results[14:15][0])[0]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4ljkyMfw_Xj"
      },
      "source": [
        "# Iteration34 :\r\n",
        "\r\n",
        "slice34 = 33\r\n",
        "\r\n",
        "loser34 = [train_regret_loser_1[slice34],\r\n",
        "       train_regret_loser_2[slice34],\r\n",
        "       train_regret_loser_3[slice34],\r\n",
        "       train_regret_loser_4[slice34],\r\n",
        "       train_regret_loser_5[slice34],\r\n",
        "       train_regret_loser_6[slice34],\r\n",
        "       train_regret_loser_7[slice34],\r\n",
        "       train_regret_loser_8[slice34],\r\n",
        "       train_regret_loser_9[slice34],\r\n",
        "       train_regret_loser_10[slice34],\r\n",
        "       train_regret_loser_11[slice34],\r\n",
        "       train_regret_loser_12[slice34],\r\n",
        "       train_regret_loser_13[slice34],\r\n",
        "       train_regret_loser_14[slice34],\r\n",
        "       train_regret_loser_15[slice34],\r\n",
        "       train_regret_loser_16[slice34],\r\n",
        "       train_regret_loser_17[slice34],\r\n",
        "       train_regret_loser_18[slice34],\r\n",
        "       train_regret_loser_19[slice34],\r\n",
        "       train_regret_loser_20[slice34]]\r\n",
        "\r\n",
        "winner34 = [train_regret_winner_1[slice34],\r\n",
        "       train_regret_winner_2[slice34],\r\n",
        "       train_regret_winner_3[slice34],\r\n",
        "       train_regret_winner_4[slice34],\r\n",
        "       train_regret_winner_5[slice34],\r\n",
        "       train_regret_winner_6[slice34],\r\n",
        "       train_regret_winner_7[slice34],\r\n",
        "       train_regret_winner_8[slice34],\r\n",
        "       train_regret_winner_9[slice34],\r\n",
        "       train_regret_winner_10[slice34],\r\n",
        "       train_regret_winner_11[slice34],\r\n",
        "       train_regret_winner_12[slice34],\r\n",
        "       train_regret_winner_13[slice34],\r\n",
        "       train_regret_winner_14[slice34],\r\n",
        "       train_regret_winner_15[slice34],\r\n",
        "       train_regret_winner_16[slice34],\r\n",
        "       train_regret_winner_17[slice34],\r\n",
        "       train_regret_winner_18[slice34],\r\n",
        "       train_regret_winner_19[slice34],\r\n",
        "       train_regret_winner_20[slice34]]\r\n",
        "\r\n",
        "loser34_results = pd.DataFrame(loser34).sort_values(by=[0], ascending=False)\r\n",
        "winner34_results = pd.DataFrame(winner34).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser34 = np.asarray(loser34_results[4:5][0])[0]\r\n",
        "median_loser34 = np.asarray(loser34_results[9:10][0])[0]\r\n",
        "upper_loser34 = np.asarray(loser34_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner34 = np.asarray(winner34_results[4:5][0])[0]\r\n",
        "median_winner34 = np.asarray(winner34_results[9:10][0])[0]\r\n",
        "upper_winner34 = np.asarray(winner34_results[14:15][0])[0]"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGKj-NR8w_ae"
      },
      "source": [
        "# Iteration44 :\r\n",
        "\r\n",
        "slice44 = 43\r\n",
        "\r\n",
        "loser44 = [train_regret_loser_1[slice44],\r\n",
        "       train_regret_loser_2[slice44],\r\n",
        "       train_regret_loser_3[slice44],\r\n",
        "       train_regret_loser_4[slice44],\r\n",
        "       train_regret_loser_5[slice44],\r\n",
        "       train_regret_loser_6[slice44],\r\n",
        "       train_regret_loser_7[slice44],\r\n",
        "       train_regret_loser_8[slice44],\r\n",
        "       train_regret_loser_9[slice44],\r\n",
        "       train_regret_loser_10[slice44],\r\n",
        "       train_regret_loser_11[slice44],\r\n",
        "       train_regret_loser_12[slice44],\r\n",
        "       train_regret_loser_13[slice44],\r\n",
        "       train_regret_loser_14[slice44],\r\n",
        "       train_regret_loser_15[slice44],\r\n",
        "       train_regret_loser_16[slice44],\r\n",
        "       train_regret_loser_17[slice44],\r\n",
        "       train_regret_loser_18[slice44],\r\n",
        "       train_regret_loser_19[slice44],\r\n",
        "       train_regret_loser_20[slice44]]\r\n",
        "\r\n",
        "winner44 = [train_regret_winner_1[slice44],\r\n",
        "       train_regret_winner_2[slice44],\r\n",
        "       train_regret_winner_3[slice44],\r\n",
        "       train_regret_winner_4[slice44],\r\n",
        "       train_regret_winner_5[slice44],\r\n",
        "       train_regret_winner_6[slice44],\r\n",
        "       train_regret_winner_7[slice44],\r\n",
        "       train_regret_winner_8[slice44],\r\n",
        "       train_regret_winner_9[slice44],\r\n",
        "       train_regret_winner_10[slice44],\r\n",
        "       train_regret_winner_11[slice44],\r\n",
        "       train_regret_winner_12[slice44],\r\n",
        "       train_regret_winner_13[slice44],\r\n",
        "       train_regret_winner_14[slice44],\r\n",
        "       train_regret_winner_15[slice44],\r\n",
        "       train_regret_winner_16[slice44],\r\n",
        "       train_regret_winner_17[slice44],\r\n",
        "       train_regret_winner_18[slice44],\r\n",
        "       train_regret_winner_19[slice44],\r\n",
        "       train_regret_winner_20[slice44]]\r\n",
        "\r\n",
        "loser44_results = pd.DataFrame(loser44).sort_values(by=[0], ascending=False)\r\n",
        "winner44_results = pd.DataFrame(winner44).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser44 = np.asarray(loser44_results[4:5][0])[0]\r\n",
        "median_loser44 = np.asarray(loser44_results[9:10][0])[0]\r\n",
        "upper_loser44 = np.asarray(loser44_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner44 = np.asarray(winner44_results[4:5][0])[0]\r\n",
        "median_winner44 = np.asarray(winner44_results[9:10][0])[0]\r\n",
        "upper_winner44 = np.asarray(winner44_results[14:15][0])[0]"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJzx094Fw_c_"
      },
      "source": [
        "# Iteration54 :\r\n",
        "\r\n",
        "slice54 = 53\r\n",
        "\r\n",
        "loser54 = [train_regret_loser_1[slice54],\r\n",
        "       train_regret_loser_2[slice54],\r\n",
        "       train_regret_loser_3[slice54],\r\n",
        "       train_regret_loser_4[slice54],\r\n",
        "       train_regret_loser_5[slice54],\r\n",
        "       train_regret_loser_6[slice54],\r\n",
        "       train_regret_loser_7[slice54],\r\n",
        "       train_regret_loser_8[slice54],\r\n",
        "       train_regret_loser_9[slice54],\r\n",
        "       train_regret_loser_10[slice54],\r\n",
        "       train_regret_loser_11[slice54],\r\n",
        "       train_regret_loser_12[slice54],\r\n",
        "       train_regret_loser_13[slice54],\r\n",
        "       train_regret_loser_14[slice54],\r\n",
        "       train_regret_loser_15[slice54],\r\n",
        "       train_regret_loser_16[slice54],\r\n",
        "       train_regret_loser_17[slice54],\r\n",
        "       train_regret_loser_18[slice54],\r\n",
        "       train_regret_loser_19[slice54],\r\n",
        "       train_regret_loser_20[slice54]]\r\n",
        "\r\n",
        "winner54 = [train_regret_winner_1[slice54],\r\n",
        "       train_regret_winner_2[slice54],\r\n",
        "       train_regret_winner_3[slice54],\r\n",
        "       train_regret_winner_4[slice54],\r\n",
        "       train_regret_winner_5[slice54],\r\n",
        "       train_regret_winner_6[slice54],\r\n",
        "       train_regret_winner_7[slice54],\r\n",
        "       train_regret_winner_8[slice54],\r\n",
        "       train_regret_winner_9[slice54],\r\n",
        "       train_regret_winner_10[slice54],\r\n",
        "       train_regret_winner_11[slice54],\r\n",
        "       train_regret_winner_12[slice54],\r\n",
        "       train_regret_winner_13[slice54],\r\n",
        "       train_regret_winner_14[slice54],\r\n",
        "       train_regret_winner_15[slice54],\r\n",
        "       train_regret_winner_16[slice54],\r\n",
        "       train_regret_winner_17[slice54],\r\n",
        "       train_regret_winner_18[slice54],\r\n",
        "       train_regret_winner_19[slice54],\r\n",
        "       train_regret_winner_20[slice54]]\r\n",
        "\r\n",
        "loser54_results = pd.DataFrame(loser54).sort_values(by=[0], ascending=False)\r\n",
        "winner54_results = pd.DataFrame(winner54).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser54 = np.asarray(loser54_results[4:5][0])[0]\r\n",
        "median_loser54 = np.asarray(loser54_results[9:10][0])[0]\r\n",
        "upper_loser54 = np.asarray(loser54_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner54 = np.asarray(winner54_results[4:5][0])[0]\r\n",
        "median_winner54 = np.asarray(winner54_results[9:10][0])[0]\r\n",
        "upper_winner54 = np.asarray(winner54_results[14:15][0])[0]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEVYMqj_w_fr"
      },
      "source": [
        "# Iteration64 :\r\n",
        "\r\n",
        "slice64 = 63\r\n",
        "\r\n",
        "loser64 = [train_regret_loser_1[slice64],\r\n",
        "       train_regret_loser_2[slice64],\r\n",
        "       train_regret_loser_3[slice64],\r\n",
        "       train_regret_loser_4[slice64],\r\n",
        "       train_regret_loser_5[slice64],\r\n",
        "       train_regret_loser_6[slice64],\r\n",
        "       train_regret_loser_7[slice64],\r\n",
        "       train_regret_loser_8[slice64],\r\n",
        "       train_regret_loser_9[slice64],\r\n",
        "       train_regret_loser_10[slice64],\r\n",
        "       train_regret_loser_11[slice64],\r\n",
        "       train_regret_loser_12[slice64],\r\n",
        "       train_regret_loser_13[slice64],\r\n",
        "       train_regret_loser_14[slice64],\r\n",
        "       train_regret_loser_15[slice64],\r\n",
        "       train_regret_loser_16[slice64],\r\n",
        "       train_regret_loser_17[slice64],\r\n",
        "       train_regret_loser_18[slice64],\r\n",
        "       train_regret_loser_19[slice64],\r\n",
        "       train_regret_loser_20[slice64]]\r\n",
        "\r\n",
        "winner64 = [train_regret_winner_1[slice64],\r\n",
        "       train_regret_winner_2[slice64],\r\n",
        "       train_regret_winner_3[slice64],\r\n",
        "       train_regret_winner_4[slice64],\r\n",
        "       train_regret_winner_5[slice64],\r\n",
        "       train_regret_winner_6[slice64],\r\n",
        "       train_regret_winner_7[slice64],\r\n",
        "       train_regret_winner_8[slice64],\r\n",
        "       train_regret_winner_9[slice64],\r\n",
        "       train_regret_winner_10[slice64],\r\n",
        "       train_regret_winner_11[slice64],\r\n",
        "       train_regret_winner_12[slice64],\r\n",
        "       train_regret_winner_13[slice64],\r\n",
        "       train_regret_winner_14[slice64],\r\n",
        "       train_regret_winner_15[slice64],\r\n",
        "       train_regret_winner_16[slice64],\r\n",
        "       train_regret_winner_17[slice64],\r\n",
        "       train_regret_winner_18[slice64],\r\n",
        "       train_regret_winner_19[slice64],\r\n",
        "       train_regret_winner_20[slice64]]\r\n",
        "\r\n",
        "loser64_results = pd.DataFrame(loser64).sort_values(by=[0], ascending=False)\r\n",
        "winner64_results = pd.DataFrame(winner64).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser64 = np.asarray(loser64_results[4:5][0])[0]\r\n",
        "median_loser64 = np.asarray(loser64_results[9:10][0])[0]\r\n",
        "upper_loser64 = np.asarray(loser64_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner64 = np.asarray(winner64_results[4:5][0])[0]\r\n",
        "median_winner64 = np.asarray(winner64_results[9:10][0])[0]\r\n",
        "upper_winner64 = np.asarray(winner64_results[14:15][0])[0]"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvr3S_p0w_ii"
      },
      "source": [
        "# Iteration74 :\r\n",
        "\r\n",
        "slice74 = 73\r\n",
        "\r\n",
        "loser74 = [train_regret_loser_1[slice74],\r\n",
        "       train_regret_loser_2[slice74],\r\n",
        "       train_regret_loser_3[slice74],\r\n",
        "       train_regret_loser_4[slice74],\r\n",
        "       train_regret_loser_5[slice74],\r\n",
        "       train_regret_loser_6[slice74],\r\n",
        "       train_regret_loser_7[slice74],\r\n",
        "       train_regret_loser_8[slice74],\r\n",
        "       train_regret_loser_9[slice74],\r\n",
        "       train_regret_loser_10[slice74],\r\n",
        "       train_regret_loser_11[slice74],\r\n",
        "       train_regret_loser_12[slice74],\r\n",
        "       train_regret_loser_13[slice74],\r\n",
        "       train_regret_loser_14[slice74],\r\n",
        "       train_regret_loser_15[slice74],\r\n",
        "       train_regret_loser_16[slice74],\r\n",
        "       train_regret_loser_17[slice74],\r\n",
        "       train_regret_loser_18[slice74],\r\n",
        "       train_regret_loser_19[slice74],\r\n",
        "       train_regret_loser_20[slice74]]\r\n",
        "\r\n",
        "winner74 = [train_regret_winner_1[slice74],\r\n",
        "       train_regret_winner_2[slice74],\r\n",
        "       train_regret_winner_3[slice74],\r\n",
        "       train_regret_winner_4[slice74],\r\n",
        "       train_regret_winner_5[slice74],\r\n",
        "       train_regret_winner_6[slice74],\r\n",
        "       train_regret_winner_7[slice74],\r\n",
        "       train_regret_winner_8[slice74],\r\n",
        "       train_regret_winner_9[slice74],\r\n",
        "       train_regret_winner_10[slice74],\r\n",
        "       train_regret_winner_11[slice74],\r\n",
        "       train_regret_winner_12[slice74],\r\n",
        "       train_regret_winner_13[slice74],\r\n",
        "       train_regret_winner_14[slice74],\r\n",
        "       train_regret_winner_15[slice74],\r\n",
        "       train_regret_winner_16[slice74],\r\n",
        "       train_regret_winner_17[slice74],\r\n",
        "       train_regret_winner_18[slice74],\r\n",
        "       train_regret_winner_19[slice74],\r\n",
        "       train_regret_winner_20[slice74]]\r\n",
        "\r\n",
        "loser74_results = pd.DataFrame(loser74).sort_values(by=[0], ascending=False)\r\n",
        "winner74_results = pd.DataFrame(winner74).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser74 = np.asarray(loser74_results[4:5][0])[0]\r\n",
        "median_loser74 = np.asarray(loser74_results[9:10][0])[0]\r\n",
        "upper_loser74 = np.asarray(loser74_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner74 = np.asarray(winner74_results[4:5][0])[0]\r\n",
        "median_winner74 = np.asarray(winner74_results[9:10][0])[0]\r\n",
        "upper_winner74 = np.asarray(winner74_results[14:15][0])[0]"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEAvUVK7w_lO"
      },
      "source": [
        "# Iteration84 :\r\n",
        "\r\n",
        "slice84 = 83\r\n",
        "\r\n",
        "loser84 = [train_regret_loser_1[slice84],\r\n",
        "       train_regret_loser_2[slice84],\r\n",
        "       train_regret_loser_3[slice84],\r\n",
        "       train_regret_loser_4[slice84],\r\n",
        "       train_regret_loser_5[slice84],\r\n",
        "       train_regret_loser_6[slice84],\r\n",
        "       train_regret_loser_7[slice84],\r\n",
        "       train_regret_loser_8[slice84],\r\n",
        "       train_regret_loser_9[slice84],\r\n",
        "       train_regret_loser_10[slice84],\r\n",
        "       train_regret_loser_11[slice84],\r\n",
        "       train_regret_loser_12[slice84],\r\n",
        "       train_regret_loser_13[slice84],\r\n",
        "       train_regret_loser_14[slice84],\r\n",
        "       train_regret_loser_15[slice84],\r\n",
        "       train_regret_loser_16[slice84],\r\n",
        "       train_regret_loser_17[slice84],\r\n",
        "       train_regret_loser_18[slice84],\r\n",
        "       train_regret_loser_19[slice84],\r\n",
        "       train_regret_loser_20[slice84]]\r\n",
        "\r\n",
        "winner84 = [train_regret_winner_1[slice84],\r\n",
        "       train_regret_winner_2[slice84],\r\n",
        "       train_regret_winner_3[slice84],\r\n",
        "       train_regret_winner_4[slice84],\r\n",
        "       train_regret_winner_5[slice84],\r\n",
        "       train_regret_winner_6[slice84],\r\n",
        "       train_regret_winner_7[slice84],\r\n",
        "       train_regret_winner_8[slice84],\r\n",
        "       train_regret_winner_9[slice84],\r\n",
        "       train_regret_winner_10[slice84],\r\n",
        "       train_regret_winner_11[slice84],\r\n",
        "       train_regret_winner_12[slice84],\r\n",
        "       train_regret_winner_13[slice84],\r\n",
        "       train_regret_winner_14[slice84],\r\n",
        "       train_regret_winner_15[slice84],\r\n",
        "       train_regret_winner_16[slice84],\r\n",
        "       train_regret_winner_17[slice84],\r\n",
        "       train_regret_winner_18[slice84],\r\n",
        "       train_regret_winner_19[slice84],\r\n",
        "       train_regret_winner_20[slice84]]\r\n",
        "\r\n",
        "loser84_results = pd.DataFrame(loser84).sort_values(by=[0], ascending=False)\r\n",
        "winner84_results = pd.DataFrame(winner84).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser84 = np.asarray(loser84_results[4:5][0])[0]\r\n",
        "median_loser84 = np.asarray(loser84_results[9:10][0])[0]\r\n",
        "upper_loser84 = np.asarray(loser84_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner84 = np.asarray(winner84_results[4:5][0])[0]\r\n",
        "median_winner84 = np.asarray(winner84_results[9:10][0])[0]\r\n",
        "upper_winner84 = np.asarray(winner84_results[14:15][0])[0]"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMZzhdGw_oC"
      },
      "source": [
        "# Iteration94 :\r\n",
        "\r\n",
        "slice94 = 93\r\n",
        "\r\n",
        "loser94 = [train_regret_loser_1[slice94],\r\n",
        "       train_regret_loser_2[slice94],\r\n",
        "       train_regret_loser_3[slice94],\r\n",
        "       train_regret_loser_4[slice94],\r\n",
        "       train_regret_loser_5[slice94],\r\n",
        "       train_regret_loser_6[slice94],\r\n",
        "       train_regret_loser_7[slice94],\r\n",
        "       train_regret_loser_8[slice94],\r\n",
        "       train_regret_loser_9[slice94],\r\n",
        "       train_regret_loser_10[slice94],\r\n",
        "       train_regret_loser_11[slice94],\r\n",
        "       train_regret_loser_12[slice94],\r\n",
        "       train_regret_loser_13[slice94],\r\n",
        "       train_regret_loser_14[slice94],\r\n",
        "       train_regret_loser_15[slice94],\r\n",
        "       train_regret_loser_16[slice94],\r\n",
        "       train_regret_loser_17[slice94],\r\n",
        "       train_regret_loser_18[slice94],\r\n",
        "       train_regret_loser_19[slice94],\r\n",
        "       train_regret_loser_20[slice94]]\r\n",
        "\r\n",
        "winner94 = [train_regret_winner_1[slice94],\r\n",
        "       train_regret_winner_2[slice94],\r\n",
        "       train_regret_winner_3[slice94],\r\n",
        "       train_regret_winner_4[slice94],\r\n",
        "       train_regret_winner_5[slice94],\r\n",
        "       train_regret_winner_6[slice94],\r\n",
        "       train_regret_winner_7[slice94],\r\n",
        "       train_regret_winner_8[slice94],\r\n",
        "       train_regret_winner_9[slice94],\r\n",
        "       train_regret_winner_10[slice94],\r\n",
        "       train_regret_winner_11[slice94],\r\n",
        "       train_regret_winner_12[slice94],\r\n",
        "       train_regret_winner_13[slice94],\r\n",
        "       train_regret_winner_14[slice94],\r\n",
        "       train_regret_winner_15[slice94],\r\n",
        "       train_regret_winner_16[slice94],\r\n",
        "       train_regret_winner_17[slice94],\r\n",
        "       train_regret_winner_18[slice94],\r\n",
        "       train_regret_winner_19[slice94],\r\n",
        "       train_regret_winner_20[slice94]]\r\n",
        "\r\n",
        "loser94_results = pd.DataFrame(loser94).sort_values(by=[0], ascending=False)\r\n",
        "winner94_results = pd.DataFrame(winner94).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser94 = np.asarray(loser94_results[4:5][0])[0]\r\n",
        "median_loser94 = np.asarray(loser94_results[9:10][0])[0]\r\n",
        "upper_loser94 = np.asarray(loser94_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner94 = np.asarray(winner94_results[4:5][0])[0]\r\n",
        "median_winner94 = np.asarray(winner94_results[9:10][0])[0]\r\n",
        "upper_winner94 = np.asarray(winner94_results[14:15][0])[0]"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMxHQOgaw_qu"
      },
      "source": [
        "# Iteration5 :\r\n",
        "\r\n",
        "slice5 = 4\r\n",
        "\r\n",
        "loser5 = [train_regret_loser_1[slice5],\r\n",
        "       train_regret_loser_2[slice5],\r\n",
        "       train_regret_loser_3[slice5],\r\n",
        "       train_regret_loser_4[slice5],\r\n",
        "       train_regret_loser_5[slice5],\r\n",
        "       train_regret_loser_6[slice5],\r\n",
        "       train_regret_loser_7[slice5],\r\n",
        "       train_regret_loser_8[slice5],\r\n",
        "       train_regret_loser_9[slice5],\r\n",
        "       train_regret_loser_10[slice5],\r\n",
        "       train_regret_loser_11[slice5],\r\n",
        "       train_regret_loser_12[slice5],\r\n",
        "       train_regret_loser_13[slice5],\r\n",
        "       train_regret_loser_14[slice5],\r\n",
        "       train_regret_loser_15[slice5],\r\n",
        "       train_regret_loser_16[slice5],\r\n",
        "       train_regret_loser_17[slice5],\r\n",
        "       train_regret_loser_18[slice5],\r\n",
        "       train_regret_loser_19[slice5],\r\n",
        "       train_regret_loser_20[slice5]]\r\n",
        "\r\n",
        "winner5 = [train_regret_winner_1[slice5],\r\n",
        "       train_regret_winner_2[slice5],\r\n",
        "       train_regret_winner_3[slice5],\r\n",
        "       train_regret_winner_4[slice5],\r\n",
        "       train_regret_winner_5[slice5],\r\n",
        "       train_regret_winner_6[slice5],\r\n",
        "       train_regret_winner_7[slice5],\r\n",
        "       train_regret_winner_8[slice5],\r\n",
        "       train_regret_winner_9[slice5],\r\n",
        "       train_regret_winner_10[slice5],\r\n",
        "       train_regret_winner_11[slice5],\r\n",
        "       train_regret_winner_12[slice5],\r\n",
        "       train_regret_winner_13[slice5],\r\n",
        "       train_regret_winner_14[slice5],\r\n",
        "       train_regret_winner_15[slice5],\r\n",
        "       train_regret_winner_16[slice5],\r\n",
        "       train_regret_winner_17[slice5],\r\n",
        "       train_regret_winner_18[slice5],\r\n",
        "       train_regret_winner_19[slice5],\r\n",
        "       train_regret_winner_20[slice5]]\r\n",
        "\r\n",
        "loser5_results = pd.DataFrame(loser5).sort_values(by=[0], ascending=False)\r\n",
        "winner5_results = pd.DataFrame(winner5).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser5 = np.asarray(loser5_results[4:5][0])[0]\r\n",
        "median_loser5 = np.asarray(loser5_results[9:10][0])[0]\r\n",
        "upper_loser5 = np.asarray(loser5_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner5 = np.asarray(winner5_results[4:5][0])[0]\r\n",
        "median_winner5 = np.asarray(winner5_results[9:10][0])[0]\r\n",
        "upper_winner5 = np.asarray(winner5_results[14:15][0])[0]"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPVFQTfNw_wF"
      },
      "source": [
        "# Iteration15 :\r\n",
        "\r\n",
        "slice15 = 14\r\n",
        "\r\n",
        "loser15 = [train_regret_loser_1[slice15],\r\n",
        "       train_regret_loser_2[slice15],\r\n",
        "       train_regret_loser_3[slice15],\r\n",
        "       train_regret_loser_4[slice15],\r\n",
        "       train_regret_loser_5[slice15],\r\n",
        "       train_regret_loser_6[slice15],\r\n",
        "       train_regret_loser_7[slice15],\r\n",
        "       train_regret_loser_8[slice15],\r\n",
        "       train_regret_loser_9[slice15],\r\n",
        "       train_regret_loser_10[slice15],\r\n",
        "       train_regret_loser_11[slice15],\r\n",
        "       train_regret_loser_12[slice15],\r\n",
        "       train_regret_loser_13[slice15],\r\n",
        "       train_regret_loser_14[slice15],\r\n",
        "       train_regret_loser_15[slice15],\r\n",
        "       train_regret_loser_16[slice15],\r\n",
        "       train_regret_loser_17[slice15],\r\n",
        "       train_regret_loser_18[slice15],\r\n",
        "       train_regret_loser_19[slice15],\r\n",
        "       train_regret_loser_20[slice15]]\r\n",
        "\r\n",
        "winner15 = [train_regret_winner_1[slice15],\r\n",
        "       train_regret_winner_2[slice15],\r\n",
        "       train_regret_winner_3[slice15],\r\n",
        "       train_regret_winner_4[slice15],\r\n",
        "       train_regret_winner_5[slice15],\r\n",
        "       train_regret_winner_6[slice15],\r\n",
        "       train_regret_winner_7[slice15],\r\n",
        "       train_regret_winner_8[slice15],\r\n",
        "       train_regret_winner_9[slice15],\r\n",
        "       train_regret_winner_10[slice15],\r\n",
        "       train_regret_winner_11[slice15],\r\n",
        "       train_regret_winner_12[slice15],\r\n",
        "       train_regret_winner_13[slice15],\r\n",
        "       train_regret_winner_14[slice15],\r\n",
        "       train_regret_winner_15[slice15],\r\n",
        "       train_regret_winner_16[slice15],\r\n",
        "       train_regret_winner_17[slice15],\r\n",
        "       train_regret_winner_18[slice15],\r\n",
        "       train_regret_winner_19[slice15],\r\n",
        "       train_regret_winner_20[slice15]]\r\n",
        "\r\n",
        "loser15_results = pd.DataFrame(loser15).sort_values(by=[0], ascending=False)\r\n",
        "winner15_results = pd.DataFrame(winner15).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser15 = np.asarray(loser15_results[4:5][0])[0]\r\n",
        "median_loser15 = np.asarray(loser15_results[9:10][0])[0]\r\n",
        "upper_loser15 = np.asarray(loser15_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner15 = np.asarray(winner15_results[4:5][0])[0]\r\n",
        "median_winner15 = np.asarray(winner15_results[9:10][0])[0]\r\n",
        "upper_winner15 = np.asarray(winner15_results[14:15][0])[0]"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADBmBA3ew_zK"
      },
      "source": [
        "# Iteration25 :\r\n",
        "\r\n",
        "slice25 = 24\r\n",
        "\r\n",
        "loser25 = [train_regret_loser_1[slice25],\r\n",
        "       train_regret_loser_2[slice25],\r\n",
        "       train_regret_loser_3[slice25],\r\n",
        "       train_regret_loser_4[slice25],\r\n",
        "       train_regret_loser_5[slice25],\r\n",
        "       train_regret_loser_6[slice25],\r\n",
        "       train_regret_loser_7[slice25],\r\n",
        "       train_regret_loser_8[slice25],\r\n",
        "       train_regret_loser_9[slice25],\r\n",
        "       train_regret_loser_10[slice25],\r\n",
        "       train_regret_loser_11[slice25],\r\n",
        "       train_regret_loser_12[slice25],\r\n",
        "       train_regret_loser_13[slice25],\r\n",
        "       train_regret_loser_14[slice25],\r\n",
        "       train_regret_loser_15[slice25],\r\n",
        "       train_regret_loser_16[slice25],\r\n",
        "       train_regret_loser_17[slice25],\r\n",
        "       train_regret_loser_18[slice25],\r\n",
        "       train_regret_loser_19[slice25],\r\n",
        "       train_regret_loser_20[slice25]]\r\n",
        "\r\n",
        "winner25 = [train_regret_winner_1[slice25],\r\n",
        "       train_regret_winner_2[slice25],\r\n",
        "       train_regret_winner_3[slice25],\r\n",
        "       train_regret_winner_4[slice25],\r\n",
        "       train_regret_winner_5[slice25],\r\n",
        "       train_regret_winner_6[slice25],\r\n",
        "       train_regret_winner_7[slice25],\r\n",
        "       train_regret_winner_8[slice25],\r\n",
        "       train_regret_winner_9[slice25],\r\n",
        "       train_regret_winner_10[slice25],\r\n",
        "       train_regret_winner_11[slice25],\r\n",
        "       train_regret_winner_12[slice25],\r\n",
        "       train_regret_winner_13[slice25],\r\n",
        "       train_regret_winner_14[slice25],\r\n",
        "       train_regret_winner_15[slice25],\r\n",
        "       train_regret_winner_16[slice25],\r\n",
        "       train_regret_winner_17[slice25],\r\n",
        "       train_regret_winner_18[slice25],\r\n",
        "       train_regret_winner_19[slice25],\r\n",
        "       train_regret_winner_20[slice25]]\r\n",
        "\r\n",
        "loser25_results = pd.DataFrame(loser25).sort_values(by=[0], ascending=False)\r\n",
        "winner25_results = pd.DataFrame(winner25).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser25 = np.asarray(loser25_results[4:5][0])[0]\r\n",
        "median_loser25 = np.asarray(loser25_results[9:10][0])[0]\r\n",
        "upper_loser25 = np.asarray(loser25_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner25 = np.asarray(winner25_results[4:5][0])[0]\r\n",
        "median_winner25 = np.asarray(winner25_results[9:10][0])[0]\r\n",
        "upper_winner25 = np.asarray(winner25_results[14:15][0])[0]"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUk9UtSTw_2N"
      },
      "source": [
        "# Iteration35 :\r\n",
        "\r\n",
        "slice35 = 34\r\n",
        "\r\n",
        "loser35 = [train_regret_loser_1[slice35],\r\n",
        "       train_regret_loser_2[slice35],\r\n",
        "       train_regret_loser_3[slice35],\r\n",
        "       train_regret_loser_4[slice35],\r\n",
        "       train_regret_loser_5[slice35],\r\n",
        "       train_regret_loser_6[slice35],\r\n",
        "       train_regret_loser_7[slice35],\r\n",
        "       train_regret_loser_8[slice35],\r\n",
        "       train_regret_loser_9[slice35],\r\n",
        "       train_regret_loser_10[slice35],\r\n",
        "       train_regret_loser_11[slice35],\r\n",
        "       train_regret_loser_12[slice35],\r\n",
        "       train_regret_loser_13[slice35],\r\n",
        "       train_regret_loser_14[slice35],\r\n",
        "       train_regret_loser_15[slice35],\r\n",
        "       train_regret_loser_16[slice35],\r\n",
        "       train_regret_loser_17[slice35],\r\n",
        "       train_regret_loser_18[slice35],\r\n",
        "       train_regret_loser_19[slice35],\r\n",
        "       train_regret_loser_20[slice35]]\r\n",
        "\r\n",
        "winner35 = [train_regret_winner_1[slice35],\r\n",
        "       train_regret_winner_2[slice35],\r\n",
        "       train_regret_winner_3[slice35],\r\n",
        "       train_regret_winner_4[slice35],\r\n",
        "       train_regret_winner_5[slice35],\r\n",
        "       train_regret_winner_6[slice35],\r\n",
        "       train_regret_winner_7[slice35],\r\n",
        "       train_regret_winner_8[slice35],\r\n",
        "       train_regret_winner_9[slice35],\r\n",
        "       train_regret_winner_10[slice35],\r\n",
        "       train_regret_winner_11[slice35],\r\n",
        "       train_regret_winner_12[slice35],\r\n",
        "       train_regret_winner_13[slice35],\r\n",
        "       train_regret_winner_14[slice35],\r\n",
        "       train_regret_winner_15[slice35],\r\n",
        "       train_regret_winner_16[slice35],\r\n",
        "       train_regret_winner_17[slice35],\r\n",
        "       train_regret_winner_18[slice35],\r\n",
        "       train_regret_winner_19[slice35],\r\n",
        "       train_regret_winner_20[slice35]]\r\n",
        "\r\n",
        "loser35_results = pd.DataFrame(loser35).sort_values(by=[0], ascending=False)\r\n",
        "winner35_results = pd.DataFrame(winner35).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser35 = np.asarray(loser35_results[4:5][0])[0]\r\n",
        "median_loser35 = np.asarray(loser35_results[9:10][0])[0]\r\n",
        "upper_loser35 = np.asarray(loser35_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner35 = np.asarray(winner35_results[4:5][0])[0]\r\n",
        "median_winner35 = np.asarray(winner35_results[9:10][0])[0]\r\n",
        "upper_winner35 = np.asarray(winner35_results[14:15][0])[0]"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX3VgqD_w_4z"
      },
      "source": [
        "# Iteration45 :\r\n",
        "\r\n",
        "slice45 = 44\r\n",
        "\r\n",
        "loser45 = [train_regret_loser_1[slice45],\r\n",
        "       train_regret_loser_2[slice45],\r\n",
        "       train_regret_loser_3[slice45],\r\n",
        "       train_regret_loser_4[slice45],\r\n",
        "       train_regret_loser_5[slice45],\r\n",
        "       train_regret_loser_6[slice45],\r\n",
        "       train_regret_loser_7[slice45],\r\n",
        "       train_regret_loser_8[slice45],\r\n",
        "       train_regret_loser_9[slice45],\r\n",
        "       train_regret_loser_10[slice45],\r\n",
        "       train_regret_loser_11[slice45],\r\n",
        "       train_regret_loser_12[slice45],\r\n",
        "       train_regret_loser_13[slice45],\r\n",
        "       train_regret_loser_14[slice45],\r\n",
        "       train_regret_loser_15[slice45],\r\n",
        "       train_regret_loser_16[slice45],\r\n",
        "       train_regret_loser_17[slice45],\r\n",
        "       train_regret_loser_18[slice45],\r\n",
        "       train_regret_loser_19[slice45],\r\n",
        "       train_regret_loser_20[slice45]]\r\n",
        "\r\n",
        "winner45 = [train_regret_winner_1[slice45],\r\n",
        "       train_regret_winner_2[slice45],\r\n",
        "       train_regret_winner_3[slice45],\r\n",
        "       train_regret_winner_4[slice45],\r\n",
        "       train_regret_winner_5[slice45],\r\n",
        "       train_regret_winner_6[slice45],\r\n",
        "       train_regret_winner_7[slice45],\r\n",
        "       train_regret_winner_8[slice45],\r\n",
        "       train_regret_winner_9[slice45],\r\n",
        "       train_regret_winner_10[slice45],\r\n",
        "       train_regret_winner_11[slice45],\r\n",
        "       train_regret_winner_12[slice45],\r\n",
        "       train_regret_winner_13[slice45],\r\n",
        "       train_regret_winner_14[slice45],\r\n",
        "       train_regret_winner_15[slice45],\r\n",
        "       train_regret_winner_16[slice45],\r\n",
        "       train_regret_winner_17[slice45],\r\n",
        "       train_regret_winner_18[slice45],\r\n",
        "       train_regret_winner_19[slice45],\r\n",
        "       train_regret_winner_20[slice45]]\r\n",
        "\r\n",
        "loser45_results = pd.DataFrame(loser45).sort_values(by=[0], ascending=False)\r\n",
        "winner45_results = pd.DataFrame(winner45).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser45 = np.asarray(loser45_results[4:5][0])[0]\r\n",
        "median_loser45 = np.asarray(loser45_results[9:10][0])[0]\r\n",
        "upper_loser45 = np.asarray(loser45_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner45 = np.asarray(winner45_results[4:5][0])[0]\r\n",
        "median_winner45 = np.asarray(winner45_results[9:10][0])[0]\r\n",
        "upper_winner45 = np.asarray(winner45_results[14:15][0])[0]"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o35W-AOzw_8F"
      },
      "source": [
        "# Iteration55 :\r\n",
        "\r\n",
        "slice55 = 54\r\n",
        "\r\n",
        "loser55 = [train_regret_loser_1[slice55],\r\n",
        "       train_regret_loser_2[slice55],\r\n",
        "       train_regret_loser_3[slice55],\r\n",
        "       train_regret_loser_4[slice55],\r\n",
        "       train_regret_loser_5[slice55],\r\n",
        "       train_regret_loser_6[slice55],\r\n",
        "       train_regret_loser_7[slice55],\r\n",
        "       train_regret_loser_8[slice55],\r\n",
        "       train_regret_loser_9[slice55],\r\n",
        "       train_regret_loser_10[slice55],\r\n",
        "       train_regret_loser_11[slice55],\r\n",
        "       train_regret_loser_12[slice55],\r\n",
        "       train_regret_loser_13[slice55],\r\n",
        "       train_regret_loser_14[slice55],\r\n",
        "       train_regret_loser_15[slice55],\r\n",
        "       train_regret_loser_16[slice55],\r\n",
        "       train_regret_loser_17[slice55],\r\n",
        "       train_regret_loser_18[slice55],\r\n",
        "       train_regret_loser_19[slice55],\r\n",
        "       train_regret_loser_20[slice55]]\r\n",
        "\r\n",
        "winner55 = [train_regret_winner_1[slice55],\r\n",
        "       train_regret_winner_2[slice55],\r\n",
        "       train_regret_winner_3[slice55],\r\n",
        "       train_regret_winner_4[slice55],\r\n",
        "       train_regret_winner_5[slice55],\r\n",
        "       train_regret_winner_6[slice55],\r\n",
        "       train_regret_winner_7[slice55],\r\n",
        "       train_regret_winner_8[slice55],\r\n",
        "       train_regret_winner_9[slice55],\r\n",
        "       train_regret_winner_10[slice55],\r\n",
        "       train_regret_winner_11[slice55],\r\n",
        "       train_regret_winner_12[slice55],\r\n",
        "       train_regret_winner_13[slice55],\r\n",
        "       train_regret_winner_14[slice55],\r\n",
        "       train_regret_winner_15[slice55],\r\n",
        "       train_regret_winner_16[slice55],\r\n",
        "       train_regret_winner_17[slice55],\r\n",
        "       train_regret_winner_18[slice55],\r\n",
        "       train_regret_winner_19[slice55],\r\n",
        "       train_regret_winner_20[slice55]]\r\n",
        "\r\n",
        "loser55_results = pd.DataFrame(loser55).sort_values(by=[0], ascending=False)\r\n",
        "winner55_results = pd.DataFrame(winner55).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser55 = np.asarray(loser55_results[4:5][0])[0]\r\n",
        "median_loser55 = np.asarray(loser55_results[9:10][0])[0]\r\n",
        "upper_loser55 = np.asarray(loser55_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner55 = np.asarray(winner55_results[4:5][0])[0]\r\n",
        "median_winner55 = np.asarray(winner55_results[9:10][0])[0]\r\n",
        "upper_winner55 = np.asarray(winner55_results[14:15][0])[0]"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUAjKXWdw__J"
      },
      "source": [
        "# Iteration65 :\r\n",
        "\r\n",
        "slice65 = 64\r\n",
        "\r\n",
        "loser65 = [train_regret_loser_1[slice65],\r\n",
        "       train_regret_loser_2[slice65],\r\n",
        "       train_regret_loser_3[slice65],\r\n",
        "       train_regret_loser_4[slice65],\r\n",
        "       train_regret_loser_5[slice65],\r\n",
        "       train_regret_loser_6[slice65],\r\n",
        "       train_regret_loser_7[slice65],\r\n",
        "       train_regret_loser_8[slice65],\r\n",
        "       train_regret_loser_9[slice65],\r\n",
        "       train_regret_loser_10[slice65],\r\n",
        "       train_regret_loser_11[slice65],\r\n",
        "       train_regret_loser_12[slice65],\r\n",
        "       train_regret_loser_13[slice65],\r\n",
        "       train_regret_loser_14[slice65],\r\n",
        "       train_regret_loser_15[slice65],\r\n",
        "       train_regret_loser_16[slice65],\r\n",
        "       train_regret_loser_17[slice65],\r\n",
        "       train_regret_loser_18[slice65],\r\n",
        "       train_regret_loser_19[slice65],\r\n",
        "       train_regret_loser_20[slice65]]\r\n",
        "\r\n",
        "winner65 = [train_regret_winner_1[slice65],\r\n",
        "       train_regret_winner_2[slice65],\r\n",
        "       train_regret_winner_3[slice65],\r\n",
        "       train_regret_winner_4[slice65],\r\n",
        "       train_regret_winner_5[slice65],\r\n",
        "       train_regret_winner_6[slice65],\r\n",
        "       train_regret_winner_7[slice65],\r\n",
        "       train_regret_winner_8[slice65],\r\n",
        "       train_regret_winner_9[slice65],\r\n",
        "       train_regret_winner_10[slice65],\r\n",
        "       train_regret_winner_11[slice65],\r\n",
        "       train_regret_winner_12[slice65],\r\n",
        "       train_regret_winner_13[slice65],\r\n",
        "       train_regret_winner_14[slice65],\r\n",
        "       train_regret_winner_15[slice65],\r\n",
        "       train_regret_winner_16[slice65],\r\n",
        "       train_regret_winner_17[slice65],\r\n",
        "       train_regret_winner_18[slice65],\r\n",
        "       train_regret_winner_19[slice65],\r\n",
        "       train_regret_winner_20[slice65]]\r\n",
        "\r\n",
        "loser65_results = pd.DataFrame(loser65).sort_values(by=[0], ascending=False)\r\n",
        "winner65_results = pd.DataFrame(winner65).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser65 = np.asarray(loser65_results[4:5][0])[0]\r\n",
        "median_loser65 = np.asarray(loser65_results[9:10][0])[0]\r\n",
        "upper_loser65 = np.asarray(loser65_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner65 = np.asarray(winner65_results[4:5][0])[0]\r\n",
        "median_winner65 = np.asarray(winner65_results[9:10][0])[0]\r\n",
        "upper_winner65 = np.asarray(winner65_results[14:15][0])[0]"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D00FcmZwxAB9"
      },
      "source": [
        "# Iteration75 :\r\n",
        "\r\n",
        "slice75 = 74\r\n",
        "\r\n",
        "loser75 = [train_regret_loser_1[slice75],\r\n",
        "       train_regret_loser_2[slice75],\r\n",
        "       train_regret_loser_3[slice75],\r\n",
        "       train_regret_loser_4[slice75],\r\n",
        "       train_regret_loser_5[slice75],\r\n",
        "       train_regret_loser_6[slice75],\r\n",
        "       train_regret_loser_7[slice75],\r\n",
        "       train_regret_loser_8[slice75],\r\n",
        "       train_regret_loser_9[slice75],\r\n",
        "       train_regret_loser_10[slice75],\r\n",
        "       train_regret_loser_11[slice75],\r\n",
        "       train_regret_loser_12[slice75],\r\n",
        "       train_regret_loser_13[slice75],\r\n",
        "       train_regret_loser_14[slice75],\r\n",
        "       train_regret_loser_15[slice75],\r\n",
        "       train_regret_loser_16[slice75],\r\n",
        "       train_regret_loser_17[slice75],\r\n",
        "       train_regret_loser_18[slice75],\r\n",
        "       train_regret_loser_19[slice75],\r\n",
        "       train_regret_loser_20[slice75]]\r\n",
        "\r\n",
        "winner75 = [train_regret_winner_1[slice75],\r\n",
        "       train_regret_winner_2[slice75],\r\n",
        "       train_regret_winner_3[slice75],\r\n",
        "       train_regret_winner_4[slice75],\r\n",
        "       train_regret_winner_5[slice75],\r\n",
        "       train_regret_winner_6[slice75],\r\n",
        "       train_regret_winner_7[slice75],\r\n",
        "       train_regret_winner_8[slice75],\r\n",
        "       train_regret_winner_9[slice75],\r\n",
        "       train_regret_winner_10[slice75],\r\n",
        "       train_regret_winner_11[slice75],\r\n",
        "       train_regret_winner_12[slice75],\r\n",
        "       train_regret_winner_13[slice75],\r\n",
        "       train_regret_winner_14[slice75],\r\n",
        "       train_regret_winner_15[slice75],\r\n",
        "       train_regret_winner_16[slice75],\r\n",
        "       train_regret_winner_17[slice75],\r\n",
        "       train_regret_winner_18[slice75],\r\n",
        "       train_regret_winner_19[slice75],\r\n",
        "       train_regret_winner_20[slice75]]\r\n",
        "\r\n",
        "loser75_results = pd.DataFrame(loser75).sort_values(by=[0], ascending=False)\r\n",
        "winner75_results = pd.DataFrame(winner75).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser75 = np.asarray(loser75_results[4:5][0])[0]\r\n",
        "median_loser75 = np.asarray(loser75_results[9:10][0])[0]\r\n",
        "upper_loser75 = np.asarray(loser75_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner75 = np.asarray(winner75_results[4:5][0])[0]\r\n",
        "median_winner75 = np.asarray(winner75_results[9:10][0])[0]\r\n",
        "upper_winner75 = np.asarray(winner75_results[14:15][0])[0]"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvnzmprxxAFB"
      },
      "source": [
        "# Iteration85 :\r\n",
        "\r\n",
        "slice85 = 84\r\n",
        "\r\n",
        "loser85 = [train_regret_loser_1[slice85],\r\n",
        "       train_regret_loser_2[slice85],\r\n",
        "       train_regret_loser_3[slice85],\r\n",
        "       train_regret_loser_4[slice85],\r\n",
        "       train_regret_loser_5[slice85],\r\n",
        "       train_regret_loser_6[slice85],\r\n",
        "       train_regret_loser_7[slice85],\r\n",
        "       train_regret_loser_8[slice85],\r\n",
        "       train_regret_loser_9[slice85],\r\n",
        "       train_regret_loser_10[slice85],\r\n",
        "       train_regret_loser_11[slice85],\r\n",
        "       train_regret_loser_12[slice85],\r\n",
        "       train_regret_loser_13[slice85],\r\n",
        "       train_regret_loser_14[slice85],\r\n",
        "       train_regret_loser_15[slice85],\r\n",
        "       train_regret_loser_16[slice85],\r\n",
        "       train_regret_loser_17[slice85],\r\n",
        "       train_regret_loser_18[slice85],\r\n",
        "       train_regret_loser_19[slice85],\r\n",
        "       train_regret_loser_20[slice85]]\r\n",
        "\r\n",
        "winner85 = [train_regret_winner_1[slice85],\r\n",
        "       train_regret_winner_2[slice85],\r\n",
        "       train_regret_winner_3[slice85],\r\n",
        "       train_regret_winner_4[slice85],\r\n",
        "       train_regret_winner_5[slice85],\r\n",
        "       train_regret_winner_6[slice85],\r\n",
        "       train_regret_winner_7[slice85],\r\n",
        "       train_regret_winner_8[slice85],\r\n",
        "       train_regret_winner_9[slice85],\r\n",
        "       train_regret_winner_10[slice85],\r\n",
        "       train_regret_winner_11[slice85],\r\n",
        "       train_regret_winner_12[slice85],\r\n",
        "       train_regret_winner_13[slice85],\r\n",
        "       train_regret_winner_14[slice85],\r\n",
        "       train_regret_winner_15[slice85],\r\n",
        "       train_regret_winner_16[slice85],\r\n",
        "       train_regret_winner_17[slice85],\r\n",
        "       train_regret_winner_18[slice85],\r\n",
        "       train_regret_winner_19[slice85],\r\n",
        "       train_regret_winner_20[slice85]]\r\n",
        "\r\n",
        "loser85_results = pd.DataFrame(loser85).sort_values(by=[0], ascending=False)\r\n",
        "winner85_results = pd.DataFrame(winner85).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser85 = np.asarray(loser85_results[4:5][0])[0]\r\n",
        "median_loser85 = np.asarray(loser85_results[9:10][0])[0]\r\n",
        "upper_loser85 = np.asarray(loser85_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner85 = np.asarray(winner85_results[4:5][0])[0]\r\n",
        "median_winner85 = np.asarray(winner85_results[9:10][0])[0]\r\n",
        "upper_winner85 = np.asarray(winner85_results[14:15][0])[0]"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztvJhrN6xAH1"
      },
      "source": [
        "# Iteration95 :\r\n",
        "\r\n",
        "slice95 = 94\r\n",
        "\r\n",
        "loser95 = [train_regret_loser_1[slice95],\r\n",
        "       train_regret_loser_2[slice95],\r\n",
        "       train_regret_loser_3[slice95],\r\n",
        "       train_regret_loser_4[slice95],\r\n",
        "       train_regret_loser_5[slice95],\r\n",
        "       train_regret_loser_6[slice95],\r\n",
        "       train_regret_loser_7[slice95],\r\n",
        "       train_regret_loser_8[slice95],\r\n",
        "       train_regret_loser_9[slice95],\r\n",
        "       train_regret_loser_10[slice95],\r\n",
        "       train_regret_loser_11[slice95],\r\n",
        "       train_regret_loser_12[slice95],\r\n",
        "       train_regret_loser_13[slice95],\r\n",
        "       train_regret_loser_14[slice95],\r\n",
        "       train_regret_loser_15[slice95],\r\n",
        "       train_regret_loser_16[slice95],\r\n",
        "       train_regret_loser_17[slice95],\r\n",
        "       train_regret_loser_18[slice95],\r\n",
        "       train_regret_loser_19[slice95],\r\n",
        "       train_regret_loser_20[slice95]]\r\n",
        "\r\n",
        "winner95 = [train_regret_winner_1[slice95],\r\n",
        "       train_regret_winner_2[slice95],\r\n",
        "       train_regret_winner_3[slice95],\r\n",
        "       train_regret_winner_4[slice95],\r\n",
        "       train_regret_winner_5[slice95],\r\n",
        "       train_regret_winner_6[slice95],\r\n",
        "       train_regret_winner_7[slice95],\r\n",
        "       train_regret_winner_8[slice95],\r\n",
        "       train_regret_winner_9[slice95],\r\n",
        "       train_regret_winner_10[slice95],\r\n",
        "       train_regret_winner_11[slice95],\r\n",
        "       train_regret_winner_12[slice95],\r\n",
        "       train_regret_winner_13[slice95],\r\n",
        "       train_regret_winner_14[slice95],\r\n",
        "       train_regret_winner_15[slice95],\r\n",
        "       train_regret_winner_16[slice95],\r\n",
        "       train_regret_winner_17[slice95],\r\n",
        "       train_regret_winner_18[slice95],\r\n",
        "       train_regret_winner_19[slice95],\r\n",
        "       train_regret_winner_20[slice95]]\r\n",
        "\r\n",
        "loser95_results = pd.DataFrame(loser95).sort_values(by=[0], ascending=False)\r\n",
        "winner95_results = pd.DataFrame(winner95).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser95 = np.asarray(loser95_results[4:5][0])[0]\r\n",
        "median_loser95 = np.asarray(loser95_results[9:10][0])[0]\r\n",
        "upper_loser95 = np.asarray(loser95_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner95 = np.asarray(winner95_results[4:5][0])[0]\r\n",
        "median_winner95 = np.asarray(winner95_results[9:10][0])[0]\r\n",
        "upper_winner95 = np.asarray(winner95_results[14:15][0])[0]"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK-4nr-OxALA"
      },
      "source": [
        "# Iteration6 :\r\n",
        "\r\n",
        "slice6 = 5\r\n",
        "\r\n",
        "loser6 = [train_regret_loser_1[slice6],\r\n",
        "       train_regret_loser_2[slice6],\r\n",
        "       train_regret_loser_3[slice6],\r\n",
        "       train_regret_loser_4[slice6],\r\n",
        "       train_regret_loser_5[slice6],\r\n",
        "       train_regret_loser_6[slice6],\r\n",
        "       train_regret_loser_7[slice6],\r\n",
        "       train_regret_loser_8[slice6],\r\n",
        "       train_regret_loser_9[slice6],\r\n",
        "       train_regret_loser_10[slice6],\r\n",
        "       train_regret_loser_11[slice6],\r\n",
        "       train_regret_loser_12[slice6],\r\n",
        "       train_regret_loser_13[slice6],\r\n",
        "       train_regret_loser_14[slice6],\r\n",
        "       train_regret_loser_15[slice6],\r\n",
        "       train_regret_loser_16[slice6],\r\n",
        "       train_regret_loser_17[slice6],\r\n",
        "       train_regret_loser_18[slice6],\r\n",
        "       train_regret_loser_19[slice6],\r\n",
        "       train_regret_loser_20[slice6]]\r\n",
        "\r\n",
        "winner6 = [train_regret_winner_1[slice6],\r\n",
        "       train_regret_winner_2[slice6],\r\n",
        "       train_regret_winner_3[slice6],\r\n",
        "       train_regret_winner_4[slice6],\r\n",
        "       train_regret_winner_5[slice6],\r\n",
        "       train_regret_winner_6[slice6],\r\n",
        "       train_regret_winner_7[slice6],\r\n",
        "       train_regret_winner_8[slice6],\r\n",
        "       train_regret_winner_9[slice6],\r\n",
        "       train_regret_winner_10[slice6],\r\n",
        "       train_regret_winner_11[slice6],\r\n",
        "       train_regret_winner_12[slice6],\r\n",
        "       train_regret_winner_13[slice6],\r\n",
        "       train_regret_winner_14[slice6],\r\n",
        "       train_regret_winner_15[slice6],\r\n",
        "       train_regret_winner_16[slice6],\r\n",
        "       train_regret_winner_17[slice6],\r\n",
        "       train_regret_winner_18[slice6],\r\n",
        "       train_regret_winner_19[slice6],\r\n",
        "       train_regret_winner_20[slice6]]\r\n",
        "\r\n",
        "loser6_results = pd.DataFrame(loser6).sort_values(by=[0], ascending=False)\r\n",
        "winner6_results = pd.DataFrame(winner6).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser6 = np.asarray(loser6_results[4:5][0])[0]\r\n",
        "median_loser6 = np.asarray(loser6_results[9:10][0])[0]\r\n",
        "upper_loser6 = np.asarray(loser6_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner6 = np.asarray(winner6_results[4:5][0])[0]\r\n",
        "median_winner6 = np.asarray(winner6_results[9:10][0])[0]\r\n",
        "upper_winner6 = np.asarray(winner6_results[14:15][0])[0]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSwfNX5ExANt"
      },
      "source": [
        "# Iteration16 :\r\n",
        "\r\n",
        "slice16 = 15\r\n",
        "\r\n",
        "loser16 = [train_regret_loser_1[slice16],\r\n",
        "       train_regret_loser_2[slice16],\r\n",
        "       train_regret_loser_3[slice16],\r\n",
        "       train_regret_loser_4[slice16],\r\n",
        "       train_regret_loser_5[slice16],\r\n",
        "       train_regret_loser_6[slice16],\r\n",
        "       train_regret_loser_7[slice16],\r\n",
        "       train_regret_loser_8[slice16],\r\n",
        "       train_regret_loser_9[slice16],\r\n",
        "       train_regret_loser_10[slice16],\r\n",
        "       train_regret_loser_11[slice16],\r\n",
        "       train_regret_loser_12[slice16],\r\n",
        "       train_regret_loser_13[slice16],\r\n",
        "       train_regret_loser_14[slice16],\r\n",
        "       train_regret_loser_15[slice16],\r\n",
        "       train_regret_loser_16[slice16],\r\n",
        "       train_regret_loser_17[slice16],\r\n",
        "       train_regret_loser_18[slice16],\r\n",
        "       train_regret_loser_19[slice16],\r\n",
        "       train_regret_loser_20[slice16]]\r\n",
        "\r\n",
        "winner16 = [train_regret_winner_1[slice16],\r\n",
        "       train_regret_winner_2[slice16],\r\n",
        "       train_regret_winner_3[slice16],\r\n",
        "       train_regret_winner_4[slice16],\r\n",
        "       train_regret_winner_5[slice16],\r\n",
        "       train_regret_winner_6[slice16],\r\n",
        "       train_regret_winner_7[slice16],\r\n",
        "       train_regret_winner_8[slice16],\r\n",
        "       train_regret_winner_9[slice16],\r\n",
        "       train_regret_winner_10[slice16],\r\n",
        "       train_regret_winner_11[slice16],\r\n",
        "       train_regret_winner_12[slice16],\r\n",
        "       train_regret_winner_13[slice16],\r\n",
        "       train_regret_winner_14[slice16],\r\n",
        "       train_regret_winner_15[slice16],\r\n",
        "       train_regret_winner_16[slice16],\r\n",
        "       train_regret_winner_17[slice16],\r\n",
        "       train_regret_winner_18[slice16],\r\n",
        "       train_regret_winner_19[slice16],\r\n",
        "       train_regret_winner_20[slice16]]\r\n",
        "\r\n",
        "loser16_results = pd.DataFrame(loser16).sort_values(by=[0], ascending=False)\r\n",
        "winner16_results = pd.DataFrame(winner16).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser16 = np.asarray(loser16_results[4:5][0])[0]\r\n",
        "median_loser16 = np.asarray(loser16_results[9:10][0])[0]\r\n",
        "upper_loser16 = np.asarray(loser16_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner16 = np.asarray(winner16_results[4:5][0])[0]\r\n",
        "median_winner16 = np.asarray(winner16_results[9:10][0])[0]\r\n",
        "upper_winner16 = np.asarray(winner16_results[14:15][0])[0]"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOB3hOLIxAQy"
      },
      "source": [
        "# Iteration26 :\r\n",
        "\r\n",
        "slice26 = 25\r\n",
        "\r\n",
        "loser26 = [train_regret_loser_1[slice26],\r\n",
        "       train_regret_loser_2[slice26],\r\n",
        "       train_regret_loser_3[slice26],\r\n",
        "       train_regret_loser_4[slice26],\r\n",
        "       train_regret_loser_5[slice26],\r\n",
        "       train_regret_loser_6[slice26],\r\n",
        "       train_regret_loser_7[slice26],\r\n",
        "       train_regret_loser_8[slice26],\r\n",
        "       train_regret_loser_9[slice26],\r\n",
        "       train_regret_loser_10[slice26],\r\n",
        "       train_regret_loser_11[slice26],\r\n",
        "       train_regret_loser_12[slice26],\r\n",
        "       train_regret_loser_13[slice26],\r\n",
        "       train_regret_loser_14[slice26],\r\n",
        "       train_regret_loser_15[slice26],\r\n",
        "       train_regret_loser_16[slice26],\r\n",
        "       train_regret_loser_17[slice26],\r\n",
        "       train_regret_loser_18[slice26],\r\n",
        "       train_regret_loser_19[slice26],\r\n",
        "       train_regret_loser_20[slice26]]\r\n",
        "\r\n",
        "winner26 = [train_regret_winner_1[slice26],\r\n",
        "       train_regret_winner_2[slice26],\r\n",
        "       train_regret_winner_3[slice26],\r\n",
        "       train_regret_winner_4[slice26],\r\n",
        "       train_regret_winner_5[slice26],\r\n",
        "       train_regret_winner_6[slice26],\r\n",
        "       train_regret_winner_7[slice26],\r\n",
        "       train_regret_winner_8[slice26],\r\n",
        "       train_regret_winner_9[slice26],\r\n",
        "       train_regret_winner_10[slice26],\r\n",
        "       train_regret_winner_11[slice26],\r\n",
        "       train_regret_winner_12[slice26],\r\n",
        "       train_regret_winner_13[slice26],\r\n",
        "       train_regret_winner_14[slice26],\r\n",
        "       train_regret_winner_15[slice26],\r\n",
        "       train_regret_winner_16[slice26],\r\n",
        "       train_regret_winner_17[slice26],\r\n",
        "       train_regret_winner_18[slice26],\r\n",
        "       train_regret_winner_19[slice26],\r\n",
        "       train_regret_winner_20[slice26]]\r\n",
        "\r\n",
        "loser26_results = pd.DataFrame(loser26).sort_values(by=[0], ascending=False)\r\n",
        "winner26_results = pd.DataFrame(winner26).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser26 = np.asarray(loser26_results[4:5][0])[0]\r\n",
        "median_loser26 = np.asarray(loser26_results[9:10][0])[0]\r\n",
        "upper_loser26 = np.asarray(loser26_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner26 = np.asarray(winner26_results[4:5][0])[0]\r\n",
        "median_winner26 = np.asarray(winner26_results[9:10][0])[0]\r\n",
        "upper_winner26 = np.asarray(winner26_results[14:15][0])[0]"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-0hQMtOxATh"
      },
      "source": [
        "# Iteration36 :\r\n",
        "\r\n",
        "slice36 = 35\r\n",
        "\r\n",
        "loser36 = [train_regret_loser_1[slice36],\r\n",
        "       train_regret_loser_2[slice36],\r\n",
        "       train_regret_loser_3[slice36],\r\n",
        "       train_regret_loser_4[slice36],\r\n",
        "       train_regret_loser_5[slice36],\r\n",
        "       train_regret_loser_6[slice36],\r\n",
        "       train_regret_loser_7[slice36],\r\n",
        "       train_regret_loser_8[slice36],\r\n",
        "       train_regret_loser_9[slice36],\r\n",
        "       train_regret_loser_10[slice36],\r\n",
        "       train_regret_loser_11[slice36],\r\n",
        "       train_regret_loser_12[slice36],\r\n",
        "       train_regret_loser_13[slice36],\r\n",
        "       train_regret_loser_14[slice36],\r\n",
        "       train_regret_loser_15[slice36],\r\n",
        "       train_regret_loser_16[slice36],\r\n",
        "       train_regret_loser_17[slice36],\r\n",
        "       train_regret_loser_18[slice36],\r\n",
        "       train_regret_loser_19[slice36],\r\n",
        "       train_regret_loser_20[slice36]]\r\n",
        "\r\n",
        "winner36 = [train_regret_winner_1[slice36],\r\n",
        "       train_regret_winner_2[slice36],\r\n",
        "       train_regret_winner_3[slice36],\r\n",
        "       train_regret_winner_4[slice36],\r\n",
        "       train_regret_winner_5[slice36],\r\n",
        "       train_regret_winner_6[slice36],\r\n",
        "       train_regret_winner_7[slice36],\r\n",
        "       train_regret_winner_8[slice36],\r\n",
        "       train_regret_winner_9[slice36],\r\n",
        "       train_regret_winner_10[slice36],\r\n",
        "       train_regret_winner_11[slice36],\r\n",
        "       train_regret_winner_12[slice36],\r\n",
        "       train_regret_winner_13[slice36],\r\n",
        "       train_regret_winner_14[slice36],\r\n",
        "       train_regret_winner_15[slice36],\r\n",
        "       train_regret_winner_16[slice36],\r\n",
        "       train_regret_winner_17[slice36],\r\n",
        "       train_regret_winner_18[slice36],\r\n",
        "       train_regret_winner_19[slice36],\r\n",
        "       train_regret_winner_20[slice36]]\r\n",
        "\r\n",
        "loser36_results = pd.DataFrame(loser36).sort_values(by=[0], ascending=False)\r\n",
        "winner36_results = pd.DataFrame(winner36).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser36 = np.asarray(loser36_results[4:5][0])[0]\r\n",
        "median_loser36 = np.asarray(loser36_results[9:10][0])[0]\r\n",
        "upper_loser36 = np.asarray(loser36_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner36 = np.asarray(winner36_results[4:5][0])[0]\r\n",
        "median_winner36 = np.asarray(winner36_results[9:10][0])[0]\r\n",
        "upper_winner36 = np.asarray(winner36_results[14:15][0])[0]"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSqBLqTgxAWs"
      },
      "source": [
        "# Iteration46 :\r\n",
        "\r\n",
        "slice46 = 45\r\n",
        "\r\n",
        "loser46 = [train_regret_loser_1[slice46],\r\n",
        "       train_regret_loser_2[slice46],\r\n",
        "       train_regret_loser_3[slice46],\r\n",
        "       train_regret_loser_4[slice46],\r\n",
        "       train_regret_loser_5[slice46],\r\n",
        "       train_regret_loser_6[slice46],\r\n",
        "       train_regret_loser_7[slice46],\r\n",
        "       train_regret_loser_8[slice46],\r\n",
        "       train_regret_loser_9[slice46],\r\n",
        "       train_regret_loser_10[slice46],\r\n",
        "       train_regret_loser_11[slice46],\r\n",
        "       train_regret_loser_12[slice46],\r\n",
        "       train_regret_loser_13[slice46],\r\n",
        "       train_regret_loser_14[slice46],\r\n",
        "       train_regret_loser_15[slice46],\r\n",
        "       train_regret_loser_16[slice46],\r\n",
        "       train_regret_loser_17[slice46],\r\n",
        "       train_regret_loser_18[slice46],\r\n",
        "       train_regret_loser_19[slice46],\r\n",
        "       train_regret_loser_20[slice46]]\r\n",
        "\r\n",
        "winner46 = [train_regret_winner_1[slice46],\r\n",
        "       train_regret_winner_2[slice46],\r\n",
        "       train_regret_winner_3[slice46],\r\n",
        "       train_regret_winner_4[slice46],\r\n",
        "       train_regret_winner_5[slice46],\r\n",
        "       train_regret_winner_6[slice46],\r\n",
        "       train_regret_winner_7[slice46],\r\n",
        "       train_regret_winner_8[slice46],\r\n",
        "       train_regret_winner_9[slice46],\r\n",
        "       train_regret_winner_10[slice46],\r\n",
        "       train_regret_winner_11[slice46],\r\n",
        "       train_regret_winner_12[slice46],\r\n",
        "       train_regret_winner_13[slice46],\r\n",
        "       train_regret_winner_14[slice46],\r\n",
        "       train_regret_winner_15[slice46],\r\n",
        "       train_regret_winner_16[slice46],\r\n",
        "       train_regret_winner_17[slice46],\r\n",
        "       train_regret_winner_18[slice46],\r\n",
        "       train_regret_winner_19[slice46],\r\n",
        "       train_regret_winner_20[slice46]]\r\n",
        "\r\n",
        "loser46_results = pd.DataFrame(loser46).sort_values(by=[0], ascending=False)\r\n",
        "winner46_results = pd.DataFrame(winner46).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser46 = np.asarray(loser46_results[4:5][0])[0]\r\n",
        "median_loser46 = np.asarray(loser46_results[9:10][0])[0]\r\n",
        "upper_loser46 = np.asarray(loser46_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner46 = np.asarray(winner46_results[4:5][0])[0]\r\n",
        "median_winner46 = np.asarray(winner46_results[9:10][0])[0]\r\n",
        "upper_winner46 = np.asarray(winner46_results[14:15][0])[0]"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFwO80w6xAZZ"
      },
      "source": [
        "# Iteration56 :\r\n",
        "\r\n",
        "slice56 = 55\r\n",
        "\r\n",
        "loser56 = [train_regret_loser_1[slice56],\r\n",
        "       train_regret_loser_2[slice56],\r\n",
        "       train_regret_loser_3[slice56],\r\n",
        "       train_regret_loser_4[slice56],\r\n",
        "       train_regret_loser_5[slice56],\r\n",
        "       train_regret_loser_6[slice56],\r\n",
        "       train_regret_loser_7[slice56],\r\n",
        "       train_regret_loser_8[slice56],\r\n",
        "       train_regret_loser_9[slice56],\r\n",
        "       train_regret_loser_10[slice56],\r\n",
        "       train_regret_loser_11[slice56],\r\n",
        "       train_regret_loser_12[slice56],\r\n",
        "       train_regret_loser_13[slice56],\r\n",
        "       train_regret_loser_14[slice56],\r\n",
        "       train_regret_loser_15[slice56],\r\n",
        "       train_regret_loser_16[slice56],\r\n",
        "       train_regret_loser_17[slice56],\r\n",
        "       train_regret_loser_18[slice56],\r\n",
        "       train_regret_loser_19[slice56],\r\n",
        "       train_regret_loser_20[slice56]]\r\n",
        "\r\n",
        "winner56 = [train_regret_winner_1[slice56],\r\n",
        "       train_regret_winner_2[slice56],\r\n",
        "       train_regret_winner_3[slice56],\r\n",
        "       train_regret_winner_4[slice56],\r\n",
        "       train_regret_winner_5[slice56],\r\n",
        "       train_regret_winner_6[slice56],\r\n",
        "       train_regret_winner_7[slice56],\r\n",
        "       train_regret_winner_8[slice56],\r\n",
        "       train_regret_winner_9[slice56],\r\n",
        "       train_regret_winner_10[slice56],\r\n",
        "       train_regret_winner_11[slice56],\r\n",
        "       train_regret_winner_12[slice56],\r\n",
        "       train_regret_winner_13[slice56],\r\n",
        "       train_regret_winner_14[slice56],\r\n",
        "       train_regret_winner_15[slice56],\r\n",
        "       train_regret_winner_16[slice56],\r\n",
        "       train_regret_winner_17[slice56],\r\n",
        "       train_regret_winner_18[slice56],\r\n",
        "       train_regret_winner_19[slice56],\r\n",
        "       train_regret_winner_20[slice56]]\r\n",
        "\r\n",
        "loser56_results = pd.DataFrame(loser56).sort_values(by=[0], ascending=False)\r\n",
        "winner56_results = pd.DataFrame(winner56).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser56 = np.asarray(loser56_results[4:5][0])[0]\r\n",
        "median_loser56 = np.asarray(loser56_results[9:10][0])[0]\r\n",
        "upper_loser56 = np.asarray(loser56_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner56 = np.asarray(winner56_results[4:5][0])[0]\r\n",
        "median_winner56 = np.asarray(winner56_results[9:10][0])[0]\r\n",
        "upper_winner56 = np.asarray(winner56_results[14:15][0])[0]"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfVZBDP8xAcC"
      },
      "source": [
        "# Iteration66 :\r\n",
        "\r\n",
        "slice66 = 65\r\n",
        "\r\n",
        "loser66 = [train_regret_loser_1[slice66],\r\n",
        "       train_regret_loser_2[slice66],\r\n",
        "       train_regret_loser_3[slice66],\r\n",
        "       train_regret_loser_4[slice66],\r\n",
        "       train_regret_loser_5[slice66],\r\n",
        "       train_regret_loser_6[slice66],\r\n",
        "       train_regret_loser_7[slice66],\r\n",
        "       train_regret_loser_8[slice66],\r\n",
        "       train_regret_loser_9[slice66],\r\n",
        "       train_regret_loser_10[slice66],\r\n",
        "       train_regret_loser_11[slice66],\r\n",
        "       train_regret_loser_12[slice66],\r\n",
        "       train_regret_loser_13[slice66],\r\n",
        "       train_regret_loser_14[slice66],\r\n",
        "       train_regret_loser_15[slice66],\r\n",
        "       train_regret_loser_16[slice66],\r\n",
        "       train_regret_loser_17[slice66],\r\n",
        "       train_regret_loser_18[slice66],\r\n",
        "       train_regret_loser_19[slice66],\r\n",
        "       train_regret_loser_20[slice66]]\r\n",
        "\r\n",
        "winner66 = [train_regret_winner_1[slice66],\r\n",
        "       train_regret_winner_2[slice66],\r\n",
        "       train_regret_winner_3[slice66],\r\n",
        "       train_regret_winner_4[slice66],\r\n",
        "       train_regret_winner_5[slice66],\r\n",
        "       train_regret_winner_6[slice66],\r\n",
        "       train_regret_winner_7[slice66],\r\n",
        "       train_regret_winner_8[slice66],\r\n",
        "       train_regret_winner_9[slice66],\r\n",
        "       train_regret_winner_10[slice66],\r\n",
        "       train_regret_winner_11[slice66],\r\n",
        "       train_regret_winner_12[slice66],\r\n",
        "       train_regret_winner_13[slice66],\r\n",
        "       train_regret_winner_14[slice66],\r\n",
        "       train_regret_winner_15[slice66],\r\n",
        "       train_regret_winner_16[slice66],\r\n",
        "       train_regret_winner_17[slice66],\r\n",
        "       train_regret_winner_18[slice66],\r\n",
        "       train_regret_winner_19[slice66],\r\n",
        "       train_regret_winner_20[slice66]]\r\n",
        "\r\n",
        "loser66_results = pd.DataFrame(loser66).sort_values(by=[0], ascending=False)\r\n",
        "winner66_results = pd.DataFrame(winner66).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser66 = np.asarray(loser66_results[4:5][0])[0]\r\n",
        "median_loser66 = np.asarray(loser66_results[9:10][0])[0]\r\n",
        "upper_loser66 = np.asarray(loser66_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner66 = np.asarray(winner66_results[4:5][0])[0]\r\n",
        "median_winner66 = np.asarray(winner66_results[9:10][0])[0]\r\n",
        "upper_winner66 = np.asarray(winner66_results[14:15][0])[0]"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnSYoG7bxAfL"
      },
      "source": [
        "# Iteration76 :\r\n",
        "\r\n",
        "slice76 = 75\r\n",
        "\r\n",
        "loser76 = [train_regret_loser_1[slice76],\r\n",
        "       train_regret_loser_2[slice76],\r\n",
        "       train_regret_loser_3[slice76],\r\n",
        "       train_regret_loser_4[slice76],\r\n",
        "       train_regret_loser_5[slice76],\r\n",
        "       train_regret_loser_6[slice76],\r\n",
        "       train_regret_loser_7[slice76],\r\n",
        "       train_regret_loser_8[slice76],\r\n",
        "       train_regret_loser_9[slice76],\r\n",
        "       train_regret_loser_10[slice76],\r\n",
        "       train_regret_loser_11[slice76],\r\n",
        "       train_regret_loser_12[slice76],\r\n",
        "       train_regret_loser_13[slice76],\r\n",
        "       train_regret_loser_14[slice76],\r\n",
        "       train_regret_loser_15[slice76],\r\n",
        "       train_regret_loser_16[slice76],\r\n",
        "       train_regret_loser_17[slice76],\r\n",
        "       train_regret_loser_18[slice76],\r\n",
        "       train_regret_loser_19[slice76],\r\n",
        "       train_regret_loser_20[slice76]]\r\n",
        "\r\n",
        "winner76 = [train_regret_winner_1[slice76],\r\n",
        "       train_regret_winner_2[slice76],\r\n",
        "       train_regret_winner_3[slice76],\r\n",
        "       train_regret_winner_4[slice76],\r\n",
        "       train_regret_winner_5[slice76],\r\n",
        "       train_regret_winner_6[slice76],\r\n",
        "       train_regret_winner_7[slice76],\r\n",
        "       train_regret_winner_8[slice76],\r\n",
        "       train_regret_winner_9[slice76],\r\n",
        "       train_regret_winner_10[slice76],\r\n",
        "       train_regret_winner_11[slice76],\r\n",
        "       train_regret_winner_12[slice76],\r\n",
        "       train_regret_winner_13[slice76],\r\n",
        "       train_regret_winner_14[slice76],\r\n",
        "       train_regret_winner_15[slice76],\r\n",
        "       train_regret_winner_16[slice76],\r\n",
        "       train_regret_winner_17[slice76],\r\n",
        "       train_regret_winner_18[slice76],\r\n",
        "       train_regret_winner_19[slice76],\r\n",
        "       train_regret_winner_20[slice76]]\r\n",
        "\r\n",
        "loser76_results = pd.DataFrame(loser76).sort_values(by=[0], ascending=False)\r\n",
        "winner76_results = pd.DataFrame(winner76).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser76 = np.asarray(loser76_results[4:5][0])[0]\r\n",
        "median_loser76 = np.asarray(loser76_results[9:10][0])[0]\r\n",
        "upper_loser76 = np.asarray(loser76_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner76 = np.asarray(winner76_results[4:5][0])[0]\r\n",
        "median_winner76 = np.asarray(winner76_results[9:10][0])[0]\r\n",
        "upper_winner76 = np.asarray(winner76_results[14:15][0])[0]"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ze_Oy9mxAiO"
      },
      "source": [
        "# Iteration86 :\r\n",
        "\r\n",
        "slice86 = 85\r\n",
        "\r\n",
        "loser86 = [train_regret_loser_1[slice86],\r\n",
        "       train_regret_loser_2[slice86],\r\n",
        "       train_regret_loser_3[slice86],\r\n",
        "       train_regret_loser_4[slice86],\r\n",
        "       train_regret_loser_5[slice86],\r\n",
        "       train_regret_loser_6[slice86],\r\n",
        "       train_regret_loser_7[slice86],\r\n",
        "       train_regret_loser_8[slice86],\r\n",
        "       train_regret_loser_9[slice86],\r\n",
        "       train_regret_loser_10[slice86],\r\n",
        "       train_regret_loser_11[slice86],\r\n",
        "       train_regret_loser_12[slice86],\r\n",
        "       train_regret_loser_13[slice86],\r\n",
        "       train_regret_loser_14[slice86],\r\n",
        "       train_regret_loser_15[slice86],\r\n",
        "       train_regret_loser_16[slice86],\r\n",
        "       train_regret_loser_17[slice86],\r\n",
        "       train_regret_loser_18[slice86],\r\n",
        "       train_regret_loser_19[slice86],\r\n",
        "       train_regret_loser_20[slice86]]\r\n",
        "\r\n",
        "winner86 = [train_regret_winner_1[slice86],\r\n",
        "       train_regret_winner_2[slice86],\r\n",
        "       train_regret_winner_3[slice86],\r\n",
        "       train_regret_winner_4[slice86],\r\n",
        "       train_regret_winner_5[slice86],\r\n",
        "       train_regret_winner_6[slice86],\r\n",
        "       train_regret_winner_7[slice86],\r\n",
        "       train_regret_winner_8[slice86],\r\n",
        "       train_regret_winner_9[slice86],\r\n",
        "       train_regret_winner_10[slice86],\r\n",
        "       train_regret_winner_11[slice86],\r\n",
        "       train_regret_winner_12[slice86],\r\n",
        "       train_regret_winner_13[slice86],\r\n",
        "       train_regret_winner_14[slice86],\r\n",
        "       train_regret_winner_15[slice86],\r\n",
        "       train_regret_winner_16[slice86],\r\n",
        "       train_regret_winner_17[slice86],\r\n",
        "       train_regret_winner_18[slice86],\r\n",
        "       train_regret_winner_19[slice86],\r\n",
        "       train_regret_winner_20[slice86]]\r\n",
        "\r\n",
        "loser86_results = pd.DataFrame(loser86).sort_values(by=[0], ascending=False)\r\n",
        "winner86_results = pd.DataFrame(winner86).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser86 = np.asarray(loser86_results[4:5][0])[0]\r\n",
        "median_loser86 = np.asarray(loser86_results[9:10][0])[0]\r\n",
        "upper_loser86 = np.asarray(loser86_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner86 = np.asarray(winner86_results[4:5][0])[0]\r\n",
        "median_winner86 = np.asarray(winner86_results[9:10][0])[0]\r\n",
        "upper_winner86 = np.asarray(winner86_results[14:15][0])[0]"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glsE9_RPxAlS"
      },
      "source": [
        "# Iteration96 :\r\n",
        "\r\n",
        "slice96 = 95\r\n",
        "\r\n",
        "loser96 = [train_regret_loser_1[slice96],\r\n",
        "       train_regret_loser_2[slice96],\r\n",
        "       train_regret_loser_3[slice96],\r\n",
        "       train_regret_loser_4[slice96],\r\n",
        "       train_regret_loser_5[slice96],\r\n",
        "       train_regret_loser_6[slice96],\r\n",
        "       train_regret_loser_7[slice96],\r\n",
        "       train_regret_loser_8[slice96],\r\n",
        "       train_regret_loser_9[slice96],\r\n",
        "       train_regret_loser_10[slice96],\r\n",
        "       train_regret_loser_11[slice96],\r\n",
        "       train_regret_loser_12[slice96],\r\n",
        "       train_regret_loser_13[slice96],\r\n",
        "       train_regret_loser_14[slice96],\r\n",
        "       train_regret_loser_15[slice96],\r\n",
        "       train_regret_loser_16[slice96],\r\n",
        "       train_regret_loser_17[slice96],\r\n",
        "       train_regret_loser_18[slice96],\r\n",
        "       train_regret_loser_19[slice96],\r\n",
        "       train_regret_loser_20[slice96]]\r\n",
        "\r\n",
        "winner96 = [train_regret_winner_1[slice96],\r\n",
        "       train_regret_winner_2[slice96],\r\n",
        "       train_regret_winner_3[slice96],\r\n",
        "       train_regret_winner_4[slice96],\r\n",
        "       train_regret_winner_5[slice96],\r\n",
        "       train_regret_winner_6[slice96],\r\n",
        "       train_regret_winner_7[slice96],\r\n",
        "       train_regret_winner_8[slice96],\r\n",
        "       train_regret_winner_9[slice96],\r\n",
        "       train_regret_winner_10[slice96],\r\n",
        "       train_regret_winner_11[slice96],\r\n",
        "       train_regret_winner_12[slice96],\r\n",
        "       train_regret_winner_13[slice96],\r\n",
        "       train_regret_winner_14[slice96],\r\n",
        "       train_regret_winner_15[slice96],\r\n",
        "       train_regret_winner_16[slice96],\r\n",
        "       train_regret_winner_17[slice96],\r\n",
        "       train_regret_winner_18[slice96],\r\n",
        "       train_regret_winner_19[slice96],\r\n",
        "       train_regret_winner_20[slice96]]\r\n",
        "\r\n",
        "loser96_results = pd.DataFrame(loser96).sort_values(by=[0], ascending=False)\r\n",
        "winner96_results = pd.DataFrame(winner96).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser96 = np.asarray(loser96_results[4:5][0])[0]\r\n",
        "median_loser96 = np.asarray(loser96_results[9:10][0])[0]\r\n",
        "upper_loser96 = np.asarray(loser96_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner96 = np.asarray(winner96_results[4:5][0])[0]\r\n",
        "median_winner96 = np.asarray(winner96_results[9:10][0])[0]\r\n",
        "upper_winner96 = np.asarray(winner96_results[14:15][0])[0]"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhsEfl1RxAoA"
      },
      "source": [
        "# Iteration7 :\r\n",
        "\r\n",
        "slice7 = 6\r\n",
        "\r\n",
        "loser7 = [train_regret_loser_1[slice7],\r\n",
        "       train_regret_loser_2[slice7],\r\n",
        "       train_regret_loser_3[slice7],\r\n",
        "       train_regret_loser_4[slice7],\r\n",
        "       train_regret_loser_5[slice7],\r\n",
        "       train_regret_loser_6[slice7],\r\n",
        "       train_regret_loser_7[slice7],\r\n",
        "       train_regret_loser_8[slice7],\r\n",
        "       train_regret_loser_9[slice7],\r\n",
        "       train_regret_loser_10[slice7],\r\n",
        "       train_regret_loser_11[slice7],\r\n",
        "       train_regret_loser_12[slice7],\r\n",
        "       train_regret_loser_13[slice7],\r\n",
        "       train_regret_loser_14[slice7],\r\n",
        "       train_regret_loser_15[slice7],\r\n",
        "       train_regret_loser_16[slice7],\r\n",
        "       train_regret_loser_17[slice7],\r\n",
        "       train_regret_loser_18[slice7],\r\n",
        "       train_regret_loser_19[slice7],\r\n",
        "       train_regret_loser_20[slice7]]\r\n",
        "\r\n",
        "winner7 = [train_regret_winner_1[slice7],\r\n",
        "       train_regret_winner_2[slice7],\r\n",
        "       train_regret_winner_3[slice7],\r\n",
        "       train_regret_winner_4[slice7],\r\n",
        "       train_regret_winner_5[slice7],\r\n",
        "       train_regret_winner_6[slice7],\r\n",
        "       train_regret_winner_7[slice7],\r\n",
        "       train_regret_winner_8[slice7],\r\n",
        "       train_regret_winner_9[slice7],\r\n",
        "       train_regret_winner_10[slice7],\r\n",
        "       train_regret_winner_11[slice7],\r\n",
        "       train_regret_winner_12[slice7],\r\n",
        "       train_regret_winner_13[slice7],\r\n",
        "       train_regret_winner_14[slice7],\r\n",
        "       train_regret_winner_15[slice7],\r\n",
        "       train_regret_winner_16[slice7],\r\n",
        "       train_regret_winner_17[slice7],\r\n",
        "       train_regret_winner_18[slice7],\r\n",
        "       train_regret_winner_19[slice7],\r\n",
        "       train_regret_winner_20[slice7]]\r\n",
        "\r\n",
        "loser7_results = pd.DataFrame(loser7).sort_values(by=[0], ascending=False)\r\n",
        "winner7_results = pd.DataFrame(winner7).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser7 = np.asarray(loser7_results[4:5][0])[0]\r\n",
        "median_loser7 = np.asarray(loser7_results[9:10][0])[0]\r\n",
        "upper_loser7 = np.asarray(loser7_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner7 = np.asarray(winner7_results[4:5][0])[0]\r\n",
        "median_winner7 = np.asarray(winner7_results[9:10][0])[0]\r\n",
        "upper_winner7 = np.asarray(winner7_results[14:15][0])[0]"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUCMheLKxArL"
      },
      "source": [
        "# Iteration17 :\r\n",
        "\r\n",
        "slice17 = 16\r\n",
        "\r\n",
        "loser17 = [train_regret_loser_1[slice17],\r\n",
        "       train_regret_loser_2[slice17],\r\n",
        "       train_regret_loser_3[slice17],\r\n",
        "       train_regret_loser_4[slice17],\r\n",
        "       train_regret_loser_5[slice17],\r\n",
        "       train_regret_loser_6[slice17],\r\n",
        "       train_regret_loser_7[slice17],\r\n",
        "       train_regret_loser_8[slice17],\r\n",
        "       train_regret_loser_9[slice17],\r\n",
        "       train_regret_loser_10[slice17],\r\n",
        "       train_regret_loser_11[slice17],\r\n",
        "       train_regret_loser_12[slice17],\r\n",
        "       train_regret_loser_13[slice17],\r\n",
        "       train_regret_loser_14[slice17],\r\n",
        "       train_regret_loser_15[slice17],\r\n",
        "       train_regret_loser_16[slice17],\r\n",
        "       train_regret_loser_17[slice17],\r\n",
        "       train_regret_loser_18[slice17],\r\n",
        "       train_regret_loser_19[slice17],\r\n",
        "       train_regret_loser_20[slice17]]\r\n",
        "\r\n",
        "winner17 = [train_regret_winner_1[slice17],\r\n",
        "       train_regret_winner_2[slice17],\r\n",
        "       train_regret_winner_3[slice17],\r\n",
        "       train_regret_winner_4[slice17],\r\n",
        "       train_regret_winner_5[slice17],\r\n",
        "       train_regret_winner_6[slice17],\r\n",
        "       train_regret_winner_7[slice17],\r\n",
        "       train_regret_winner_8[slice17],\r\n",
        "       train_regret_winner_9[slice17],\r\n",
        "       train_regret_winner_10[slice17],\r\n",
        "       train_regret_winner_11[slice17],\r\n",
        "       train_regret_winner_12[slice17],\r\n",
        "       train_regret_winner_13[slice17],\r\n",
        "       train_regret_winner_14[slice17],\r\n",
        "       train_regret_winner_15[slice17],\r\n",
        "       train_regret_winner_16[slice17],\r\n",
        "       train_regret_winner_17[slice17],\r\n",
        "       train_regret_winner_18[slice17],\r\n",
        "       train_regret_winner_19[slice17],\r\n",
        "       train_regret_winner_20[slice17]]\r\n",
        "\r\n",
        "loser17_results = pd.DataFrame(loser17).sort_values(by=[0], ascending=False)\r\n",
        "winner17_results = pd.DataFrame(winner17).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser17 = np.asarray(loser17_results[4:5][0])[0]\r\n",
        "median_loser17 = np.asarray(loser17_results[9:10][0])[0]\r\n",
        "upper_loser17 = np.asarray(loser17_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner17 = np.asarray(winner17_results[4:5][0])[0]\r\n",
        "median_winner17 = np.asarray(winner17_results[9:10][0])[0]\r\n",
        "upper_winner17 = np.asarray(winner17_results[14:15][0])[0]"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYnBmq7_xAuB"
      },
      "source": [
        "# Iteration27 :\r\n",
        "\r\n",
        "slice27 = 26\r\n",
        "\r\n",
        "loser27 = [train_regret_loser_1[slice27],\r\n",
        "       train_regret_loser_2[slice27],\r\n",
        "       train_regret_loser_3[slice27],\r\n",
        "       train_regret_loser_4[slice27],\r\n",
        "       train_regret_loser_5[slice27],\r\n",
        "       train_regret_loser_6[slice27],\r\n",
        "       train_regret_loser_7[slice27],\r\n",
        "       train_regret_loser_8[slice27],\r\n",
        "       train_regret_loser_9[slice27],\r\n",
        "       train_regret_loser_10[slice27],\r\n",
        "       train_regret_loser_11[slice27],\r\n",
        "       train_regret_loser_12[slice27],\r\n",
        "       train_regret_loser_13[slice27],\r\n",
        "       train_regret_loser_14[slice27],\r\n",
        "       train_regret_loser_15[slice27],\r\n",
        "       train_regret_loser_16[slice27],\r\n",
        "       train_regret_loser_17[slice27],\r\n",
        "       train_regret_loser_18[slice27],\r\n",
        "       train_regret_loser_19[slice27],\r\n",
        "       train_regret_loser_20[slice27]]\r\n",
        "\r\n",
        "winner27 = [train_regret_winner_1[slice27],\r\n",
        "       train_regret_winner_2[slice27],\r\n",
        "       train_regret_winner_3[slice27],\r\n",
        "       train_regret_winner_4[slice27],\r\n",
        "       train_regret_winner_5[slice27],\r\n",
        "       train_regret_winner_6[slice27],\r\n",
        "       train_regret_winner_7[slice27],\r\n",
        "       train_regret_winner_8[slice27],\r\n",
        "       train_regret_winner_9[slice27],\r\n",
        "       train_regret_winner_10[slice27],\r\n",
        "       train_regret_winner_11[slice27],\r\n",
        "       train_regret_winner_12[slice27],\r\n",
        "       train_regret_winner_13[slice27],\r\n",
        "       train_regret_winner_14[slice27],\r\n",
        "       train_regret_winner_15[slice27],\r\n",
        "       train_regret_winner_16[slice27],\r\n",
        "       train_regret_winner_17[slice27],\r\n",
        "       train_regret_winner_18[slice27],\r\n",
        "       train_regret_winner_19[slice27],\r\n",
        "       train_regret_winner_20[slice27]]\r\n",
        "\r\n",
        "loser27_results = pd.DataFrame(loser27).sort_values(by=[0], ascending=False)\r\n",
        "winner27_results = pd.DataFrame(winner27).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser27 = np.asarray(loser27_results[4:5][0])[0]\r\n",
        "median_loser27 = np.asarray(loser27_results[9:10][0])[0]\r\n",
        "upper_loser27 = np.asarray(loser27_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner27 = np.asarray(winner27_results[4:5][0])[0]\r\n",
        "median_winner27 = np.asarray(winner27_results[9:10][0])[0]\r\n",
        "upper_winner27 = np.asarray(winner27_results[14:15][0])[0]"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ChA8KOUxAw6"
      },
      "source": [
        "# Iteration37 :\r\n",
        "\r\n",
        "slice37 = 36\r\n",
        "\r\n",
        "loser37 = [train_regret_loser_1[slice37],\r\n",
        "       train_regret_loser_2[slice37],\r\n",
        "       train_regret_loser_3[slice37],\r\n",
        "       train_regret_loser_4[slice37],\r\n",
        "       train_regret_loser_5[slice37],\r\n",
        "       train_regret_loser_6[slice37],\r\n",
        "       train_regret_loser_7[slice37],\r\n",
        "       train_regret_loser_8[slice37],\r\n",
        "       train_regret_loser_9[slice37],\r\n",
        "       train_regret_loser_10[slice37],\r\n",
        "       train_regret_loser_11[slice37],\r\n",
        "       train_regret_loser_12[slice37],\r\n",
        "       train_regret_loser_13[slice37],\r\n",
        "       train_regret_loser_14[slice37],\r\n",
        "       train_regret_loser_15[slice37],\r\n",
        "       train_regret_loser_16[slice37],\r\n",
        "       train_regret_loser_17[slice37],\r\n",
        "       train_regret_loser_18[slice37],\r\n",
        "       train_regret_loser_19[slice37],\r\n",
        "       train_regret_loser_20[slice37]]\r\n",
        "\r\n",
        "winner37 = [train_regret_winner_1[slice37],\r\n",
        "       train_regret_winner_2[slice37],\r\n",
        "       train_regret_winner_3[slice37],\r\n",
        "       train_regret_winner_4[slice37],\r\n",
        "       train_regret_winner_5[slice37],\r\n",
        "       train_regret_winner_6[slice37],\r\n",
        "       train_regret_winner_7[slice37],\r\n",
        "       train_regret_winner_8[slice37],\r\n",
        "       train_regret_winner_9[slice37],\r\n",
        "       train_regret_winner_10[slice37],\r\n",
        "       train_regret_winner_11[slice37],\r\n",
        "       train_regret_winner_12[slice37],\r\n",
        "       train_regret_winner_13[slice37],\r\n",
        "       train_regret_winner_14[slice37],\r\n",
        "       train_regret_winner_15[slice37],\r\n",
        "       train_regret_winner_16[slice37],\r\n",
        "       train_regret_winner_17[slice37],\r\n",
        "       train_regret_winner_18[slice37],\r\n",
        "       train_regret_winner_19[slice37],\r\n",
        "       train_regret_winner_20[slice37]]\r\n",
        "\r\n",
        "loser37_results = pd.DataFrame(loser37).sort_values(by=[0], ascending=False)\r\n",
        "winner37_results = pd.DataFrame(winner37).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser37 = np.asarray(loser37_results[4:5][0])[0]\r\n",
        "median_loser37 = np.asarray(loser37_results[9:10][0])[0]\r\n",
        "upper_loser37 = np.asarray(loser37_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner37 = np.asarray(winner37_results[4:5][0])[0]\r\n",
        "median_winner37 = np.asarray(winner37_results[9:10][0])[0]\r\n",
        "upper_winner37 = np.asarray(winner37_results[14:15][0])[0]"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVsY1buDxAzx"
      },
      "source": [
        "# Iteration47 :\r\n",
        "\r\n",
        "slice47 = 46\r\n",
        "\r\n",
        "loser47 = [train_regret_loser_1[slice47],\r\n",
        "       train_regret_loser_2[slice47],\r\n",
        "       train_regret_loser_3[slice47],\r\n",
        "       train_regret_loser_4[slice47],\r\n",
        "       train_regret_loser_5[slice47],\r\n",
        "       train_regret_loser_6[slice47],\r\n",
        "       train_regret_loser_7[slice47],\r\n",
        "       train_regret_loser_8[slice47],\r\n",
        "       train_regret_loser_9[slice47],\r\n",
        "       train_regret_loser_10[slice47],\r\n",
        "       train_regret_loser_11[slice47],\r\n",
        "       train_regret_loser_12[slice47],\r\n",
        "       train_regret_loser_13[slice47],\r\n",
        "       train_regret_loser_14[slice47],\r\n",
        "       train_regret_loser_15[slice47],\r\n",
        "       train_regret_loser_16[slice47],\r\n",
        "       train_regret_loser_17[slice47],\r\n",
        "       train_regret_loser_18[slice47],\r\n",
        "       train_regret_loser_19[slice47],\r\n",
        "       train_regret_loser_20[slice47]]\r\n",
        "\r\n",
        "winner47 = [train_regret_winner_1[slice47],\r\n",
        "       train_regret_winner_2[slice47],\r\n",
        "       train_regret_winner_3[slice47],\r\n",
        "       train_regret_winner_4[slice47],\r\n",
        "       train_regret_winner_5[slice47],\r\n",
        "       train_regret_winner_6[slice47],\r\n",
        "       train_regret_winner_7[slice47],\r\n",
        "       train_regret_winner_8[slice47],\r\n",
        "       train_regret_winner_9[slice47],\r\n",
        "       train_regret_winner_10[slice47],\r\n",
        "       train_regret_winner_11[slice47],\r\n",
        "       train_regret_winner_12[slice47],\r\n",
        "       train_regret_winner_13[slice47],\r\n",
        "       train_regret_winner_14[slice47],\r\n",
        "       train_regret_winner_15[slice47],\r\n",
        "       train_regret_winner_16[slice47],\r\n",
        "       train_regret_winner_17[slice47],\r\n",
        "       train_regret_winner_18[slice47],\r\n",
        "       train_regret_winner_19[slice47],\r\n",
        "       train_regret_winner_20[slice47]]\r\n",
        "\r\n",
        "loser47_results = pd.DataFrame(loser47).sort_values(by=[0], ascending=False)\r\n",
        "winner47_results = pd.DataFrame(winner47).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser47 = np.asarray(loser47_results[4:5][0])[0]\r\n",
        "median_loser47 = np.asarray(loser47_results[9:10][0])[0]\r\n",
        "upper_loser47 = np.asarray(loser47_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner47 = np.asarray(winner47_results[4:5][0])[0]\r\n",
        "median_winner47 = np.asarray(winner47_results[9:10][0])[0]\r\n",
        "upper_winner47 = np.asarray(winner47_results[14:15][0])[0]"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fIy_EyTxA20"
      },
      "source": [
        "# Iteration57 :\r\n",
        "\r\n",
        "slice57 = 56\r\n",
        "\r\n",
        "loser57 = [train_regret_loser_1[slice57],\r\n",
        "       train_regret_loser_2[slice57],\r\n",
        "       train_regret_loser_3[slice57],\r\n",
        "       train_regret_loser_4[slice57],\r\n",
        "       train_regret_loser_5[slice57],\r\n",
        "       train_regret_loser_6[slice57],\r\n",
        "       train_regret_loser_7[slice57],\r\n",
        "       train_regret_loser_8[slice57],\r\n",
        "       train_regret_loser_9[slice57],\r\n",
        "       train_regret_loser_10[slice57],\r\n",
        "       train_regret_loser_11[slice57],\r\n",
        "       train_regret_loser_12[slice57],\r\n",
        "       train_regret_loser_13[slice57],\r\n",
        "       train_regret_loser_14[slice57],\r\n",
        "       train_regret_loser_15[slice57],\r\n",
        "       train_regret_loser_16[slice57],\r\n",
        "       train_regret_loser_17[slice57],\r\n",
        "       train_regret_loser_18[slice57],\r\n",
        "       train_regret_loser_19[slice57],\r\n",
        "       train_regret_loser_20[slice57]]\r\n",
        "\r\n",
        "winner57 = [train_regret_winner_1[slice57],\r\n",
        "       train_regret_winner_2[slice57],\r\n",
        "       train_regret_winner_3[slice57],\r\n",
        "       train_regret_winner_4[slice57],\r\n",
        "       train_regret_winner_5[slice57],\r\n",
        "       train_regret_winner_6[slice57],\r\n",
        "       train_regret_winner_7[slice57],\r\n",
        "       train_regret_winner_8[slice57],\r\n",
        "       train_regret_winner_9[slice57],\r\n",
        "       train_regret_winner_10[slice57],\r\n",
        "       train_regret_winner_11[slice57],\r\n",
        "       train_regret_winner_12[slice57],\r\n",
        "       train_regret_winner_13[slice57],\r\n",
        "       train_regret_winner_14[slice57],\r\n",
        "       train_regret_winner_15[slice57],\r\n",
        "       train_regret_winner_16[slice57],\r\n",
        "       train_regret_winner_17[slice57],\r\n",
        "       train_regret_winner_18[slice57],\r\n",
        "       train_regret_winner_19[slice57],\r\n",
        "       train_regret_winner_20[slice57]]\r\n",
        "\r\n",
        "loser57_results = pd.DataFrame(loser57).sort_values(by=[0], ascending=False)\r\n",
        "winner57_results = pd.DataFrame(winner57).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser57 = np.asarray(loser57_results[4:5][0])[0]\r\n",
        "median_loser57 = np.asarray(loser57_results[9:10][0])[0]\r\n",
        "upper_loser57 = np.asarray(loser57_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner57 = np.asarray(winner57_results[4:5][0])[0]\r\n",
        "median_winner57 = np.asarray(winner57_results[9:10][0])[0]\r\n",
        "upper_winner57 = np.asarray(winner57_results[14:15][0])[0]"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umwdBl8XxA5r"
      },
      "source": [
        "# Iteration67 :\r\n",
        "\r\n",
        "slice67 = 66\r\n",
        "\r\n",
        "loser67 = [train_regret_loser_1[slice67],\r\n",
        "       train_regret_loser_2[slice67],\r\n",
        "       train_regret_loser_3[slice67],\r\n",
        "       train_regret_loser_4[slice67],\r\n",
        "       train_regret_loser_5[slice67],\r\n",
        "       train_regret_loser_6[slice67],\r\n",
        "       train_regret_loser_7[slice67],\r\n",
        "       train_regret_loser_8[slice67],\r\n",
        "       train_regret_loser_9[slice67],\r\n",
        "       train_regret_loser_10[slice67],\r\n",
        "       train_regret_loser_11[slice67],\r\n",
        "       train_regret_loser_12[slice67],\r\n",
        "       train_regret_loser_13[slice67],\r\n",
        "       train_regret_loser_14[slice67],\r\n",
        "       train_regret_loser_15[slice67],\r\n",
        "       train_regret_loser_16[slice67],\r\n",
        "       train_regret_loser_17[slice67],\r\n",
        "       train_regret_loser_18[slice67],\r\n",
        "       train_regret_loser_19[slice67],\r\n",
        "       train_regret_loser_20[slice67]]\r\n",
        "\r\n",
        "winner67 = [train_regret_winner_1[slice67],\r\n",
        "       train_regret_winner_2[slice67],\r\n",
        "       train_regret_winner_3[slice67],\r\n",
        "       train_regret_winner_4[slice67],\r\n",
        "       train_regret_winner_5[slice67],\r\n",
        "       train_regret_winner_6[slice67],\r\n",
        "       train_regret_winner_7[slice67],\r\n",
        "       train_regret_winner_8[slice67],\r\n",
        "       train_regret_winner_9[slice67],\r\n",
        "       train_regret_winner_10[slice67],\r\n",
        "       train_regret_winner_11[slice67],\r\n",
        "       train_regret_winner_12[slice67],\r\n",
        "       train_regret_winner_13[slice67],\r\n",
        "       train_regret_winner_14[slice67],\r\n",
        "       train_regret_winner_15[slice67],\r\n",
        "       train_regret_winner_16[slice67],\r\n",
        "       train_regret_winner_17[slice67],\r\n",
        "       train_regret_winner_18[slice67],\r\n",
        "       train_regret_winner_19[slice67],\r\n",
        "       train_regret_winner_20[slice67]]\r\n",
        "\r\n",
        "loser67_results = pd.DataFrame(loser67).sort_values(by=[0], ascending=False)\r\n",
        "winner67_results = pd.DataFrame(winner67).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser67 = np.asarray(loser67_results[4:5][0])[0]\r\n",
        "median_loser67 = np.asarray(loser67_results[9:10][0])[0]\r\n",
        "upper_loser67 = np.asarray(loser67_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner67 = np.asarray(winner67_results[4:5][0])[0]\r\n",
        "median_winner67 = np.asarray(winner67_results[9:10][0])[0]\r\n",
        "upper_winner67 = np.asarray(winner67_results[14:15][0])[0]"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF3KFX-ZxA8q"
      },
      "source": [
        "# Iteration77 :\r\n",
        "\r\n",
        "slice77 = 76\r\n",
        "\r\n",
        "loser77 = [train_regret_loser_1[slice77],\r\n",
        "       train_regret_loser_2[slice77],\r\n",
        "       train_regret_loser_3[slice77],\r\n",
        "       train_regret_loser_4[slice77],\r\n",
        "       train_regret_loser_5[slice77],\r\n",
        "       train_regret_loser_6[slice77],\r\n",
        "       train_regret_loser_7[slice77],\r\n",
        "       train_regret_loser_8[slice77],\r\n",
        "       train_regret_loser_9[slice77],\r\n",
        "       train_regret_loser_10[slice77],\r\n",
        "       train_regret_loser_11[slice77],\r\n",
        "       train_regret_loser_12[slice77],\r\n",
        "       train_regret_loser_13[slice77],\r\n",
        "       train_regret_loser_14[slice77],\r\n",
        "       train_regret_loser_15[slice77],\r\n",
        "       train_regret_loser_16[slice77],\r\n",
        "       train_regret_loser_17[slice77],\r\n",
        "       train_regret_loser_18[slice77],\r\n",
        "       train_regret_loser_19[slice77],\r\n",
        "       train_regret_loser_20[slice77]]\r\n",
        "\r\n",
        "winner77 = [train_regret_winner_1[slice77],\r\n",
        "       train_regret_winner_2[slice77],\r\n",
        "       train_regret_winner_3[slice77],\r\n",
        "       train_regret_winner_4[slice77],\r\n",
        "       train_regret_winner_5[slice77],\r\n",
        "       train_regret_winner_6[slice77],\r\n",
        "       train_regret_winner_7[slice77],\r\n",
        "       train_regret_winner_8[slice77],\r\n",
        "       train_regret_winner_9[slice77],\r\n",
        "       train_regret_winner_10[slice77],\r\n",
        "       train_regret_winner_11[slice77],\r\n",
        "       train_regret_winner_12[slice77],\r\n",
        "       train_regret_winner_13[slice77],\r\n",
        "       train_regret_winner_14[slice77],\r\n",
        "       train_regret_winner_15[slice77],\r\n",
        "       train_regret_winner_16[slice77],\r\n",
        "       train_regret_winner_17[slice77],\r\n",
        "       train_regret_winner_18[slice77],\r\n",
        "       train_regret_winner_19[slice77],\r\n",
        "       train_regret_winner_20[slice77]]\r\n",
        "\r\n",
        "loser77_results = pd.DataFrame(loser77).sort_values(by=[0], ascending=False)\r\n",
        "winner77_results = pd.DataFrame(winner77).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser77 = np.asarray(loser77_results[4:5][0])[0]\r\n",
        "median_loser77 = np.asarray(loser77_results[9:10][0])[0]\r\n",
        "upper_loser77 = np.asarray(loser77_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner77 = np.asarray(winner77_results[4:5][0])[0]\r\n",
        "median_winner77 = np.asarray(winner77_results[9:10][0])[0]\r\n",
        "upper_winner77 = np.asarray(winner77_results[14:15][0])[0]"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVYft39xA_t"
      },
      "source": [
        "# Iteration87 :\r\n",
        "\r\n",
        "slice87 = 86\r\n",
        "\r\n",
        "loser87 = [train_regret_loser_1[slice87],\r\n",
        "       train_regret_loser_2[slice87],\r\n",
        "       train_regret_loser_3[slice87],\r\n",
        "       train_regret_loser_4[slice87],\r\n",
        "       train_regret_loser_5[slice87],\r\n",
        "       train_regret_loser_6[slice87],\r\n",
        "       train_regret_loser_7[slice87],\r\n",
        "       train_regret_loser_8[slice87],\r\n",
        "       train_regret_loser_9[slice87],\r\n",
        "       train_regret_loser_10[slice87],\r\n",
        "       train_regret_loser_11[slice87],\r\n",
        "       train_regret_loser_12[slice87],\r\n",
        "       train_regret_loser_13[slice87],\r\n",
        "       train_regret_loser_14[slice87],\r\n",
        "       train_regret_loser_15[slice87],\r\n",
        "       train_regret_loser_16[slice87],\r\n",
        "       train_regret_loser_17[slice87],\r\n",
        "       train_regret_loser_18[slice87],\r\n",
        "       train_regret_loser_19[slice87],\r\n",
        "       train_regret_loser_20[slice87]]\r\n",
        "\r\n",
        "winner87 = [train_regret_winner_1[slice87],\r\n",
        "       train_regret_winner_2[slice87],\r\n",
        "       train_regret_winner_3[slice87],\r\n",
        "       train_regret_winner_4[slice87],\r\n",
        "       train_regret_winner_5[slice87],\r\n",
        "       train_regret_winner_6[slice87],\r\n",
        "       train_regret_winner_7[slice87],\r\n",
        "       train_regret_winner_8[slice87],\r\n",
        "       train_regret_winner_9[slice87],\r\n",
        "       train_regret_winner_10[slice87],\r\n",
        "       train_regret_winner_11[slice87],\r\n",
        "       train_regret_winner_12[slice87],\r\n",
        "       train_regret_winner_13[slice87],\r\n",
        "       train_regret_winner_14[slice87],\r\n",
        "       train_regret_winner_15[slice87],\r\n",
        "       train_regret_winner_16[slice87],\r\n",
        "       train_regret_winner_17[slice87],\r\n",
        "       train_regret_winner_18[slice87],\r\n",
        "       train_regret_winner_19[slice87],\r\n",
        "       train_regret_winner_20[slice87]]\r\n",
        "\r\n",
        "loser87_results = pd.DataFrame(loser87).sort_values(by=[0], ascending=False)\r\n",
        "winner87_results = pd.DataFrame(winner87).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser87 = np.asarray(loser87_results[4:5][0])[0]\r\n",
        "median_loser87 = np.asarray(loser87_results[9:10][0])[0]\r\n",
        "upper_loser87 = np.asarray(loser87_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner87 = np.asarray(winner87_results[4:5][0])[0]\r\n",
        "median_winner87 = np.asarray(winner87_results[9:10][0])[0]\r\n",
        "upper_winner87 = np.asarray(winner87_results[14:15][0])[0]"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gPkLC0yxBCs"
      },
      "source": [
        "# Iteration97 :\r\n",
        "\r\n",
        "slice97 = 96\r\n",
        "\r\n",
        "loser97 = [train_regret_loser_1[slice97],\r\n",
        "       train_regret_loser_2[slice97],\r\n",
        "       train_regret_loser_3[slice97],\r\n",
        "       train_regret_loser_4[slice97],\r\n",
        "       train_regret_loser_5[slice97],\r\n",
        "       train_regret_loser_6[slice97],\r\n",
        "       train_regret_loser_7[slice97],\r\n",
        "       train_regret_loser_8[slice97],\r\n",
        "       train_regret_loser_9[slice97],\r\n",
        "       train_regret_loser_10[slice97],\r\n",
        "       train_regret_loser_11[slice97],\r\n",
        "       train_regret_loser_12[slice97],\r\n",
        "       train_regret_loser_13[slice97],\r\n",
        "       train_regret_loser_14[slice97],\r\n",
        "       train_regret_loser_15[slice97],\r\n",
        "       train_regret_loser_16[slice97],\r\n",
        "       train_regret_loser_17[slice97],\r\n",
        "       train_regret_loser_18[slice97],\r\n",
        "       train_regret_loser_19[slice97],\r\n",
        "       train_regret_loser_20[slice97]]\r\n",
        "\r\n",
        "winner97 = [train_regret_winner_1[slice97],\r\n",
        "       train_regret_winner_2[slice97],\r\n",
        "       train_regret_winner_3[slice97],\r\n",
        "       train_regret_winner_4[slice97],\r\n",
        "       train_regret_winner_5[slice97],\r\n",
        "       train_regret_winner_6[slice97],\r\n",
        "       train_regret_winner_7[slice97],\r\n",
        "       train_regret_winner_8[slice97],\r\n",
        "       train_regret_winner_9[slice97],\r\n",
        "       train_regret_winner_10[slice97],\r\n",
        "       train_regret_winner_11[slice97],\r\n",
        "       train_regret_winner_12[slice97],\r\n",
        "       train_regret_winner_13[slice97],\r\n",
        "       train_regret_winner_14[slice97],\r\n",
        "       train_regret_winner_15[slice97],\r\n",
        "       train_regret_winner_16[slice97],\r\n",
        "       train_regret_winner_17[slice97],\r\n",
        "       train_regret_winner_18[slice97],\r\n",
        "       train_regret_winner_19[slice97],\r\n",
        "       train_regret_winner_20[slice97]]\r\n",
        "\r\n",
        "loser97_results = pd.DataFrame(loser97).sort_values(by=[0], ascending=False)\r\n",
        "winner97_results = pd.DataFrame(winner97).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser97 = np.asarray(loser97_results[4:5][0])[0]\r\n",
        "median_loser97 = np.asarray(loser97_results[9:10][0])[0]\r\n",
        "upper_loser97 = np.asarray(loser97_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner97 = np.asarray(winner97_results[4:5][0])[0]\r\n",
        "median_winner97 = np.asarray(winner97_results[9:10][0])[0]\r\n",
        "upper_winner97 = np.asarray(winner97_results[14:15][0])[0]"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbgYEpYUxBFr"
      },
      "source": [
        "# Iteration8 :\r\n",
        "\r\n",
        "slice8 = 7\r\n",
        "\r\n",
        "loser8 = [train_regret_loser_1[slice8],\r\n",
        "       train_regret_loser_2[slice8],\r\n",
        "       train_regret_loser_3[slice8],\r\n",
        "       train_regret_loser_4[slice8],\r\n",
        "       train_regret_loser_5[slice8],\r\n",
        "       train_regret_loser_6[slice8],\r\n",
        "       train_regret_loser_7[slice8],\r\n",
        "       train_regret_loser_8[slice8],\r\n",
        "       train_regret_loser_9[slice8],\r\n",
        "       train_regret_loser_10[slice8],\r\n",
        "       train_regret_loser_11[slice8],\r\n",
        "       train_regret_loser_12[slice8],\r\n",
        "       train_regret_loser_13[slice8],\r\n",
        "       train_regret_loser_14[slice8],\r\n",
        "       train_regret_loser_15[slice8],\r\n",
        "       train_regret_loser_16[slice8],\r\n",
        "       train_regret_loser_17[slice8],\r\n",
        "       train_regret_loser_18[slice8],\r\n",
        "       train_regret_loser_19[slice8],\r\n",
        "       train_regret_loser_20[slice8]]\r\n",
        "\r\n",
        "winner8 = [train_regret_winner_1[slice8],\r\n",
        "       train_regret_winner_2[slice8],\r\n",
        "       train_regret_winner_3[slice8],\r\n",
        "       train_regret_winner_4[slice8],\r\n",
        "       train_regret_winner_5[slice8],\r\n",
        "       train_regret_winner_6[slice8],\r\n",
        "       train_regret_winner_7[slice8],\r\n",
        "       train_regret_winner_8[slice8],\r\n",
        "       train_regret_winner_9[slice8],\r\n",
        "       train_regret_winner_10[slice8],\r\n",
        "       train_regret_winner_11[slice8],\r\n",
        "       train_regret_winner_12[slice8],\r\n",
        "       train_regret_winner_13[slice8],\r\n",
        "       train_regret_winner_14[slice8],\r\n",
        "       train_regret_winner_15[slice8],\r\n",
        "       train_regret_winner_16[slice8],\r\n",
        "       train_regret_winner_17[slice8],\r\n",
        "       train_regret_winner_18[slice8],\r\n",
        "       train_regret_winner_19[slice8],\r\n",
        "       train_regret_winner_20[slice8]]\r\n",
        "\r\n",
        "loser8_results = pd.DataFrame(loser8).sort_values(by=[0], ascending=False)\r\n",
        "winner8_results = pd.DataFrame(winner8).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser8 = np.asarray(loser8_results[4:5][0])[0]\r\n",
        "median_loser8 = np.asarray(loser8_results[9:10][0])[0]\r\n",
        "upper_loser8 = np.asarray(loser8_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner8 = np.asarray(winner8_results[4:5][0])[0]\r\n",
        "median_winner8 = np.asarray(winner8_results[9:10][0])[0]\r\n",
        "upper_winner8 = np.asarray(winner8_results[14:15][0])[0]"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im9dHUqvxBH9"
      },
      "source": [
        "# Iteration18 :\r\n",
        "\r\n",
        "slice18 = 17\r\n",
        "\r\n",
        "loser18 = [train_regret_loser_1[slice18],\r\n",
        "       train_regret_loser_2[slice18],\r\n",
        "       train_regret_loser_3[slice18],\r\n",
        "       train_regret_loser_4[slice18],\r\n",
        "       train_regret_loser_5[slice18],\r\n",
        "       train_regret_loser_6[slice18],\r\n",
        "       train_regret_loser_7[slice18],\r\n",
        "       train_regret_loser_8[slice18],\r\n",
        "       train_regret_loser_9[slice18],\r\n",
        "       train_regret_loser_10[slice18],\r\n",
        "       train_regret_loser_11[slice18],\r\n",
        "       train_regret_loser_12[slice18],\r\n",
        "       train_regret_loser_13[slice18],\r\n",
        "       train_regret_loser_14[slice18],\r\n",
        "       train_regret_loser_15[slice18],\r\n",
        "       train_regret_loser_16[slice18],\r\n",
        "       train_regret_loser_17[slice18],\r\n",
        "       train_regret_loser_18[slice18],\r\n",
        "       train_regret_loser_19[slice18],\r\n",
        "       train_regret_loser_20[slice18]]\r\n",
        "\r\n",
        "winner18 = [train_regret_winner_1[slice18],\r\n",
        "       train_regret_winner_2[slice18],\r\n",
        "       train_regret_winner_3[slice18],\r\n",
        "       train_regret_winner_4[slice18],\r\n",
        "       train_regret_winner_5[slice18],\r\n",
        "       train_regret_winner_6[slice18],\r\n",
        "       train_regret_winner_7[slice18],\r\n",
        "       train_regret_winner_8[slice18],\r\n",
        "       train_regret_winner_9[slice18],\r\n",
        "       train_regret_winner_10[slice18],\r\n",
        "       train_regret_winner_11[slice18],\r\n",
        "       train_regret_winner_12[slice18],\r\n",
        "       train_regret_winner_13[slice18],\r\n",
        "       train_regret_winner_14[slice18],\r\n",
        "       train_regret_winner_15[slice18],\r\n",
        "       train_regret_winner_16[slice18],\r\n",
        "       train_regret_winner_17[slice18],\r\n",
        "       train_regret_winner_18[slice18],\r\n",
        "       train_regret_winner_19[slice18],\r\n",
        "       train_regret_winner_20[slice18]]\r\n",
        "\r\n",
        "loser18_results = pd.DataFrame(loser18).sort_values(by=[0], ascending=False)\r\n",
        "winner18_results = pd.DataFrame(winner18).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser18 = np.asarray(loser18_results[4:5][0])[0]\r\n",
        "median_loser18 = np.asarray(loser18_results[9:10][0])[0]\r\n",
        "upper_loser18 = np.asarray(loser18_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner18 = np.asarray(winner18_results[4:5][0])[0]\r\n",
        "median_winner18 = np.asarray(winner18_results[9:10][0])[0]\r\n",
        "upper_winner18 = np.asarray(winner18_results[14:15][0])[0]"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvqFjlBDxBK4"
      },
      "source": [
        "# Iteration28 :\r\n",
        "\r\n",
        "slice28 = 27\r\n",
        "\r\n",
        "loser28 = [train_regret_loser_1[slice28],\r\n",
        "       train_regret_loser_2[slice28],\r\n",
        "       train_regret_loser_3[slice28],\r\n",
        "       train_regret_loser_4[slice28],\r\n",
        "       train_regret_loser_5[slice28],\r\n",
        "       train_regret_loser_6[slice28],\r\n",
        "       train_regret_loser_7[slice28],\r\n",
        "       train_regret_loser_8[slice28],\r\n",
        "       train_regret_loser_9[slice28],\r\n",
        "       train_regret_loser_10[slice28],\r\n",
        "       train_regret_loser_11[slice28],\r\n",
        "       train_regret_loser_12[slice28],\r\n",
        "       train_regret_loser_13[slice28],\r\n",
        "       train_regret_loser_14[slice28],\r\n",
        "       train_regret_loser_15[slice28],\r\n",
        "       train_regret_loser_16[slice28],\r\n",
        "       train_regret_loser_17[slice28],\r\n",
        "       train_regret_loser_18[slice28],\r\n",
        "       train_regret_loser_19[slice28],\r\n",
        "       train_regret_loser_20[slice28]]\r\n",
        "\r\n",
        "winner28 = [train_regret_winner_1[slice28],\r\n",
        "       train_regret_winner_2[slice28],\r\n",
        "       train_regret_winner_3[slice28],\r\n",
        "       train_regret_winner_4[slice28],\r\n",
        "       train_regret_winner_5[slice28],\r\n",
        "       train_regret_winner_6[slice28],\r\n",
        "       train_regret_winner_7[slice28],\r\n",
        "       train_regret_winner_8[slice28],\r\n",
        "       train_regret_winner_9[slice28],\r\n",
        "       train_regret_winner_10[slice28],\r\n",
        "       train_regret_winner_11[slice28],\r\n",
        "       train_regret_winner_12[slice28],\r\n",
        "       train_regret_winner_13[slice28],\r\n",
        "       train_regret_winner_14[slice28],\r\n",
        "       train_regret_winner_15[slice28],\r\n",
        "       train_regret_winner_16[slice28],\r\n",
        "       train_regret_winner_17[slice28],\r\n",
        "       train_regret_winner_18[slice28],\r\n",
        "       train_regret_winner_19[slice28],\r\n",
        "       train_regret_winner_20[slice28]]\r\n",
        "\r\n",
        "loser28_results = pd.DataFrame(loser28).sort_values(by=[0], ascending=False)\r\n",
        "winner28_results = pd.DataFrame(winner28).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser28 = np.asarray(loser28_results[4:5][0])[0]\r\n",
        "median_loser28 = np.asarray(loser28_results[9:10][0])[0]\r\n",
        "upper_loser28 = np.asarray(loser28_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner28 = np.asarray(winner28_results[4:5][0])[0]\r\n",
        "median_winner28 = np.asarray(winner28_results[9:10][0])[0]\r\n",
        "upper_winner28 = np.asarray(winner28_results[14:15][0])[0]"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It5daJCEted3"
      },
      "source": [
        "# Iteration38 :\r\n",
        "\r\n",
        "slice38 = 37\r\n",
        "\r\n",
        "loser38 = [train_regret_loser_1[slice38],\r\n",
        "       train_regret_loser_2[slice38],\r\n",
        "       train_regret_loser_3[slice38],\r\n",
        "       train_regret_loser_4[slice38],\r\n",
        "       train_regret_loser_5[slice38],\r\n",
        "       train_regret_loser_6[slice38],\r\n",
        "       train_regret_loser_7[slice38],\r\n",
        "       train_regret_loser_8[slice38],\r\n",
        "       train_regret_loser_9[slice38],\r\n",
        "       train_regret_loser_10[slice38],\r\n",
        "       train_regret_loser_11[slice38],\r\n",
        "       train_regret_loser_12[slice38],\r\n",
        "       train_regret_loser_13[slice38],\r\n",
        "       train_regret_loser_14[slice38],\r\n",
        "       train_regret_loser_15[slice38],\r\n",
        "       train_regret_loser_16[slice38],\r\n",
        "       train_regret_loser_17[slice38],\r\n",
        "       train_regret_loser_18[slice38],\r\n",
        "       train_regret_loser_19[slice38],\r\n",
        "       train_regret_loser_20[slice38]]\r\n",
        "\r\n",
        "winner38 = [train_regret_winner_1[slice38],\r\n",
        "       train_regret_winner_2[slice38],\r\n",
        "       train_regret_winner_3[slice38],\r\n",
        "       train_regret_winner_4[slice38],\r\n",
        "       train_regret_winner_5[slice38],\r\n",
        "       train_regret_winner_6[slice38],\r\n",
        "       train_regret_winner_7[slice38],\r\n",
        "       train_regret_winner_8[slice38],\r\n",
        "       train_regret_winner_9[slice38],\r\n",
        "       train_regret_winner_10[slice38],\r\n",
        "       train_regret_winner_11[slice38],\r\n",
        "       train_regret_winner_12[slice38],\r\n",
        "       train_regret_winner_13[slice38],\r\n",
        "       train_regret_winner_14[slice38],\r\n",
        "       train_regret_winner_15[slice38],\r\n",
        "       train_regret_winner_16[slice38],\r\n",
        "       train_regret_winner_17[slice38],\r\n",
        "       train_regret_winner_18[slice38],\r\n",
        "       train_regret_winner_19[slice38],\r\n",
        "       train_regret_winner_20[slice38]]\r\n",
        "\r\n",
        "loser38_results = pd.DataFrame(loser38).sort_values(by=[0], ascending=False)\r\n",
        "winner38_results = pd.DataFrame(winner38).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser38 = np.asarray(loser38_results[4:5][0])[0]\r\n",
        "median_loser38 = np.asarray(loser38_results[9:10][0])[0]\r\n",
        "upper_loser38 = np.asarray(loser38_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner38 = np.asarray(winner38_results[4:5][0])[0]\r\n",
        "median_winner38 = np.asarray(winner38_results[9:10][0])[0]\r\n",
        "upper_winner38 = np.asarray(winner38_results[14:15][0])[0]"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GekXOf_gtegw"
      },
      "source": [
        "# Iteration48 :\r\n",
        "\r\n",
        "slice48 = 47\r\n",
        "\r\n",
        "loser48 = [train_regret_loser_1[slice48],\r\n",
        "       train_regret_loser_2[slice48],\r\n",
        "       train_regret_loser_3[slice48],\r\n",
        "       train_regret_loser_4[slice48],\r\n",
        "       train_regret_loser_5[slice48],\r\n",
        "       train_regret_loser_6[slice48],\r\n",
        "       train_regret_loser_7[slice48],\r\n",
        "       train_regret_loser_8[slice48],\r\n",
        "       train_regret_loser_9[slice48],\r\n",
        "       train_regret_loser_10[slice48],\r\n",
        "       train_regret_loser_11[slice48],\r\n",
        "       train_regret_loser_12[slice48],\r\n",
        "       train_regret_loser_13[slice48],\r\n",
        "       train_regret_loser_14[slice48],\r\n",
        "       train_regret_loser_15[slice48],\r\n",
        "       train_regret_loser_16[slice48],\r\n",
        "       train_regret_loser_17[slice48],\r\n",
        "       train_regret_loser_18[slice48],\r\n",
        "       train_regret_loser_19[slice48],\r\n",
        "       train_regret_loser_20[slice48]]\r\n",
        "\r\n",
        "winner48 = [train_regret_winner_1[slice48],\r\n",
        "       train_regret_winner_2[slice48],\r\n",
        "       train_regret_winner_3[slice48],\r\n",
        "       train_regret_winner_4[slice48],\r\n",
        "       train_regret_winner_5[slice48],\r\n",
        "       train_regret_winner_6[slice48],\r\n",
        "       train_regret_winner_7[slice48],\r\n",
        "       train_regret_winner_8[slice48],\r\n",
        "       train_regret_winner_9[slice48],\r\n",
        "       train_regret_winner_10[slice48],\r\n",
        "       train_regret_winner_11[slice48],\r\n",
        "       train_regret_winner_12[slice48],\r\n",
        "       train_regret_winner_13[slice48],\r\n",
        "       train_regret_winner_14[slice48],\r\n",
        "       train_regret_winner_15[slice48],\r\n",
        "       train_regret_winner_16[slice48],\r\n",
        "       train_regret_winner_17[slice48],\r\n",
        "       train_regret_winner_18[slice48],\r\n",
        "       train_regret_winner_19[slice48],\r\n",
        "       train_regret_winner_20[slice48]]\r\n",
        "\r\n",
        "loser48_results = pd.DataFrame(loser48).sort_values(by=[0], ascending=False)\r\n",
        "winner48_results = pd.DataFrame(winner48).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser48 = np.asarray(loser48_results[4:5][0])[0]\r\n",
        "median_loser48 = np.asarray(loser48_results[9:10][0])[0]\r\n",
        "upper_loser48 = np.asarray(loser48_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner48 = np.asarray(winner48_results[4:5][0])[0]\r\n",
        "median_winner48 = np.asarray(winner48_results[9:10][0])[0]\r\n",
        "upper_winner48 = np.asarray(winner48_results[14:15][0])[0]"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNpV6knOtejv"
      },
      "source": [
        "# Iteration58 :\r\n",
        "\r\n",
        "slice58 = 57\r\n",
        "\r\n",
        "loser58 = [train_regret_loser_1[slice58],\r\n",
        "       train_regret_loser_2[slice58],\r\n",
        "       train_regret_loser_3[slice58],\r\n",
        "       train_regret_loser_4[slice58],\r\n",
        "       train_regret_loser_5[slice58],\r\n",
        "       train_regret_loser_6[slice58],\r\n",
        "       train_regret_loser_7[slice58],\r\n",
        "       train_regret_loser_8[slice58],\r\n",
        "       train_regret_loser_9[slice58],\r\n",
        "       train_regret_loser_10[slice58],\r\n",
        "       train_regret_loser_11[slice58],\r\n",
        "       train_regret_loser_12[slice58],\r\n",
        "       train_regret_loser_13[slice58],\r\n",
        "       train_regret_loser_14[slice58],\r\n",
        "       train_regret_loser_15[slice58],\r\n",
        "       train_regret_loser_16[slice58],\r\n",
        "       train_regret_loser_17[slice58],\r\n",
        "       train_regret_loser_18[slice58],\r\n",
        "       train_regret_loser_19[slice58],\r\n",
        "       train_regret_loser_20[slice58]]\r\n",
        "\r\n",
        "winner58 = [train_regret_winner_1[slice58],\r\n",
        "       train_regret_winner_2[slice58],\r\n",
        "       train_regret_winner_3[slice58],\r\n",
        "       train_regret_winner_4[slice58],\r\n",
        "       train_regret_winner_5[slice58],\r\n",
        "       train_regret_winner_6[slice58],\r\n",
        "       train_regret_winner_7[slice58],\r\n",
        "       train_regret_winner_8[slice58],\r\n",
        "       train_regret_winner_9[slice58],\r\n",
        "       train_regret_winner_10[slice58],\r\n",
        "       train_regret_winner_11[slice58],\r\n",
        "       train_regret_winner_12[slice58],\r\n",
        "       train_regret_winner_13[slice58],\r\n",
        "       train_regret_winner_14[slice58],\r\n",
        "       train_regret_winner_15[slice58],\r\n",
        "       train_regret_winner_16[slice58],\r\n",
        "       train_regret_winner_17[slice58],\r\n",
        "       train_regret_winner_18[slice58],\r\n",
        "       train_regret_winner_19[slice58],\r\n",
        "       train_regret_winner_20[slice58]]\r\n",
        "\r\n",
        "loser58_results = pd.DataFrame(loser58).sort_values(by=[0], ascending=False)\r\n",
        "winner58_results = pd.DataFrame(winner58).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser58 = np.asarray(loser58_results[4:5][0])[0]\r\n",
        "median_loser58 = np.asarray(loser58_results[9:10][0])[0]\r\n",
        "upper_loser58 = np.asarray(loser58_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner58 = np.asarray(winner58_results[4:5][0])[0]\r\n",
        "median_winner58 = np.asarray(winner58_results[9:10][0])[0]\r\n",
        "upper_winner58 = np.asarray(winner58_results[14:15][0])[0]"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VFsqaBqtemn"
      },
      "source": [
        "# Iteration68 :\r\n",
        "\r\n",
        "slice68 = 67\r\n",
        "\r\n",
        "loser68 = [train_regret_loser_1[slice68],\r\n",
        "       train_regret_loser_2[slice68],\r\n",
        "       train_regret_loser_3[slice68],\r\n",
        "       train_regret_loser_4[slice68],\r\n",
        "       train_regret_loser_5[slice68],\r\n",
        "       train_regret_loser_6[slice68],\r\n",
        "       train_regret_loser_7[slice68],\r\n",
        "       train_regret_loser_8[slice68],\r\n",
        "       train_regret_loser_9[slice68],\r\n",
        "       train_regret_loser_10[slice68],\r\n",
        "       train_regret_loser_11[slice68],\r\n",
        "       train_regret_loser_12[slice68],\r\n",
        "       train_regret_loser_13[slice68],\r\n",
        "       train_regret_loser_14[slice68],\r\n",
        "       train_regret_loser_15[slice68],\r\n",
        "       train_regret_loser_16[slice68],\r\n",
        "       train_regret_loser_17[slice68],\r\n",
        "       train_regret_loser_18[slice68],\r\n",
        "       train_regret_loser_19[slice68],\r\n",
        "       train_regret_loser_20[slice68]]\r\n",
        "\r\n",
        "winner68 = [train_regret_winner_1[slice68],\r\n",
        "       train_regret_winner_2[slice68],\r\n",
        "       train_regret_winner_3[slice68],\r\n",
        "       train_regret_winner_4[slice68],\r\n",
        "       train_regret_winner_5[slice68],\r\n",
        "       train_regret_winner_6[slice68],\r\n",
        "       train_regret_winner_7[slice68],\r\n",
        "       train_regret_winner_8[slice68],\r\n",
        "       train_regret_winner_9[slice68],\r\n",
        "       train_regret_winner_10[slice68],\r\n",
        "       train_regret_winner_11[slice68],\r\n",
        "       train_regret_winner_12[slice68],\r\n",
        "       train_regret_winner_13[slice68],\r\n",
        "       train_regret_winner_14[slice68],\r\n",
        "       train_regret_winner_15[slice68],\r\n",
        "       train_regret_winner_16[slice68],\r\n",
        "       train_regret_winner_17[slice68],\r\n",
        "       train_regret_winner_18[slice68],\r\n",
        "       train_regret_winner_19[slice68],\r\n",
        "       train_regret_winner_20[slice68]]\r\n",
        "\r\n",
        "loser68_results = pd.DataFrame(loser68).sort_values(by=[0], ascending=False)\r\n",
        "winner68_results = pd.DataFrame(winner68).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser68 = np.asarray(loser68_results[4:5][0])[0]\r\n",
        "median_loser68 = np.asarray(loser68_results[9:10][0])[0]\r\n",
        "upper_loser68 = np.asarray(loser68_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner68 = np.asarray(winner68_results[4:5][0])[0]\r\n",
        "median_winner68 = np.asarray(winner68_results[9:10][0])[0]\r\n",
        "upper_winner68 = np.asarray(winner68_results[14:15][0])[0]"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XlFH0Wxtepo"
      },
      "source": [
        "# Iteration78 :\r\n",
        "\r\n",
        "slice78 = 77\r\n",
        "\r\n",
        "loser78 = [train_regret_loser_1[slice78],\r\n",
        "       train_regret_loser_2[slice78],\r\n",
        "       train_regret_loser_3[slice78],\r\n",
        "       train_regret_loser_4[slice78],\r\n",
        "       train_regret_loser_5[slice78],\r\n",
        "       train_regret_loser_6[slice78],\r\n",
        "       train_regret_loser_7[slice78],\r\n",
        "       train_regret_loser_8[slice78],\r\n",
        "       train_regret_loser_9[slice78],\r\n",
        "       train_regret_loser_10[slice78],\r\n",
        "       train_regret_loser_11[slice78],\r\n",
        "       train_regret_loser_12[slice78],\r\n",
        "       train_regret_loser_13[slice78],\r\n",
        "       train_regret_loser_14[slice78],\r\n",
        "       train_regret_loser_15[slice78],\r\n",
        "       train_regret_loser_16[slice78],\r\n",
        "       train_regret_loser_17[slice78],\r\n",
        "       train_regret_loser_18[slice78],\r\n",
        "       train_regret_loser_19[slice78],\r\n",
        "       train_regret_loser_20[slice78]]\r\n",
        "\r\n",
        "winner78 = [train_regret_winner_1[slice78],\r\n",
        "       train_regret_winner_2[slice78],\r\n",
        "       train_regret_winner_3[slice78],\r\n",
        "       train_regret_winner_4[slice78],\r\n",
        "       train_regret_winner_5[slice78],\r\n",
        "       train_regret_winner_6[slice78],\r\n",
        "       train_regret_winner_7[slice78],\r\n",
        "       train_regret_winner_8[slice78],\r\n",
        "       train_regret_winner_9[slice78],\r\n",
        "       train_regret_winner_10[slice78],\r\n",
        "       train_regret_winner_11[slice78],\r\n",
        "       train_regret_winner_12[slice78],\r\n",
        "       train_regret_winner_13[slice78],\r\n",
        "       train_regret_winner_14[slice78],\r\n",
        "       train_regret_winner_15[slice78],\r\n",
        "       train_regret_winner_16[slice78],\r\n",
        "       train_regret_winner_17[slice78],\r\n",
        "       train_regret_winner_18[slice78],\r\n",
        "       train_regret_winner_19[slice78],\r\n",
        "       train_regret_winner_20[slice78]]\r\n",
        "\r\n",
        "loser78_results = pd.DataFrame(loser78).sort_values(by=[0], ascending=False)\r\n",
        "winner78_results = pd.DataFrame(winner78).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser78 = np.asarray(loser78_results[4:5][0])[0]\r\n",
        "median_loser78 = np.asarray(loser78_results[9:10][0])[0]\r\n",
        "upper_loser78 = np.asarray(loser78_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner78 = np.asarray(winner78_results[4:5][0])[0]\r\n",
        "median_winner78 = np.asarray(winner78_results[9:10][0])[0]\r\n",
        "upper_winner78 = np.asarray(winner78_results[14:15][0])[0]"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsL0PJVetesC"
      },
      "source": [
        "# Iteration88 :\r\n",
        "\r\n",
        "slice88 = 87\r\n",
        "\r\n",
        "loser88 = [train_regret_loser_1[slice88],\r\n",
        "       train_regret_loser_2[slice88],\r\n",
        "       train_regret_loser_3[slice88],\r\n",
        "       train_regret_loser_4[slice88],\r\n",
        "       train_regret_loser_5[slice88],\r\n",
        "       train_regret_loser_6[slice88],\r\n",
        "       train_regret_loser_7[slice88],\r\n",
        "       train_regret_loser_8[slice88],\r\n",
        "       train_regret_loser_9[slice88],\r\n",
        "       train_regret_loser_10[slice88],\r\n",
        "       train_regret_loser_11[slice88],\r\n",
        "       train_regret_loser_12[slice88],\r\n",
        "       train_regret_loser_13[slice88],\r\n",
        "       train_regret_loser_14[slice88],\r\n",
        "       train_regret_loser_15[slice88],\r\n",
        "       train_regret_loser_16[slice88],\r\n",
        "       train_regret_loser_17[slice88],\r\n",
        "       train_regret_loser_18[slice88],\r\n",
        "       train_regret_loser_19[slice88],\r\n",
        "       train_regret_loser_20[slice88]]\r\n",
        "\r\n",
        "winner88 = [train_regret_winner_1[slice88],\r\n",
        "       train_regret_winner_2[slice88],\r\n",
        "       train_regret_winner_3[slice88],\r\n",
        "       train_regret_winner_4[slice88],\r\n",
        "       train_regret_winner_5[slice88],\r\n",
        "       train_regret_winner_6[slice88],\r\n",
        "       train_regret_winner_7[slice88],\r\n",
        "       train_regret_winner_8[slice88],\r\n",
        "       train_regret_winner_9[slice88],\r\n",
        "       train_regret_winner_10[slice88],\r\n",
        "       train_regret_winner_11[slice88],\r\n",
        "       train_regret_winner_12[slice88],\r\n",
        "       train_regret_winner_13[slice88],\r\n",
        "       train_regret_winner_14[slice88],\r\n",
        "       train_regret_winner_15[slice88],\r\n",
        "       train_regret_winner_16[slice88],\r\n",
        "       train_regret_winner_17[slice88],\r\n",
        "       train_regret_winner_18[slice88],\r\n",
        "       train_regret_winner_19[slice88],\r\n",
        "       train_regret_winner_20[slice88]]\r\n",
        "\r\n",
        "loser88_results = pd.DataFrame(loser88).sort_values(by=[0], ascending=False)\r\n",
        "winner88_results = pd.DataFrame(winner88).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser88 = np.asarray(loser88_results[4:5][0])[0]\r\n",
        "median_loser88 = np.asarray(loser88_results[9:10][0])[0]\r\n",
        "upper_loser88 = np.asarray(loser88_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner88 = np.asarray(winner88_results[4:5][0])[0]\r\n",
        "median_winner88 = np.asarray(winner88_results[9:10][0])[0]\r\n",
        "upper_winner88 = np.asarray(winner88_results[14:15][0])[0]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYWEWGku1o_9"
      },
      "source": [
        "# Iteration98 :\r\n",
        "\r\n",
        "slice98 = 97\r\n",
        "\r\n",
        "loser98 = [train_regret_loser_1[slice98],\r\n",
        "       train_regret_loser_2[slice98],\r\n",
        "       train_regret_loser_3[slice98],\r\n",
        "       train_regret_loser_4[slice98],\r\n",
        "       train_regret_loser_5[slice98],\r\n",
        "       train_regret_loser_6[slice98],\r\n",
        "       train_regret_loser_7[slice98],\r\n",
        "       train_regret_loser_8[slice98],\r\n",
        "       train_regret_loser_9[slice98],\r\n",
        "       train_regret_loser_10[slice98],\r\n",
        "       train_regret_loser_11[slice98],\r\n",
        "       train_regret_loser_12[slice98],\r\n",
        "       train_regret_loser_13[slice98],\r\n",
        "       train_regret_loser_14[slice98],\r\n",
        "       train_regret_loser_15[slice98],\r\n",
        "       train_regret_loser_16[slice98],\r\n",
        "       train_regret_loser_17[slice98],\r\n",
        "       train_regret_loser_18[slice98],\r\n",
        "       train_regret_loser_19[slice98],\r\n",
        "       train_regret_loser_20[slice98]]\r\n",
        "\r\n",
        "winner98 = [train_regret_winner_1[slice98],\r\n",
        "       train_regret_winner_2[slice98],\r\n",
        "       train_regret_winner_3[slice98],\r\n",
        "       train_regret_winner_4[slice98],\r\n",
        "       train_regret_winner_5[slice98],\r\n",
        "       train_regret_winner_6[slice98],\r\n",
        "       train_regret_winner_7[slice98],\r\n",
        "       train_regret_winner_8[slice98],\r\n",
        "       train_regret_winner_9[slice98],\r\n",
        "       train_regret_winner_10[slice98],\r\n",
        "       train_regret_winner_11[slice98],\r\n",
        "       train_regret_winner_12[slice98],\r\n",
        "       train_regret_winner_13[slice98],\r\n",
        "       train_regret_winner_14[slice98],\r\n",
        "       train_regret_winner_15[slice98],\r\n",
        "       train_regret_winner_16[slice98],\r\n",
        "       train_regret_winner_17[slice98],\r\n",
        "       train_regret_winner_18[slice98],\r\n",
        "       train_regret_winner_19[slice98],\r\n",
        "       train_regret_winner_20[slice98]]\r\n",
        "\r\n",
        "loser98_results = pd.DataFrame(loser98).sort_values(by=[0], ascending=False)\r\n",
        "winner98_results = pd.DataFrame(winner98).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser98 = np.asarray(loser98_results[4:5][0])[0]\r\n",
        "median_loser98 = np.asarray(loser98_results[9:10][0])[0]\r\n",
        "upper_loser98 = np.asarray(loser98_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner98 = np.asarray(winner98_results[4:5][0])[0]\r\n",
        "median_winner98 = np.asarray(winner98_results[9:10][0])[0]\r\n",
        "upper_winner98 = np.asarray(winner98_results[14:15][0])[0]"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guLGgcX91pDK"
      },
      "source": [
        "# Iteration9 :\r\n",
        "\r\n",
        "slice9 = 8\r\n",
        "\r\n",
        "loser9 = [train_regret_loser_1[slice9],\r\n",
        "       train_regret_loser_2[slice9],\r\n",
        "       train_regret_loser_3[slice9],\r\n",
        "       train_regret_loser_4[slice9],\r\n",
        "       train_regret_loser_5[slice9],\r\n",
        "       train_regret_loser_6[slice9],\r\n",
        "       train_regret_loser_7[slice9],\r\n",
        "       train_regret_loser_8[slice9],\r\n",
        "       train_regret_loser_9[slice9],\r\n",
        "       train_regret_loser_10[slice9],\r\n",
        "       train_regret_loser_11[slice9],\r\n",
        "       train_regret_loser_12[slice9],\r\n",
        "       train_regret_loser_13[slice9],\r\n",
        "       train_regret_loser_14[slice9],\r\n",
        "       train_regret_loser_15[slice9],\r\n",
        "       train_regret_loser_16[slice9],\r\n",
        "       train_regret_loser_17[slice9],\r\n",
        "       train_regret_loser_18[slice9],\r\n",
        "       train_regret_loser_19[slice9],\r\n",
        "       train_regret_loser_20[slice9]]\r\n",
        "\r\n",
        "winner9 = [train_regret_winner_1[slice9],\r\n",
        "       train_regret_winner_2[slice9],\r\n",
        "       train_regret_winner_3[slice9],\r\n",
        "       train_regret_winner_4[slice9],\r\n",
        "       train_regret_winner_5[slice9],\r\n",
        "       train_regret_winner_6[slice9],\r\n",
        "       train_regret_winner_7[slice9],\r\n",
        "       train_regret_winner_8[slice9],\r\n",
        "       train_regret_winner_9[slice9],\r\n",
        "       train_regret_winner_10[slice9],\r\n",
        "       train_regret_winner_11[slice9],\r\n",
        "       train_regret_winner_12[slice9],\r\n",
        "       train_regret_winner_13[slice9],\r\n",
        "       train_regret_winner_14[slice9],\r\n",
        "       train_regret_winner_15[slice9],\r\n",
        "       train_regret_winner_16[slice9],\r\n",
        "       train_regret_winner_17[slice9],\r\n",
        "       train_regret_winner_18[slice9],\r\n",
        "       train_regret_winner_19[slice9],\r\n",
        "       train_regret_winner_20[slice9]]\r\n",
        "\r\n",
        "loser9_results = pd.DataFrame(loser9).sort_values(by=[0], ascending=False)\r\n",
        "winner9_results = pd.DataFrame(winner9).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser9 = np.asarray(loser9_results[4:5][0])[0]\r\n",
        "median_loser9 = np.asarray(loser9_results[9:10][0])[0]\r\n",
        "upper_loser9 = np.asarray(loser9_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner9 = np.asarray(winner9_results[4:5][0])[0]\r\n",
        "median_winner9 = np.asarray(winner9_results[9:10][0])[0]\r\n",
        "upper_winner9 = np.asarray(winner9_results[14:15][0])[0]"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3_9-eoT1pGd"
      },
      "source": [
        "# Iteration19 :\r\n",
        "\r\n",
        "slice19 = 18\r\n",
        "\r\n",
        "loser19 = [train_regret_loser_1[slice19],\r\n",
        "       train_regret_loser_2[slice19],\r\n",
        "       train_regret_loser_3[slice19],\r\n",
        "       train_regret_loser_4[slice19],\r\n",
        "       train_regret_loser_5[slice19],\r\n",
        "       train_regret_loser_6[slice19],\r\n",
        "       train_regret_loser_7[slice19],\r\n",
        "       train_regret_loser_8[slice19],\r\n",
        "       train_regret_loser_9[slice19],\r\n",
        "       train_regret_loser_10[slice19],\r\n",
        "       train_regret_loser_11[slice19],\r\n",
        "       train_regret_loser_12[slice19],\r\n",
        "       train_regret_loser_13[slice19],\r\n",
        "       train_regret_loser_14[slice19],\r\n",
        "       train_regret_loser_15[slice19],\r\n",
        "       train_regret_loser_16[slice19],\r\n",
        "       train_regret_loser_17[slice19],\r\n",
        "       train_regret_loser_18[slice19],\r\n",
        "       train_regret_loser_19[slice19],\r\n",
        "       train_regret_loser_20[slice19]]\r\n",
        "\r\n",
        "winner19 = [train_regret_winner_1[slice19],\r\n",
        "       train_regret_winner_2[slice19],\r\n",
        "       train_regret_winner_3[slice19],\r\n",
        "       train_regret_winner_4[slice19],\r\n",
        "       train_regret_winner_5[slice19],\r\n",
        "       train_regret_winner_6[slice19],\r\n",
        "       train_regret_winner_7[slice19],\r\n",
        "       train_regret_winner_8[slice19],\r\n",
        "       train_regret_winner_9[slice19],\r\n",
        "       train_regret_winner_10[slice19],\r\n",
        "       train_regret_winner_11[slice19],\r\n",
        "       train_regret_winner_12[slice19],\r\n",
        "       train_regret_winner_13[slice19],\r\n",
        "       train_regret_winner_14[slice19],\r\n",
        "       train_regret_winner_15[slice19],\r\n",
        "       train_regret_winner_16[slice19],\r\n",
        "       train_regret_winner_17[slice19],\r\n",
        "       train_regret_winner_18[slice19],\r\n",
        "       train_regret_winner_19[slice19],\r\n",
        "       train_regret_winner_20[slice19]]\r\n",
        "\r\n",
        "loser19_results = pd.DataFrame(loser19).sort_values(by=[0], ascending=False)\r\n",
        "winner19_results = pd.DataFrame(winner19).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser19 = np.asarray(loser19_results[4:5][0])[0]\r\n",
        "median_loser19 = np.asarray(loser19_results[9:10][0])[0]\r\n",
        "upper_loser19 = np.asarray(loser19_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner19 = np.asarray(winner19_results[4:5][0])[0]\r\n",
        "median_winner19 = np.asarray(winner19_results[9:10][0])[0]\r\n",
        "upper_winner19 = np.asarray(winner19_results[14:15][0])[0]"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ae5x13M1pRp"
      },
      "source": [
        "# Iteration29 :\r\n",
        "\r\n",
        "slice29 = 28\r\n",
        "\r\n",
        "loser29 = [train_regret_loser_1[slice29],\r\n",
        "       train_regret_loser_2[slice29],\r\n",
        "       train_regret_loser_3[slice29],\r\n",
        "       train_regret_loser_4[slice29],\r\n",
        "       train_regret_loser_5[slice29],\r\n",
        "       train_regret_loser_6[slice29],\r\n",
        "       train_regret_loser_7[slice29],\r\n",
        "       train_regret_loser_8[slice29],\r\n",
        "       train_regret_loser_9[slice29],\r\n",
        "       train_regret_loser_10[slice29],\r\n",
        "       train_regret_loser_11[slice29],\r\n",
        "       train_regret_loser_12[slice29],\r\n",
        "       train_regret_loser_13[slice29],\r\n",
        "       train_regret_loser_14[slice29],\r\n",
        "       train_regret_loser_15[slice29],\r\n",
        "       train_regret_loser_16[slice29],\r\n",
        "       train_regret_loser_17[slice29],\r\n",
        "       train_regret_loser_18[slice29],\r\n",
        "       train_regret_loser_19[slice29],\r\n",
        "       train_regret_loser_20[slice29]]\r\n",
        "\r\n",
        "winner29 = [train_regret_winner_1[slice29],\r\n",
        "       train_regret_winner_2[slice29],\r\n",
        "       train_regret_winner_3[slice29],\r\n",
        "       train_regret_winner_4[slice29],\r\n",
        "       train_regret_winner_5[slice29],\r\n",
        "       train_regret_winner_6[slice29],\r\n",
        "       train_regret_winner_7[slice29],\r\n",
        "       train_regret_winner_8[slice29],\r\n",
        "       train_regret_winner_9[slice29],\r\n",
        "       train_regret_winner_10[slice29],\r\n",
        "       train_regret_winner_11[slice29],\r\n",
        "       train_regret_winner_12[slice29],\r\n",
        "       train_regret_winner_13[slice29],\r\n",
        "       train_regret_winner_14[slice29],\r\n",
        "       train_regret_winner_15[slice29],\r\n",
        "       train_regret_winner_16[slice29],\r\n",
        "       train_regret_winner_17[slice29],\r\n",
        "       train_regret_winner_18[slice29],\r\n",
        "       train_regret_winner_19[slice29],\r\n",
        "       train_regret_winner_20[slice29]]\r\n",
        "\r\n",
        "loser29_results = pd.DataFrame(loser29).sort_values(by=[0], ascending=False)\r\n",
        "winner29_results = pd.DataFrame(winner29).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser29 = np.asarray(loser29_results[4:5][0])[0]\r\n",
        "median_loser29 = np.asarray(loser29_results[9:10][0])[0]\r\n",
        "upper_loser29 = np.asarray(loser29_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner29 = np.asarray(winner29_results[4:5][0])[0]\r\n",
        "median_winner29 = np.asarray(winner29_results[9:10][0])[0]\r\n",
        "upper_winner29 = np.asarray(winner29_results[14:15][0])[0]"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR9aPvBy1pUc"
      },
      "source": [
        "# Iteration39 :\r\n",
        "\r\n",
        "slice39 = 38\r\n",
        "\r\n",
        "loser39 = [train_regret_loser_1[slice39],\r\n",
        "       train_regret_loser_2[slice39],\r\n",
        "       train_regret_loser_3[slice39],\r\n",
        "       train_regret_loser_4[slice39],\r\n",
        "       train_regret_loser_5[slice39],\r\n",
        "       train_regret_loser_6[slice39],\r\n",
        "       train_regret_loser_7[slice39],\r\n",
        "       train_regret_loser_8[slice39],\r\n",
        "       train_regret_loser_9[slice39],\r\n",
        "       train_regret_loser_10[slice39],\r\n",
        "       train_regret_loser_11[slice39],\r\n",
        "       train_regret_loser_12[slice39],\r\n",
        "       train_regret_loser_13[slice39],\r\n",
        "       train_regret_loser_14[slice39],\r\n",
        "       train_regret_loser_15[slice39],\r\n",
        "       train_regret_loser_16[slice39],\r\n",
        "       train_regret_loser_17[slice39],\r\n",
        "       train_regret_loser_18[slice39],\r\n",
        "       train_regret_loser_19[slice39],\r\n",
        "       train_regret_loser_20[slice39]]\r\n",
        "\r\n",
        "winner39 = [train_regret_winner_1[slice39],\r\n",
        "       train_regret_winner_2[slice39],\r\n",
        "       train_regret_winner_3[slice39],\r\n",
        "       train_regret_winner_4[slice39],\r\n",
        "       train_regret_winner_5[slice39],\r\n",
        "       train_regret_winner_6[slice39],\r\n",
        "       train_regret_winner_7[slice39],\r\n",
        "       train_regret_winner_8[slice39],\r\n",
        "       train_regret_winner_9[slice39],\r\n",
        "       train_regret_winner_10[slice39],\r\n",
        "       train_regret_winner_11[slice39],\r\n",
        "       train_regret_winner_12[slice39],\r\n",
        "       train_regret_winner_13[slice39],\r\n",
        "       train_regret_winner_14[slice39],\r\n",
        "       train_regret_winner_15[slice39],\r\n",
        "       train_regret_winner_16[slice39],\r\n",
        "       train_regret_winner_17[slice39],\r\n",
        "       train_regret_winner_18[slice39],\r\n",
        "       train_regret_winner_19[slice39],\r\n",
        "       train_regret_winner_20[slice39]]\r\n",
        "\r\n",
        "loser39_results = pd.DataFrame(loser39).sort_values(by=[0], ascending=False)\r\n",
        "winner39_results = pd.DataFrame(winner39).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser39 = np.asarray(loser39_results[4:5][0])[0]\r\n",
        "median_loser39 = np.asarray(loser39_results[9:10][0])[0]\r\n",
        "upper_loser39 = np.asarray(loser39_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner39 = np.asarray(winner39_results[4:5][0])[0]\r\n",
        "median_winner39 = np.asarray(winner39_results[9:10][0])[0]\r\n",
        "upper_winner39 = np.asarray(winner39_results[14:15][0])[0]"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vb7vh2K1pXp"
      },
      "source": [
        "# Iteration49 :\r\n",
        "\r\n",
        "slice49 = 48\r\n",
        "\r\n",
        "loser49 = [train_regret_loser_1[slice49],\r\n",
        "       train_regret_loser_2[slice49],\r\n",
        "       train_regret_loser_3[slice49],\r\n",
        "       train_regret_loser_4[slice49],\r\n",
        "       train_regret_loser_5[slice49],\r\n",
        "       train_regret_loser_6[slice49],\r\n",
        "       train_regret_loser_7[slice49],\r\n",
        "       train_regret_loser_8[slice49],\r\n",
        "       train_regret_loser_9[slice49],\r\n",
        "       train_regret_loser_10[slice49],\r\n",
        "       train_regret_loser_11[slice49],\r\n",
        "       train_regret_loser_12[slice49],\r\n",
        "       train_regret_loser_13[slice49],\r\n",
        "       train_regret_loser_14[slice49],\r\n",
        "       train_regret_loser_15[slice49],\r\n",
        "       train_regret_loser_16[slice49],\r\n",
        "       train_regret_loser_17[slice49],\r\n",
        "       train_regret_loser_18[slice49],\r\n",
        "       train_regret_loser_19[slice49],\r\n",
        "       train_regret_loser_20[slice49]]\r\n",
        "\r\n",
        "winner49 = [train_regret_winner_1[slice49],\r\n",
        "       train_regret_winner_2[slice49],\r\n",
        "       train_regret_winner_3[slice49],\r\n",
        "       train_regret_winner_4[slice49],\r\n",
        "       train_regret_winner_5[slice49],\r\n",
        "       train_regret_winner_6[slice49],\r\n",
        "       train_regret_winner_7[slice49],\r\n",
        "       train_regret_winner_8[slice49],\r\n",
        "       train_regret_winner_9[slice49],\r\n",
        "       train_regret_winner_10[slice49],\r\n",
        "       train_regret_winner_11[slice49],\r\n",
        "       train_regret_winner_12[slice49],\r\n",
        "       train_regret_winner_13[slice49],\r\n",
        "       train_regret_winner_14[slice49],\r\n",
        "       train_regret_winner_15[slice49],\r\n",
        "       train_regret_winner_16[slice49],\r\n",
        "       train_regret_winner_17[slice49],\r\n",
        "       train_regret_winner_18[slice49],\r\n",
        "       train_regret_winner_19[slice49],\r\n",
        "       train_regret_winner_20[slice49]]\r\n",
        "\r\n",
        "loser49_results = pd.DataFrame(loser49).sort_values(by=[0], ascending=False)\r\n",
        "winner49_results = pd.DataFrame(winner49).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser49 = np.asarray(loser49_results[4:5][0])[0]\r\n",
        "median_loser49 = np.asarray(loser49_results[9:10][0])[0]\r\n",
        "upper_loser49 = np.asarray(loser49_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner49 = np.asarray(winner49_results[4:5][0])[0]\r\n",
        "median_winner49 = np.asarray(winner49_results[9:10][0])[0]\r\n",
        "upper_winner49 = np.asarray(winner49_results[14:15][0])[0]"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wN7DWwt1paM"
      },
      "source": [
        "# Iteration59 :\r\n",
        "\r\n",
        "slice59 = 58\r\n",
        "\r\n",
        "loser59 = [train_regret_loser_1[slice59],\r\n",
        "       train_regret_loser_2[slice59],\r\n",
        "       train_regret_loser_3[slice59],\r\n",
        "       train_regret_loser_4[slice59],\r\n",
        "       train_regret_loser_5[slice59],\r\n",
        "       train_regret_loser_6[slice59],\r\n",
        "       train_regret_loser_7[slice59],\r\n",
        "       train_regret_loser_8[slice59],\r\n",
        "       train_regret_loser_9[slice59],\r\n",
        "       train_regret_loser_10[slice59],\r\n",
        "       train_regret_loser_11[slice59],\r\n",
        "       train_regret_loser_12[slice59],\r\n",
        "       train_regret_loser_13[slice59],\r\n",
        "       train_regret_loser_14[slice59],\r\n",
        "       train_regret_loser_15[slice59],\r\n",
        "       train_regret_loser_16[slice59],\r\n",
        "       train_regret_loser_17[slice59],\r\n",
        "       train_regret_loser_18[slice59],\r\n",
        "       train_regret_loser_19[slice59],\r\n",
        "       train_regret_loser_20[slice59]]\r\n",
        "\r\n",
        "winner59 = [train_regret_winner_1[slice59],\r\n",
        "       train_regret_winner_2[slice59],\r\n",
        "       train_regret_winner_3[slice59],\r\n",
        "       train_regret_winner_4[slice59],\r\n",
        "       train_regret_winner_5[slice59],\r\n",
        "       train_regret_winner_6[slice59],\r\n",
        "       train_regret_winner_7[slice59],\r\n",
        "       train_regret_winner_8[slice59],\r\n",
        "       train_regret_winner_9[slice59],\r\n",
        "       train_regret_winner_10[slice59],\r\n",
        "       train_regret_winner_11[slice59],\r\n",
        "       train_regret_winner_12[slice59],\r\n",
        "       train_regret_winner_13[slice59],\r\n",
        "       train_regret_winner_14[slice59],\r\n",
        "       train_regret_winner_15[slice59],\r\n",
        "       train_regret_winner_16[slice59],\r\n",
        "       train_regret_winner_17[slice59],\r\n",
        "       train_regret_winner_18[slice59],\r\n",
        "       train_regret_winner_19[slice59],\r\n",
        "       train_regret_winner_20[slice59]]\r\n",
        "\r\n",
        "loser59_results = pd.DataFrame(loser59).sort_values(by=[0], ascending=False)\r\n",
        "winner59_results = pd.DataFrame(winner59).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser59 = np.asarray(loser59_results[4:5][0])[0]\r\n",
        "median_loser59 = np.asarray(loser59_results[9:10][0])[0]\r\n",
        "upper_loser59 = np.asarray(loser59_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner59 = np.asarray(winner59_results[4:5][0])[0]\r\n",
        "median_winner59 = np.asarray(winner59_results[9:10][0])[0]\r\n",
        "upper_winner59 = np.asarray(winner59_results[14:15][0])[0]"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqtgekml1pde"
      },
      "source": [
        "# Iteration69 :\r\n",
        "\r\n",
        "slice69 = 68\r\n",
        "\r\n",
        "loser69 = [train_regret_loser_1[slice69],\r\n",
        "       train_regret_loser_2[slice69],\r\n",
        "       train_regret_loser_3[slice69],\r\n",
        "       train_regret_loser_4[slice69],\r\n",
        "       train_regret_loser_5[slice69],\r\n",
        "       train_regret_loser_6[slice69],\r\n",
        "       train_regret_loser_7[slice69],\r\n",
        "       train_regret_loser_8[slice69],\r\n",
        "       train_regret_loser_9[slice69],\r\n",
        "       train_regret_loser_10[slice69],\r\n",
        "       train_regret_loser_11[slice69],\r\n",
        "       train_regret_loser_12[slice69],\r\n",
        "       train_regret_loser_13[slice69],\r\n",
        "       train_regret_loser_14[slice69],\r\n",
        "       train_regret_loser_15[slice69],\r\n",
        "       train_regret_loser_16[slice69],\r\n",
        "       train_regret_loser_17[slice69],\r\n",
        "       train_regret_loser_18[slice69],\r\n",
        "       train_regret_loser_19[slice69],\r\n",
        "       train_regret_loser_20[slice69]]\r\n",
        "\r\n",
        "winner69 = [train_regret_winner_1[slice69],\r\n",
        "       train_regret_winner_2[slice69],\r\n",
        "       train_regret_winner_3[slice69],\r\n",
        "       train_regret_winner_4[slice69],\r\n",
        "       train_regret_winner_5[slice69],\r\n",
        "       train_regret_winner_6[slice69],\r\n",
        "       train_regret_winner_7[slice69],\r\n",
        "       train_regret_winner_8[slice69],\r\n",
        "       train_regret_winner_9[slice69],\r\n",
        "       train_regret_winner_10[slice69],\r\n",
        "       train_regret_winner_11[slice69],\r\n",
        "       train_regret_winner_12[slice69],\r\n",
        "       train_regret_winner_13[slice69],\r\n",
        "       train_regret_winner_14[slice69],\r\n",
        "       train_regret_winner_15[slice69],\r\n",
        "       train_regret_winner_16[slice69],\r\n",
        "       train_regret_winner_17[slice69],\r\n",
        "       train_regret_winner_18[slice69],\r\n",
        "       train_regret_winner_19[slice69],\r\n",
        "       train_regret_winner_20[slice69]]\r\n",
        "\r\n",
        "loser69_results = pd.DataFrame(loser69).sort_values(by=[0], ascending=False)\r\n",
        "winner69_results = pd.DataFrame(winner69).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser69 = np.asarray(loser69_results[4:5][0])[0]\r\n",
        "median_loser69 = np.asarray(loser69_results[9:10][0])[0]\r\n",
        "upper_loser69 = np.asarray(loser69_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner69 = np.asarray(winner69_results[4:5][0])[0]\r\n",
        "median_winner69 = np.asarray(winner69_results[9:10][0])[0]\r\n",
        "upper_winner69 = np.asarray(winner69_results[14:15][0])[0]"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFTa1171pgF"
      },
      "source": [
        "# Iteration79 :\r\n",
        "\r\n",
        "slice79 = 78\r\n",
        "\r\n",
        "loser79 = [train_regret_loser_1[slice79],\r\n",
        "       train_regret_loser_2[slice79],\r\n",
        "       train_regret_loser_3[slice79],\r\n",
        "       train_regret_loser_4[slice79],\r\n",
        "       train_regret_loser_5[slice79],\r\n",
        "       train_regret_loser_6[slice79],\r\n",
        "       train_regret_loser_7[slice79],\r\n",
        "       train_regret_loser_8[slice79],\r\n",
        "       train_regret_loser_9[slice79],\r\n",
        "       train_regret_loser_10[slice79],\r\n",
        "       train_regret_loser_11[slice79],\r\n",
        "       train_regret_loser_12[slice79],\r\n",
        "       train_regret_loser_13[slice79],\r\n",
        "       train_regret_loser_14[slice79],\r\n",
        "       train_regret_loser_15[slice79],\r\n",
        "       train_regret_loser_16[slice79],\r\n",
        "       train_regret_loser_17[slice79],\r\n",
        "       train_regret_loser_18[slice79],\r\n",
        "       train_regret_loser_19[slice79],\r\n",
        "       train_regret_loser_20[slice79]]\r\n",
        "\r\n",
        "winner79 = [train_regret_winner_1[slice79],\r\n",
        "       train_regret_winner_2[slice79],\r\n",
        "       train_regret_winner_3[slice79],\r\n",
        "       train_regret_winner_4[slice79],\r\n",
        "       train_regret_winner_5[slice79],\r\n",
        "       train_regret_winner_6[slice79],\r\n",
        "       train_regret_winner_7[slice79],\r\n",
        "       train_regret_winner_8[slice79],\r\n",
        "       train_regret_winner_9[slice79],\r\n",
        "       train_regret_winner_10[slice79],\r\n",
        "       train_regret_winner_11[slice79],\r\n",
        "       train_regret_winner_12[slice79],\r\n",
        "       train_regret_winner_13[slice79],\r\n",
        "       train_regret_winner_14[slice79],\r\n",
        "       train_regret_winner_15[slice79],\r\n",
        "       train_regret_winner_16[slice79],\r\n",
        "       train_regret_winner_17[slice79],\r\n",
        "       train_regret_winner_18[slice79],\r\n",
        "       train_regret_winner_19[slice79],\r\n",
        "       train_regret_winner_20[slice79]]\r\n",
        "\r\n",
        "loser79_results = pd.DataFrame(loser79).sort_values(by=[0], ascending=False)\r\n",
        "winner79_results = pd.DataFrame(winner79).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser79 = np.asarray(loser79_results[4:5][0])[0]\r\n",
        "median_loser79 = np.asarray(loser79_results[9:10][0])[0]\r\n",
        "upper_loser79 = np.asarray(loser79_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner79 = np.asarray(winner79_results[4:5][0])[0]\r\n",
        "median_winner79 = np.asarray(winner79_results[9:10][0])[0]\r\n",
        "upper_winner79 = np.asarray(winner79_results[14:15][0])[0]"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTnRF4lx1pio"
      },
      "source": [
        "# Iteration89 :\r\n",
        "\r\n",
        "slice89 = 88\r\n",
        "\r\n",
        "loser89 = [train_regret_loser_1[slice89],\r\n",
        "       train_regret_loser_2[slice89],\r\n",
        "       train_regret_loser_3[slice89],\r\n",
        "       train_regret_loser_4[slice89],\r\n",
        "       train_regret_loser_5[slice89],\r\n",
        "       train_regret_loser_6[slice89],\r\n",
        "       train_regret_loser_7[slice89],\r\n",
        "       train_regret_loser_8[slice89],\r\n",
        "       train_regret_loser_9[slice89],\r\n",
        "       train_regret_loser_10[slice89],\r\n",
        "       train_regret_loser_11[slice89],\r\n",
        "       train_regret_loser_12[slice89],\r\n",
        "       train_regret_loser_13[slice89],\r\n",
        "       train_regret_loser_14[slice89],\r\n",
        "       train_regret_loser_15[slice89],\r\n",
        "       train_regret_loser_16[slice89],\r\n",
        "       train_regret_loser_17[slice89],\r\n",
        "       train_regret_loser_18[slice89],\r\n",
        "       train_regret_loser_19[slice89],\r\n",
        "       train_regret_loser_20[slice89]]\r\n",
        "\r\n",
        "winner89 = [train_regret_winner_1[slice89],\r\n",
        "       train_regret_winner_2[slice89],\r\n",
        "       train_regret_winner_3[slice89],\r\n",
        "       train_regret_winner_4[slice89],\r\n",
        "       train_regret_winner_5[slice89],\r\n",
        "       train_regret_winner_6[slice89],\r\n",
        "       train_regret_winner_7[slice89],\r\n",
        "       train_regret_winner_8[slice89],\r\n",
        "       train_regret_winner_9[slice89],\r\n",
        "       train_regret_winner_10[slice89],\r\n",
        "       train_regret_winner_11[slice89],\r\n",
        "       train_regret_winner_12[slice89],\r\n",
        "       train_regret_winner_13[slice89],\r\n",
        "       train_regret_winner_14[slice89],\r\n",
        "       train_regret_winner_15[slice89],\r\n",
        "       train_regret_winner_16[slice89],\r\n",
        "       train_regret_winner_17[slice89],\r\n",
        "       train_regret_winner_18[slice89],\r\n",
        "       train_regret_winner_19[slice89],\r\n",
        "       train_regret_winner_20[slice89]]\r\n",
        "\r\n",
        "loser89_results = pd.DataFrame(loser89).sort_values(by=[0], ascending=False)\r\n",
        "winner89_results = pd.DataFrame(winner89).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser89 = np.asarray(loser89_results[4:5][0])[0]\r\n",
        "median_loser89 = np.asarray(loser89_results[9:10][0])[0]\r\n",
        "upper_loser89 = np.asarray(loser89_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner89 = np.asarray(winner89_results[4:5][0])[0]\r\n",
        "median_winner89 = np.asarray(winner89_results[9:10][0])[0]\r\n",
        "upper_winner89 = np.asarray(winner89_results[14:15][0])[0]"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiLAF38i1plO"
      },
      "source": [
        "# Iteration99 :\r\n",
        "\r\n",
        "slice99 = 98\r\n",
        "\r\n",
        "loser99 = [train_regret_loser_1[slice99],\r\n",
        "       train_regret_loser_2[slice99],\r\n",
        "       train_regret_loser_3[slice99],\r\n",
        "       train_regret_loser_4[slice99],\r\n",
        "       train_regret_loser_5[slice99],\r\n",
        "       train_regret_loser_6[slice99],\r\n",
        "       train_regret_loser_7[slice99],\r\n",
        "       train_regret_loser_8[slice99],\r\n",
        "       train_regret_loser_9[slice99],\r\n",
        "       train_regret_loser_10[slice99],\r\n",
        "       train_regret_loser_11[slice99],\r\n",
        "       train_regret_loser_12[slice99],\r\n",
        "       train_regret_loser_13[slice99],\r\n",
        "       train_regret_loser_14[slice99],\r\n",
        "       train_regret_loser_15[slice99],\r\n",
        "       train_regret_loser_16[slice99],\r\n",
        "       train_regret_loser_17[slice99],\r\n",
        "       train_regret_loser_18[slice99],\r\n",
        "       train_regret_loser_19[slice99],\r\n",
        "       train_regret_loser_20[slice99]]\r\n",
        "\r\n",
        "winner99 = [train_regret_winner_1[slice99],\r\n",
        "       train_regret_winner_2[slice99],\r\n",
        "       train_regret_winner_3[slice99],\r\n",
        "       train_regret_winner_4[slice99],\r\n",
        "       train_regret_winner_5[slice99],\r\n",
        "       train_regret_winner_6[slice99],\r\n",
        "       train_regret_winner_7[slice99],\r\n",
        "       train_regret_winner_8[slice99],\r\n",
        "       train_regret_winner_9[slice99],\r\n",
        "       train_regret_winner_10[slice99],\r\n",
        "       train_regret_winner_11[slice99],\r\n",
        "       train_regret_winner_12[slice99],\r\n",
        "       train_regret_winner_13[slice99],\r\n",
        "       train_regret_winner_14[slice99],\r\n",
        "       train_regret_winner_15[slice99],\r\n",
        "       train_regret_winner_16[slice99],\r\n",
        "       train_regret_winner_17[slice99],\r\n",
        "       train_regret_winner_18[slice99],\r\n",
        "       train_regret_winner_19[slice99],\r\n",
        "       train_regret_winner_20[slice99]]\r\n",
        "\r\n",
        "loser99_results = pd.DataFrame(loser99).sort_values(by=[0], ascending=False)\r\n",
        "winner99_results = pd.DataFrame(winner99).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser99 = np.asarray(loser99_results[4:5][0])[0]\r\n",
        "median_loser99 = np.asarray(loser99_results[9:10][0])[0]\r\n",
        "upper_loser99 = np.asarray(loser99_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner99 = np.asarray(winner99_results[4:5][0])[0]\r\n",
        "median_winner99 = np.asarray(winner99_results[9:10][0])[0]\r\n",
        "upper_winner99 = np.asarray(winner99_results[14:15][0])[0]"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBd_N0F21pn0"
      },
      "source": [
        "# Iteration10 :\r\n",
        "\r\n",
        "slice10 = 9\r\n",
        "\r\n",
        "loser10 = [train_regret_loser_1[slice10],\r\n",
        "       train_regret_loser_2[slice10],\r\n",
        "       train_regret_loser_3[slice10],\r\n",
        "       train_regret_loser_4[slice10],\r\n",
        "       train_regret_loser_5[slice10],\r\n",
        "       train_regret_loser_6[slice10],\r\n",
        "       train_regret_loser_7[slice10],\r\n",
        "       train_regret_loser_8[slice10],\r\n",
        "       train_regret_loser_9[slice10],\r\n",
        "       train_regret_loser_10[slice10],\r\n",
        "       train_regret_loser_11[slice10],\r\n",
        "       train_regret_loser_12[slice10],\r\n",
        "       train_regret_loser_13[slice10],\r\n",
        "       train_regret_loser_14[slice10],\r\n",
        "       train_regret_loser_15[slice10],\r\n",
        "       train_regret_loser_16[slice10],\r\n",
        "       train_regret_loser_17[slice10],\r\n",
        "       train_regret_loser_18[slice10],\r\n",
        "       train_regret_loser_19[slice10],\r\n",
        "       train_regret_loser_20[slice10]]\r\n",
        "\r\n",
        "winner10 = [train_regret_winner_1[slice10],\r\n",
        "       train_regret_winner_2[slice10],\r\n",
        "       train_regret_winner_3[slice10],\r\n",
        "       train_regret_winner_4[slice10],\r\n",
        "       train_regret_winner_5[slice10],\r\n",
        "       train_regret_winner_6[slice10],\r\n",
        "       train_regret_winner_7[slice10],\r\n",
        "       train_regret_winner_8[slice10],\r\n",
        "       train_regret_winner_9[slice10],\r\n",
        "       train_regret_winner_10[slice10],\r\n",
        "       train_regret_winner_11[slice10],\r\n",
        "       train_regret_winner_12[slice10],\r\n",
        "       train_regret_winner_13[slice10],\r\n",
        "       train_regret_winner_14[slice10],\r\n",
        "       train_regret_winner_15[slice10],\r\n",
        "       train_regret_winner_16[slice10],\r\n",
        "       train_regret_winner_17[slice10],\r\n",
        "       train_regret_winner_18[slice10],\r\n",
        "       train_regret_winner_19[slice10],\r\n",
        "       train_regret_winner_20[slice10]]\r\n",
        "\r\n",
        "loser10_results = pd.DataFrame(loser10).sort_values(by=[0], ascending=False)\r\n",
        "winner10_results = pd.DataFrame(winner10).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser10 = np.asarray(loser10_results[4:5][0])[0]\r\n",
        "median_loser10 = np.asarray(loser10_results[9:10][0])[0]\r\n",
        "upper_loser10 = np.asarray(loser10_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner10 = np.asarray(winner10_results[4:5][0])[0]\r\n",
        "median_winner10 = np.asarray(winner10_results[9:10][0])[0]\r\n",
        "upper_winner10 = np.asarray(winner10_results[14:15][0])[0]"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXjdqc4s1pqb"
      },
      "source": [
        "# Iteration20 :\r\n",
        "\r\n",
        "slice20 = 19\r\n",
        "\r\n",
        "loser20 = [train_regret_loser_1[slice20],\r\n",
        "       train_regret_loser_2[slice20],\r\n",
        "       train_regret_loser_3[slice20],\r\n",
        "       train_regret_loser_4[slice20],\r\n",
        "       train_regret_loser_5[slice20],\r\n",
        "       train_regret_loser_6[slice20],\r\n",
        "       train_regret_loser_7[slice20],\r\n",
        "       train_regret_loser_8[slice20],\r\n",
        "       train_regret_loser_9[slice20],\r\n",
        "       train_regret_loser_10[slice20],\r\n",
        "       train_regret_loser_11[slice20],\r\n",
        "       train_regret_loser_12[slice20],\r\n",
        "       train_regret_loser_13[slice20],\r\n",
        "       train_regret_loser_14[slice20],\r\n",
        "       train_regret_loser_15[slice20],\r\n",
        "       train_regret_loser_16[slice20],\r\n",
        "       train_regret_loser_17[slice20],\r\n",
        "       train_regret_loser_18[slice20],\r\n",
        "       train_regret_loser_19[slice20],\r\n",
        "       train_regret_loser_20[slice20]]\r\n",
        "\r\n",
        "winner20 = [train_regret_winner_1[slice20],\r\n",
        "       train_regret_winner_2[slice20],\r\n",
        "       train_regret_winner_3[slice20],\r\n",
        "       train_regret_winner_4[slice20],\r\n",
        "       train_regret_winner_5[slice20],\r\n",
        "       train_regret_winner_6[slice20],\r\n",
        "       train_regret_winner_7[slice20],\r\n",
        "       train_regret_winner_8[slice20],\r\n",
        "       train_regret_winner_9[slice20],\r\n",
        "       train_regret_winner_10[slice20],\r\n",
        "       train_regret_winner_11[slice20],\r\n",
        "       train_regret_winner_12[slice20],\r\n",
        "       train_regret_winner_13[slice20],\r\n",
        "       train_regret_winner_14[slice20],\r\n",
        "       train_regret_winner_15[slice20],\r\n",
        "       train_regret_winner_16[slice20],\r\n",
        "       train_regret_winner_17[slice20],\r\n",
        "       train_regret_winner_18[slice20],\r\n",
        "       train_regret_winner_19[slice20],\r\n",
        "       train_regret_winner_20[slice20]]\r\n",
        "\r\n",
        "loser20_results = pd.DataFrame(loser20).sort_values(by=[0], ascending=False)\r\n",
        "winner20_results = pd.DataFrame(winner20).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser20 = np.asarray(loser20_results[4:5][0])[0]\r\n",
        "median_loser20 = np.asarray(loser20_results[9:10][0])[0]\r\n",
        "upper_loser20 = np.asarray(loser20_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner20 = np.asarray(winner20_results[4:5][0])[0]\r\n",
        "median_winner20 = np.asarray(winner20_results[9:10][0])[0]\r\n",
        "upper_winner20 = np.asarray(winner20_results[14:15][0])[0]"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQBVS6dx1ptB"
      },
      "source": [
        "# Iteration30 :\r\n",
        "\r\n",
        "slice30 = 29\r\n",
        "\r\n",
        "loser30 = [train_regret_loser_1[slice30],\r\n",
        "       train_regret_loser_2[slice30],\r\n",
        "       train_regret_loser_3[slice30],\r\n",
        "       train_regret_loser_4[slice30],\r\n",
        "       train_regret_loser_5[slice30],\r\n",
        "       train_regret_loser_6[slice30],\r\n",
        "       train_regret_loser_7[slice30],\r\n",
        "       train_regret_loser_8[slice30],\r\n",
        "       train_regret_loser_9[slice30],\r\n",
        "       train_regret_loser_10[slice30],\r\n",
        "       train_regret_loser_11[slice30],\r\n",
        "       train_regret_loser_12[slice30],\r\n",
        "       train_regret_loser_13[slice30],\r\n",
        "       train_regret_loser_14[slice30],\r\n",
        "       train_regret_loser_15[slice30],\r\n",
        "       train_regret_loser_16[slice30],\r\n",
        "       train_regret_loser_17[slice30],\r\n",
        "       train_regret_loser_18[slice30],\r\n",
        "       train_regret_loser_19[slice30],\r\n",
        "       train_regret_loser_20[slice30]]\r\n",
        "\r\n",
        "winner30 = [train_regret_winner_1[slice30],\r\n",
        "       train_regret_winner_2[slice30],\r\n",
        "       train_regret_winner_3[slice30],\r\n",
        "       train_regret_winner_4[slice30],\r\n",
        "       train_regret_winner_5[slice30],\r\n",
        "       train_regret_winner_6[slice30],\r\n",
        "       train_regret_winner_7[slice30],\r\n",
        "       train_regret_winner_8[slice30],\r\n",
        "       train_regret_winner_9[slice30],\r\n",
        "       train_regret_winner_10[slice30],\r\n",
        "       train_regret_winner_11[slice30],\r\n",
        "       train_regret_winner_12[slice30],\r\n",
        "       train_regret_winner_13[slice30],\r\n",
        "       train_regret_winner_14[slice30],\r\n",
        "       train_regret_winner_15[slice30],\r\n",
        "       train_regret_winner_16[slice30],\r\n",
        "       train_regret_winner_17[slice30],\r\n",
        "       train_regret_winner_18[slice30],\r\n",
        "       train_regret_winner_19[slice30],\r\n",
        "       train_regret_winner_20[slice30]]\r\n",
        "\r\n",
        "loser30_results = pd.DataFrame(loser30).sort_values(by=[0], ascending=False)\r\n",
        "winner30_results = pd.DataFrame(winner30).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser30 = np.asarray(loser30_results[4:5][0])[0]\r\n",
        "median_loser30 = np.asarray(loser30_results[9:10][0])[0]\r\n",
        "upper_loser30 = np.asarray(loser30_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner30 = np.asarray(winner30_results[4:5][0])[0]\r\n",
        "median_winner30 = np.asarray(winner30_results[9:10][0])[0]\r\n",
        "upper_winner30 = np.asarray(winner30_results[14:15][0])[0]"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-iWfLkj1pvn"
      },
      "source": [
        "# Iteration40 :\r\n",
        "\r\n",
        "slice40 = 39\r\n",
        "\r\n",
        "loser40 = [train_regret_loser_1[slice40],\r\n",
        "       train_regret_loser_2[slice40],\r\n",
        "       train_regret_loser_3[slice40],\r\n",
        "       train_regret_loser_4[slice40],\r\n",
        "       train_regret_loser_5[slice40],\r\n",
        "       train_regret_loser_6[slice40],\r\n",
        "       train_regret_loser_7[slice40],\r\n",
        "       train_regret_loser_8[slice40],\r\n",
        "       train_regret_loser_9[slice40],\r\n",
        "       train_regret_loser_10[slice40],\r\n",
        "       train_regret_loser_11[slice40],\r\n",
        "       train_regret_loser_12[slice40],\r\n",
        "       train_regret_loser_13[slice40],\r\n",
        "       train_regret_loser_14[slice40],\r\n",
        "       train_regret_loser_15[slice40],\r\n",
        "       train_regret_loser_16[slice40],\r\n",
        "       train_regret_loser_17[slice40],\r\n",
        "       train_regret_loser_18[slice40],\r\n",
        "       train_regret_loser_19[slice40],\r\n",
        "       train_regret_loser_20[slice40]]\r\n",
        "\r\n",
        "winner40 = [train_regret_winner_1[slice40],\r\n",
        "       train_regret_winner_2[slice40],\r\n",
        "       train_regret_winner_3[slice40],\r\n",
        "       train_regret_winner_4[slice40],\r\n",
        "       train_regret_winner_5[slice40],\r\n",
        "       train_regret_winner_6[slice40],\r\n",
        "       train_regret_winner_7[slice40],\r\n",
        "       train_regret_winner_8[slice40],\r\n",
        "       train_regret_winner_9[slice40],\r\n",
        "       train_regret_winner_10[slice40],\r\n",
        "       train_regret_winner_11[slice40],\r\n",
        "       train_regret_winner_12[slice40],\r\n",
        "       train_regret_winner_13[slice40],\r\n",
        "       train_regret_winner_14[slice40],\r\n",
        "       train_regret_winner_15[slice40],\r\n",
        "       train_regret_winner_16[slice40],\r\n",
        "       train_regret_winner_17[slice40],\r\n",
        "       train_regret_winner_18[slice40],\r\n",
        "       train_regret_winner_19[slice40],\r\n",
        "       train_regret_winner_20[slice40]]\r\n",
        "\r\n",
        "loser40_results = pd.DataFrame(loser40).sort_values(by=[0], ascending=False)\r\n",
        "winner40_results = pd.DataFrame(winner40).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser40 = np.asarray(loser40_results[4:5][0])[0]\r\n",
        "median_loser40 = np.asarray(loser40_results[9:10][0])[0]\r\n",
        "upper_loser40 = np.asarray(loser40_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner40 = np.asarray(winner40_results[4:5][0])[0]\r\n",
        "median_winner40 = np.asarray(winner40_results[9:10][0])[0]\r\n",
        "upper_winner40 = np.asarray(winner40_results[14:15][0])[0]"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G5i-Cjw2U7K"
      },
      "source": [
        "# Iteration50 :\r\n",
        "\r\n",
        "slice50 = 49\r\n",
        "\r\n",
        "loser50 = [train_regret_loser_1[slice50],\r\n",
        "       train_regret_loser_2[slice50],\r\n",
        "       train_regret_loser_3[slice50],\r\n",
        "       train_regret_loser_4[slice50],\r\n",
        "       train_regret_loser_5[slice50],\r\n",
        "       train_regret_loser_6[slice50],\r\n",
        "       train_regret_loser_7[slice50],\r\n",
        "       train_regret_loser_8[slice50],\r\n",
        "       train_regret_loser_9[slice50],\r\n",
        "       train_regret_loser_10[slice50],\r\n",
        "       train_regret_loser_11[slice50],\r\n",
        "       train_regret_loser_12[slice50],\r\n",
        "       train_regret_loser_13[slice50],\r\n",
        "       train_regret_loser_14[slice50],\r\n",
        "       train_regret_loser_15[slice50],\r\n",
        "       train_regret_loser_16[slice50],\r\n",
        "       train_regret_loser_17[slice50],\r\n",
        "       train_regret_loser_18[slice50],\r\n",
        "       train_regret_loser_19[slice50],\r\n",
        "       train_regret_loser_20[slice50]]\r\n",
        "\r\n",
        "winner50 = [train_regret_winner_1[slice50],\r\n",
        "       train_regret_winner_2[slice50],\r\n",
        "       train_regret_winner_3[slice50],\r\n",
        "       train_regret_winner_4[slice50],\r\n",
        "       train_regret_winner_5[slice50],\r\n",
        "       train_regret_winner_6[slice50],\r\n",
        "       train_regret_winner_7[slice50],\r\n",
        "       train_regret_winner_8[slice50],\r\n",
        "       train_regret_winner_9[slice50],\r\n",
        "       train_regret_winner_10[slice50],\r\n",
        "       train_regret_winner_11[slice50],\r\n",
        "       train_regret_winner_12[slice50],\r\n",
        "       train_regret_winner_13[slice50],\r\n",
        "       train_regret_winner_14[slice50],\r\n",
        "       train_regret_winner_15[slice50],\r\n",
        "       train_regret_winner_16[slice50],\r\n",
        "       train_regret_winner_17[slice50],\r\n",
        "       train_regret_winner_18[slice50],\r\n",
        "       train_regret_winner_19[slice50],\r\n",
        "       train_regret_winner_20[slice50]]\r\n",
        "\r\n",
        "loser50_results = pd.DataFrame(loser50).sort_values(by=[0], ascending=False)\r\n",
        "winner50_results = pd.DataFrame(winner50).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser50 = np.asarray(loser50_results[4:5][0])[0]\r\n",
        "median_loser50 = np.asarray(loser50_results[9:10][0])[0]\r\n",
        "upper_loser50 = np.asarray(loser50_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner50 = np.asarray(winner50_results[4:5][0])[0]\r\n",
        "median_winner50 = np.asarray(winner50_results[9:10][0])[0]\r\n",
        "upper_winner50 = np.asarray(winner50_results[14:15][0])[0]"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY6qxZQA2U-r"
      },
      "source": [
        "# Iteration60 :\r\n",
        "\r\n",
        "slice60 = 59\r\n",
        "\r\n",
        "loser60 = [train_regret_loser_1[slice60],\r\n",
        "       train_regret_loser_2[slice60],\r\n",
        "       train_regret_loser_3[slice60],\r\n",
        "       train_regret_loser_4[slice60],\r\n",
        "       train_regret_loser_5[slice60],\r\n",
        "       train_regret_loser_6[slice60],\r\n",
        "       train_regret_loser_7[slice60],\r\n",
        "       train_regret_loser_8[slice60],\r\n",
        "       train_regret_loser_9[slice60],\r\n",
        "       train_regret_loser_10[slice60],\r\n",
        "       train_regret_loser_11[slice60],\r\n",
        "       train_regret_loser_12[slice60],\r\n",
        "       train_regret_loser_13[slice60],\r\n",
        "       train_regret_loser_14[slice60],\r\n",
        "       train_regret_loser_15[slice60],\r\n",
        "       train_regret_loser_16[slice60],\r\n",
        "       train_regret_loser_17[slice60],\r\n",
        "       train_regret_loser_18[slice60],\r\n",
        "       train_regret_loser_19[slice60],\r\n",
        "       train_regret_loser_20[slice60]]\r\n",
        "\r\n",
        "winner60 = [train_regret_winner_1[slice60],\r\n",
        "       train_regret_winner_2[slice60],\r\n",
        "       train_regret_winner_3[slice60],\r\n",
        "       train_regret_winner_4[slice60],\r\n",
        "       train_regret_winner_5[slice60],\r\n",
        "       train_regret_winner_6[slice60],\r\n",
        "       train_regret_winner_7[slice60],\r\n",
        "       train_regret_winner_8[slice60],\r\n",
        "       train_regret_winner_9[slice60],\r\n",
        "       train_regret_winner_10[slice60],\r\n",
        "       train_regret_winner_11[slice60],\r\n",
        "       train_regret_winner_12[slice60],\r\n",
        "       train_regret_winner_13[slice60],\r\n",
        "       train_regret_winner_14[slice60],\r\n",
        "       train_regret_winner_15[slice60],\r\n",
        "       train_regret_winner_16[slice60],\r\n",
        "       train_regret_winner_17[slice60],\r\n",
        "       train_regret_winner_18[slice60],\r\n",
        "       train_regret_winner_19[slice60],\r\n",
        "       train_regret_winner_20[slice60]]\r\n",
        "\r\n",
        "loser60_results = pd.DataFrame(loser60).sort_values(by=[0], ascending=False)\r\n",
        "winner60_results = pd.DataFrame(winner60).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser60 = np.asarray(loser60_results[4:5][0])[0]\r\n",
        "median_loser60 = np.asarray(loser60_results[9:10][0])[0]\r\n",
        "upper_loser60 = np.asarray(loser60_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner60 = np.asarray(winner60_results[4:5][0])[0]\r\n",
        "median_winner60 = np.asarray(winner60_results[9:10][0])[0]\r\n",
        "upper_winner60 = np.asarray(winner60_results[14:15][0])[0]"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBqgVxVH2VCU"
      },
      "source": [
        "# Iteration70 :\r\n",
        "\r\n",
        "slice70 = 69\r\n",
        "\r\n",
        "loser70 = [train_regret_loser_1[slice70],\r\n",
        "       train_regret_loser_2[slice70],\r\n",
        "       train_regret_loser_3[slice70],\r\n",
        "       train_regret_loser_4[slice70],\r\n",
        "       train_regret_loser_5[slice70],\r\n",
        "       train_regret_loser_6[slice70],\r\n",
        "       train_regret_loser_7[slice70],\r\n",
        "       train_regret_loser_8[slice70],\r\n",
        "       train_regret_loser_9[slice70],\r\n",
        "       train_regret_loser_10[slice70],\r\n",
        "       train_regret_loser_11[slice70],\r\n",
        "       train_regret_loser_12[slice70],\r\n",
        "       train_regret_loser_13[slice70],\r\n",
        "       train_regret_loser_14[slice70],\r\n",
        "       train_regret_loser_15[slice70],\r\n",
        "       train_regret_loser_16[slice70],\r\n",
        "       train_regret_loser_17[slice70],\r\n",
        "       train_regret_loser_18[slice70],\r\n",
        "       train_regret_loser_19[slice70],\r\n",
        "       train_regret_loser_20[slice70]]\r\n",
        "\r\n",
        "winner70 = [train_regret_winner_1[slice70],\r\n",
        "       train_regret_winner_2[slice70],\r\n",
        "       train_regret_winner_3[slice70],\r\n",
        "       train_regret_winner_4[slice70],\r\n",
        "       train_regret_winner_5[slice70],\r\n",
        "       train_regret_winner_6[slice70],\r\n",
        "       train_regret_winner_7[slice70],\r\n",
        "       train_regret_winner_8[slice70],\r\n",
        "       train_regret_winner_9[slice70],\r\n",
        "       train_regret_winner_10[slice70],\r\n",
        "       train_regret_winner_11[slice70],\r\n",
        "       train_regret_winner_12[slice70],\r\n",
        "       train_regret_winner_13[slice70],\r\n",
        "       train_regret_winner_14[slice70],\r\n",
        "       train_regret_winner_15[slice70],\r\n",
        "       train_regret_winner_16[slice70],\r\n",
        "       train_regret_winner_17[slice70],\r\n",
        "       train_regret_winner_18[slice70],\r\n",
        "       train_regret_winner_19[slice70],\r\n",
        "       train_regret_winner_20[slice70]]\r\n",
        "\r\n",
        "loser70_results = pd.DataFrame(loser70).sort_values(by=[0], ascending=False)\r\n",
        "winner70_results = pd.DataFrame(winner70).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser70 = np.asarray(loser70_results[4:5][0])[0]\r\n",
        "median_loser70 = np.asarray(loser70_results[9:10][0])[0]\r\n",
        "upper_loser70 = np.asarray(loser70_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner70 = np.asarray(winner70_results[4:5][0])[0]\r\n",
        "median_winner70 = np.asarray(winner70_results[9:10][0])[0]\r\n",
        "upper_winner70 = np.asarray(winner70_results[14:15][0])[0]"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF7mlDZL1pyN"
      },
      "source": [
        "# Iteration80 :\r\n",
        "\r\n",
        "slice80 = 79\r\n",
        "\r\n",
        "loser80 = [train_regret_loser_1[slice80],\r\n",
        "       train_regret_loser_2[slice80],\r\n",
        "       train_regret_loser_3[slice80],\r\n",
        "       train_regret_loser_4[slice80],\r\n",
        "       train_regret_loser_5[slice80],\r\n",
        "       train_regret_loser_6[slice80],\r\n",
        "       train_regret_loser_7[slice80],\r\n",
        "       train_regret_loser_8[slice80],\r\n",
        "       train_regret_loser_9[slice80],\r\n",
        "       train_regret_loser_10[slice80],\r\n",
        "       train_regret_loser_11[slice80],\r\n",
        "       train_regret_loser_12[slice80],\r\n",
        "       train_regret_loser_13[slice80],\r\n",
        "       train_regret_loser_14[slice80],\r\n",
        "       train_regret_loser_15[slice80],\r\n",
        "       train_regret_loser_16[slice80],\r\n",
        "       train_regret_loser_17[slice80],\r\n",
        "       train_regret_loser_18[slice80],\r\n",
        "       train_regret_loser_19[slice80],\r\n",
        "       train_regret_loser_20[slice80]]\r\n",
        "\r\n",
        "winner80 = [train_regret_winner_1[slice80],\r\n",
        "       train_regret_winner_2[slice80],\r\n",
        "       train_regret_winner_3[slice80],\r\n",
        "       train_regret_winner_4[slice80],\r\n",
        "       train_regret_winner_5[slice80],\r\n",
        "       train_regret_winner_6[slice80],\r\n",
        "       train_regret_winner_7[slice80],\r\n",
        "       train_regret_winner_8[slice80],\r\n",
        "       train_regret_winner_9[slice80],\r\n",
        "       train_regret_winner_10[slice80],\r\n",
        "       train_regret_winner_11[slice80],\r\n",
        "       train_regret_winner_12[slice80],\r\n",
        "       train_regret_winner_13[slice80],\r\n",
        "       train_regret_winner_14[slice80],\r\n",
        "       train_regret_winner_15[slice80],\r\n",
        "       train_regret_winner_16[slice80],\r\n",
        "       train_regret_winner_17[slice80],\r\n",
        "       train_regret_winner_18[slice80],\r\n",
        "       train_regret_winner_19[slice80],\r\n",
        "       train_regret_winner_20[slice80]]\r\n",
        "\r\n",
        "loser80_results = pd.DataFrame(loser80).sort_values(by=[0], ascending=False)\r\n",
        "winner80_results = pd.DataFrame(winner80).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser80 = np.asarray(loser80_results[4:5][0])[0]\r\n",
        "median_loser80 = np.asarray(loser80_results[9:10][0])[0]\r\n",
        "upper_loser80 = np.asarray(loser80_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner80 = np.asarray(winner80_results[4:5][0])[0]\r\n",
        "median_winner80 = np.asarray(winner80_results[9:10][0])[0]\r\n",
        "upper_winner80 = np.asarray(winner80_results[14:15][0])[0]"
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Rw8IkD1p0z"
      },
      "source": [
        "# Iteration90 :\r\n",
        "\r\n",
        "slice90 = 89\r\n",
        "\r\n",
        "loser90 = [train_regret_loser_1[slice90],\r\n",
        "       train_regret_loser_2[slice90],\r\n",
        "       train_regret_loser_3[slice90],\r\n",
        "       train_regret_loser_4[slice90],\r\n",
        "       train_regret_loser_5[slice90],\r\n",
        "       train_regret_loser_6[slice90],\r\n",
        "       train_regret_loser_7[slice90],\r\n",
        "       train_regret_loser_8[slice90],\r\n",
        "       train_regret_loser_9[slice90],\r\n",
        "       train_regret_loser_10[slice90],\r\n",
        "       train_regret_loser_11[slice90],\r\n",
        "       train_regret_loser_12[slice90],\r\n",
        "       train_regret_loser_13[slice90],\r\n",
        "       train_regret_loser_14[slice90],\r\n",
        "       train_regret_loser_15[slice90],\r\n",
        "       train_regret_loser_16[slice90],\r\n",
        "       train_regret_loser_17[slice90],\r\n",
        "       train_regret_loser_18[slice90],\r\n",
        "       train_regret_loser_19[slice90],\r\n",
        "       train_regret_loser_20[slice90]]\r\n",
        "\r\n",
        "winner90 = [train_regret_winner_1[slice90],\r\n",
        "       train_regret_winner_2[slice90],\r\n",
        "       train_regret_winner_3[slice90],\r\n",
        "       train_regret_winner_4[slice90],\r\n",
        "       train_regret_winner_5[slice90],\r\n",
        "       train_regret_winner_6[slice90],\r\n",
        "       train_regret_winner_7[slice90],\r\n",
        "       train_regret_winner_8[slice90],\r\n",
        "       train_regret_winner_9[slice90],\r\n",
        "       train_regret_winner_10[slice90],\r\n",
        "       train_regret_winner_11[slice90],\r\n",
        "       train_regret_winner_12[slice90],\r\n",
        "       train_regret_winner_13[slice90],\r\n",
        "       train_regret_winner_14[slice90],\r\n",
        "       train_regret_winner_15[slice90],\r\n",
        "       train_regret_winner_16[slice90],\r\n",
        "       train_regret_winner_17[slice90],\r\n",
        "       train_regret_winner_18[slice90],\r\n",
        "       train_regret_winner_19[slice90],\r\n",
        "       train_regret_winner_20[slice90]]\r\n",
        "\r\n",
        "loser90_results = pd.DataFrame(loser90).sort_values(by=[0], ascending=False)\r\n",
        "winner90_results = pd.DataFrame(winner90).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser90 = np.asarray(loser90_results[4:5][0])[0]\r\n",
        "median_loser90 = np.asarray(loser90_results[9:10][0])[0]\r\n",
        "upper_loser90 = np.asarray(loser90_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner90 = np.asarray(winner90_results[4:5][0])[0]\r\n",
        "median_winner90 = np.asarray(winner90_results[9:10][0])[0]\r\n",
        "upper_winner90 = np.asarray(winner90_results[14:15][0])[0]"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiljCrq21p3a"
      },
      "source": [
        "# Iteration100 :\r\n",
        "\r\n",
        "slice100 = 99\r\n",
        "\r\n",
        "loser100 = [train_regret_loser_1[slice100],\r\n",
        "       train_regret_loser_2[slice100],\r\n",
        "       train_regret_loser_3[slice100],\r\n",
        "       train_regret_loser_4[slice100],\r\n",
        "       train_regret_loser_5[slice100],\r\n",
        "       train_regret_loser_6[slice100],\r\n",
        "       train_regret_loser_7[slice100],\r\n",
        "       train_regret_loser_8[slice100],\r\n",
        "       train_regret_loser_9[slice100],\r\n",
        "       train_regret_loser_10[slice100],\r\n",
        "       train_regret_loser_11[slice100],\r\n",
        "       train_regret_loser_12[slice100],\r\n",
        "       train_regret_loser_13[slice100],\r\n",
        "       train_regret_loser_14[slice100],\r\n",
        "       train_regret_loser_15[slice100],\r\n",
        "       train_regret_loser_16[slice100],\r\n",
        "       train_regret_loser_17[slice100],\r\n",
        "       train_regret_loser_18[slice100],\r\n",
        "       train_regret_loser_19[slice100],\r\n",
        "       train_regret_loser_20[slice100]]\r\n",
        "\r\n",
        "winner100 = [train_regret_winner_1[slice100],\r\n",
        "       train_regret_winner_2[slice100],\r\n",
        "       train_regret_winner_3[slice100],\r\n",
        "       train_regret_winner_4[slice100],\r\n",
        "       train_regret_winner_5[slice100],\r\n",
        "       train_regret_winner_6[slice100],\r\n",
        "       train_regret_winner_7[slice100],\r\n",
        "       train_regret_winner_8[slice100],\r\n",
        "       train_regret_winner_9[slice100],\r\n",
        "       train_regret_winner_10[slice100],\r\n",
        "       train_regret_winner_11[slice100],\r\n",
        "       train_regret_winner_12[slice100],\r\n",
        "       train_regret_winner_13[slice100],\r\n",
        "       train_regret_winner_14[slice100],\r\n",
        "       train_regret_winner_15[slice100],\r\n",
        "       train_regret_winner_16[slice100],\r\n",
        "       train_regret_winner_17[slice100],\r\n",
        "       train_regret_winner_18[slice100],\r\n",
        "       train_regret_winner_19[slice100],\r\n",
        "       train_regret_winner_20[slice100]]\r\n",
        "\r\n",
        "loser100_results = pd.DataFrame(loser100).sort_values(by=[0], ascending=False)\r\n",
        "winner100_results = pd.DataFrame(winner100).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser100 = np.asarray(loser100_results[4:5][0])[0]\r\n",
        "median_loser100 = np.asarray(loser100_results[9:10][0])[0]\r\n",
        "upper_loser100 = np.asarray(loser100_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner100 = np.asarray(winner100_results[4:5][0])[0]\r\n",
        "median_winner100 = np.asarray(winner100_results[9:10][0])[0]\r\n",
        "upper_winner100 = np.asarray(winner100_results[14:15][0])[0]"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OItJgqUT2oNb"
      },
      "source": [
        "### Summarize arrays: 'Loser'\r\n",
        "\r\n",
        "lower_loser = [lower_loser1,\r\n",
        "            lower_loser2,\r\n",
        "            lower_loser3,\r\n",
        "            lower_loser4,\r\n",
        "            lower_loser5,\r\n",
        "            lower_loser6,\r\n",
        "            lower_loser7,\r\n",
        "            lower_loser8,\r\n",
        "            lower_loser9,\r\n",
        "            lower_loser10,\r\n",
        "            lower_loser11,\r\n",
        "            lower_loser12,\r\n",
        "            lower_loser13,\r\n",
        "            lower_loser14,\r\n",
        "            lower_loser15,\r\n",
        "            lower_loser16,\r\n",
        "            lower_loser17,\r\n",
        "            lower_loser18,\r\n",
        "            lower_loser19,\r\n",
        "            lower_loser20,\r\n",
        "            lower_loser21,\r\n",
        "            lower_loser22,\r\n",
        "            lower_loser23,\r\n",
        "            lower_loser24,\r\n",
        "            lower_loser25,\r\n",
        "            lower_loser26,\r\n",
        "            lower_loser27,\r\n",
        "            lower_loser28,\r\n",
        "            lower_loser29,\r\n",
        "            lower_loser30,\r\n",
        "            lower_loser31,\r\n",
        "            lower_loser32,\r\n",
        "            lower_loser33,\r\n",
        "            lower_loser34,\r\n",
        "            lower_loser35,\r\n",
        "            lower_loser36,\r\n",
        "            lower_loser37,\r\n",
        "            lower_loser38,\r\n",
        "            lower_loser39,\r\n",
        "            lower_loser40,\r\n",
        "            lower_loser41,\r\n",
        "            lower_loser42,\r\n",
        "            lower_loser43,\r\n",
        "            lower_loser44,\r\n",
        "            lower_loser45,\r\n",
        "            lower_loser46,\r\n",
        "            lower_loser47,\r\n",
        "            lower_loser48,\r\n",
        "            lower_loser49,\r\n",
        "            lower_loser50,\r\n",
        "            lower_loser51,\r\n",
        "            lower_loser52,\r\n",
        "            lower_loser53,\r\n",
        "            lower_loser54,\r\n",
        "            lower_loser55,\r\n",
        "            lower_loser56,\r\n",
        "            lower_loser57,\r\n",
        "            lower_loser58,\r\n",
        "            lower_loser59,\r\n",
        "            lower_loser60,\r\n",
        "            lower_loser61,\r\n",
        "            lower_loser62,\r\n",
        "            lower_loser63,\r\n",
        "            lower_loser64,\r\n",
        "            lower_loser65,\r\n",
        "            lower_loser66,\r\n",
        "            lower_loser67,\r\n",
        "            lower_loser68,\r\n",
        "            lower_loser69,\r\n",
        "            lower_loser70,\r\n",
        "            lower_loser71,\r\n",
        "            lower_loser72,\r\n",
        "            lower_loser73,\r\n",
        "            lower_loser74,\r\n",
        "            lower_loser75,\r\n",
        "            lower_loser76,\r\n",
        "            lower_loser77,\r\n",
        "            lower_loser78,\r\n",
        "            lower_loser79,\r\n",
        "            lower_loser80,\r\n",
        "            lower_loser81,\r\n",
        "            lower_loser82,\r\n",
        "            lower_loser83,\r\n",
        "            lower_loser84,\r\n",
        "            lower_loser85,\r\n",
        "            lower_loser86,\r\n",
        "            lower_loser87,\r\n",
        "            lower_loser88,\r\n",
        "            lower_loser89,\r\n",
        "            lower_loser90,\r\n",
        "            lower_loser91,\r\n",
        "            lower_loser92,\r\n",
        "            lower_loser93,\r\n",
        "            lower_loser94,\r\n",
        "            lower_loser95,\r\n",
        "            lower_loser96,\r\n",
        "            lower_loser97,\r\n",
        "            lower_loser98,\r\n",
        "            lower_loser99,\r\n",
        "            lower_loser100,\r\n",
        "            lower_loser101]\r\n",
        "\r\n",
        "median_loser = [median_loser1,\r\n",
        "            median_loser2,\r\n",
        "            median_loser3,\r\n",
        "            median_loser4,\r\n",
        "            median_loser5,\r\n",
        "            median_loser6,\r\n",
        "            median_loser7,\r\n",
        "            median_loser8,\r\n",
        "            median_loser9,\r\n",
        "            median_loser10,\r\n",
        "            median_loser11,\r\n",
        "            median_loser12,\r\n",
        "            median_loser13,\r\n",
        "            median_loser14,\r\n",
        "            median_loser15,\r\n",
        "            median_loser16,\r\n",
        "            median_loser17,\r\n",
        "            median_loser18,\r\n",
        "            median_loser19,\r\n",
        "            median_loser20,\r\n",
        "            median_loser21,\r\n",
        "            median_loser22,\r\n",
        "            median_loser23,\r\n",
        "            median_loser24,\r\n",
        "            median_loser25,\r\n",
        "            median_loser26,\r\n",
        "            median_loser27,\r\n",
        "            median_loser28,\r\n",
        "            median_loser29,\r\n",
        "            median_loser30,\r\n",
        "            median_loser31,\r\n",
        "            median_loser32,\r\n",
        "            median_loser33,\r\n",
        "            median_loser34,\r\n",
        "            median_loser35,\r\n",
        "            median_loser36,\r\n",
        "            median_loser37,\r\n",
        "            median_loser38,\r\n",
        "            median_loser39,\r\n",
        "            median_loser40,\r\n",
        "            median_loser41,\r\n",
        "            median_loser42,\r\n",
        "            median_loser43,\r\n",
        "            median_loser44,\r\n",
        "            median_loser45,\r\n",
        "            median_loser46,\r\n",
        "            median_loser47,\r\n",
        "            median_loser48,\r\n",
        "            median_loser49,\r\n",
        "            median_loser50,\r\n",
        "            median_loser51,\r\n",
        "            median_loser52,\r\n",
        "            median_loser53,\r\n",
        "            median_loser54,\r\n",
        "            median_loser55,\r\n",
        "            median_loser56,\r\n",
        "            median_loser57,\r\n",
        "            median_loser58,\r\n",
        "            median_loser59,\r\n",
        "            median_loser60,\r\n",
        "            median_loser61,\r\n",
        "            median_loser62,\r\n",
        "            median_loser63,\r\n",
        "            median_loser64,\r\n",
        "            median_loser65,\r\n",
        "            median_loser66,\r\n",
        "            median_loser67,\r\n",
        "            median_loser68,\r\n",
        "            median_loser69,\r\n",
        "            median_loser70,\r\n",
        "            median_loser71,\r\n",
        "            median_loser72,\r\n",
        "            median_loser73,\r\n",
        "            median_loser74,\r\n",
        "            median_loser75,\r\n",
        "            median_loser76,\r\n",
        "            median_loser77,\r\n",
        "            median_loser78,\r\n",
        "            median_loser79,\r\n",
        "            median_loser80,\r\n",
        "            median_loser81,\r\n",
        "            median_loser82,\r\n",
        "            median_loser83,\r\n",
        "            median_loser84,\r\n",
        "            median_loser85,\r\n",
        "            median_loser86,\r\n",
        "            median_loser87,\r\n",
        "            median_loser88,\r\n",
        "            median_loser89,\r\n",
        "            median_loser90,\r\n",
        "            median_loser91,\r\n",
        "            median_loser92,\r\n",
        "            median_loser93,\r\n",
        "            median_loser94,\r\n",
        "            median_loser95,\r\n",
        "            median_loser96,\r\n",
        "            median_loser97,\r\n",
        "            median_loser98,\r\n",
        "            median_loser99,\r\n",
        "            median_loser100,\r\n",
        "            median_loser101]\r\n",
        "\r\n",
        "upper_loser = [upper_loser1,\r\n",
        "            upper_loser2,\r\n",
        "            upper_loser3,\r\n",
        "            upper_loser4,\r\n",
        "            upper_loser5,\r\n",
        "            upper_loser6,\r\n",
        "            upper_loser7,\r\n",
        "            upper_loser8,\r\n",
        "            upper_loser9,\r\n",
        "            upper_loser10,\r\n",
        "            upper_loser11,\r\n",
        "            upper_loser12,\r\n",
        "            upper_loser13,\r\n",
        "            upper_loser14,\r\n",
        "            upper_loser15,\r\n",
        "            upper_loser16,\r\n",
        "            upper_loser17,\r\n",
        "            upper_loser18,\r\n",
        "            upper_loser19,\r\n",
        "            upper_loser20,\r\n",
        "            upper_loser21,\r\n",
        "            upper_loser22,\r\n",
        "            upper_loser23,\r\n",
        "            upper_loser24,\r\n",
        "            upper_loser25,\r\n",
        "            upper_loser26,\r\n",
        "            upper_loser27,\r\n",
        "            upper_loser28,\r\n",
        "            upper_loser29,\r\n",
        "            upper_loser30,\r\n",
        "            upper_loser31,\r\n",
        "            upper_loser32,\r\n",
        "            upper_loser33,\r\n",
        "            upper_loser34,\r\n",
        "            upper_loser35,\r\n",
        "            upper_loser36,\r\n",
        "            upper_loser37,\r\n",
        "            upper_loser38,\r\n",
        "            upper_loser39,\r\n",
        "            upper_loser40,\r\n",
        "            upper_loser41,\r\n",
        "            upper_loser42,\r\n",
        "            upper_loser43,\r\n",
        "            upper_loser44,\r\n",
        "            upper_loser45,\r\n",
        "            upper_loser46,\r\n",
        "            upper_loser47,\r\n",
        "            upper_loser48,\r\n",
        "            upper_loser49,\r\n",
        "            upper_loser50,\r\n",
        "            upper_loser51,\r\n",
        "            upper_loser52,\r\n",
        "            upper_loser53,\r\n",
        "            upper_loser54,\r\n",
        "            upper_loser55,\r\n",
        "            upper_loser56,\r\n",
        "            upper_loser57,\r\n",
        "            upper_loser58,\r\n",
        "            upper_loser59,\r\n",
        "            upper_loser60,\r\n",
        "            upper_loser61,\r\n",
        "            upper_loser62,\r\n",
        "            upper_loser63,\r\n",
        "            upper_loser64,\r\n",
        "            upper_loser65,\r\n",
        "            upper_loser66,\r\n",
        "            upper_loser67,\r\n",
        "            upper_loser68,\r\n",
        "            upper_loser69,\r\n",
        "            upper_loser70,\r\n",
        "            upper_loser71,\r\n",
        "            upper_loser72,\r\n",
        "            upper_loser73,\r\n",
        "            upper_loser74,\r\n",
        "            upper_loser75,\r\n",
        "            upper_loser76,\r\n",
        "            upper_loser77,\r\n",
        "            upper_loser78,\r\n",
        "            upper_loser79,\r\n",
        "            upper_loser80,\r\n",
        "            upper_loser81,\r\n",
        "            upper_loser82,\r\n",
        "            upper_loser83,\r\n",
        "            upper_loser84,\r\n",
        "            upper_loser85,\r\n",
        "            upper_loser86,\r\n",
        "            upper_loser87,\r\n",
        "            upper_loser88,\r\n",
        "            upper_loser89,\r\n",
        "            upper_loser90,\r\n",
        "            upper_loser91,\r\n",
        "            upper_loser92,\r\n",
        "            upper_loser93,\r\n",
        "            upper_loser94,\r\n",
        "            upper_loser95,\r\n",
        "            upper_loser96,\r\n",
        "            upper_loser97,\r\n",
        "            upper_loser98,\r\n",
        "            upper_loser99,\r\n",
        "            upper_loser100,\r\n",
        "            upper_loser101]"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19FndLT2oU3"
      },
      "source": [
        "### Summarize arrays: 'Winner'\r\n",
        "\r\n",
        "lower_winner = [lower_winner1,\r\n",
        "            lower_winner2,\r\n",
        "            lower_winner3,\r\n",
        "            lower_winner4,\r\n",
        "            lower_winner5,\r\n",
        "            lower_winner6,\r\n",
        "            lower_winner7,\r\n",
        "            lower_winner8,\r\n",
        "            lower_winner9,\r\n",
        "            lower_winner10,\r\n",
        "            lower_winner11,\r\n",
        "            lower_winner12,\r\n",
        "            lower_winner13,\r\n",
        "            lower_winner14,\r\n",
        "            lower_winner15,\r\n",
        "            lower_winner16,\r\n",
        "            lower_winner17,\r\n",
        "            lower_winner18,\r\n",
        "            lower_winner19,\r\n",
        "            lower_winner20,\r\n",
        "            lower_winner21,\r\n",
        "            lower_winner22,\r\n",
        "            lower_winner23,\r\n",
        "            lower_winner24,\r\n",
        "            lower_winner25,\r\n",
        "            lower_winner26,\r\n",
        "            lower_winner27,\r\n",
        "            lower_winner28,\r\n",
        "            lower_winner29,\r\n",
        "            lower_winner30,\r\n",
        "            lower_winner31,\r\n",
        "            lower_winner32,\r\n",
        "            lower_winner33,\r\n",
        "            lower_winner34,\r\n",
        "            lower_winner35,\r\n",
        "            lower_winner36,\r\n",
        "            lower_winner37,\r\n",
        "            lower_winner38,\r\n",
        "            lower_winner39,\r\n",
        "            lower_winner40,\r\n",
        "            lower_winner41,\r\n",
        "            lower_winner42,\r\n",
        "            lower_winner43,\r\n",
        "            lower_winner44,\r\n",
        "            lower_winner45,\r\n",
        "            lower_winner46,\r\n",
        "            lower_winner47,\r\n",
        "            lower_winner48,\r\n",
        "            lower_winner49,\r\n",
        "            lower_winner50,\r\n",
        "            lower_winner51,\r\n",
        "            lower_winner52,\r\n",
        "            lower_winner53,\r\n",
        "            lower_winner54,\r\n",
        "            lower_winner55,\r\n",
        "            lower_winner56,\r\n",
        "            lower_winner57,\r\n",
        "            lower_winner58,\r\n",
        "            lower_winner59,\r\n",
        "            lower_winner60,\r\n",
        "            lower_winner61,\r\n",
        "            lower_winner62,\r\n",
        "            lower_winner63,\r\n",
        "            lower_winner64,\r\n",
        "            lower_winner65,\r\n",
        "            lower_winner66,\r\n",
        "            lower_winner67,\r\n",
        "            lower_winner68,\r\n",
        "            lower_winner69,\r\n",
        "            lower_winner70,\r\n",
        "            lower_winner71,\r\n",
        "            lower_winner72,\r\n",
        "            lower_winner73,\r\n",
        "            lower_winner74,\r\n",
        "            lower_winner75,\r\n",
        "            lower_winner76,\r\n",
        "            lower_winner77,\r\n",
        "            lower_winner78,\r\n",
        "            lower_winner79,\r\n",
        "            lower_winner80,\r\n",
        "            lower_winner81,\r\n",
        "            lower_winner82,\r\n",
        "            lower_winner83,\r\n",
        "            lower_winner84,\r\n",
        "            lower_winner85,\r\n",
        "            lower_winner86,\r\n",
        "            lower_winner87,\r\n",
        "            lower_winner88,\r\n",
        "            lower_winner89,\r\n",
        "            lower_winner90,\r\n",
        "            lower_winner91,\r\n",
        "            lower_winner92,\r\n",
        "            lower_winner93,\r\n",
        "            lower_winner94,\r\n",
        "            lower_winner95,\r\n",
        "            lower_winner96,\r\n",
        "            lower_winner97,\r\n",
        "            lower_winner98,\r\n",
        "            lower_winner99,\r\n",
        "            lower_winner100,\r\n",
        "            lower_winner101]\r\n",
        "\r\n",
        "median_winner = [median_winner1,\r\n",
        "            median_winner2,\r\n",
        "            median_winner3,\r\n",
        "            median_winner4,\r\n",
        "            median_winner5,\r\n",
        "            median_winner6,\r\n",
        "            median_winner7,\r\n",
        "            median_winner8,\r\n",
        "            median_winner9,\r\n",
        "            median_winner10,\r\n",
        "            median_winner11,\r\n",
        "            median_winner12,\r\n",
        "            median_winner13,\r\n",
        "            median_winner14,\r\n",
        "            median_winner15,\r\n",
        "            median_winner16,\r\n",
        "            median_winner17,\r\n",
        "            median_winner18,\r\n",
        "            median_winner19,\r\n",
        "            median_winner20,\r\n",
        "            median_winner21,\r\n",
        "            median_winner22,\r\n",
        "            median_winner23,\r\n",
        "            median_winner24,\r\n",
        "            median_winner25,\r\n",
        "            median_winner26,\r\n",
        "            median_winner27,\r\n",
        "            median_winner28,\r\n",
        "            median_winner29,\r\n",
        "            median_winner30,\r\n",
        "            median_winner31,\r\n",
        "            median_winner32,\r\n",
        "            median_winner33,\r\n",
        "            median_winner34,\r\n",
        "            median_winner35,\r\n",
        "            median_winner36,\r\n",
        "            median_winner37,\r\n",
        "            median_winner38,\r\n",
        "            median_winner39,\r\n",
        "            median_winner40,\r\n",
        "            median_winner41,\r\n",
        "            median_winner42,\r\n",
        "            median_winner43,\r\n",
        "            median_winner44,\r\n",
        "            median_winner45,\r\n",
        "            median_winner46,\r\n",
        "            median_winner47,\r\n",
        "            median_winner48,\r\n",
        "            median_winner49,\r\n",
        "            median_winner50,\r\n",
        "            median_winner51,\r\n",
        "            median_winner52,\r\n",
        "            median_winner53,\r\n",
        "            median_winner54,\r\n",
        "            median_winner55,\r\n",
        "            median_winner56,\r\n",
        "            median_winner57,\r\n",
        "            median_winner58,\r\n",
        "            median_winner59,\r\n",
        "            median_winner60,\r\n",
        "            median_winner61,\r\n",
        "            median_winner62,\r\n",
        "            median_winner63,\r\n",
        "            median_winner64,\r\n",
        "            median_winner65,\r\n",
        "            median_winner66,\r\n",
        "            median_winner67,\r\n",
        "            median_winner68,\r\n",
        "            median_winner69,\r\n",
        "            median_winner70,\r\n",
        "            median_winner71,\r\n",
        "            median_winner72,\r\n",
        "            median_winner73,\r\n",
        "            median_winner74,\r\n",
        "            median_winner75,\r\n",
        "            median_winner76,\r\n",
        "            median_winner77,\r\n",
        "            median_winner78,\r\n",
        "            median_winner79,\r\n",
        "            median_winner80,\r\n",
        "            median_winner81,\r\n",
        "            median_winner82,\r\n",
        "            median_winner83,\r\n",
        "            median_winner84,\r\n",
        "            median_winner85,\r\n",
        "            median_winner86,\r\n",
        "            median_winner87,\r\n",
        "            median_winner88,\r\n",
        "            median_winner89,\r\n",
        "            median_winner90,\r\n",
        "            median_winner91,\r\n",
        "            median_winner92,\r\n",
        "            median_winner93,\r\n",
        "            median_winner94,\r\n",
        "            median_winner95,\r\n",
        "            median_winner96,\r\n",
        "            median_winner97,\r\n",
        "            median_winner98,\r\n",
        "            median_winner99,\r\n",
        "            median_winner100,\r\n",
        "            median_winner101]\r\n",
        "\r\n",
        "upper_winner = [upper_winner1,\r\n",
        "            upper_winner2,\r\n",
        "            upper_winner3,\r\n",
        "            upper_winner4,\r\n",
        "            upper_winner5,\r\n",
        "            upper_winner6,\r\n",
        "            upper_winner7,\r\n",
        "            upper_winner8,\r\n",
        "            upper_winner9,\r\n",
        "            upper_winner10,\r\n",
        "            upper_winner11,\r\n",
        "            upper_winner12,\r\n",
        "            upper_winner13,\r\n",
        "            upper_winner14,\r\n",
        "            upper_winner15,\r\n",
        "            upper_winner16,\r\n",
        "            upper_winner17,\r\n",
        "            upper_winner18,\r\n",
        "            upper_winner19,\r\n",
        "            upper_winner20,\r\n",
        "            upper_winner21,\r\n",
        "            upper_winner22,\r\n",
        "            upper_winner23,\r\n",
        "            upper_winner24,\r\n",
        "            upper_winner25,\r\n",
        "            upper_winner26,\r\n",
        "            upper_winner27,\r\n",
        "            upper_winner28,\r\n",
        "            upper_winner29,\r\n",
        "            upper_winner30,\r\n",
        "            upper_winner31,\r\n",
        "            upper_winner32,\r\n",
        "            upper_winner33,\r\n",
        "            upper_winner34,\r\n",
        "            upper_winner35,\r\n",
        "            upper_winner36,\r\n",
        "            upper_winner37,\r\n",
        "            upper_winner38,\r\n",
        "            upper_winner39,\r\n",
        "            upper_winner40,\r\n",
        "            upper_winner41,\r\n",
        "            upper_winner42,\r\n",
        "            upper_winner43,\r\n",
        "            upper_winner44,\r\n",
        "            upper_winner45,\r\n",
        "            upper_winner46,\r\n",
        "            upper_winner47,\r\n",
        "            upper_winner48,\r\n",
        "            upper_winner49,\r\n",
        "            upper_winner50,\r\n",
        "            upper_winner51,\r\n",
        "            upper_winner52,\r\n",
        "            upper_winner53,\r\n",
        "            upper_winner54,\r\n",
        "            upper_winner55,\r\n",
        "            upper_winner56,\r\n",
        "            upper_winner57,\r\n",
        "            upper_winner58,\r\n",
        "            upper_winner59,\r\n",
        "            upper_winner60,\r\n",
        "            upper_winner61,\r\n",
        "            upper_winner62,\r\n",
        "            upper_winner63,\r\n",
        "            upper_winner64,\r\n",
        "            upper_winner65,\r\n",
        "            upper_winner66,\r\n",
        "            upper_winner67,\r\n",
        "            upper_winner68,\r\n",
        "            upper_winner69,\r\n",
        "            upper_winner70,\r\n",
        "            upper_winner71,\r\n",
        "            upper_winner72,\r\n",
        "            upper_winner73,\r\n",
        "            upper_winner74,\r\n",
        "            upper_winner75,\r\n",
        "            upper_winner76,\r\n",
        "            upper_winner77,\r\n",
        "            upper_winner78,\r\n",
        "            upper_winner79,\r\n",
        "            upper_winner80,\r\n",
        "            upper_winner81,\r\n",
        "            upper_winner82,\r\n",
        "            upper_winner83,\r\n",
        "            upper_winner84,\r\n",
        "            upper_winner85,\r\n",
        "            upper_winner86,\r\n",
        "            upper_winner87,\r\n",
        "            upper_winner88,\r\n",
        "            upper_winner89,\r\n",
        "            upper_winner90,\r\n",
        "            upper_winner91,\r\n",
        "            upper_winner92,\r\n",
        "            upper_winner93,\r\n",
        "            upper_winner94,\r\n",
        "            upper_winner95,\r\n",
        "            upper_winner96,\r\n",
        "            upper_winner97,\r\n",
        "            upper_winner98,\r\n",
        "            upper_winner99,\r\n",
        "            upper_winner100,\r\n",
        "            upper_winner101]"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84XIzmWD2oba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "1b19cedd-598d-4ead-9c1a-f65a2d88df97"
      },
      "source": [
        "### Visualize!\r\n",
        "\r\n",
        "title = obj_func\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(median_loser, color = 'Green')\r\n",
        "plt.plot(median_winner, color = 'Blue')\r\n",
        "\r\n",
        "xstar = np.arange(0, max_iter+1, step=1)\r\n",
        "plt.fill_between(xstar, lower_loser, upper_loser, facecolor = 'Green', alpha=0.4, label='GP EI Regret IQR: dEI')\r\n",
        "plt.fill_between(xstar, lower_winner, upper_winner, facecolor = 'Blue', alpha=0.4, label='STP EI Regret IQR: dEI')\r\n",
        "\r\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\r\n",
        "plt.xlabel('(Post-initialization) iteration $\\it{k}$', weight = 'bold', family = 'Arial') \r\n",
        "plt.ylabel('log(Regret)', weight = 'bold', family = 'Arial') \r\n",
        "plt.legend(loc=1) # add plot legend\r\n",
        "\r\n",
        "plt.show() "
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5dkR2Id2oiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a4cb41-e0dc-43c4-ba22-9abcb62b7bdd"
      },
      "source": [
        "time_lose, time_win"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13542.18981719017, 16990.071573972702)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNLBF57p2opi"
      },
      "source": [
        ""
      ],
      "execution_count": 205,
      "outputs": []
    }
  ]
}