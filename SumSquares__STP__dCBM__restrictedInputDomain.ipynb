{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SumSquares__STP__dCBM__restrictedInputDomain.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaQo_XsusPbm"
      },
      "source": [
        "SumSquares synthetic function:\n",
        "\n",
        "GP EI: (exact GP EI gradients) vs. STP CBM: (exact STP CBM gradients)\n",
        "\n",
        "https://www.sfu.ca/~ssurjano/sumsqu.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhgucjJgsYfm",
        "outputId": "496dd79d-58b9-4428-fa0b-b18a4690d4e6"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyGPGO in /usr/local/lib/python3.7/dist-packages (0.4.0.dev1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (3.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyGPGO) (0.22.2.post1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from theano->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (1.1.5)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (4.41.1)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (0.5.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from pyMC3->pyGPGO) (2.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E99qMZverfrP"
      },
      "source": [
        "### Import modules:\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "from pyGPGO.logger import EventLogger\n",
        "from pyGPGO.GPGO import GPGO\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\n",
        "from pyGPGO.surrogates.tStudentProcess import tStudentProcess\n",
        "from pyGPGO.acquisition import Acquisition\n",
        "from pyGPGO.covfunc import squaredExponential\n",
        "\n",
        "from collections import OrderedDict\n",
        "from joblib import Parallel, delayed\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\n",
        "from scipy.optimize import minimize\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.special import gamma\n",
        "from scipy.stats import norm, t\n",
        "from matplotlib.pyplot import rc\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiJSpz2P9qXK"
      },
      "source": [
        "n_start_AcqFunc = 250 #multi-start iterations to avoid local optima in AcqFunc optimization"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzPUbCs3s9nu"
      },
      "source": [
        "### Inputs:\n",
        "\n",
        "obj_func = 'SumSquares'\n",
        "n_test = n_start_AcqFunc # test points\n",
        "df = 3 # nu\n",
        "\n",
        "util_loser = 'dEI_GP'\n",
        "util_winner = 'dCBM_STP'\n",
        "\n",
        "n_init = 5 # random initialisations"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AMqjmpbtAb1"
      },
      "source": [
        "### Objective function:\n",
        "\n",
        "if obj_func == 'SumSquares': # 8-D\n",
        "            \n",
        "    def f_syn_polarity(x1_training, x2_training, x3_training, x4_training, x5_training, x6_training, x7_training, x8_training):\n",
        "        return  operator * (  1 * x1_training ** 2\n",
        "                            + 2 * x2_training ** 2\n",
        "                            + 3 * x3_training ** 2\n",
        "                            + 4 * x4_training ** 2\n",
        "                            + 5 * x5_training ** 2\n",
        "                            + 6 * x6_training ** 2\n",
        "                            + 7 * x7_training ** 2\n",
        "                            + 8 * x8_training ** 2)\n",
        "                            \n",
        "# Constraints:\n",
        "    lb = -5.12 \n",
        "    ub = +5.12\n",
        "    \n",
        "# Input array dimension(s):\n",
        "    dim = 8\n",
        "    max_iter = 100\n",
        "\n",
        "# 8-D inputs' parameter bounds:\n",
        "    param = {'x1_training': ('cont', [lb, ub]),\n",
        "             'x2_training': ('cont', [lb, ub]),\n",
        "             'x3_training': ('cont', [lb, ub]),\n",
        "             'x4_training': ('cont', [lb, ub]),\n",
        "             'x5_training': ('cont', [lb, ub]),\n",
        "             'x6_training': ('cont', [lb, ub]),\n",
        "             'x7_training': ('cont', [lb, ub]),\n",
        "             'x8_training': ('cont', [lb, ub])\n",
        "            }\n",
        "\n",
        "    \n",
        "# True y bounds:\n",
        "    y_lb = 0.00000\n",
        "    operator = -1 # targets global minimum \n",
        "    y_global_orig = y_lb * operator # targets global minimum\n",
        "\n",
        "# Test data:\n",
        "    x1_test = np.linspace(lb, ub, max_iter) \n",
        "    x2_test = np.linspace(lb, ub, max_iter)\n",
        "    x3_test = np.linspace(lb, ub, max_iter)\n",
        "    x4_test = np.linspace(lb, ub, max_iter)\n",
        "    x5_test = np.linspace(lb, ub, max_iter)\n",
        "    x6_test = np.linspace(lb, ub, max_iter)\n",
        "    x7_test = np.linspace(lb, ub, max_iter)\n",
        "    x8_test = np.linspace(lb, ub, max_iter)\n",
        "    Xstar_d = np.column_stack((x1_test,x2_test,x3_test,x4_test,x5_test,x6_test,x7_test,x8_test))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GlOrB5CyJkY"
      },
      "source": [
        "Beta_CBM = 1.5 # Default UCB Acquisition function parameter in pyGPGO https://github.com/josejimenezluna/pyGPGO/blob/master/pyGPGO/acquisition.py#L83"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyQX-59DtC7-"
      },
      "source": [
        "### Cumulative Regret Calculator:\n",
        "\n",
        "def min_max_array(x):\n",
        "    new_list = []\n",
        "    for i, num in enumerate(x):\n",
        "            new_list.append(np.min(x[0:i+1]))\n",
        "    return new_list"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE_I_YSntHxl"
      },
      "source": [
        "### Set-seeds:\n",
        "\n",
        "run_num_1 = 111\n",
        "run_num_2 = 113\n",
        "run_num_3 = 3333\n",
        "run_num_4 = 444\n",
        "run_num_5 = 5555\n",
        "run_num_6 = 6\n",
        "run_num_7 = 777\n",
        "run_num_8 = 887\n",
        "run_num_9 = 99\n",
        "run_num_10 = 1000\n",
        "run_num_11 = 1113\n",
        "run_num_12 = 1234\n",
        "run_num_13 = 2345\n",
        "run_num_14 = 88\n",
        "run_num_15 = 1556\n",
        "run_num_16 = 1666\n",
        "run_num_17 = 717\n",
        "run_num_18 = 8\n",
        "run_num_19 = 1998\n",
        "run_num_20 = 2000"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe29v5N5tKjF"
      },
      "source": [
        "### Derivatives - Squared-exponential covariance function:\n",
        "\n",
        "def l2norm_(X, Xstar):\n",
        "    \n",
        "    return cdist(X, Xstar)\n",
        "\n",
        "def kronDelta(X, Xstar):\n",
        "\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\n",
        "\n",
        "class squaredExponentialDeriv(squaredExponential):\n",
        "    \n",
        "    def K(self, X, Xstar):\n",
        "        \n",
        "        r = (l2norm_(X, Xstar)/self.l)\n",
        "        K = self.sigmaf * np.exp(-1/2*r **2) + self.sigman * kronDelta(X, Xstar)\n",
        "        return K\n",
        "    \n",
        "    def dK(self, X, Xstar):\n",
        "        \n",
        "        r = (l2norm_(X, Xstar)/self.l)\n",
        "        dK = self.sigmaf/self.l**2 * np.exp(-1/2 * r **2) * l2norm_(X, Xstar)\n",
        "        return dK\n",
        "    \n",
        "        \n",
        "    def d2K(self, X, Xstar):\n",
        "        \n",
        "        r = (l2norm_(X, Xstar)/self.l)\n",
        "        d2K = self.sigmaf/self.l**2 * np.exp(-1/2 * r **2) * (r**2-1)\n",
        "        return d2K\n",
        "    \n",
        "cov_func = squaredExponential()\n",
        "d_cov_func = squaredExponentialDeriv()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEBX5l7TtNSN"
      },
      "source": [
        "class Acquisition_new(Acquisition):    \n",
        "    def __init__(self, mode, eps=1e-08, **params):\n",
        "        \n",
        "        self.params = params\n",
        "        self.eps = eps\n",
        "\n",
        "        mode_dict = {\n",
        "            'dEI_GP': self.dEI_GP,\n",
        "            'dCBM_STP': self.dCBM_STP\n",
        "        }\n",
        "\n",
        "        self.f = mode_dict[mode]\n",
        "    \n",
        "    def dEI_GP(self, tau, mean, std, ds, dm, dvdv, d2v, d2m):\n",
        "        z = -1 * (tau - mean - self.eps) / (std + self.eps)\n",
        "        \n",
        "        dsdx = ds / 2 * (std + self.eps)\n",
        "        d2sdx = -dsdx**2 / ((std + self.eps)) - dvdv / (std + self.eps) - d2v / (std + self.eps)\n",
        "        dmdx = (dm - z * dsdx) / (std + self.eps)\n",
        "        d2mdx = (d2m - (z * d2sdx + 2 * dmdx * dsdx)) / (std + self.eps)\n",
        "        \n",
        "        f = (std + self.eps) * (z * norm.cdf(z) + norm.pdf(z)[0])\n",
        "        df = (f / (std + self.eps) * dsdx + (std + self.eps) * norm.cdf(z) * dmdx)\n",
        "        d2f = (f / (std + self.eps) * d2sdx + dsdx * dmdx * norm.cdf(z) \\\n",
        "            + d2mdx * (std + self.eps) * norm.cdf(z) + dsdx * norm.cdf(z) * dmdx \\\n",
        "            + norm.pdf(z)[0] * (std + self.eps) * dmdx)\n",
        "            \n",
        "        return f, df, d2f\n",
        "\n",
        "    def dCBM_STP(self, tau, mean, std, ds, dm, dvdv, d2v, d2m, nu=3.0):\n",
        "    \n",
        "        gamma = -1 * (y_global_orig - mean - self.eps) / (std + self.eps)\n",
        "        dsdx = ds / 2 * (std + self.eps)\n",
        "        dmdx = (dm - gamma * dsdx) / (std + self.eps)\n",
        "\n",
        "        f = (std + self.eps) * (gamma + np.sqrt(Beta_CBM))\n",
        "        df = dsdx * (gamma + np.sqrt(Beta_CBM)) + (std + self.eps) * (dmdx + np.sqrt(Beta_CBM))\n",
        "        return f, df\n",
        "    \n",
        "    def _eval(self, tau, mean, std):\n",
        "    \n",
        "        return self.f(tau, mean, std, **self.params)\n",
        "    \n",
        "    def d_eval(self, tau, mean, std, ds, dm, dvdv, d2v, d2m):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, dvdv, d2v, d2m, **self.params)\n",
        "\n",
        "    def d_eval_stp(self, tau, mean, std, ds, dm, dvdv, d2v, d2m, nu=3.0):\n",
        "    \n",
        "        return self.f(tau, mean, std, ds, dm, dvdv, d2v, d2m, nu=3.0, **self.params)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SdY8rHwtRJ_"
      },
      "source": [
        "### Surrogate derivatives: \n",
        "\n",
        "from scipy.linalg import cholesky, solve\n",
        "\n",
        "class dGaussianProcess(GaussianProcess):\n",
        "    l = 1\n",
        "    sigmaf = 1\n",
        "    sigman = 1e-6\n",
        "\n",
        "    def AcqGrad(self, Xstar, return_std=False):\n",
        "        r_X = l2norm_(self.X, self.X)/self.l\n",
        "        K = self.sigmaf * np.exp(-1/2*r_X **2) + self.sigman * kronDelta(self.X, self.X)\n",
        "        L = cholesky(K).T\n",
        "        alpha = solve(L.T, solve(L, self.y))\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = squaredExponentialDeriv.K(self, self.X, Xstar).T\n",
        "        dKstar = squaredExponentialDeriv.dK(self, self.X, Xstar).T\n",
        "        d2Kstar = squaredExponentialDeriv.d2K(self, self.X, Xstar).T\n",
        "        v = solve(self.L, Kstar.T)\n",
        "        dv = solve(self.L, dKstar.T)\n",
        "        d2v = solve(self.L, d2Kstar.T)\n",
        "        \n",
        "        ds = -2 * np.dot(dv.T, v)\n",
        "        dvdv = np.dot(dv.T, dv)\n",
        "        d2s = -2 * (dvdv + d2v)\n",
        "        \n",
        "        dm = np.dot(dKstar, alpha)\n",
        "        d2m = np.dot(d2Kstar, alpha)\n",
        "        return ds, dm, dvdv, d2v, d2m\n",
        "\n",
        "class dtStudentProcess(tStudentProcess):\n",
        "    l = 1\n",
        "    sigmaf = 1\n",
        "    sigman = 1e-6\n",
        "    \n",
        "    def AcqGrad(self, Xstar, return_std=False):\n",
        "        r_X = l2norm_(self.X, self.X)/self.l\n",
        "        K = self.sigmaf * np.exp(-1/2*r_X **2) + self.sigman * kronDelta(self.X, self.X)\n",
        "        L = cholesky(K).T\n",
        "        alpha = solve(L.T, solve(L, self.y))\n",
        "        Xstar = np.atleast_2d(Xstar)\n",
        "        Kstar = squaredExponentialDeriv.K(self, self.X, Xstar).T\n",
        "        dKstar = squaredExponentialDeriv.dK(self, self.X, Xstar).T\n",
        "        d2Kstar = squaredExponentialDeriv.d2K(self, self.X, Xstar).T\n",
        "        v = solve(L, Kstar.T)\n",
        "        dv = solve(L, dKstar.T)\n",
        "        d2v = solve(L, d2Kstar.T)\n",
        "\n",
        "        smd_adj = (self.nu + self.beta1 - 2) / (self.nu + self.n1 - 2)\n",
        "        \n",
        "        ds = -2 * smd_adj * np.dot(dv.T, v)\n",
        "        dvdv = np.dot(dv.T, dv)\n",
        "        d2s = -2 * smd_adj * (dvdv + d2v)\n",
        "        \n",
        "        dm = np.dot(dKstar, alpha)\n",
        "        d2m = np.dot(d2Kstar, alpha)\n",
        "        return ds, dm, dvdv, d2v, d2m"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNv4Z0EqtUi2"
      },
      "source": [
        "class dGPGO(GPGO):  \n",
        "    n_start = n_start_AcqFunc\n",
        "    eps = 1e-08\n",
        "        \n",
        "    def func(self, xnew):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + 1e-6)\n",
        "        ds, dm, dvdv, d2v, d2m = self.GP.AcqGrad(xnew, return_std=True)\n",
        "        f  = np.empty((self.n_start,))\n",
        "        df = np.empty((self.n_start,))\n",
        "        f  = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[0]\n",
        "        df = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m)[1]\n",
        "        df_array = np.full((len(xnew),),df)\n",
        "        return f, df_array\n",
        "        \n",
        "    def d_optimizeAcq(self, method='L-BFGS-B', n_start=n_start):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "    \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self.logger._printInit(self)\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self.logger._printCurrent(self)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7vea4uj-GOi"
      },
      "source": [
        "## dGPGO_stp - BayesOpt derivatives' class: Student's-t\n",
        "\n",
        "class dGPGO_stp(GPGO):  \n",
        "    n_start = 100\n",
        "        \n",
        "    def func_stp(self, xnew):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + 1e-6)\n",
        "        ds, dm, dvdv, d2v, d2m = self.GP.AcqGrad(xnew, return_std=True)\n",
        "        f  = np.empty((self.n_start,))\n",
        "        df = np.empty((self.n_start,))\n",
        "        f  = -self.A.d_eval_stp(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m, nu=df)[0]\n",
        "        df = -self.A.d_eval_stp(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2v=d2v, d2m=d2m, nu=df)[1]\n",
        "        df_array = np.full((len(xnew),),df)\n",
        "        return f, df_array\n",
        "        \n",
        "    def d_optimizeAcq_stp(self, method='L-BFGS-B', n_start=n_start):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func_stp,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "\n",
        "        self.x_best = x_best\n",
        "        self.f_best = f_best\n",
        "        self.best = x_best[np.argmin(f_best)]\n",
        "    \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self.logger._printInit(self)\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq_stp()\n",
        "            self.updateGP()\n",
        "            self.logger._printCurrent(self)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expMSaSUtcB-"
      },
      "source": [
        "### d2GPGO - BayesOpt class: \n",
        "\n",
        "class d2GPGO(GPGO):  \n",
        "    n_start = 100\n",
        "    p = np.full((n_start,1),1)\n",
        "    \n",
        "    def func(self, xnew):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + 1e-6)\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\n",
        "        f  = np.empty((self.n_start,))\n",
        "        df = np.empty((self.n_start,))\n",
        "        f  = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[0]\n",
        "        df = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[1]\n",
        "        df_array = np.full((len(xnew),),df)\n",
        "        return f, df_array\n",
        "    \n",
        "    def hessp_nonzero(self, xnew, p):\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\n",
        "        new_std = np.sqrt(new_var + 1e-6)\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\n",
        "        df2 = np.empty((self.n_start,))\n",
        "        df2 = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[2]\n",
        "        H2 = np.empty((self.n_start,))\n",
        "        df2 = np.asarray(df2)\n",
        "        p = np.asarray(p)\n",
        "        H2 = np.multiply(df2,p)\n",
        "        return H2\n",
        "    \n",
        "    def d_optimizeAcq(self, method='Newton-CG', n_start=n_start):\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\n",
        "        start_points_arr = np.array([list(s.values())\n",
        "                                     for s in start_points_dict])\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\n",
        "        f_best = np.empty((n_start,))\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func,\n",
        "                                                                 x0=start_point,\n",
        "                                                                 method=method,\n",
        "                                                                 jac = True,\n",
        "                                                                 hessp = self.hessp_nonzero,\n",
        "                                                                 bounds=self.parameter_range) for start_point in\n",
        "                                               start_points_arr)\n",
        "        \n",
        "        x_best = np.array([res.x for res in opt])\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\n",
        "\n",
        "        self.best = x_best[np.argmin(f_best)]     \n",
        "    \n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\n",
        "        \n",
        "        if not resume:\n",
        "            self.init_evals = init_evals\n",
        "            self._firstRun(self.init_evals)\n",
        "            self.logger._printInit(self)\n",
        "        for iteration in range(max_iter):\n",
        "            self.d_optimizeAcq()\n",
        "            self.updateGP()\n",
        "            self.logger._printCurrent(self)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umKPgDuEtcxH",
        "outputId": "a7eee491-9e04-4c36-a9b7-54873b6e6d4a"
      },
      "source": [
        "start_lose = time.time()\n",
        "start_lose"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1616572654.6796505"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfEuNIqvtdSv",
        "outputId": "3b061dfd-133a-4d46-ad73-ef99f036821f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 1\n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_loser_1 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_1 = dGPGO(surrogate_loser_1, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.1486226  -3.38872572 -0.65475564  2.75724772 -2.09586888 -3.59257132\n",
            " -4.88982196 -0.8169012 ]. \t  -328.0959084909929 \t -201.54672633894333\n",
            "init   \t [-2.67589487 -1.6624006   5.02489564 -2.68568111 -4.28858717  1.73670644\n",
            "  1.24152749 -2.31164385]. \t  -280.8839324859534 \t -201.54672633894333\n",
            "init   \t [-0.34589276 -3.90791423 -4.36267454  4.10392759  3.01017662  3.4874332\n",
            "  3.22772436  5.02737768]. \t  -548.5335043326104 \t -201.54672633894333\n",
            "init   \t [ 0.79128402  3.21297323 -0.80570494 -4.83893289 -0.46964077 -4.04146089\n",
            "  3.24833343  2.024732  ]. \t  -322.64234862459267 \t -201.54672633894333\n",
            "init   \t [ 0.66852251 -2.31191249  5.10437114 -3.70644938  1.18185664 -0.15322828\n",
            " -0.97252315  2.33317475]. \t  -201.54672633894333 \t -201.54672633894333\n",
            "1      \t [-1.8143854  -1.01841357 -1.85378403  4.57955153  4.28757363  3.21376643\n",
            " -4.77105058  4.54013818]. \t  -577.6945507490634 \t -201.54672633894333\n",
            "2      \t [ 0.73477645  4.76179847  2.44940567  3.13414171 -3.48280262  1.90357758\n",
            " -3.83397596  3.09532749]. \t  -365.1147228674192 \t -201.54672633894333\n",
            "3      \t [-3.5467779   3.96685844  3.46147609 -1.56535356  3.7231233  -1.41064385\n",
            " -0.09555    -0.96783139]. \t  \u001b[92m-178.6035640716962\u001b[0m \t -178.6035640716962\n",
            "4      \t [ 4.70386575 -0.61990413 -3.52715656  1.33889179 -0.68273896 -1.23336882\n",
            "  5.01603996 -0.44567422]. \t  -256.559397064366 \t -178.6035640716962\n",
            "5      \t [-0.90304164 -4.48687786 -2.04677476 -0.42286783  3.29703598  4.43106951\n",
            "  2.02351792 -2.70572486]. \t  -313.75120296777686 \t -178.6035640716962\n",
            "6      \t [ 4.54601656 -2.9331311  -0.72674805 -4.70035876 -4.64794837  1.61737369\n",
            "  4.62058541 -2.42925591]. \t  -448.20220732965174 \t -178.6035640716962\n",
            "7      \t [-4.28389253 -3.73571984 -2.80655181  4.05331295 -3.78737786  3.18892028\n",
            "  3.94559298  0.89872328]. \t  -383.7825097969107 \t -178.6035640716962\n",
            "8      \t [ 4.95813127  4.96607931 -2.50561052  4.8892261   1.12715432  3.11191532\n",
            "  2.30920718  2.42021385]. \t  -337.00236425324454 \t -178.6035640716962\n",
            "9      \t [-2.17149059 -3.59638969  4.80494534 -0.21803099 -4.46695367 -3.25794579\n",
            " -3.89312838  4.85422792]. \t  -558.093067666367 \t -178.6035640716962\n",
            "10     \t [-1.92504556  1.47737033 -4.68448457 -4.21674554 -3.773463    4.80149054\n",
            "  1.64440906  2.29176778]. \t  -415.4951538555236 \t -178.6035640716962\n",
            "11     \t [-0.54926905 -3.67610341 -4.87724758 -1.49098033  4.71038006 -2.59407233\n",
            " -4.56647697 -5.11754304]. \t  -614.3805166225843 \t -178.6035640716962\n",
            "12     \t [ 2.15963188 -0.28935896  3.4330065   2.88435574  4.27790585 -3.59554826\n",
            "  4.51075703  4.08577132]. \t  -518.5130170758617 \t -178.6035640716962\n",
            "13     \t [ 4.23570729 -1.25322567 -4.62947164 -1.05331365 -2.46562431  1.1914759\n",
            " -2.57181313  2.46364884]. \t  -223.58655635373117 \t -178.6035640716962\n",
            "14     \t [ 2.7096023   4.01633633  4.42758465  0.27090644  2.56072218  3.20835866\n",
            "  4.91152799 -2.00296156]. \t  -394.21241125830977 \t -178.6035640716962\n",
            "15     \t [ 1.39724163  4.57433139 -4.27303488 -4.52305432 -4.06237888  0.60552741\n",
            "  2.07899585 -3.80950005]. \t  -411.47834480380516 \t -178.6035640716962\n",
            "16     \t [-1.83201609  0.49357821  3.33050886  4.68592079 -1.28128738 -0.32263751\n",
            "  2.7114435  -2.46402514]. \t  -233.81970085263237 \t -178.6035640716962\n",
            "17     \t [-0.64250492  4.02745109 -4.34114381  0.48860422  3.6144917  -0.22614658\n",
            " -0.36824808 -4.38741486]. \t  -310.91918711145547 \t -178.6035640716962\n",
            "18     \t [-2.83735731  0.64370077 -2.81905553 -3.31724895  4.90273561 -4.05767388\n",
            " -4.74791825  4.28473602]. \t  -600.3802641582724 \t -178.6035640716962\n",
            "19     \t [-4.6177753  -5.12       -5.12       -3.77963294 -5.12       -5.12\n",
            " -5.12       -5.12      ]. \t  -891.1127494403648 \t -178.6035640716962\n",
            "20     \t [ 1.9378258  -0.40952615 -4.48307333  3.37434648  1.41469669  3.7276301\n",
            " -5.03852252 -3.00652418]. \t  -453.32794428016115 \t -178.6035640716962\n",
            "21     \t [ 5.07111796  3.61588356  3.4351822   0.47630014  4.47335197  3.31201939\n",
            " -4.06301797  1.22378051]. \t  -381.58348162523873 \t -178.6035640716962\n",
            "22     \t [ 4.17234548 -3.74905414 -3.28714663 -4.64943455  3.46893149 -0.91697168\n",
            "  3.294976   -4.08604531]. \t  -439.18089529704207 \t -178.6035640716962\n",
            "23     \t [-4.06928374 -3.26578657 -0.23424264 -3.38168932 -1.78761698  3.68828215\n",
            " -4.90574398 -0.38207461]. \t  -351.0282334804192 \t -178.6035640716962\n",
            "24     \t [ 4.34737899  1.11821238 -3.5484966  -3.11002767  4.92652316  4.21818856\n",
            " -2.46464939  3.78102538]. \t  -482.867615012529 \t -178.6035640716962\n",
            "25     \t [ 3.52034175  2.20470734  4.9804913   2.53008909 -0.99106825 -3.82779259\n",
            " -3.68515401 -4.95183672]. \t  -506.1866325099793 \t -178.6035640716962\n",
            "26     \t [-4.71325354  0.12246692  4.20094829  3.08876566  4.01784593  3.47738765\n",
            "  2.56283126  2.56049282]. \t  -365.0450428305473 \t -178.6035640716962\n",
            "27     \t [-2.49808257  4.75065964  4.44686159 -4.88354925 -0.93892423  4.94734784\n",
            "  2.87944842  1.54779587]. \t  -434.5672340323659 \t -178.6035640716962\n",
            "28     \t [-4.89988621  4.21603438 -1.20137908  2.95240933 -2.91031254 -0.15904329\n",
            "  3.50721142  4.5311823 ]. \t  -391.61358719881946 \t -178.6035640716962\n",
            "29     \t [-4.18014667  1.74241484 -2.71315089  2.39393234 -3.34192551 -4.95366543\n",
            " -4.4650306   3.54951905]. \t  -511.97616621076304 \t -178.6035640716962\n",
            "30     \t [ 3.49892523 -4.7474275   2.72098332  4.67729941  3.10982505 -1.59525928\n",
            " -2.37362939  4.65839384]. \t  -443.70643578214737 \t -178.6035640716962\n",
            "31     \t [-5.00032705  2.54540284 -3.95784229  1.64796881 -3.92295653 -0.82039946\n",
            " -1.56928399 -3.69252898]. \t  -303.1211727260613 \t -178.6035640716962\n",
            "32     \t [ 5.11656808 -4.93464889  4.34227567  0.98576649 -1.60020465  2.77092347\n",
            "  3.93631358  4.62322016]. \t  -473.6604497374435 \t -178.6035640716962\n",
            "33     \t [ 2.85960226  1.58136403  2.54750539  4.44904883 -4.01792361 -4.30011451\n",
            "  2.3325104   3.77652939]. \t  -455.6703288108725 \t -178.6035640716962\n",
            "34     \t [-3.54459935  1.46610183 -5.01645307 -1.45635243  4.46382659  0.84644066\n",
            "  1.87163321  5.10013455]. \t  -437.3809130991791 \t -178.6035640716962\n",
            "35     \t [-3.51160644  1.10856337  1.12871135 -3.7390973  -3.92134226 -3.78712372\n",
            " -4.91832849 -2.28298046]. \t  -448.4987141336687 \t -178.6035640716962\n",
            "36     \t [ 4.71260685 -2.49237623  4.70617449  4.20653469  3.85063847  2.3875272\n",
            " -2.52132316 -5.07327811]. \t  -530.6000131506784 \t -178.6035640716962\n",
            "37     \t [ 2.93549399  3.90657854 -4.93585962 -4.17749541  3.4097731  -4.83751273\n",
            "  4.28033909 -4.18294895]. \t  -648.8013936318323 \t -178.6035640716962\n",
            "38     \t [ 4.56855361  4.20367402  2.77799543 -2.10763528 -1.93730782 -4.43642414\n",
            " -3.30261693  4.72665452]. \t  -489.07173105620086 \t -178.6035640716962\n",
            "39     \t [ 0.19846559 -5.00044851  0.74470773 -2.72860159 -3.52381154 -4.7474923\n",
            "  4.0222522   3.62534674]. \t  -497.2062333586665 \t -178.6035640716962\n",
            "40     \t [-1.38858521 -3.79328489 -1.9414471   1.17654329 -3.64858264 -5.07094967\n",
            "  3.02573596 -4.00943782]. \t  -461.08909598755315 \t -178.6035640716962\n",
            "41     \t [-3.94618998 -5.09977543  2.8350304  -3.05255108  2.49290155 -1.73084766\n",
            "  2.75878975 -3.18852749]. \t  -312.63019828576853 \t -178.6035640716962\n",
            "42     \t [ 4.28955641  1.62393721  2.62907685 -4.54514822 -3.36256723  4.01124725\n",
            " -1.89065269  1.8597176 ]. \t  -332.8095508882435 \t -178.6035640716962\n",
            "43     \t [-0.83279837 -3.58557033  1.65479721  3.35596166  4.91761397 -4.56161818\n",
            " -0.42980325 -4.89714434]. \t  -518.5852545005152 \t -178.6035640716962\n",
            "44     \t [-1.41733079 -3.40864428 -3.62978511  3.60345237  2.82708193 -4.98170245\n",
            " -0.11553571  3.64503984]. \t  -411.96211342431735 \t -178.6035640716962\n",
            "45     \t [ 3.68806589  0.29580031 -2.19194252 -4.0516204   0.3010597  -4.84995289\n",
            " -3.64586132 -2.82393441]. \t  -392.28159388543196 \t -178.6035640716962\n",
            "46     \t [ 0.35116245  3.8033669   3.27706938 -4.26440167  1.2857908   2.93571608\n",
            " -4.10115539 -4.72062457]. \t  -490.0001145922474 \t -178.6035640716962\n",
            "47     \t [ 0.72680912 -3.07683771  4.38815288  3.73295233 -4.75761292  4.78597016\n",
            " -4.35491819  4.78988401]. \t  -699.8780650728008 \t -178.6035640716962\n",
            "48     \t [ 0.13427484  4.58581167 -3.18088403  4.90150377 -1.97735851  2.73120737\n",
            "  3.93778666 -4.88157839]. \t  -532.018696550027 \t -178.6035640716962\n",
            "49     \t [-4.25120525 -4.33823768  3.11744765  4.83632822 -2.07364259  4.08534982\n",
            " -1.50597231 -2.14310463]. \t  -352.68839521256666 \t -178.6035640716962\n",
            "50     \t [-3.10079482  4.13865676  4.49257427  4.24417958  2.9946261  -5.10855223\n",
            " -0.56397688  4.40120627]. \t  -535.0879847234389 \t -178.6035640716962\n",
            "51     \t [ 4.89193555  2.9922182  -4.4090565   4.35654599 -3.14151355 -4.80922228\n",
            " -2.82633321  4.88653197]. \t  -611.1350065409885 \t -178.6035640716962\n",
            "52     \t [-5.116761   -3.4078763   4.70720691  1.68481497  3.37414999 -4.02799518\n",
            "  1.66036894  2.49068206]. \t  -350.4349456414508 \t -178.6035640716962\n",
            "53     \t [-4.00640676  4.29859192 -3.65006298  4.81681688  4.59271114 -4.32264932\n",
            "  5.02264788 -0.0077478 ]. \t  -579.9490422624966 \t -178.6035640716962\n",
            "54     \t [-4.75240757 -3.46651478 -4.16468996 -4.98850156 -3.00145315  2.39926035\n",
            "  3.05701124 -4.36268176]. \t  -495.4568131158855 \t -178.6035640716962\n",
            "55     \t [ 3.20948721  1.96142984  3.35512418 -2.77770081 -2.2567875  -2.72112168\n",
            "  4.80561782 -4.88575929]. \t  -505.14364186131274 \t -178.6035640716962\n",
            "56     \t [-4.44119934e+00  3.04367392e-04 -3.62044560e+00 -1.97100678e+00\n",
            "  5.09749507e+00  4.18575338e+00 -4.21634254e+00 -4.21908595e+00]. \t  -576.4803706937469 \t -178.6035640716962\n",
            "57     \t [ 3.56056097 -4.44071809 -1.92416096  4.5107665  -4.95588368  4.21496174\n",
            "  0.35656126 -1.70094388]. \t  -398.0477547919105 \t -178.6035640716962\n",
            "58     \t [ 0.05087862 -4.63262675  0.33468986 -0.37208618  4.43577072 -0.27981907\n",
            " -5.09650944  1.05332295]. \t  -333.3617692962063 \t -178.6035640716962\n",
            "59     \t [-4.20870321  5.00949523  1.03039795  1.54033222 -4.96287694  3.59014249\n",
            "  1.84870613 -1.7221088 ]. \t  -328.71366723065853 \t -178.6035640716962\n",
            "60     \t [-5.08081323 -5.00831854 -4.90907437 -4.03653195  1.31763745  1.93052368\n",
            " -1.72084209  4.48152714]. \t  -425.89670536930737 \t -178.6035640716962\n",
            "61     \t [-2.94630156  1.85204064 -4.48177937  4.37779427 -4.41801324  4.03286316\n",
            " -2.50716564  3.27228062]. \t  -477.30200921170746 \t -178.6035640716962\n",
            "62     \t [ 4.3689575   2.55954    -0.04175663  4.80091338  4.53786046 -2.940185\n",
            "  1.81799721 -3.2895046 ]. \t  -388.922123600972 \t -178.6035640716962\n",
            "63     \t [ 1.33916895 -4.77790072 -4.93183509 -5.12       -5.12       -2.10968421\n",
            " -0.23332327 -3.72876564]. \t  -494.6638645271121 \t -178.6035640716962\n",
            "64     \t [-2.2885106  -4.67712229  4.87497832 -1.68992639  1.39745979  0.80964265\n",
            " -4.22030748 -4.72678449]. \t  -448.8223685697748 \t -178.6035640716962\n",
            "65     \t [-5.11055397  3.631714   -4.03296505 -2.29371128  1.80389207  4.17381884\n",
            "  4.04026145 -1.38891296]. \t  -372.8286591368994 \t -178.6035640716962\n",
            "66     \t [ 3.04268536 -5.00534717  5.07241896  4.49395668 -4.02561866  0.81209006\n",
            " -3.08483143 -4.47221424]. \t  -528.9396900978516 \t -178.6035640716962\n",
            "67     \t [-4.66570291 -4.31556099  2.18051378 -4.47874819  0.05598302  4.86168445\n",
            "  1.95509287  3.25786486]. \t  -407.0152888715192 \t -178.6035640716962\n",
            "68     \t [ 1.37223287  4.95820864 -4.81528016  3.43028316  3.39085129 -1.6402152\n",
            " -4.22357095  1.92000498]. \t  -395.67124028208036 \t -178.6035640716962\n",
            "69     \t [-3.83097923 -4.7518301   4.81915116  1.24160059 -4.99047192 -4.87429373\n",
            " -2.03764122 -3.62714484]. \t  -537.0649183600898 \t -178.6035640716962\n",
            "70     \t [ 5.06129809  2.27866397  3.54546799 -3.95068559  4.64638981 -4.23106984\n",
            "  0.95893603 -0.91302245]. \t  -364.6062449412112 \t -178.6035640716962\n",
            "71     \t [-3.20445527  4.41189001  0.20716407 -3.93343932 -2.58444563  2.53802105\n",
            " -4.20626839  4.22901457]. \t  -450.1860823877116 \t -178.6035640716962\n",
            "72     \t [ 3.02492529  4.90843552 -4.24231339 -3.17702213  3.53836559  2.7130223\n",
            "  4.23784998  4.05318127]. \t  -515.6061281830977 \t -178.6035640716962\n",
            "73     \t [ 4.57208879  2.73644531 -0.24566955  4.9034039  -4.24131199  2.20580032\n",
            " -4.63963904 -3.8880297 ]. \t  -522.9897219624268 \t -178.6035640716962\n",
            "74     \t [-1.15658486  3.66035293  3.70892326  4.82043448  1.40931522  4.09437184\n",
            " -4.85968452 -3.31276901]. \t  -525.9741205638004 \t -178.6035640716962\n",
            "75     \t [ 3.84632847 -5.05248846  3.94826548  0.36598291 -0.03446007 -3.45069702\n",
            "  2.70219193 -4.83560437]. \t  -422.778939476137 \t -178.6035640716962\n",
            "76     \t [-4.77083464 -5.05914554 -5.01383676  2.0723645  -1.06459966  0.20687424\n",
            " -4.09418749 -4.34951055]. \t  -441.15140429941516 \t -178.6035640716962\n",
            "77     \t [ 4.30412742 -4.61623693  2.46223679 -3.30428667  4.97611899  3.06559302\n",
            "  2.20357931  4.29797528]. \t  -484.9729001273622 \t -178.6035640716962\n",
            "78     \t [-3.85278565  0.56308074 -1.81020507  4.654868    1.79699693  4.82559072\n",
            "  1.14697003 -1.85039183]. \t  -304.44411438595876 \t -178.6035640716962\n",
            "79     \t [ 5.11077465 -3.74174269 -1.15481817 -1.12097858  4.04048535  4.26432903\n",
            " -3.15785625 -5.09715995]. \t  -531.5358123413586 \t -178.6035640716962\n",
            "80     \t [ 1.01657741 -4.84006104  4.80662852  4.15648053 -4.43489169  4.35995235\n",
            "  4.89739863 -4.71934194]. \t  -744.767694637913 \t -178.6035640716962\n",
            "81     \t [-1.41300679  3.63408947  4.60404256 -1.77317678 -4.97538877 -2.46082105\n",
            "  1.78860756  3.61396973]. \t  -391.5643932015539 \t -178.6035640716962\n",
            "82     \t [-3.19543964  4.5692405   4.53625101 -0.76515767  4.30732802  4.5923212\n",
            " -3.17058534  4.27376166]. \t  -551.8317841031061 \t -178.6035640716962\n",
            "83     \t [ 4.64539093  4.10040387  0.67526913  4.06356214 -3.94020298 -3.31861195\n",
            "  3.38154254 -5.08222306]. \t  -553.0052439005033 \t -178.6035640716962\n",
            "84     \t [ 2.30830736 -5.01434541  4.21668411 -2.65624817 -4.62285088  2.28946276\n",
            " -4.69694087 -1.21247914]. \t  -441.6727047768591 \t -178.6035640716962\n",
            "85     \t [-3.67731504 -3.04531645 -4.48100564 -4.31398812  3.45849246 -3.44589359\n",
            "  4.73951721  0.35476119]. \t  -456.0497132950756 \t -178.6035640716962\n",
            "86     \t [ 3.51856878 -2.86245972  3.47495537 -3.39508718  2.04822444  4.42507835\n",
            "  3.10402858 -4.60605682]. \t  -486.7351457963999 \t -178.6035640716962\n",
            "87     \t [ 5.09284279 -4.25958418 -4.98065014 -3.44895771 -1.91043409 -4.54127354\n",
            "  4.8443878   4.74911329]. \t  -670.9240799985643 \t -178.6035640716962\n",
            "88     \t [-4.38605568  2.71456403 -4.94148169 -4.51823576 -2.58987641 -4.01666373\n",
            " -0.5418209   3.00044118]. \t  -393.3027336129907 \t -178.6035640716962\n",
            "89     \t [ 4.87461019  5.10418234  4.5542836  -2.31746233 -4.32425886  3.93096793\n",
            "  4.34327107  4.96251876]. \t  -674.846093936041 \t -178.6035640716962\n",
            "90     \t [-4.82213779 -1.43632134 -3.01387076  2.49227512  2.54331968 -1.36796155\n",
            "  4.93091166 -3.89251817]. \t  -414.45614036868307 \t -178.6035640716962\n",
            "91     \t [-3.50092552 -3.56371935 -0.64864517  0.40088294 -4.02236227  1.83781066\n",
            " -1.34563209  4.65117183]. \t  -326.46627494834104 \t -178.6035640716962\n",
            "92     \t [-4.42744353  4.96920143  3.58906869 -3.82776924 -2.65633257 -0.05572861\n",
            "  2.06635206 -4.40819512]. \t  -386.88499078009846 \t -178.6035640716962\n",
            "93     \t [-5.11971688  3.97085911  0.06406568  4.29879087  1.36125853 -2.2747117\n",
            " -2.3306557  -3.01272566]. \t  -282.6244926818938 \t -178.6035640716962\n",
            "94     \t [ 5.10445822  5.03694086 -3.83870615 -2.71947569  1.02793789  0.24332367\n",
            " -2.51261392 -0.77658436]. \t  -205.2420143608214 \t -178.6035640716962\n",
            "95     \t [-0.0408155  -4.89736627  4.70520283  3.50796092  3.61607695  2.20036275\n",
            "  3.96498487 -5.04763415]. \t  -571.9162775689066 \t -178.6035640716962\n",
            "96     \t [ 4.24977257 -2.70573376 -4.61390983  3.1100096   0.89577822  4.98180319\n",
            "  4.39987763 -5.11389164]. \t  -632.9055226242197 \t -178.6035640716962\n",
            "97     \t [ 4.69354154 -4.12489815  3.61995903 -1.20863372 -4.07588019 -5.10394983\n",
            " -1.86524354  4.24310558]. \t  -508.9657075217095 \t -178.6035640716962\n",
            "98     \t [ 3.68560779  1.52635715  4.57627363  4.94619402 -1.32564003  2.71459309\n",
            "  4.08863979  3.91059024]. \t  -471.29067612044463 \t -178.6035640716962\n",
            "99     \t [ 0.13366929 -4.98732101  2.48558377  4.87395579 -4.86882914  0.45525966\n",
            "  2.73524812  3.79284561]. \t  -450.5483220186158 \t -178.6035640716962\n",
            "100    \t [-5.11894699 -4.63836431  1.44214954 -4.3262629   0.67535932 -3.97661072\n",
            " -1.96594995  2.08875689]. \t  -309.45715882810106 \t -178.6035640716962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j6UBhkdtdVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ee7f77-5b9e-44ed-86b8-2a7d4114a6b0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 2\n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_loser_2 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_2 = dGPGO(surrogate_loser_2, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.60433145 -4.36322715  4.04410125 -0.65030607 -3.81258     0.77678463\n",
            "  3.48642222 -0.66436556]. \t  -266.73879363027606 \t -205.20381448253355\n",
            "init   \t [ 2.00612414  1.89069411  2.05463926  2.86406925  1.46175353  4.72090796\n",
            " -4.00931957  3.03212891]. \t  -387.12857956211883 \t -205.20381448253355\n",
            "init   \t [ 3.40562005 -2.39607436  3.44765838  0.32897952  0.17313346 -4.11046182\n",
            "  4.2892185   1.70658296]. \t  -312.7789728136913 \t -205.20381448253355\n",
            "init   \t [-3.33025814 -2.89083891 -0.32895713 -0.65647368  3.98698988 -2.84058346\n",
            "  0.91155831 -2.28145592]. \t  -205.20381448253355 \t -205.20381448253355\n",
            "init   \t [ 0.26339516 -2.46418319  0.29643398 -1.92367877  0.45222142 -2.6413414\n",
            " -4.15500263 -3.17986428]. \t  -271.9028038542476 \t -205.20381448253355\n",
            "1      \t [-3.58107824  4.03913561 -2.04029852 -2.32586783 -5.05364741  1.00365777\n",
            "  3.01415303  1.00987973]. \t  -285.07587324909576 \t -205.20381448253355\n",
            "2      \t [-4.60448096  2.80813531  4.99563621  0.03781622  4.39034062  3.92653567\n",
            "  0.21104926  2.43029119]. \t  -348.29121948523493 \t -205.20381448253355\n",
            "3      \t [-2.10140792  2.67807242  1.68628494  4.56034289 -1.8500807  -3.14762825\n",
            " -4.13600895 -2.97135732]. \t  -377.41471871614783 \t -205.20381448253355\n",
            "4      \t [ 1.0793017  -0.36269218 -3.70580843 -3.98481813 -0.83044235 -0.83705955\n",
            "  3.56686091 -3.98529023]. \t  -329.9121011113058 \t -205.20381448253355\n",
            "5      \t [ 3.31386882  4.20874624  2.80639656  4.70516753  0.77583565 -1.58822836\n",
            "  2.17294614 -1.95275945]. \t  -240.29324869898412 \t -205.20381448253355\n",
            "6      \t [ 4.95105294e+00  4.19026678e+00  4.72038052e+00 -3.21008855e+00\n",
            " -4.04784285e+00 -3.82553410e+00  1.05024894e+00 -4.81361638e-03]. \t  -345.1490179673393 \t -205.20381448253355\n",
            "7      \t [ 2.33545738 -4.97304683 -4.30376547  2.72277784  1.61017345 -2.10463381\n",
            "  1.33501868  4.40780283]. \t  -347.5839427484643 \t -205.20381448253355\n",
            "8      \t [-2.34986063  1.8091521   3.7986963   3.9519721  -3.28891208 -2.7619696\n",
            "  5.03032181  1.33988379]. \t  -409.1773629633698 \t -205.20381448253355\n",
            "9      \t [-3.22273268e+00  2.37005141e+00 -4.16522439e+00  6.51493680e-01\n",
            " -3.89879744e+00 -2.57010452e-03 -4.59403457e+00  3.66840666e+00]. \t  -406.76223418427173 \t -205.20381448253355\n",
            "10     \t [-2.61774008 -4.98801546 -4.77330403  0.84989543 -2.31165075  3.71622484\n",
            " -2.20166958 -4.92897108]. \t  -465.7258412436761 \t -205.20381448253355\n",
            "11     \t [-5.12       -3.43039073 -5.12       -4.89541015 -5.12       -5.12\n",
            " -1.87831075 -5.12      ]. \t  -747.0228821526194 \t -205.20381448253355\n",
            "12     \t [-2.74383482 -4.76027162  1.56539778 -4.87420914 -4.82820318  2.10326527\n",
            "  3.89508325 -4.56467333]. \t  -571.2238045852524 \t -205.20381448253355\n",
            "13     \t [-0.35945995 -4.31149655 -3.88015628  2.80347209  2.46317906  4.17909046\n",
            "  3.79086206 -1.0943501 ]. \t  -359.2121790938139 \t -205.20381448253355\n",
            "14     \t [-4.05057391  1.19906134  3.80677173 -4.20000697 -4.82457075 -4.60601283\n",
            " -4.89577116  0.38034293]. \t  -545.9292653945729 \t -205.20381448253355\n",
            "15     \t [ 4.00042221  4.15917878 -4.70357692  4.66649121  2.92576875  4.34557436\n",
            "  3.36154581 -0.58452661]. \t  -442.01439791400554 \t -205.20381448253355\n",
            "16     \t [-3.39620382 -4.92915808  4.72708377 -2.1033081   2.09920674  3.26277488\n",
            " -4.5062692  -4.33858475]. \t  -523.4983023419858 \t -205.20381448253355\n",
            "17     \t [ 1.98515247 -1.1162395  -2.96726016 -3.22734207 -5.04243962  0.87905021\n",
            "  5.10220265  4.71029511]. \t  -565.9993633594706 \t -205.20381448253355\n",
            "18     \t [-1.28941789 -2.74865336  4.12940631  3.5732032  -4.87864481  3.37777225\n",
            " -2.22426517 -2.22784091]. \t  -380.79954058960857 \t -205.20381448253355\n",
            "19     \t [ 3.17368219  3.42580892  0.41376376  3.82604179 -3.20112617  1.84845424\n",
            "  2.07407295  4.87122735]. \t  -384.29261628418 \t -205.20381448253355\n",
            "20     \t [ 1.77264381  3.40420581  4.06924414 -3.9926708  -3.76638096  4.72642494\n",
            " -1.6555747   2.69280524]. \t  -421.9202016332203 \t -205.20381448253355\n",
            "21     \t [-3.13128023 -3.80195953 -1.82995089  1.06242989 -1.24072416  3.61857374\n",
            " -1.40095991  5.10594269]. \t  -361.84136302467107 \t -205.20381448253355\n",
            "22     \t [ 2.71831835  2.67512725 -4.86121531 -3.79827197 -2.84846596 -0.93125416\n",
            " -4.32262479 -4.92646952]. \t  -521.0321972445549 \t -205.20381448253355\n",
            "23     \t [-4.06338518  4.72613409 -4.95656976 -4.43895757  4.19095298 -0.63936677\n",
            " -4.12108722  4.04667178]. \t  -553.8650266915038 \t -205.20381448253355\n",
            "24     \t [ 4.76009479  4.0149267   1.48402281 -2.07349993  4.13480995  5.0475682\n",
            "  5.01421097 -0.02580223]. \t  -493.0547964266358 \t -205.20381448253355\n",
            "25     \t [ 2.27363383 -0.89577868 -3.54680665 -1.84567889  2.87796295 -4.72404239\n",
            " -4.05541075  3.7379042 ]. \t  -460.35261367757926 \t -205.20381448253355\n",
            "26     \t [ 2.83314974 -3.19221916  1.85999456 -4.0034306   4.72378396  4.96489271\n",
            "  0.83894983  3.61788868]. \t  -472.00726685636505 \t -205.20381448253355\n",
            "27     \t [-3.0112922   1.59168628 -4.9661564   2.23883566  4.69468012  2.62841085\n",
            " -4.26505663 -4.73727671]. \t  -566.6931294890983 \t -205.20381448253355\n",
            "28     \t [-1.65516454 -0.40272635  4.0227448  -4.57250632  4.03751885 -2.77520498\n",
            "  4.14272249  3.88730923]. \t  -503.9854295947243 \t -205.20381448253355\n",
            "29     \t [-5.02533033  3.44944246  2.78118279 -2.91610821  1.87181413  0.85076349\n",
            " -0.28051198 -4.56371099]. \t  -295.30263807348786 \t -205.20381448253355\n",
            "30     \t [ 4.41932741 -0.20513988 -1.98251394 -5.10549001  5.00406475 -2.11768139\n",
            "  5.03191053  2.88918385]. \t  -531.8005158122904 \t -205.20381448253355\n",
            "31     \t [ 5.04076916  0.40952426 -4.70537138  1.927475   -5.07048048  4.49987135\n",
            "  4.37503007 -2.91891915]. \t  -559.2158162968242 \t -205.20381448253355\n",
            "32     \t [ 5.10569294  0.47148334 -4.07810266  1.38449582 -4.56139638 -3.47793813\n",
            " -5.10472494  3.58300957]. \t  -545.7919560018566 \t -205.20381448253355\n",
            "33     \t [ 4.62633951 -0.8008661  -1.83903656 -4.51376061 -1.95654027  1.49919124\n",
            " -3.59515761  1.92319954]. \t  -267.0194710085083 \t -205.20381448253355\n",
            "34     \t [ 3.65938321  4.7131228  -1.45326883  4.09968362  2.05891247 -2.60588818\n",
            " -4.74209317  2.08320302]. \t  -385.4532664657366 \t -205.20381448253355\n",
            "35     \t [ 2.16181213 -3.4514385   2.13807284  3.63737917 -1.72780553 -2.02956057\n",
            " -4.85921337  4.91008962]. \t  -492.93124146713467 \t -205.20381448253355\n",
            "36     \t [-3.5307784   4.70926616 -4.51000288  3.73276765  4.01398265 -2.09382881\n",
            "  1.68903504  2.71772964]. \t  -359.49867564858533 \t -205.20381448253355\n",
            "37     \t [-4.43965999 -4.44144977  0.32768465 -2.94604459 -3.90736056 -2.77507687\n",
            "  0.58510467  1.72800053]. \t  -243.0303411869632 \t -205.20381448253355\n",
            "38     \t [-1.51942612  4.7435367  -4.04175857 -5.00329791  2.34995023  4.67975545\n",
            " -1.83047509 -4.21304987]. \t  -520.9151175840888 \t -205.20381448253355\n",
            "39     \t [ 3.82832248 -0.54790786 -2.83848643 -1.79004786  4.58905072  5.04901325\n",
            " -4.51055539 -1.91953824]. \t  -482.3894870178258 \t -205.20381448253355\n",
            "40     \t [-4.57024609  1.740183   -3.37122051 -1.9649861   5.09488946  3.63558555\n",
            "  3.29879462  2.9033142 ]. \t  -429.1862627601474 \t -205.20381448253355\n",
            "41     \t [-0.45217569  4.92834826 -1.70794599 -2.10481222  5.08563179 -4.87289645\n",
            " -3.16501689 -4.65969324]. \t  -590.8660969826783 \t -205.20381448253355\n",
            "42     \t [ 1.65012337  2.63229413 -4.23668583  4.41671876 -4.17441048 -3.87788147\n",
            "  0.79343623 -3.7126064 ]. \t  -440.4896506595188 \t -205.20381448253355\n",
            "43     \t [-2.03990967 -2.37808422  1.83496803  4.78460755  3.94000459  0.69592214\n",
            "  1.68880674  3.51211123]. \t  -316.31090701968634 \t -205.20381448253355\n",
            "44     \t [-5.04812331 -2.11376174 -4.96100723  4.20478529  3.02978249 -5.06748408\n",
            " -3.62085827 -3.84424889]. \t  -588.9497593205815 \t -205.20381448253355\n",
            "45     \t [ 1.07478063  4.22677161  3.11106884 -3.22558246  4.46408112 -0.95141406\n",
            " -4.44050673  3.6509712 ]. \t  -457.27478572008846 \t -205.20381448253355\n",
            "46     \t [-3.88848965 -3.73497948  4.15016171 -3.14285281  3.868979   -0.46727879\n",
            " -3.34382558  4.16497727]. \t  -427.4016787229124 \t -205.20381448253355\n",
            "47     \t [-4.16015188 -3.50926668  2.3517009   3.15617493  4.74264754  5.1060005\n",
            " -4.71787613  4.68869369]. \t  -698.9442708396496 \t -205.20381448253355\n",
            "48     \t [ 2.66839396  5.01583393 -2.35761539 -1.37029358 -3.23083501 -4.93076305\n",
            "  2.77707835  2.75795647]. \t  -394.525135506849 \t -205.20381448253355\n",
            "49     \t [ 4.79222054  3.37275172  4.53249427 -4.42405919  3.24235076 -4.24621873\n",
            "  5.0536739  -2.70329731]. \t  -583.6223014617374 \t -205.20381448253355\n",
            "50     \t [ 3.36948159 -3.02137115  4.85322141  5.01311203 -4.51652643 -4.59341315\n",
            " -1.09534574 -4.71977194]. \t  -615.9973907484066 \t -205.20381448253355\n",
            "51     \t [-4.44028917 -3.42764893  4.66777121 -1.49350413 -0.47409231  4.49053307\n",
            "  3.99986492  1.67960966]. \t  -374.1744905144789 \t -205.20381448253355\n",
            "52     \t [-3.68872506  2.61743966 -2.5130144   1.49224406  1.4226413   4.70715536\n",
            "  3.24086789 -5.10308763]. \t  -480.07957673172336 \t -205.20381448253355\n",
            "53     \t [ 1.84941564  5.01038629 -2.84016568 -0.03383008  4.98729348 -2.36013214\n",
            "  4.86952141 -3.28560477]. \t  -487.96656503063355 \t -205.20381448253355\n",
            "54     \t [-4.32260683 -2.99108047 -4.17611218 -2.24123784  1.418179   -4.18077514\n",
            "  2.70254212  4.88218875]. \t  -465.7320974384571 \t -205.20381448253355\n",
            "55     \t [-3.80526209  4.89911735  2.70137742  5.06767009  4.02690318 -4.97774365\n",
            "  3.29449828 -3.3702309 ]. \t  -583.691181613033 \t -205.20381448253355\n",
            "56     \t [ 4.53352193 -3.91068307 -2.33427793  2.31844024 -4.63309735 -3.99640386\n",
            "  4.39449856 -2.34619655]. \t  -471.36077311657 \t -205.20381448253355\n",
            "57     \t [ 3.38609615 -2.88457345  3.31985771  2.47749963  4.77479943  1.04182905\n",
            "  2.86353077 -3.9983938 ]. \t  -391.525436257035 \t -205.20381448253355\n",
            "58     \t [ 4.37849071  4.44126115  4.2156092   0.44479182  3.86033837  0.24395199\n",
            " -3.94040689 -3.00175771]. \t  -368.3664006413996 \t -205.20381448253355\n",
            "59     \t [ 3.1444391   4.49979543 -0.87278189  1.76149835 -4.93221172  1.82603751\n",
            " -4.19850134  0.06105907]. \t  -330.14232599197277 \t -205.20381448253355\n",
            "60     \t [-4.82183569 -4.83358444 -3.22001796  4.81166664 -2.9735258  -2.99233584\n",
            "  0.48455932  1.71644855]. \t  -316.83813710437283 \t -205.20381448253355\n",
            "61     \t [ 3.20802435 -4.37622959 -1.67534178  5.10164565  1.66575766  0.20664911\n",
            " -2.82997798 -4.91994956]. \t  -424.9602777514018 \t -205.20381448253355\n",
            "62     \t [-1.08241013  4.06648448  0.85472488  3.97388722 -4.83826172  2.76619079\n",
            "  3.55132261 -4.30672048]. \t  -499.2237135982564 \t -205.20381448253355\n",
            "63     \t [ 0.1005769  -3.47689389 -5.01666767 -4.8476402  -4.90267213  4.05874708\n",
            "  0.05580106 -0.7125732 ]. \t  -416.7924415541221 \t -205.20381448253355\n",
            "64     \t [ 0.2370887   0.97399353 -5.12       -5.12       -5.12       -5.12\n",
            " -1.8379977   0.86444462]. \t  -503.4385026809674 \t -205.20381448253355\n",
            "65     \t [-2.85246369 -3.0521596   4.35859245 -4.20583547  4.25999384  3.16225751\n",
            "  4.37957814 -4.89783638]. \t  -631.428413188213 \t -205.20381448253355\n",
            "66     \t [-5.10793054 -4.72419363  0.54818852  2.43034055 -3.64631032 -3.4799733\n",
            " -2.17291989 -4.73845719]. \t  -447.06877578133225 \t -205.20381448253355\n",
            "67     \t [-2.71576481  1.64184641  2.16729266  3.6764636   4.87984431 -4.33652913\n",
            " -5.03811107  3.09529531]. \t  -567.1457872537084 \t -205.20381448253355\n",
            "68     \t [-1.820107    5.06893676  2.92557486 -4.7379063  -2.06928067 -3.38397148\n",
            "  4.35402782 -1.58367839]. \t  -413.0534144970227 \t -205.20381448253355\n",
            "69     \t [ 3.69308976 -4.62494601  4.72140238 -4.69469061 -1.12791401 -3.81940651\n",
            " -1.61156672  4.14679823]. \t  -461.09022635050167 \t -205.20381448253355\n",
            "70     \t [-5.07696954 -2.93736587 -4.57843213 -4.46220768  2.83240764 -1.68862341\n",
            " -4.6926524   1.31966602]. \t  -410.86358010979745 \t -205.20381448253355\n",
            "71     \t [ 4.88213042 -4.40273088  4.65929709 -3.25733207  0.83066957  2.59232312\n",
            " -4.71716218 -2.57396202]. \t  -422.70574465918975 \t -205.20381448253355\n",
            "72     \t [ 2.07543348  0.8506837   1.84584722 -2.69958227 -4.62404397  2.71760848\n",
            " -1.90155612 -4.58718478]. \t  -389.99799511466017 \t -205.20381448253355\n",
            "73     \t [-0.87456373 -5.11610213 -5.06824434 -2.46817669  3.82777825  4.22531169\n",
            " -4.48353083  4.37422509]. \t  -628.706836721851 \t -205.20381448253355\n",
            "74     \t [ 3.28956713  4.87454615 -4.59756689 -4.43709769  3.98896543  4.28842628\n",
            " -1.29889148  2.88552981]. \t  -468.8307776460498 \t -205.20381448253355\n",
            "75     \t [ 2.54608794  4.53871199  3.13018641  3.80253337 -4.70561221 -3.21855553\n",
            " -4.52250213  3.83885104]. \t  -568.8475444686522 \t -205.20381448253355\n",
            "76     \t [-2.56039145  3.46733859  4.91462549  2.14268527  2.32562956  4.95929711\n",
            " -4.8521194  -5.00356491]. \t  -661.122774713394 \t -205.20381448253355\n",
            "77     \t [ 4.19921635 -4.13576005 -5.08235854 -2.30929278  3.68556396  0.5655553\n",
            "  1.10322577 -0.30824678]. \t  -229.7807815323248 \t -205.20381448253355\n",
            "78     \t [ 4.30470265 -3.48479048  3.41867735  4.80142573 -0.30128821  3.15577951\n",
            "  0.28525138  2.20252777]. \t  -269.6809604559236 \t -205.20381448253355\n",
            "79     \t [ 0.33019399 -2.24894995  4.66459501 -4.88496649  0.38314758 -4.96060883\n",
            "  4.82739116 -3.35137946]. \t  -572.3112517481062 \t -205.20381448253355\n",
            "80     \t [ 3.8028368   0.90465333  5.10559894 -5.01418619  0.08429727  4.15561277\n",
            "  4.62625877  4.25163785]. \t  -592.9455590715716 \t -205.20381448253355\n",
            "81     \t [-4.777756   -1.02531315  4.56662448  3.61436189 -4.00635664 -4.77797107\n",
            " -1.2409007   4.4264625 ]. \t  -524.5020283677778 \t -205.20381448253355\n",
            "82     \t [-4.45449551  4.19139595 -5.07073419  3.08527364 -2.82669437  2.99991511\n",
            " -4.85503943 -4.36455414]. \t  -581.5332867760093 \t -205.20381448253355\n",
            "83     \t [-4.68815223 -4.07505125  1.86904991  3.94603702  0.65634513  2.6236039\n",
            "  4.29276958 -3.06202669]. \t  -375.4126156768334 \t -205.20381448253355\n",
            "84     \t [-4.17597231  0.07399827  4.25402625 -0.13438906 -2.33530115  4.20426749\n",
            " -4.00830319  4.31338312]. \t  -466.4431564811076 \t -205.20381448253355\n",
            "85     \t [-1.13007063 -4.65178386 -4.26892404  4.44514632  2.59937426  4.95272199\n",
            " -5.10405702  0.29289924]. \t  -542.2702560995635 \t -205.20381448253355\n",
            "86     \t [-1.15336559  5.05506058  1.86314739 -4.85191339 -1.32629675 -3.46227419\n",
            " -0.66268263  5.10296237]. \t  -449.13094430807206 \t -205.20381448253355\n",
            "87     \t [ 4.94144731 -3.63731067 -3.55704099  2.5708142  -4.27535511  4.53713701\n",
            " -4.18205914  3.69462789]. \t  -561.8084364995563 \t -205.20381448253355\n",
            "88     \t [ 4.36661442 -1.41410614 -2.37964451  4.26676938  2.80432637 -3.39693116\n",
            "  4.63302479 -1.54869915]. \t  -390.87438444523934 \t -205.20381448253355\n",
            "89     \t [ 4.69700199 -3.02381797  3.88605617 -4.32558823 -2.90451682 -4.30152308\n",
            " -1.26468256 -2.99691285]. \t  -396.7434712243486 \t -205.20381448253355\n",
            "90     \t [ 3.55615483  4.63603033  0.27819476 -4.68466769  0.52380261  1.13302734\n",
            " -0.45612107 -2.2104675 ]. \t  \u001b[92m-193.26842335836582\u001b[0m \t -193.26842335836582\n",
            "91     \t [4.10345471 2.71040448 3.90663338 0.57369875 3.52191583 0.54793306\n",
            " 1.28964667 4.16628857]. \t  -292.95964254113215 \t -193.26842335836582\n",
            "92     \t [-3.08050046  1.00401555 -4.87370323 -5.12        0.6349139  -5.12\n",
            " -4.28038962 -5.12      ]. \t  -684.8914524658223 \t -193.26842335836582\n",
            "93     \t [ 5.02179851 -4.08200011 -4.74063667  2.38259331 -3.50230389 -4.81361105\n",
            " -4.86650747 -3.37287357]. \t  -605.8180656163602 \t -193.26842335836582\n",
            "94     \t [ 4.5303776   4.65445707 -4.41916792  0.63533956  5.02543227 -0.98432673\n",
            "  2.09189457  4.15125045]. \t  -424.63746786503214 \t -193.26842335836582\n",
            "95     \t [-4.91522103  0.2662331  -4.30387437  4.63449328 -2.58970302  4.48432274\n",
            "  4.44237356  1.38523953]. \t  -473.46687315495 \t -193.26842335836582\n",
            "96     \t [ 4.26397637 -3.09213529  1.89182087  4.77004596  4.89146921 -4.51242135\n",
            " -4.83769487  0.62679372]. \t  -547.8244461446143 \t -193.26842335836582\n",
            "97     \t [ 0.12639672 -4.7535464   4.29546638  1.05414722  4.87167725 -4.71475792\n",
            "  0.00876931  4.24515102]. \t  -501.21722811283337 \t -193.26842335836582\n",
            "98     \t [-2.33645724 -4.00316033 -4.59329485 -4.53947544  1.39972388  4.88492764\n",
            "  1.73340836 -4.01055787]. \t  -485.91281029790207 \t -193.26842335836582\n",
            "99     \t [ 0.95765638 -3.55164261  2.06717215  3.88104496 -4.76770042 -1.58483748\n",
            "  1.94413515  4.891949  ]. \t  -445.8471240639599 \t -193.26842335836582\n",
            "100    \t [-0.19204005 -4.93371752 -1.52163738  3.86646956 -4.63571274  4.40078885\n",
            "  2.5602573   0.37834623]. \t  -386.1449117099215 \t -193.26842335836582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWnL1rwztdYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cd1e9c7-5593-4066-9c78-fe80f215878c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 3\n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_loser_3 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_3 = dGPGO(surrogate_loser_3, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.57613422e+00 -4.00126694e+00 -1.42118102e-01 -1.72873986e-03\n",
            "  1.60880639e+00 -2.70454056e+00  1.15501968e+00 -3.89475939e+00]. \t  -226.23757295607857 \t -200.83819991364615\n",
            "init   \t [ 2.17295152 -1.30498005  0.25362711 -2.42394027  1.24550372 -0.52121845\n",
            " -2.87678861  3.56542093]. \t  -200.83819991364615 \t -200.83819991364615\n",
            "init   \t [ 4.51432417  5.05385819 -3.54862621  1.12022459 -2.14496207 -2.14068561\n",
            "  3.26002484  1.12353371]. \t  -249.2524227715819 \t -200.83819991364615\n",
            "init   \t [ 1.1383917   3.70078893 -1.31804167 -3.13683123 -0.37390212 -2.85955193\n",
            " -3.88879197  1.70639   ]. \t  -252.1724482635516 \t -200.83819991364615\n",
            "init   \t [ 2.32018826 -0.4223289  -1.35717313 -2.05342954 -2.49788598  2.26036994\n",
            " -4.91879441  2.94613072]. \t  -328.7841092566316 \t -200.83819991364615\n",
            "1      \t [-3.55865421  4.31406842 -3.85626065 -3.59130616  2.02875186  3.68832922\n",
            " -3.19072393 -3.1190355 ]. \t  -397.3824499112952 \t -200.83819991364615\n",
            "2      \t [ 1.61474467 -2.07662329  1.28272464 -4.59017283  4.08130204  3.35896166\n",
            "  3.43878606 -2.59421678]. \t  -388.0443276485657 \t -200.83819991364615\n",
            "3      \t [-3.5553363  -2.51308271 -2.98117052 -0.24939697 -2.0899883   0.42425475\n",
            " -2.2295405  -2.63903951]. \t  \u001b[92m-165.6149144600416\u001b[0m \t -165.6149144600416\n",
            "4      \t [ 0.16800741  4.43349801  1.98132744 -3.84107635  0.97602154 -4.70843947\n",
            "  3.98726329  4.25714016]. \t  -504.18580326144445 \t -165.6149144600416\n",
            "5      \t [-4.99583186 -0.17514218 -1.89337007  0.86461806  0.6602039   2.79787651\n",
            "  4.87752486 -3.50544022]. \t  -352.7491483820859 \t -165.6149144600416\n",
            "6      \t [-0.85454523  1.90921614  2.65947013  4.05894716 -4.79502561  0.71319089\n",
            " -4.45606246 -3.76644578]. \t  -465.6365719436497 \t -165.6149144600416\n",
            "7      \t [-3.29853345  2.00623056 -2.03050638 -2.82838086  4.16457577  4.25733991\n",
            "  3.15621368  4.25224594]. \t  -473.15073965838565 \t -165.6149144600416\n",
            "8      \t [-3.69790866  3.91048608 -1.95059034  4.94006827  3.95991808 -1.64178344\n",
            " -3.07477592  4.08531902]. \t  -447.56569153718317 \t -165.6149144600416\n",
            "9      \t [ 3.48363279 -4.77781707 -2.57716541 -4.63400729 -3.56865426  3.70754444\n",
            "  1.88975794 -2.34405226]. \t  -378.7189324711516 \t -165.6149144600416\n",
            "10     \t [ 1.1031735  -4.19883417  5.02658808  4.39804141  0.44308548 -5.04226789\n",
            " -0.45318247  2.84156246]. \t  -409.21009964433546 \t -165.6149144600416\n",
            "11     \t [ 4.92864448  2.02027643  0.45674349  4.39030744  3.79716567 -3.29947963\n",
            " -4.91267816 -4.3503863 ]. \t  -567.9390760654609 \t -165.6149144600416\n",
            "12     \t [ 2.05296226 -0.05004244 -5.07803325 -3.36613229  2.85810006 -1.64192996\n",
            "  3.82055175  2.16789855]. \t  -323.69618053459465 \t -165.6149144600416\n",
            "13     \t [-5.12       -5.12       -5.12       -5.12       -4.81069891 -5.12\n",
            " -4.84804668 -5.12      ]. \t  -909.3846161522091 \t -165.6149144600416\n",
            "14     \t [ 2.97780262 -0.39346246  1.90010274  2.96225562  3.11651999  3.49034808\n",
            "  4.49646808  1.75514882]. \t  -342.93855631708135 \t -165.6149144600416\n",
            "15     \t [-1.13037769 -0.08290228  2.43403225  3.96112439 -3.85020688 -4.51945585\n",
            "  3.67312703 -1.94919222]. \t  -403.33825428051796 \t -165.6149144600416\n",
            "16     \t [ 3.53136129 -3.78883587 -4.82888144  4.39438933  4.55010586  4.94452443\n",
            " -2.19098578 -2.04648888]. \t  -505.6930978235834 \t -165.6149144600416\n",
            "17     \t [-3.58364227  4.6350722   4.93340123  3.05909439  3.62045623 -4.1262635\n",
            "  3.03388363  2.04441228]. \t  -431.8207986956495 \t -165.6149144600416\n",
            "18     \t [ 4.32867925 -2.48201178 -3.96885691  3.68052988 -0.33972975 -2.67451474\n",
            " -0.12052241  2.20086011]. \t  -214.8461226417243 \t -165.6149144600416\n",
            "19     \t [ 3.34358602 -2.49797282 -0.19168509 -4.55364232  4.62525955  1.29160328\n",
            " -4.66359344 -4.45479365]. \t  -534.6919487688178 \t -165.6149144600416\n",
            "20     \t [-2.63042317 -4.08007274 -1.71321857  4.94443504 -0.10361633  0.98970497\n",
            " -4.79064079  3.77069421]. \t  -427.1357485116609 \t -165.6149144600416\n",
            "21     \t [-4.24674033 -2.51746553 -4.9018085  -2.9409886   0.99191976 -4.32331428\n",
            " -4.39718023  4.39391235]. \t  -544.254790781821 \t -165.6149144600416\n",
            "22     \t [ 2.99353594  3.99083914  4.03543583 -1.72880278 -3.15032815 -3.89359782\n",
            " -2.70714492 -4.66200809]. \t  -467.38256671628403 \t -165.6149144600416\n",
            "23     \t [-3.02973341  0.73977026  3.94972792  2.27951195  3.41645874 -2.4192243\n",
            " -1.60445245 -4.06933467]. \t  -321.8321348771259 \t -165.6149144600416\n",
            "24     \t [ 3.00632812  0.02171602  3.86664579  4.78360119 -4.01932428  4.60487711\n",
            "  2.3459114  -2.43737356]. \t  -439.4767809678742 \t -165.6149144600416\n",
            "25     \t [ 3.14948666  2.56698501  3.11243386  4.36758631  4.43605767  1.28845414\n",
            " -4.31363559  4.90350181]. \t  -559.4235908290552 \t -165.6149144600416\n",
            "26     \t [-4.031317    4.73374386  2.34687521  4.46465774 -2.15159996  3.54014599\n",
            "  2.76746115  4.69538213]. \t  -485.6518324241008 \t -165.6149144600416\n",
            "27     \t [ 2.88872717 -4.40914625  4.47493629  5.0224009  -0.29186588 -1.12464564\n",
            " -3.81799438 -4.95966476]. \t  -515.0397527334343 \t -165.6149144600416\n",
            "28     \t [-4.92564809 -2.09757831  1.92267124 -4.98223983 -1.49506402  1.46552054\n",
            "  2.64896263  3.94907986]. \t  -341.38598801189954 \t -165.6149144600416\n",
            "29     \t [ 1.90605704  0.76386745  5.01884806 -3.18399255 -2.98357142  1.19953494\n",
            "  1.12503714  0.05526961]. \t  -182.9439767091382 \t -165.6149144600416\n",
            "30     \t [-0.69404662 -0.96891864 -4.12410031  5.04611574 -1.8394591   2.72722187\n",
            "  4.91656901  5.03472585]. \t  -588.7778079012201 \t -165.6149144600416\n",
            "31     \t [-4.17644533  3.24873341 -4.17747225  0.30164602  2.29251636 -3.95622078\n",
            " -4.18085204 -4.60371101]. \t  -503.3671777354435 \t -165.6149144600416\n",
            "32     \t [-4.94151531 -3.15576797  2.20062317  2.28976708  4.38231657 -3.18032351\n",
            "  4.72422864  3.78170681]. \t  -507.1857201430117 \t -165.6149144600416\n",
            "33     \t [-3.55028654  3.67277985 -2.53310403 -2.41026927 -2.71663822 -4.49801299\n",
            "  3.31786564 -4.36421295]. \t  -469.7924037164481 \t -165.6149144600416\n",
            "34     \t [-0.99523326  4.57301701  1.64025597  3.13242291  4.97756553  4.81504752\n",
            "  3.4615533  -3.69545857]. \t  -546.2517303604358 \t -165.6149144600416\n",
            "35     \t [ 2.68457784  3.30276331 -4.23908102  4.09956665 -4.54024951  4.33665699\n",
            " -1.71198155  3.67054731]. \t  -494.3670570278788 \t -165.6149144600416\n",
            "36     \t [-4.87917131  3.89610413  4.74492988 -3.79911642  3.84599038  4.2467039\n",
            "  1.60781127 -4.04502532]. \t  -510.6002007614677 \t -165.6149144600416\n",
            "37     \t [ 4.41425462 -3.63192689 -0.67828279 -2.13706813 -3.99088409 -4.65069894\n",
            "  3.9495238   5.08958641]. \t  -591.3479424071611 \t -165.6149144600416\n",
            "38     \t [-1.3319591  -4.46609804  4.3228492   4.69954022 -4.72707002  0.97812151\n",
            "  4.2261878   4.59690529]. \t  -597.6132010849167 \t -165.6149144600416\n",
            "39     \t [ 4.66194442  4.16529656  3.36567233  3.94592082 -4.65698133 -0.71144314\n",
            " -3.96154872  3.17353416]. \t  -454.599445650608 \t -165.6149144600416\n",
            "40     \t [-4.95488466 -4.55741242 -4.91109712 -2.1252972   0.80110553  3.46981454\n",
            " -0.36434769  4.519742  ]. \t  -396.3153905975478 \t -165.6149144600416\n",
            "41     \t [ 3.71918161  4.21934514 -1.53518931  1.98334018  3.5918785  -3.90469685\n",
            "  5.06134933 -4.96004254]. \t  -604.3679060542768 \t -165.6149144600416\n",
            "42     \t [-3.99099689  3.01021382  3.63866031 -3.77721951 -4.64925369  4.09388695\n",
            " -3.83683348 -4.1970832 ]. \t  -583.4502847375934 \t -165.6149144600416\n",
            "43     \t [-4.12544837  5.08412044 -4.26201647 -1.37893367 -3.69236395  1.62943046\n",
            " -3.29209868  4.46618292]. \t  -450.35380514877863 \t -165.6149144600416\n",
            "44     \t [ 1.96275455 -4.6324552   4.47998593  1.59017621 -1.79777771  5.02986485\n",
            " -2.49555549  2.25328451]. \t  -369.26732623377575 \t -165.6149144600416\n",
            "45     \t [-1.96721046 -4.41867388  3.41979989 -3.65373615 -4.6123689  -2.86302341\n",
            "  4.65786482 -1.71983031]. \t  -462.48713553606797 \t -165.6149144600416\n",
            "46     \t [-1.03675744  4.68144449  0.8528998  -1.8921516   3.77161869  4.53650027\n",
            " -4.88550376  3.11847673]. \t  -500.89072714847566 \t -165.6149144600416\n",
            "47     \t [-5.0483826  -4.35425836 -0.88121373 -4.56125872  4.03374884 -4.67471046\n",
            " -0.51284743 -2.36443401]. \t  -407.9938642331148 \t -165.6149144600416\n",
            "48     \t [ 4.9789063  -2.1235961   0.41078697 -0.62579769 -3.89706573  3.77240055\n",
            "  4.36765051  4.54054743]. \t  -495.6703642853077 \t -165.6149144600416\n",
            "49     \t [ 1.50557294 -4.2794977   1.99767154 -4.90794662 -4.51864128 -2.54635977\n",
            " -4.42315655 -2.07185031]. \t  -459.5037765363599 \t -165.6149144600416\n",
            "50     \t [ 5.04147769 -1.78697239 -1.32860303  4.28851798 -4.88679281 -5.09553574\n",
            " -3.3114969  -3.31996518]. \t  -550.7942008285715 \t -165.6149144600416\n",
            "51     \t [-1.47998092 -4.15883223  4.85249255  1.88283239  0.88909716  4.19050888\n",
            "  0.84429073 -4.98931261]. \t  -435.0527650969827 \t -165.6149144600416\n",
            "52     \t [-4.97421906 -0.85648591  4.25896552 -0.47011627  4.3686422   4.69681493\n",
            " -5.00963231 -2.40909019]. \t  -531.4006225352056 \t -165.6149144600416\n",
            "53     \t [-3.54673805  2.06728473 -3.81297971 -4.83820017 -3.788281    4.48723515\n",
            "  4.8911578   0.8224492 ]. \t  -523.8182440769525 \t -165.6149144600416\n",
            "54     \t [ 4.46531086  4.83294392 -3.36937247 -4.42519204  4.88574428  5.01152055\n",
            "  0.96979715  2.28421934]. \t  -497.41033088296564 \t -165.6149144600416\n",
            "55     \t [ 4.34457417  4.61702411 -1.85499373  0.52439663 -5.08340819  4.35856684\n",
            "  3.36422128 -3.66354742]. \t  -502.7184755643889 \t -165.6149144600416\n",
            "56     \t [ 4.77176329 -4.29936615  4.90405609 -1.6697823   3.28360609 -4.35365338\n",
            " -4.0765625  -0.28308008]. \t  -427.6465520399117 \t -165.6149144600416\n",
            "57     \t [-2.90773754  1.26518453 -3.62006142 -4.18007324 -4.9322785  -4.20928722\n",
            "  4.50561161  3.25022131]. \t  -575.4236149346191 \t -165.6149144600416\n",
            "58     \t [ 2.51322501  1.9581762  -4.9597527  -4.99844048 -2.50488669 -0.89137049\n",
            "  0.14459634 -3.49294192]. \t  -321.611314983077 \t -165.6149144600416\n",
            "59     \t [-1.24232018  2.09841867  4.96602357 -3.35216259  4.45676059 -2.81719908\n",
            "  4.41325125 -3.60542495]. \t  -516.5456847327612 \t -165.6149144600416\n",
            "60     \t [-4.92817098  2.21078551  4.71659487 -0.53303935 -2.4597139  -2.86713936\n",
            " -4.26006985  4.49398829]. \t  -470.11604300232807 \t -165.6149144600416\n",
            "61     \t [-4.78236536  4.29451938  4.15099296 -3.87697169  4.99372898 -2.66546176\n",
            " -3.53091469 -0.45875287]. \t  -427.84258487125794 \t -165.6149144600416\n",
            "62     \t [-3.9108347  -3.83265284 -4.83821904  3.026387   -5.03437244 -1.43163238\n",
            "  4.82136358 -2.5690875 ]. \t  -506.07671595336 \t -165.6149144600416\n",
            "63     \t [ 5.08384265  1.8726926  -2.30657908  4.93208369  4.8513518  -4.06389485\n",
            "  4.22884152  3.88805787]. \t  -609.0093059293391 \t -165.6149144600416\n",
            "64     \t [-5.09016046  0.96403342 -3.25397902  4.15021595  3.18635166  3.55677407\n",
            " -4.77840043 -0.94738262]. \t  -422.1108425170692 \t -165.6149144600416\n",
            "65     \t [ 4.47280976  3.50057154  5.01362074  2.91406407  1.72915963  3.89601157\n",
            " -3.50524873 -3.60669899]. \t  -449.98728923236666 \t -165.6149144600416\n",
            "66     \t [-5.09722005  3.92552686 -2.68075681  4.92793409 -0.41795657 -3.49457334\n",
            "  4.8449486   4.99495702]. \t  -613.5558323074906 \t -165.6149144600416\n",
            "67     \t [ 3.67751966 -0.37519853 -2.60989024  3.24005886 -2.56528732  4.51222152\n",
            " -2.93118562 -4.20208253]. \t  -432.69948379437574 \t -165.6149144600416\n",
            "68     \t [-3.75126853  3.52881083 -4.77893937  3.63389032 -4.4222119   2.84015228\n",
            "  2.08208046 -0.40248944]. \t  -338.13242327945835 \t -165.6149144600416\n",
            "69     \t [ 4.88704416  4.72680515  1.09302443 -3.95184806  2.33142824  2.05278167\n",
            " -5.08980273 -4.43580748]. \t  -525.8361044788596 \t -165.6149144600416\n",
            "70     \t [ 4.75020844  2.38537111  2.70645962 -4.37269825  2.15285028  3.13243601\n",
            "  2.74998334  5.0632273 ]. \t  -472.47497989037333 \t -165.6149144600416\n",
            "71     \t [ 5.03930603  2.80194249  4.8834581   0.88400214 -3.23721565 -2.31670457\n",
            "  4.59354103  4.63873408]. \t  -520.2144081899424 \t -165.6149144600416\n",
            "72     \t [-4.4390866  -4.72131909  4.66162941 -0.59318343 -4.56119753  3.25507445\n",
            " -4.57199531  0.12954487]. \t  -444.9389458226059 \t -165.6149144600416\n",
            "73     \t [-0.12063523 -4.69021229 -2.88610585 -0.29097971 -4.7879143  -3.51602815\n",
            " -1.16437768  2.38247372]. \t  -313.033449428373 \t -165.6149144600416\n",
            "74     \t [-1.59409257 -3.75216083 -3.99548533  3.71190855  4.60611715 -3.78966652\n",
            " -4.48396171 -3.21495295]. \t  -549.3831009491103 \t -165.6149144600416\n",
            "75     \t [ 1.98801674  3.82025468  4.22760207 -0.34831578  4.69712482 -5.06519566\n",
            " -4.64682073  4.60202249]. \t  -672.0756942531416 \t -165.6149144600416\n",
            "76     \t [ 4.58998869  3.31811055 -4.38742089 -4.19599107 -3.87143644  2.30985043\n",
            "  1.44139322  4.26543201]. \t  -438.3085989125789 \t -165.6149144600416\n",
            "77     \t [ 2.2063623   3.53425288 -3.2532456   4.79636906  4.15274694  3.41667844\n",
            "  1.04814473  4.81613386]. \t  -503.14146661337656 \t -165.6149144600416\n",
            "78     \t [-5.12        0.03479205 -1.06546065 -5.12       -5.12       -5.12\n",
            " -5.12        0.34910778]. \t  -607.3142500823373 \t -165.6149144600416\n",
            "79     \t [-4.27748432 -0.94938718 -0.13659505  5.0348937  -2.34161379 -4.8530344\n",
            " -3.9055406  -1.10907426]. \t  -406.89666712115735 \t -165.6149144600416\n",
            "80     \t [-2.02205068 -1.62346134  4.00588647  2.23208234  4.40349156  2.21673169\n",
            " -0.00783817  4.92018734]. \t  -397.5335513407766 \t -165.6149144600416\n",
            "81     \t [ 4.26338672  2.57335483 -4.94632075  0.22565791 -4.39057838 -2.32664834\n",
            " -4.76031295 -1.24269519]. \t  -404.86676315486346 \t -165.6149144600416\n",
            "82     \t [ 4.7204559   1.00911129  4.92105632  0.73338349  4.32158967 -3.21458855\n",
            "  3.0373618   2.00719069]. \t  -351.3127529134782 \t -165.6149144600416\n",
            "83     \t [-4.90706675 -2.21688423  4.17314472 -5.03864563  2.93672548 -2.76668083\n",
            " -4.90958683  3.84490801]. \t  -563.749425509587 \t -165.6149144600416\n",
            "84     \t [-4.67296149  1.34741134 -2.25810548 -1.10093894  3.41619499 -3.66950071\n",
            "  1.39563734  1.82984245]. \t  -225.17755715694943 \t -165.6149144600416\n",
            "85     \t [-2.07223155 -2.53699654  4.63102996 -3.73058305 -0.76715238 -5.1067947\n",
            "  3.28327891  4.52525613]. \t  -535.8768751113289 \t -165.6149144600416\n",
            "86     \t [ 1.76867618 -5.12       -3.74075223 -3.21374523 -5.12       -5.12\n",
            " -0.28866445 -5.12      ]. \t  -637.5062207021906 \t -165.6149144600416\n",
            "87     \t [ 0.45808553 -0.48758756 -5.09556988 -1.64903818  4.62588738  2.84332173\n",
            " -4.90243115 -0.0495337 ]. \t  -413.21461814510985 \t -165.6149144600416\n",
            "88     \t [ 4.44490271 -1.77443053 -4.53953354  3.19262259 -5.08748307  1.96906582\n",
            "  4.88875002  0.22213943]. \t  -449.0174634326367 \t -165.6149144600416\n",
            "89     \t [-2.54579889  1.61691184 -3.78875499  3.98651805  5.10508405  0.13004974\n",
            "  5.00629468  1.6062125 ]. \t  -444.83434480572805 \t -165.6149144600416\n",
            "90     \t [-2.31340285  4.35542242  3.74381205 -4.76285802 -2.08659593  4.47695757\n",
            " -1.54339928  2.65444546]. \t  -391.1504160503256 \t -165.6149144600416\n",
            "91     \t [-2.01033793  3.9884939   3.75088164 -4.96137682 -2.53003927  4.6296153\n",
            "  4.41065071 -2.41475418]. \t  -519.9567055998066 \t -165.6149144600416\n",
            "92     \t [ 1.59886628 -2.73366291 -4.54576404  0.17159108  5.09620569  4.9027707\n",
            "  4.04082488 -4.95799001]. \t  -664.6425906762959 \t -165.6149144600416\n",
            "93     \t [ 2.28218018 -2.08016562  4.98518464  0.06076062 -5.11912625 -4.10216019\n",
            " -4.77152726  4.19535195]. \t  -620.6071971060567 \t -165.6149144600416\n",
            "94     \t [-3.34113688 -4.30964653 -1.12825647 -3.8736219  -5.00379611  0.61158191\n",
            " -4.75109609  4.25348968]. \t  -542.3298426871994 \t -165.6149144600416\n",
            "95     \t [ 0.85648405  3.73037645 -2.4121026  -4.54126286  4.66624228 -2.03014517\n",
            "  0.12993294 -3.08215142]. \t  -338.2254304290095 \t -165.6149144600416\n",
            "96     \t [ 4.10536235 -2.46491047  4.27593762 -1.96821445 -4.78476044 -5.02441499\n",
            "  1.53943102 -0.43372814]. \t  -383.38400123824306 \t -165.6149144600416\n",
            "97     \t [-5.04978285 -1.94000921 -2.77796168  2.65938095  4.65492609 -4.45313076\n",
            "  2.49973763 -4.98040857]. \t  -553.9685192141608 \t -165.6149144600416\n",
            "98     \t [-3.81555206 -3.34517769  1.75825915 -1.02303398 -0.97013503 -5.12\n",
            " -5.12       -5.12      ]. \t  -605.6078948975702 \t -165.6149144600416\n",
            "99     \t [ 3.15541014 -3.77158908  2.40531833 -5.03761839  4.27693924 -3.58593346\n",
            "  2.3533155   1.84480358]. \t  -391.8810644588522 \t -165.6149144600416\n",
            "100    \t [ 2.99214261 -4.12008532 -3.78842699 -5.11970551  4.36066714 -5.03349041\n",
            " -3.71366618  2.16256168]. \t  -571.8510424121014 \t -165.6149144600416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zciLjgNltda2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93246c1c-7458-4b3f-b804-5919fb103911"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 4\n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_loser_4 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_4 = dGPGO(surrogate_loser_4, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.47505713  3.29006044  1.45620137  1.71235961 -4.71920737 -4.44751474\n",
            " -2.28863345 -1.88046844]. \t  -346.80639555492485 \t -165.62625697677552\n",
            "init   \t [-3.1376137  -3.10176889  3.57585195  3.50574682 -1.56298519  2.45496116\n",
            " -0.06749038 -0.27635987]. \t  -165.62625697677552 \t -165.62625697677552\n",
            "init   \t [-3.7790926  -1.54671161  4.27823555  2.60935971 -4.15202172  0.36061924\n",
            "  2.14992129  0.60475125]. \t  -223.4687278056974 \t -165.62625697677552\n",
            "init   \t [-0.25707746  4.70597666  2.91673192  2.51031751  4.76862861  1.58260827\n",
            "  2.63690453 -2.92386101]. \t  -340.87882459564884 \t -165.62625697677552\n",
            "init   \t [-4.10230933 -4.5220156  -2.28380738  4.65096756 -4.15019246  2.30585903\n",
            " -2.53997873  4.26674294]. \t  -468.7231264209916 \t -165.62625697677552\n",
            "1      \t [-5.01918393  0.79364164 -1.36560668  2.11685063 -4.95451332 -1.5583133\n",
            " -2.89797694 -3.01695924]. \t  -318.88110310996603 \t -165.62625697677552\n",
            "2      \t [ 3.54516043 -1.42323946 -4.61942583 -1.93849124 -1.92826544 -0.09386274\n",
            " -3.70385749 -3.87289928]. \t  -330.33627399869533 \t -165.62625697677552\n",
            "3      \t [-2.34545924 -2.03518697  2.56446338 -4.74275426  3.67939613 -3.77571172\n",
            " -1.69528942 -0.5983289 ]. \t  -299.6972370092073 \t -165.62625697677552\n",
            "4      \t [-1.01140414 -4.19690605  1.82013476  1.45813409  4.3944177   0.17426992\n",
            "  2.61182883  3.92706365]. \t  -322.55720555713225 \t -165.62625697677552\n",
            "5      \t [ 3.49032464  4.50549384 -3.44357038  0.25746208  4.54250808 -0.61800521\n",
            "  1.3142628   3.58580495]. \t  -309.03945825584924 \t -165.62625697677552\n",
            "6      \t [-4.73452544 -1.51784525  0.21632425 -3.96512521 -0.50894267  2.32715874\n",
            "  3.31555728  4.95803156]. \t  -397.44887630623725 \t -165.62625697677552\n",
            "7      \t [ 5.05721107 -0.73504045  1.81893561 -3.61959059  4.43392939  2.50894246\n",
            "  3.01984378 -2.07442034]. \t  -323.31663332385546 \t -165.62625697677552\n",
            "8      \t [-2.45939082  3.09116909 -3.71993571 -1.17328657  4.13862467 -4.03748134\n",
            " -4.57108429  4.50515008]. \t  -564.2627302489559 \t -165.62625697677552\n",
            "9      \t [-3.43492556 -3.48806407  0.28606616 -3.69657405  0.95021213  4.44753644\n",
            " -4.89535155 -0.75776699]. \t  -386.57898774726226 \t -165.62625697677552\n",
            "10     \t [ 3.70504083 -0.13991164  1.26491221  3.14015639 -1.35427699 -3.67670235\n",
            "  2.38213063  4.93532467]. \t  -382.86924845962477 \t -165.62625697677552\n",
            "11     \t [-3.73604379  2.96763984  4.34030965 -1.39384588 -0.76286163  4.9629884\n",
            " -3.82243764  2.49926289]. \t  -398.80292371344024 \t -165.62625697677552\n",
            "12     \t [ 2.26491442 -2.34540858  5.01457694  4.19403389  2.55896403 -2.31585649\n",
            " -0.4986284  -2.79403495]. \t  -291.0434415735902 \t -165.62625697677552\n",
            "13     \t [ 1.50021988 -3.47491017 -3.29191989 -4.26138418 -0.85682774  0.45035284\n",
            " -2.43760353  4.84067645]. \t  -365.48669059964334 \t -165.62625697677552\n",
            "14     \t [ 5.09691867  5.07559595 -2.88853554 -5.00232913  0.37578615  3.62083152\n",
            "  4.64360644 -0.43733557]. \t  -434.4662944881213 \t -165.62625697677552\n",
            "15     \t [-3.6158695  -4.79150953  0.82115895 -2.73957691 -3.68183712  3.989516\n",
            "  3.75239705 -4.48652105]. \t  -513.9070769159513 \t -165.62625697677552\n",
            "16     \t [-2.53393613 -4.25205142 -0.11288972 -4.2943875  -3.98835532 -4.89155879\n",
            " -2.50192308 -3.70427783]. \t  -493.07570630767134 \t -165.62625697677552\n",
            "17     \t [ 3.54165343 -0.58420498 -2.588283   -2.19884608 -3.71708536 -2.03375769\n",
            "  4.45423903  0.29959193]. \t  -286.1636230308406 \t -165.62625697677552\n",
            "18     \t [ 4.1688311  -0.08902562 -4.08985813  0.65959919 -3.8314677   5.05567496\n",
            "  3.74942437 -4.81908603]. \t  -580.2719293163149 \t -165.62625697677552\n",
            "19     \t [-3.66319505  3.30234239  4.80066624 -0.05187924 -4.36030968 -5.07227254\n",
            "  3.63959906 -4.81198466]. \t  -631.7774182772243 \t -165.62625697677552\n",
            "20     \t [-3.70882206  0.5842027   4.53118503  3.6495549   4.09461325 -3.80595201\n",
            " -3.31073523  2.34402518]. \t  -420.7331828989557 \t -165.62625697677552\n",
            "21     \t [ 4.73328863  3.40840836  3.54358644 -4.93191994 -0.98263771 -0.06106715\n",
            " -3.02498656 -1.06113311]. \t  -258.5169614271728 \t -165.62625697677552\n",
            "22     \t [ 4.34232439  3.15549294 -4.77312578 -0.81397856 -2.91364198  2.37455478\n",
            " -3.52491898  3.77936766]. \t  -387.2904323875654 \t -165.62625697677552\n",
            "23     \t [ 2.00618998  4.96347294 -4.30338854  4.24862896  2.37251093  0.82079581\n",
            " -4.61570579 -1.74294898]. \t  -386.6802001722146 \t -165.62625697677552\n",
            "24     \t [-1.63187867  2.43718436 -1.17596281 -4.26478997 -3.39363039  4.47161846\n",
            " -0.92358154 -4.65775401]. \t  -448.529427612134 \t -165.62625697677552\n",
            "25     \t [-3.63567322 -0.12313914 -4.71053878  4.37095835 -2.97486154  3.48557213\n",
            "  4.07020148 -0.47275424]. \t  -391.1351181981359 \t -165.62625697677552\n",
            "26     \t [-4.9615414   4.94629939  5.01731945 -4.15975243  3.95092943 -3.74835771\n",
            "  2.60281201 -1.02427437]. \t  -436.44913883346106 \t -165.62625697677552\n",
            "27     \t [ 4.19230208  2.06176265  4.38990758 -0.43661639 -1.25587382  4.53345984\n",
            " -0.11451758  3.80684021]. \t  -331.88123117587526 \t -165.62625697677552\n",
            "28     \t [ 2.35663103 -3.34995305 -3.36991925  4.40284361  3.22664151 -0.05902715\n",
            "  3.15070992 -2.40611726]. \t  -307.4882708064932 \t -165.62625697677552\n",
            "29     \t [ 1.08864835  3.47241036  4.53949122  2.94787777 -3.90444286  4.55438279\n",
            " -5.10183095 -4.37252254]. \t  -657.7114640943697 \t -165.62625697677552\n",
            "30     \t [-1.41898482  4.92583961 -4.94642521 -4.79569849  2.73572569  0.79717265\n",
            " -4.07146886 -1.81565499]. \t  -399.58228872329 \t -165.62625697677552\n",
            "31     \t [-4.04672308  1.36694416 -2.55425896 -0.63388063  4.83042003  4.1956964\n",
            " -0.22885207  1.4164824 ]. \t  -279.998965486268 \t -165.62625697677552\n",
            "32     \t [-3.68725976  2.3662998  -4.86958037 -4.35218697  4.98986055 -4.46874284\n",
            "  4.2295472   3.06949586]. \t  -616.6086412305444 \t -165.62625697677552\n",
            "33     \t [ 2.05553216 -4.92358126 -2.65708516  4.46171082  4.52229288 -4.64651414\n",
            " -4.67762688 -2.38860822]. \t  -584.117448518153 \t -165.62625697677552\n",
            "34     \t [ 3.49213566  2.24070924  4.07326683 -3.06354887  0.0315269  -4.48337375\n",
            "  4.1922037  -2.4999187 ]. \t  -403.17996393395447 \t -165.62625697677552\n",
            "35     \t [-3.07036989  4.84669453 -3.31937617  1.16486375 -1.93352885 -4.80392985\n",
            "  3.20152566 -0.86741465]. \t  -329.817223817093 \t -165.62625697677552\n",
            "36     \t [-4.4693135   4.24575924  4.34788956 -2.89311773 -3.41521267 -4.62574296\n",
            " -4.51234823 -0.19691766]. \t  -475.7632517638615 \t -165.62625697677552\n",
            "37     \t [-4.16577721 -4.82950388 -4.13682216 -1.42047958  4.0108296  -1.53265204\n",
            " -2.07065768 -3.57638182]. \t  -350.27817931919253 \t -165.62625697677552\n",
            "38     \t [ 2.01288193  3.90602575  0.74177315  4.80515031 -4.9293886   3.4677554\n",
            "  3.71663735  4.51148837]. \t  -581.7426243210931 \t -165.62625697677552\n",
            "39     \t [ 4.71135264 -4.81028362  4.99344759 -3.43226543 -4.20836564 -2.57255652\n",
            "  4.93035028 -4.0707644 ]. \t  -621.387289667498 \t -165.62625697677552\n",
            "40     \t [-3.86408081  1.27074799 -1.68289142 -5.02524457 -1.14862427 -2.80662577\n",
            "  2.98352762 -5.01609701]. \t  -445.1288949476939 \t -165.62625697677552\n",
            "41     \t [ 4.99349296 -4.72145956  4.89385346 -4.52431866 -2.53866717  1.02481825\n",
            " -2.81884111 -4.3718911 ]. \t  -470.300755947742 \t -165.62625697677552\n",
            "42     \t [ 3.09246127 -2.91584899 -2.67933395 -3.4061245   4.709839    4.00411078\n",
            "  4.81478763  5.11656374]. \t  -673.3302856958901 \t -165.62625697677552\n",
            "43     \t [-1.39388747 -3.62837202  4.96442223 -3.42199624 -4.85960481 -4.64392792\n",
            " -2.8779756   4.02146774]. \t  -583.8818078333904 \t -165.62625697677552\n",
            "44     \t [ 4.22878517 -3.07960587  4.66638752 -3.51627598  3.21379107 -4.17001454\n",
            "  0.78820669  5.11385107]. \t  -521.1699369701614 \t -165.62625697677552\n",
            "45     \t [-4.97826534 -1.74405833 -4.10950109  4.18549814 -1.58781355 -4.48704652\n",
            "  3.15913296  3.37776899]. \t  -446.14689358970065 \t -165.62625697677552\n",
            "46     \t [-1.59895184  3.91870139  1.76888148 -4.75108055 -3.20395753 -4.6596455\n",
            "  4.99097192  4.5598154 ]. \t  -655.2514123995427 \t -165.62625697677552\n",
            "47     \t [-3.24050441  4.63779314  3.53340366 -3.52871269 -5.0009759   4.23517642\n",
            "  4.65287417  1.380623  ]. \t  -540.2439371266017 \t -165.62625697677552\n",
            "48     \t [-0.08268464 -3.01794114 -3.86106004  4.11054815  4.67280777  1.96810106\n",
            " -4.43742264  3.74185167]. \t  -512.7954144565903 \t -165.62625697677552\n",
            "49     \t [ 3.0771607  -3.11848983 -3.80064725 -1.50142848  3.2375712  -4.6539392\n",
            "  4.88586619  4.51069208]. \t  -593.5075838503064 \t -165.62625697677552\n",
            "50     \t [ 4.62613876 -3.94198209  1.34494833  5.09015594 -3.61727211  4.30527645\n",
            " -0.45825317 -1.1142595 ]. \t  -349.58329887537025 \t -165.62625697677552\n",
            "51     \t [ 2.29144752  1.50604255  2.19446091 -1.28749084  5.05792847  0.07649388\n",
            " -4.2660425  -5.0743926 ]. \t  -492.2023890626025 \t -165.62625697677552\n",
            "52     \t [ 2.89924106  0.94427124 -4.36314016  3.40613346 -0.22078198 -4.88266217\n",
            " -4.05091569  2.49358912]. \t  -421.60623380014516 \t -165.62625697677552\n",
            "53     \t [ 1.7919446   1.45105706  2.52006068  4.88967291 -5.03337778  4.91207056\n",
            " -4.50667879  5.06207845]. \t  -740.7231852385021 \t -165.62625697677552\n",
            "54     \t [ 1.23905907  4.82622565  4.73916637 -3.70947578  4.02377106 -2.1582398\n",
            " -0.09775774  4.25478178]. \t  -424.3340127885607 \t -165.62625697677552\n",
            "55     \t [-4.83589962 -3.363515   -4.16259109  1.7545687   1.0357585  -2.75844215\n",
            "  5.00556226 -4.54046398]. \t  -501.64200749100223 \t -165.62625697677552\n",
            "56     \t [ 4.42800168  4.06193053 -3.86452486 -4.27510735  0.90075845 -4.31692437\n",
            " -3.06199143  0.70816652]. \t  -356.0299708689756 \t -165.62625697677552\n",
            "57     \t [-1.18451018  4.40017574  3.3940554   4.34125962  3.89509741 -5.04960053\n",
            " -5.04181338 -4.68555665]. \t  -732.4955507858289 \t -165.62625697677552\n",
            "58     \t [ 4.82994584  4.52287158  4.55497273  4.43016223  3.17448385 -4.73547746\n",
            "  2.72390375 -0.57508113]. \t  -444.5083178224643 \t -165.62625697677552\n",
            "59     \t [-4.22491123  1.26222638 -3.60199002 -3.84293935 -4.30125447  4.74547749\n",
            " -4.40856938  4.72930298]. \t  -661.6321644973 \t -165.62625697677552\n",
            "60     \t [ 0.95932012 -3.03416377  2.95373278  3.98510846 -3.1865968  -3.89115261\n",
            " -4.90876334  4.93048586]. \t  -613.79820121912 \t -165.62625697677552\n",
            "61     \t [ 5.10499047 -4.23322368  2.29312869  4.96980923 -4.1653669  -3.61533284\n",
            " -3.53823373 -3.92138915]. \t  -552.2998503690442 \t -165.62625697677552\n",
            "62     \t [ 4.56507774 -4.90386904 -0.56535324 -4.99475918  4.80670382 -0.82323109\n",
            " -4.22133815 -2.26976494]. \t  -455.22594640899257 \t -165.62625697677552\n",
            "63     \t [-1.05039069  0.68355127 -4.19564669  4.94812646 -2.68387265  4.10117563\n",
            " -4.58439506 -4.52620049]. \t  -600.7263656076404 \t -165.62625697677552\n",
            "64     \t [-4.96733132  4.63576615 -4.56332158  4.73083269  0.22445431 -0.38725406\n",
            " -2.05384748  1.4246682 ]. \t  -266.56701440459847 \t -165.62625697677552\n",
            "65     \t [ 1.18373656 -5.10983457  4.74603199  2.41431814  2.42733262  4.68569219\n",
            "  4.25854693 -3.88811873]. \t  -553.592516093492 \t -165.62625697677552\n",
            "66     \t [ 4.47791536  2.33363091  3.56191685  3.83686828 -2.43158037  2.20750038\n",
            "  4.082594   -3.16059452]. \t  -383.280521167169 \t -165.62625697677552\n",
            "67     \t [ 2.05262862 -3.63780147 -4.6952681   1.11199706  3.77424821  4.7857118\n",
            " -1.9888943  -5.01629588]. \t  -539.4019321487931 \t -165.62625697677552\n",
            "68     \t [-1.30113567 -4.80931659 -2.48450831 -4.82460956  3.3205888  -2.4391623\n",
            "  4.9785216  -1.73999304]. \t  -448.1267537540673 \t -165.62625697677552\n",
            "69     \t [-4.88087915  1.1348718   1.82573471 -4.29701784  3.92875696  4.89982762\n",
            "  5.0468847  -1.02696219]. \t  -518.2162676065285 \t -165.62625697677552\n",
            "70     \t [-2.02867082  4.08071587 -4.19298989 -4.74597024 -2.65372822 -0.77433828\n",
            "  0.35035512  2.5668459 ]. \t  -272.63820608378415 \t -165.62625697677552\n",
            "71     \t [-3.91579297  2.983796   -4.1054409  -4.80459465 -3.99445447 -4.47904137\n",
            " -4.69632305 -2.95513959]. \t  -600.4401192910566 \t -165.62625697677552\n",
            "72     \t [ 4.69489593 -1.36998931  1.97807735 -4.16627125  4.48251888  3.13258266\n",
            " -3.90097938  3.37902142]. \t  -464.1745134021964 \t -165.62625697677552\n",
            "73     \t [ 5.01208483 -4.94297882  2.60079822 -2.40418821 -4.84431371 -2.51615655\n",
            "  0.97737934  3.2090241 ]. \t  -361.7927287704697 \t -165.62625697677552\n",
            "74     \t [ 3.49708795  2.56561464 -3.40831629  4.63568724 -2.97108589 -2.77066645\n",
            "  3.99595497 -4.83555673]. \t  -535.2334020439778 \t -165.62625697677552\n",
            "75     \t [ 1.27667045  4.51829971  3.16142655  0.08068238 -1.54597296 -1.23122179\n",
            " -4.82622213  4.90827207]. \t  -449.2914667990942 \t -165.62625697677552\n",
            "76     \t [ 0.38047663  2.34909616 -0.16102969  4.95862712  4.61788186  3.75450469\n",
            "  5.08709422  4.00058336]. \t  -610.0000187721168 \t -165.62625697677552\n",
            "77     \t [-4.19849007 -4.52931035  2.04156674  2.02705829  5.08419325  1.95949096\n",
            " -1.98386407 -4.21306865]. \t  -409.4287987774777 \t -165.62625697677552\n",
            "78     \t [ 0.81470437  4.60126009  3.94436945  4.15484833  3.44911906  4.7720427\n",
            " -3.81123847  0.39985389]. \t  -457.8064379580194 \t -165.62625697677552\n",
            "79     \t [-3.99796553  1.19294355  4.112126    4.86905843  1.40104702 -4.58743096\n",
            "  4.7195217  -0.44413327]. \t  -457.96664883491206 \t -165.62625697677552\n",
            "80     \t [ 4.71788565 -5.04772256  4.00380159  3.02051147  2.48574484  4.76713036\n",
            "  0.6127438   2.8755163 ]. \t  -393.82745583456915 \t -165.62625697677552\n",
            "81     \t [-5.08615385  4.63044117  1.20331427 -2.34535867  4.96059725  4.29494385\n",
            " -4.53610601 -4.78847972]. \t  -656.2846458615176 \t -165.62625697677552\n",
            "82     \t [ 4.40820115 -4.83454729  2.69618153  1.56182296  4.80461299 -2.21910501\n",
            " -4.61839976  3.1169096 ]. \t  -469.73969124148704 \t -165.62625697677552\n",
            "83     \t [-4.89984049 -3.3592679   1.20540119 -2.48056532 -2.12529646 -5.00105269\n",
            "  4.02330022 -0.91132527]. \t  -368.14990763888454 \t -165.62625697677552\n",
            "84     \t [ 0.9851916  -3.50173032 -0.34879664  3.99440008 -3.40094434 -3.00899245\n",
            "  2.35411478 -1.33505802]. \t  -254.8890978479035 \t -165.62625697677552\n",
            "85     \t [ 3.92752576  4.46615573 -2.19292504  4.27013742  4.499913   -3.53676154\n",
            "  1.18881018 -5.10905806]. \t  -537.6924677348178 \t -165.62625697677552\n",
            "86     \t [ 0.10245101 -4.28066737  3.08871985 -1.24222938 -4.66169489  4.03906074\n",
            " -3.47393428  4.33587404]. \t  -512.8688597969028 \t -165.62625697677552\n",
            "87     \t [ 4.95478892  4.28139428 -2.81219477 -1.24291975 -5.10523269 -4.66815474\n",
            "  1.16554188  4.97414781]. \t  -559.6289261368829 \t -165.62625697677552\n",
            "88     \t [ 4.47536446  5.11655944 -2.07770197  1.00071495 -2.42358955  3.97584781\n",
            " -3.68402746 -4.83979936]. \t  -495.9503035134253 \t -165.62625697677552\n",
            "89     \t [ 3.34323705  3.10091551 -1.64017058 -5.09266497 -1.5500836  -5.02756571\n",
            "  0.56145356 -4.68510546]. \t  -483.70062578352247 \t -165.62625697677552\n",
            "90     \t [-4.30843857  0.87990698 -3.77357284  5.0833708   3.01509568 -2.28850899\n",
            " -3.32270491 -4.58609264]. \t  -488.6114980330026 \t -165.62625697677552\n",
            "91     \t [-2.01795314  4.79275112  4.89633545  3.76447858 -0.13933403  2.92000972\n",
            "  4.29001857  1.54108449]. \t  -377.7057171179371 \t -165.62625697677552\n",
            "92     \t [-4.61999878 -4.75082259 -4.19683092 -3.85593038 -4.18302783 -4.75011851\n",
            "  4.02019717  4.85575336]. \t  -703.4289712256426 \t -165.62625697677552\n",
            "93     \t [-2.26607318 -4.85402882 -2.70232422 -2.18559123  4.81889032 -4.1529624\n",
            " -4.4440031   4.75887961]. \t  -632.2839104327916 \t -165.62625697677552\n",
            "94     \t [ 0.3336282   5.08510966  1.51290283 -1.5106927  -4.90295856  0.18402841\n",
            "  4.24181941 -4.60623651]. \t  -483.9121368685097 \t -165.62625697677552\n",
            "95     \t [-5.12       -5.12       -5.12       -5.12        0.23096563 -5.12\n",
            " -5.12       -0.50350562]. \t  -605.2260688704608 \t -165.62625697677552\n",
            "96     \t [-3.98972493  4.67987075  1.97133185  3.95128986 -4.43573025 -0.77084049\n",
            " -1.65911367  3.45976185]. \t  -350.8014073927576 \t -165.62625697677552\n",
            "97     \t [-1.65837132  3.78613275 -3.48886382  0.30086509 -3.21731461  4.99493286\n",
            "  1.11896345  3.6612319 ]. \t  -385.75158829960986 \t -165.62625697677552\n",
            "98     \t [ 3.35017179 -0.47869756  1.75112949 -4.18923282 -3.80705211  5.03410863\n",
            "  3.31814723 -1.63813514]. \t  -414.14033215249276 \t -165.62625697677552\n",
            "99     \t [-1.39163114  4.57134583 -4.99147532  2.43382887 -0.79641025  3.29697123\n",
            "  1.82460388 -4.99240697]. \t  -433.2583485848504 \t -165.62625697677552\n",
            "100    \t [ 2.58338169 -4.10755125 -2.06996104  4.00117821  0.45206168  4.20633099\n",
            "  3.88926949  3.07815599]. \t  -406.1761358815405 \t -165.62625697677552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH76hlE2tddm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74935f4c-c4bf-414d-ec2e-2ae36cea0e9b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 5\n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_loser_5 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_5 = dGPGO(surrogate_loser_5, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.58729753  0.42762882  0.61873954 -1.20782752 -3.90047561  3.54303094\n",
            "  2.45495411  4.42734146]. \t  -358.07993275421416 \t -191.0582179343833\n",
            "init   \t [ 3.67951879  2.13099137  1.85311997 -0.93591243  2.81174646  4.9610363\n",
            "  4.76656492  2.68257959]. \t  -440.2387279623039 \t -191.0582179343833\n",
            "init   \t [ 2.28457508 -3.1898747  -0.24613755 -2.16324482  3.55437597  3.73325571\n",
            " -1.2826718  -0.39471791]. \t  -204.02442667207546 \t -191.0582179343833\n",
            "init   \t [3.75520732 3.06877821 2.55257243 0.39811528 0.98991542 2.6976486\n",
            " 2.32004232 2.54212732]. \t  -191.0582179343833 \t -191.0582179343833\n",
            "init   \t [ 0.5992029   3.04558915 -1.51609106  4.46525397  4.55980658  3.872474\n",
            " -1.66783187  4.83819235]. \t  -506.2318322394824 \t -191.0582179343833\n",
            "1      \t [ 2.93499453 -4.66586726 -4.44927383  4.16377803  3.1780443  -4.4736638\n",
            " -0.65762836  1.31319723]. \t  -368.2961856386949 \t -191.0582179343833\n",
            "2      \t [-1.17343893 -3.84389035 -2.84342415 -4.04422171 -0.2015563  -2.63778573\n",
            " -0.25088104  0.97245514]. \t  \u001b[92m-170.5625917535914\u001b[0m \t -170.5625917535914\n",
            "3      \t [ 0.16471768 -1.55288    -2.70880353  3.24811743  0.36701741  0.77219384\n",
            "  3.43195549 -4.86663863]. \t  -345.23673182195546 \t -170.5625917535914\n",
            "4      \t [ 2.34262684  4.33520792 -4.50777938  1.15587138  2.36170739 -3.38944867\n",
            " -4.71681112 -2.20304355]. \t  -400.7641750492331 \t -170.5625917535914\n",
            "5      \t [-2.96489911e-03  3.20621581e+00 -1.53267486e+00  4.29738075e-01\n",
            " -3.51692901e+00 -4.59367930e+00  1.11305274e+00 -3.84765614e+00]. \t  -343.9087769128066 \t -170.5625917535914\n",
            "6      \t [-3.13469556 -1.06340474  4.75679604  2.55261997 -2.57791231 -4.37003313\n",
            " -1.9998041   1.17662843]. \t  -292.91422388884996 \t -170.5625917535914\n",
            "7      \t [ 3.76780927 -3.61837208  5.08490111  0.53948569  4.58846195 -3.56537275\n",
            " -1.34823879  4.60669661]. \t  -483.1531336259286 \t -170.5625917535914\n",
            "8      \t [ 3.86560629  3.94064489 -4.92423919 -3.11858659  0.21275663  3.08598528\n",
            " -1.38104352  1.29235925]. \t  -241.72566601926175 \t -170.5625917535914\n",
            "9      \t [-4.43514584  1.63284787  3.20130493 -4.29445809  0.36932758  3.1096296\n",
            " -3.18039699 -4.01024866]. \t  -387.67946478997555 \t -170.5625917535914\n",
            "10     \t [ 0.57918812 -1.27301857 -1.60583996  4.57224101 -5.11405873 -3.54223127\n",
            " -5.08018675 -2.93794031]. \t  -550.6967548948048 \t -170.5625917535914\n",
            "11     \t [-2.04288174  1.92724755  1.78611519 -4.91665611  2.74814586 -4.17521066\n",
            " -3.44121405  3.49951913]. \t  -441.089168643814 \t -170.5625917535914\n",
            "12     \t [-2.64712335 -1.67801236  2.40426663  3.46096282  3.58546381  0.85947678\n",
            " -2.39545945 -4.84681336]. \t  -374.70359695355705 \t -170.5625917535914\n",
            "13     \t [-3.74071788 -0.11736652  1.49774963  4.01633387 -4.20438289  4.02088889\n",
            " -3.30855977 -1.34051979]. \t  -361.6654163044921 \t -170.5625917535914\n",
            "14     \t [-3.7996221   4.99523501 -3.02007887  2.72005147  1.40991291  2.20712428\n",
            " -2.93451843 -2.05935467]. \t  -254.67420279006052 \t -170.5625917535914\n",
            "15     \t [-4.41447036 -4.87046567 -4.94564978 -4.61081931 -5.12       -5.12\n",
            " -5.12       -5.06425315]. \t  -902.3798741157899 \t -170.5625917535914\n",
            "16     \t [ 3.24460129  0.2192569   3.65340883 -0.85275618 -2.04937054  0.23809855\n",
            " -0.77352082 -4.89089436]. \t  -270.4694114501725 \t -170.5625917535914\n",
            "17     \t [ 2.64862787 -4.1477411   4.40164116  4.99954793  1.05188356 -1.04422038\n",
            "  2.7234174  -2.05109203]. \t  -297.17751148012564 \t -170.5625917535914\n",
            "18     \t [-2.63373184 -4.0324312   3.718451   -3.96088722 -4.81332415  2.6882799\n",
            "  1.54897652 -2.7717451 ]. \t  -381.15009481702805 \t -170.5625917535914\n",
            "19     \t [-3.18245826 -2.56965169  4.62714329 -0.90638767  4.22702225  1.8001303\n",
            "  4.2636719   1.04823791]. \t  -335.6758878253862 \t -170.5625917535914\n",
            "20     \t [-0.06256051  3.73969012  1.78719432  3.98674821  4.80049678 -4.83960568\n",
            "  3.15189846  3.37634255]. \t  -517.6266189272541 \t -170.5625917535914\n",
            "21     \t [-4.97243297  1.44414082 -2.19799861 -2.92655015  4.0023898  -3.33904197\n",
            " -0.23976703 -2.67385464]. \t  -282.2377865990213 \t -170.5625917535914\n",
            "22     \t [-4.89757019  4.36872835  1.74423362 -1.32501662 -1.50627094  2.30136911\n",
            "  3.92078043 -0.88931707]. \t  -235.36427012393375 \t -170.5625917535914\n",
            "23     \t [ 4.23166752 -1.94797354 -4.82168404  3.44132259 -5.00051887  2.26104707\n",
            " -4.60717952  3.57032796]. \t  -548.8735313774636 \t -170.5625917535914\n",
            "24     \t [-4.68969889  4.90087992 -2.36252947 -3.18017888 -4.843878   -0.07787627\n",
            " -1.88053165  5.09961213]. \t  -477.3846150251172 \t -170.5625917535914\n",
            "25     \t [ 1.44288672  2.5205166   2.6189566  -4.48262537  2.9027562   3.66776694\n",
            "  4.67679015 -5.07786133]. \t  -597.9694742386596 \t -170.5625917535914\n",
            "26     \t [-4.16883871  0.65631436  5.03502845 -0.85718494  1.75124238  3.10457269\n",
            " -4.21989664  4.78289738]. \t  -478.06034355183635 \t -170.5625917535914\n",
            "27     \t [ 4.97444514  1.09641338 -4.04663537 -5.0342975   4.8418141  -3.87068655\n",
            "  2.806562   -3.84436198]. \t  -558.1313172795503 \t -170.5625917535914\n",
            "28     \t [ 4.65224675  4.86421848 -1.4739816   4.23482187 -0.95789412 -3.34526563\n",
            " -3.12354182  4.13261482]. \t  -423.8736279594338 \t -170.5625917535914\n",
            "29     \t [-0.61525911 -4.86184133 -3.75673943 -2.12980373 -3.23610045  2.3791203\n",
            " -3.99687278 -4.49968519]. \t  -468.26236496878676 \t -170.5625917535914\n",
            "30     \t [-4.88371024 -1.49593119 -1.96774734  3.30157222  0.43627315  4.10256581\n",
            "  2.18983697  2.77529846]. \t  -280.6677539427682 \t -170.5625917535914\n",
            "31     \t [-1.31491736  0.46459246 -4.30519314 -5.10207524  3.22276782  1.87079803\n",
            "  4.70858376  3.95454408]. \t  -515.122602854345 \t -170.5625917535914\n",
            "32     \t [ 5.0535868  -4.90543654 -0.50252182 -1.82441814 -4.24317193 -4.03924552\n",
            "  4.44938429 -2.39047586]. \t  -459.9466551401748 \t -170.5625917535914\n",
            "33     \t [-2.94129254  0.22570811  4.60219389 -3.10056298  0.39127115 -3.10544165\n",
            "  4.39758485 -4.35278389]. \t  -456.32078013067337 \t -170.5625917535914\n",
            "34     \t [ 3.19652878  1.07663641  0.97026642 -2.59314768 -2.15337128 -0.00643437\n",
            " -4.76513874  4.83020436]. \t  -411.0361100802038 \t -170.5625917535914\n",
            "35     \t [ 4.9030994   1.84976432 -4.38068057 -5.0828358   4.51341454 -2.89180329\n",
            " -4.99665389  2.61626981]. \t  -573.3501099464734 \t -170.5625917535914\n",
            "36     \t [-1.79614281 -0.33328993 -4.91788117  5.00840199 -3.50231672 -3.4409085\n",
            " -4.46533257  5.03995755]. \t  -651.4952820107997 \t -170.5625917535914\n",
            "37     \t [ 2.0399069   1.24986676 -3.12019755 -0.89445331 -3.84210142 -4.46277331\n",
            "  4.03255723  4.6592869 ]. \t  -520.5016892048434 \t -170.5625917535914\n",
            "38     \t [-4.77683813 -3.51218304  0.94640865  2.31477979  4.76610895 -3.48310409\n",
            " -1.3977521   3.81853545]. \t  -388.305669467196 \t -170.5625917535914\n",
            "39     \t [ 3.02474753 -2.60098448 -1.91309042 -2.35161702  1.11895624 -4.43694146\n",
            " -4.36973581 -4.97891563]. \t  -512.1374498905877 \t -170.5625917535914\n",
            "40     \t [ 1.53873518  4.98226448 -4.99524276  3.94777254 -3.31516802  3.69271777\n",
            "  2.95543128 -2.638963  ]. \t  -442.8343133517079 \t -170.5625917535914\n",
            "41     \t [-4.36173021 -3.9309503  -3.31583767 -0.74139981 -4.6813144   1.39031546\n",
            " -2.35795557  4.62656667]. \t  -416.444483467822 \t -170.5625917535914\n",
            "42     \t [ 4.45394191 -4.92701426  2.14518884 -2.05022034  3.75560991 -1.39485025\n",
            "  4.87738782 -4.09585909]. \t  -481.9352068018284 \t -170.5625917535914\n",
            "43     \t [-5.10700847  0.96517124 -0.21274176  3.88360771 -0.76431721 -3.34265975\n",
            "  5.02597597  1.24399995]. \t  -347.5745363512074 \t -170.5625917535914\n",
            "44     \t [-4.20538464  3.91632159 -3.94594242 -4.35681082 -4.20373099  1.99575367\n",
            " -3.80210463 -5.07311632]. \t  -590.338034456558 \t -170.5625917535914\n",
            "45     \t [-4.69179692 -5.04904811  1.65949004  3.1738175  -1.02337289 -4.1405256\n",
            "  4.04569007 -4.34860737]. \t  -495.509442533153 \t -170.5625917535914\n",
            "46     \t [ 2.93597698  4.85788184  3.66938222 -2.11554857 -3.81328182 -2.92012164\n",
            "  5.02373446  0.34598913]. \t  -415.60455045967035 \t -170.5625917535914\n",
            "47     \t [ 2.91981188  3.71357624  3.132862    4.90846218  0.24163651  4.55591584\n",
            " -3.68650793 -4.25381423]. \t  -526.645099898332 \t -170.5625917535914\n",
            "48     \t [ 3.78827701 -3.63713832  3.97542108  4.78553922 -4.98964864  1.60783723\n",
            " -3.55323818  4.05640353]. \t  -539.8336529451656 \t -170.5625917535914\n",
            "49     \t [-2.38624939 -2.77083377 -4.74815005  3.31290152 -4.91626722 -0.48806421\n",
            "  3.37551153  0.17605847]. \t  -334.86945478783844 \t -170.5625917535914\n",
            "50     \t [-3.99911125  0.81146823 -3.88384085 -3.60817374 -3.12447775  0.66749154\n",
            "  4.25113883 -4.75531536]. \t  -473.5327206522214 \t -170.5625917535914\n",
            "51     \t [ 0.8107498  -2.03772529  4.44593675  3.16737622 -2.47688946 -4.22843324\n",
            "  4.53913323  4.96992725]. \t  -588.1704347259567 \t -170.5625917535914\n",
            "52     \t [-4.08199087 -4.55796547 -4.70417445 -3.18313824  3.00276246  4.23616163\n",
            "  3.13932793 -2.75826221]. \t  -447.73504242956585 \t -170.5625917535914\n",
            "53     \t [ 3.5159025   4.9976916   3.97136927  2.8047874   4.31940127 -2.05593425\n",
            " -3.76280598  1.22811029]. \t  -370.92239560646937 \t -170.5625917535914\n",
            "54     \t [-4.29008475  1.6782253  -3.08190662 -2.07693659  0.96963056  4.89921859\n",
            " -4.15129885  3.31863813]. \t  -427.2416360759374 \t -170.5625917535914\n",
            "55     \t [ 4.98862196  1.60593042 -4.12687206 -1.14586082 -3.73879442  1.61146293\n",
            " -4.78482336 -4.97962559]. \t  -530.498487060293 \t -170.5625917535914\n",
            "56     \t [ 4.84776332 -0.3047525  -4.18307494 -3.64349938 -2.30087818  1.69571577\n",
            "  4.2947325  -3.26106498]. \t  -387.19361889923385 \t -170.5625917535914\n",
            "57     \t [-1.8046752  -3.33824688  4.96235012 -4.65027917  4.58081336 -1.37964766\n",
            " -3.70082485 -2.52555545]. \t  -449.15977495094336 \t -170.5625917535914\n",
            "58     \t [-0.6603844   2.71157113 -4.00293208 -4.57764109  4.3432387   3.93860384\n",
            " -3.50102062 -3.32507644]. \t  -508.6742286514814 \t -170.5625917535914\n",
            "59     \t [ 4.57458738 -1.4329981  -3.55488994  4.67360462  2.85785941  4.27231259\n",
            "  4.10541577  4.98866446]. \t  -617.7438509418171 \t -170.5625917535914\n",
            "60     \t [-4.6551142  -3.70556473  0.71827027 -4.03583377  4.31848637 -5.11202057\n",
            "  4.97753654  2.95046675]. \t  -608.9483324477758 \t -170.5625917535914\n",
            "61     \t [ 0.67983339  1.87325392  4.93780311  4.37169356 -2.56952269  3.95115095\n",
            "  4.0447975  -3.16895424]. \t  -478.6155236184386 \t -170.5625917535914\n",
            "62     \t [-3.35528432  4.26227619  4.76565631 -3.5380039  -5.05074636 -4.32077508\n",
            " -0.8839173   4.99358826]. \t  -610.3175922708701 \t -170.5625917535914\n",
            "63     \t [ 4.41092411 -1.37001466 -3.64669073  3.58358101  4.93558607  1.31844994\n",
            " -2.03965701 -2.92049128]. \t  -344.0588735313062 \t -170.5625917535914\n",
            "64     \t [ 4.11476895 -1.08959796  2.3174951  -4.99530746 -0.94561179 -4.84649871\n",
            "  2.95538242  1.72920505]. \t  -365.69391270308824 \t -170.5625917535914\n",
            "65     \t [ 4.46375389  3.20625835  3.54340736  4.92362013 -1.25993898 -3.62067344\n",
            "  3.16194907 -2.35988652]. \t  -376.2514884309388 \t -170.5625917535914\n",
            "66     \t [-4.13076498  3.73110975 -3.28921475  3.89373217  2.42932348  4.65657044\n",
            "  4.58200166 -4.35812467]. \t  -596.5261135250646 \t -170.5625917535914\n",
            "67     \t [-3.16519875 -0.45541548  5.01384748 -3.22710526 -4.99135736  3.64775943\n",
            " -4.65720196  0.93947113]. \t  -490.79881614040494 \t -170.5625917535914\n",
            "68     \t [-5.07107444  4.33201087  3.67840217  5.11205341  4.41737346 -3.12154522\n",
            " -3.9680809  -0.45272278]. \t  -476.26225476315636 \t -170.5625917535914\n",
            "69     \t [ 2.99190675  2.70358298 -4.62100084 -0.87561194  4.91566986 -2.86413461\n",
            "  1.99643276  3.78579643]. \t  -403.294855421847 \t -170.5625917535914\n",
            "70     \t [-2.47804407 -4.76348533  4.57609367 -4.12379796 -1.40823495 -0.82065257\n",
            "  1.56743384  4.06837517]. \t  -345.9348321282109 \t -170.5625917535914\n",
            "71     \t [-3.01401651 -4.61678598 -4.41845702  0.32038761  4.8586541   1.5214467\n",
            "  0.64856524  4.25954136]. \t  -390.7079984911159 \t -170.5625917535914\n",
            "72     \t [ 4.54094172  3.33215067 -4.54246433  2.26833849  2.174782   -4.55915527\n",
            "  4.48741208 -3.94624197]. \t  -539.2144327600191 \t -170.5625917535914\n",
            "73     \t [-4.36760348 -4.12199628 -4.2345425   2.75475087  1.14412786 -4.27189065\n",
            " -2.56266441 -2.70567645]. \t  -357.78199022171316 \t -170.5625917535914\n",
            "74     \t [-4.68198722  4.66168341  4.16684538  1.90220801  4.35872784  2.12365146\n",
            "  4.21486522  3.09065961]. \t  -454.76992289128657 \t -170.5625917535914\n",
            "75     \t [ 2.17445034 -3.91375764  3.92937917  4.89894542  3.36176419  3.39568961\n",
            " -1.33712272  4.19740308]. \t  -456.8343200735353 \t -170.5625917535914\n",
            "76     \t [ 3.95450225 -4.7685027  -2.16690115  2.49580181 -3.83594711  2.5272977\n",
            "  3.06179207  2.85165995]. \t  -342.6913760136247 \t -170.5625917535914\n",
            "77     \t [ 2.15972132  1.16619461  1.61922762  1.94215122  4.62301379 -2.73103838\n",
            "  1.58151031 -3.1246916 ]. \t  -277.56842667116587 \t -170.5625917535914\n",
            "78     \t [ 3.83229011  4.50436931 -1.68077225  3.78317468 -4.00415629  4.46902667\n",
            " -1.7275095   4.10886533]. \t  -476.9415143192159 \t -170.5625917535914\n",
            "79     \t [-3.08221666  2.32046364  5.07071134 -4.87238014 -4.01137275 -4.8510413\n",
            " -5.05512339 -3.23593565]. \t  -676.6671666351632 \t -170.5625917535914\n",
            "80     \t [ 4.54326727 -4.23750775  1.01132584  3.61773392 -5.00669297  2.78578666\n",
            "  1.62542025 -4.79068484]. \t  -485.9722990102056 \t -170.5625917535914\n",
            "81     \t [ 3.60946327 -5.0731789   3.55797784 -2.22807956 -2.62265546  1.88593949\n",
            " -4.92551429 -0.70240705]. \t  -351.8415437991673 \t -170.5625917535914\n",
            "82     \t [-2.85403882  1.98311751 -4.88033746 -3.91103078 -4.98259299 -3.68793624\n",
            "  1.5712635   0.49311118]. \t  -373.61253433913197 \t -170.5625917535914\n",
            "83     \t [ 1.0046888   0.61435767  3.91158371 -3.55284239  5.04459097 -2.50993556\n",
            "  4.48869253  3.74596029]. \t  -516.4909098149207 \t -170.5625917535914\n",
            "84     \t [-0.97253451 -5.12        0.51870732 -5.12        0.37021578 -5.12\n",
            "  0.77384319 -5.12      ]. \t  -530.9181267913498 \t -170.5625917535914\n",
            "85     \t [-3.29033539  4.76637268  4.04473326  3.73074711 -4.21091207 -1.46232616\n",
            " -3.34734746 -4.18924738]. \t  -481.3372040782275 \t -170.5625917535914\n",
            "86     \t [ 0.47220287  4.74355946  5.01235824  0.7558429  -3.00214236  2.30610591\n",
            " -3.04598549  2.94935401]. \t  -334.39083404249567 \t -170.5625917535914\n",
            "87     \t [-3.21139451  3.76982124 -0.60894695 -2.83099632  1.43649844 -4.19681085\n",
            "  4.18170701  3.24254183]. \t  -394.42307058184207 \t -170.5625917535914\n",
            "88     \t [-4.68169581  4.27793282 -3.18796188  3.0126791   3.4380351  -4.20747467\n",
            " -1.51799104  5.07827657]. \t  -513.0726447508399 \t -170.5625917535914\n",
            "89     \t [ 4.65521554  4.37538615  1.65987945  4.10358111  4.56884127  4.43100799\n",
            "  4.04975609 -3.37531218]. \t  -563.7022235023243 \t -170.5625917535914\n",
            "90     \t [ 3.22163377 -4.96327034 -2.63213369 -0.89234801  4.75291816 -0.55195739\n",
            "  4.37707793  2.2067151 ]. \t  -371.4640600407514 \t -170.5625917535914\n",
            "91     \t [ 1.82163861 -4.93697285 -4.92067656  5.09471084 -3.55865637  4.77718608\n",
            " -3.65313972 -3.43903984]. \t  -616.8124428938056 \t -170.5625917535914\n",
            "92     \t [-3.75775216  5.05670623 -5.00239738  2.27216321 -4.18178609 -4.87312331\n",
            " -2.66266951 -0.47362308]. \t  -442.32797034329906 \t -170.5625917535914\n",
            "93     \t [-4.50973303 -5.11504091  4.59971485  1.37165236 -4.43658334 -2.95698278\n",
            " -2.96985574 -4.86774757]. \t  -545.8417044788937 \t -170.5625917535914\n",
            "94     \t [ 1.38625679 -1.27492439  4.33402626  1.50471878 -4.67224589 -5.05776115\n",
            "  4.55163702 -3.04071332]. \t  -552.205029868409 \t -170.5625917535914\n",
            "95     \t [ 4.82039877 -5.00677241 -4.62533035 -3.249361   -0.68630139  2.37389573\n",
            " -4.44535344  4.75200538]. \t  -534.9341595501454 \t -170.5625917535914\n",
            "96     \t [ 1.25639828 -1.85343011  0.69049117  4.26032312 -0.20958425 -4.70430847\n",
            " -2.02694597  4.74114916]. \t  -424.0709587766619 \t -170.5625917535914\n",
            "97     \t [-0.70799245 -5.10100457  4.98767784  3.31856414 -3.58423963  4.58895018\n",
            "  5.02979499  2.67644853]. \t  -596.2075396820351 \t -170.5625917535914\n",
            "98     \t [-3.43330284  4.09279919 -0.88268012  4.4505207  -4.39314273  1.38207241\n",
            "  2.53169366  3.93989437]. \t  -403.8632000262604 \t -170.5625917535914\n",
            "99     \t [ 4.27125903  5.05211766  4.8480031  -4.67881799 -0.73361327 -3.95109953\n",
            " -3.93326426 -3.29711488]. \t  -518.9859663086402 \t -170.5625917535914\n",
            "100    \t [-3.05748815 -2.00328985  1.05440773 -4.13067601  5.11364434  4.46040992\n",
            "  0.65034147  4.88433567]. \t  -532.892657926842 \t -170.5625917535914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_Amb8TtdgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a51a572-7332-415b-c653-729021db9429"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 6\n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_loser_6 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_6 = dGPGO(surrogate_loser_6, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.02288795 -1.72052679  3.28938622 -4.69302655 -4.0175956   0.97333314\n",
            "  0.30532979 -0.83141193]. \t  -235.23441702954543 \t -201.94095626044867\n",
            "init   \t [-1.68542362  1.25459899 -0.6334318   2.41543277  0.18469286  0.80751207\n",
            "  1.48843618  5.01989654]. \t  -251.71565703551553 \t -201.94095626044867\n",
            "init   \t [ 3.27534794 -0.88882243  3.85298079  3.31529659 -4.56218104  2.2388453\n",
            "  3.09422656  2.42080403]. \t  -348.8531157616155 \t -201.94095626044867\n",
            "init   \t [ 2.14150913  0.41919339 -3.84180045  4.68630831 -0.9906555  -2.89842012\n",
            "  2.22490467  5.06068417]. \t  -431.90936813726233 \t -201.94095626044867\n",
            "init   \t [-2.50251207  1.75420858  1.01382055  2.22548117  4.47845923 -1.51746797\n",
            " -2.52278684 -0.99868151]. \t  -201.94095626044867 \t -201.94095626044867\n",
            "1      \t [ 2.52426974  2.29448261 -0.96145617  5.01124965 -0.50688737 -1.29220163\n",
            "  2.14659693 -4.27562441]. \t  -309.93117061486333 \t -201.94095626044867\n",
            "2      \t [-2.1732107  -4.071104   -1.05955676  0.563544   -2.4916715  -4.43837041\n",
            "  3.16725126 -3.45000541]. \t  -357.18651782929135 \t -201.94095626044867\n",
            "3      \t [ 0.45041751  3.04462334 -4.19217931  4.07489457 -5.03627391  4.82675639\n",
            " -0.2109413  -1.32181192]. \t  -418.7792092236846 \t -201.94095626044867\n",
            "4      \t [ 1.13973531  0.02174566 -4.62097322  2.28023966 -4.53238513 -1.3679228\n",
            " -4.92490741  2.61866956]. \t  -424.7403788210404 \t -201.94095626044867\n",
            "5      \t [-4.09131316  0.92385945  3.58336907 -1.58465775 -1.76392005 -1.00200185\n",
            "  3.29877381 -0.03674573]. \t  \u001b[92m-164.77731695731757\u001b[0m \t -164.77731695731757\n",
            "6      \t [-0.36675946  1.75512676 -4.97484639 -2.33012056  1.71913733 -4.05086626\n",
            " -2.23443154  0.20696239]. \t  -250.78631759071766 \t -164.77731695731757\n",
            "7      \t [-4.09980816 -2.43417915  2.31668169 -2.56361355 -3.28974468  4.50139526\n",
            " -4.54042416 -3.56396318]. \t  -492.6586685976233 \t -164.77731695731757\n",
            "8      \t [ 1.29040313 -2.6311265   1.32394803 -4.64369555  3.72243003 -4.69094677\n",
            " -4.55281376 -2.0883067 ]. \t  -488.3222489970762 \t -164.77731695731757\n",
            "9      \t [ 4.94251725 -4.98573359  0.21587065  4.12642972  4.11603157 -4.32322334\n",
            " -2.98601239 -3.47119565]. \t  -498.0506683117082 \t -164.77731695731757\n",
            "10     \t [ 1.53642786  3.01514227  4.7331146  -4.42892316  1.0647551   4.81474145\n",
            "  3.12109734  4.72628662]. \t  -557.8612899465525 \t -164.77731695731757\n",
            "11     \t [ 3.96580616  2.52455738  2.0656669  -1.16255556  3.51379228 -3.23829501\n",
            " -1.5787945   2.99633296]. \t  -260.60672211274664 \t -164.77731695731757\n",
            "12     \t [ 2.02100411 -5.01594556 -1.3855721   0.62551375  2.62736825  3.94402312\n",
            "  2.80181189 -0.11408451]. \t  -244.63077846579424 \t -164.77731695731757\n",
            "13     \t [ 4.61355455  5.01149033  4.92708657  1.56485643  0.07889719  1.75870422\n",
            " -3.75184781 -3.49806805]. \t  -369.15434656076263 \t -164.77731695731757\n",
            "14     \t [-4.72521673  4.01200939 -4.38670087  0.72894853  3.9132738   3.9186637\n",
            "  0.29224917 -0.34697818]. \t  -284.6401375353442 \t -164.77731695731757\n",
            "15     \t [ 0.31503705 -4.27728734  3.14979058 -4.82271222  3.39361475 -4.76696735\n",
            "  4.1525441   3.58866611]. \t  -577.1479018428682 \t -164.77731695731757\n",
            "16     \t [-4.70316117 -4.81303537  4.87284899  2.86873913 -1.93295945  0.95053279\n",
            "  0.56045546  4.8668206 ]. \t  -388.3920237547741 \t -164.77731695731757\n",
            "17     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -164.77731695731757\n",
            "18     \t [ 3.0621335  -3.83722124 -4.57291373 -2.98991527 -3.49840827 -2.93790622\n",
            "  3.22473093  4.94452732]. \t  -518.6792794160901 \t -164.77731695731757\n",
            "19     \t [ 1.37420932  4.44983787 -1.44114859 -0.50031095 -4.73574972 -3.02909364\n",
            " -3.19701011 -4.48583637]. \t  -448.4395532196568 \t -164.77731695731757\n",
            "20     \t [-4.74811932 -4.52423685  3.24890576 -1.26214877 -0.21969924 -4.29073589\n",
            " -4.86606152 -4.80637369]. \t  -562.78385275587 \t -164.77731695731757\n",
            "21     \t [-4.80158625 -3.68595799 -4.49577738 -1.33744718  4.58488467  2.9409182\n",
            " -2.54652381 -3.49962922]. \t  -418.3914636274104 \t -164.77731695731757\n",
            "22     \t [ 4.56858159 -0.46890403 -1.73938087 -5.10381081 -3.04288541  4.7104021\n",
            "  3.80023754  4.66228705]. \t  -588.9946440415033 \t -164.77731695731757\n",
            "23     \t [-0.47478383 -3.91317548 -4.45893212 -3.71223433  2.18038364  3.53001812\n",
            " -4.85261294  4.61274091]. \t  -579.2107935342232 \t -164.77731695731757\n",
            "24     \t [-1.3123044  -1.06276225 -2.99383547 -3.63941589  4.84964678 -1.97189335\n",
            "  4.36577852 -4.9872492 ]. \t  -557.1785559146126 \t -164.77731695731757\n",
            "25     \t [-4.76582696 -3.72587711  5.02102407  1.46067925  4.39617027 -2.55285987\n",
            "  2.80741902 -0.34428639]. \t  -326.49741294817176 \t -164.77731695731757\n",
            "26     \t [-0.25087833 -4.08478393  0.94952612  5.04897473 -4.37250306  2.61554368\n",
            "  4.18845154 -5.04607657]. \t  -601.2525641427246 \t -164.77731695731757\n",
            "27     \t [ 3.32191507 -3.58946269  3.78704996 -4.83714074  2.35063048  5.07625521\n",
            " -3.31692995  3.51169979]. \t  -531.3285422178127 \t -164.77731695731757\n",
            "28     \t [ 1.48464095  3.71070133  4.70741056 -4.94508457  4.26863427  2.67142277\n",
            "  1.96098864 -4.4416771 ]. \t  -512.7088446718955 \t -164.77731695731757\n",
            "29     \t [ 3.28494987  1.20672309 -4.72801175  3.48291648  3.74395917  4.92076252\n",
            " -4.00503747  2.33361496]. \t  -500.50629167013386 \t -164.77731695731757\n",
            "30     \t [-1.18850877 -1.05962212  1.07237734 -4.89956999 -4.18277073 -4.7849305\n",
            " -4.99745433  4.38705186]. \t  -656.7741294875693 \t -164.77731695731757\n",
            "31     \t [ 5.02686492 -5.09193218 -4.8303958  -2.07741361  2.70325395 -4.78013666\n",
            " -2.91499643  2.24977672]. \t  -437.99421697748124 \t -164.77731695731757\n",
            "32     \t [ 4.32658983 -4.29818579 -0.68082755 -5.0198795   0.26120002 -4.99672828\n",
            "  4.21941159 -4.49706032]. \t  -594.4128608696217 \t -164.77731695731757\n",
            "33     \t [ 4.38558278  2.99563846 -4.71044041 -4.53949001  3.91853084  2.97066705\n",
            " -0.12067873  2.6687154 ]. \t  -372.9755359377102 \t -164.77731695731757\n",
            "34     \t [ 3.95921476  3.78974623 -3.88386858  4.86035848  4.97629056  2.08739476\n",
            "  4.87012373  4.27359275]. \t  -646.2415136288151 \t -164.77731695731757\n",
            "35     \t [ 4.43075817 -4.59120006 -2.00390977  1.05067564 -1.51513376  5.05061691\n",
            " -4.49581418 -1.38679661]. \t  -399.65508732820285 \t -164.77731695731757\n",
            "36     \t [ 1.84867142  0.29931834 -4.37002632 -3.99397652 -1.2940945   3.18229895\n",
            "  0.67430744 -3.67171015]. \t  -304.8655927864166 \t -164.77731695731757\n",
            "37     \t [-5.10828365  5.05147192  2.29367149 -4.87814879  0.12862564 -3.14033673\n",
            " -4.98189492  3.19578919]. \t  -502.789927011225 \t -164.77731695731757\n",
            "38     \t [-2.12975785  5.11142181 -4.23320432 -4.73005131 -2.56911904  1.48031785\n",
            "  0.45428452  5.07324308]. \t  -453.5396246959348 \t -164.77731695731757\n",
            "39     \t [-4.80404916 -1.71913086 -3.11028913  4.48196197  2.61329168  0.75291798\n",
            "  3.74390034 -2.29757719]. \t  -316.2595333688694 \t -164.77731695731757\n",
            "40     \t [-4.66785309  4.52681451 -3.08262597  2.41647685 -4.28834933 -0.72389205\n",
            "  4.98317578 -4.50138702]. \t  -545.6561260198213 \t -164.77731695731757\n",
            "41     \t [-1.14577803  5.11808203  0.98196399 -4.78325047 -4.26321619  2.7508076\n",
            "  4.78700729 -2.94159828]. \t  -514.0218260936645 \t -164.77731695731757\n",
            "42     \t [-4.12609413  4.58755389 -3.36498297 -2.95696137  4.93378209 -2.9160946\n",
            "  4.14810934  4.32859829]. \t  -571.1342256158591 \t -164.77731695731757\n",
            "43     \t [ 5.04450135  4.37337376 -3.63543418 -3.59941166 -4.25998444 -2.41329929\n",
            "  4.83806738 -4.1434245 ]. \t  -582.0454145109604 \t -164.77731695731757\n",
            "44     \t [-2.13408115 -3.63969293  4.65435468  2.46090398  3.53777371  3.7588719\n",
            " -4.48627744 -5.05927127]. \t  -613.2728022695852 \t -164.77731695731757\n",
            "45     \t [ 4.60128397  1.89132279  2.64282265 -1.83611109 -2.58266513 -4.94756114\n",
            "  4.66649328  0.78118728]. \t  -400.3008769330892 \t -164.77731695731757\n",
            "46     \t [ 5.08584458 -1.38529228  3.32266535  4.54750677 -4.59590878 -2.13686158\n",
            " -4.37334088  3.48826769]. \t  -509.7792877708723 \t -164.77731695731757\n",
            "47     \t [-4.47283955  4.71353005  3.85198869  3.13930862 -4.025476   -1.90650231\n",
            " -3.33199908 -2.82171847]. \t  -392.618587052664 \t -164.77731695731757\n",
            "48     \t [-4.21118263 -1.40540477  3.73480251 -3.92055982  4.76599501  0.78233481\n",
            " -3.73640363  1.78791681]. \t  -365.55777647040816 \t -164.77731695731757\n",
            "49     \t [ 3.48852012 -2.5101336   4.82638717  1.65768636  4.96745779 -0.07654104\n",
            "  3.44493893 -3.43505227]. \t  -406.5282870326812 \t -164.77731695731757\n",
            "50     \t [-0.61576101  4.36328377  5.06106294  4.88474657  3.13673506  4.61268433\n",
            "  0.590607    1.10223796]. \t  -399.75954180243696 \t -164.77731695731757\n",
            "51     \t [-2.26059625 -4.38928305  0.05269601  4.6878816   1.02626655 -0.78604708\n",
            " -4.83300892  2.28773245]. \t  -345.9040929057934 \t -164.77731695731757\n",
            "52     \t [ 4.06423984  4.74846442  1.19701709 -4.93512717 -2.32138     1.77032442\n",
            " -4.94740091  1.52989586]. \t  -399.14474276879787 \t -164.77731695731757\n",
            "53     \t [-3.72213007 -4.86577659 -5.09394073  1.43329188 -4.11159646  4.56752318\n",
            "  4.62788341 -0.09216994]. \t  -506.95664634541043 \t -164.77731695731757\n",
            "54     \t [-3.674521    3.48926876  3.72410548  5.1117599   0.99019762 -3.57711338\n",
            "  5.03208606 -1.98055099]. \t  -474.2901254628675 \t -164.77731695731757\n",
            "55     \t [-2.12090376  2.33891593  4.92474178  4.98811739 -1.75450193 -1.02182278\n",
            " -4.51349594  4.8098808 ]. \t  -537.0610544614326 \t -164.77731695731757\n",
            "56     \t [ 5.02715399 -2.77568685  0.72666253 -2.60146951  4.34259481  3.23495476\n",
            " -2.24759114 -3.68774458]. \t  -370.57342674357756 \t -164.77731695731757\n",
            "57     \t [-4.91209741  0.52113487 -0.53496452 -4.51510576  3.7422428   4.39208233\n",
            "  4.3552975   4.91258562]. \t  -618.6876682105092 \t -164.77731695731757\n",
            "58     \t [ 4.39921449  4.42879376  4.92622824  4.71731248  1.87260332 -1.7438891\n",
            "  3.90133528  2.9162708 ]. \t  -430.75695193304756 \t -164.77731695731757\n",
            "59     \t [ 0.70127303 -3.76012076 -2.236577    4.96127098 -4.14501168 -3.28851258\n",
            " -3.66507698 -3.80638238]. \t  -502.961867402069 \t -164.77731695731757\n",
            "60     \t [ 4.54999576 -2.85932663  5.08591057  1.91906308 -3.8298999  -2.67360764\n",
            "  1.38081045 -5.10224247]. \t  -467.2238524033479 \t -164.77731695731757\n",
            "61     \t [-0.76958747 -4.32656779 -1.98211412  4.58132046  5.10634124  0.21352224\n",
            "  3.41172719  5.04403432]. \t  -549.4355501999553 \t -164.77731695731757\n",
            "62     \t [ 4.57863143  4.88090881 -1.42429533  5.10231232 -4.11167057  3.60160511\n",
            " -4.29811952  4.93026772]. \t  -664.9662915663754 \t -164.77731695731757\n",
            "63     \t [ 0.06814496  1.41507323  2.84042003  0.73157262 -2.0247006   5.10557721\n",
            "  1.13308205 -3.19566692]. \t  -297.93825551386294 \t -164.77731695731757\n",
            "64     \t [ 4.33125458  3.39448302  4.04872279 -3.94142837 -1.01620288 -3.19773961\n",
            " -0.93375045 -4.18444768]. \t  -365.81731659935895 \t -164.77731695731757\n",
            "65     \t [-4.50628757 -3.60240404  0.02547933  0.98285289  0.03057927 -4.569045\n",
            "  4.17112549  5.06464476]. \t  -502.3819403609468 \t -164.77731695731757\n",
            "66     \t [-3.22241016  4.387044   -4.28676743  4.56079728 -0.66577086 -2.96341213\n",
            " -2.57015492 -4.78231992]. \t  -471.32051718861777 \t -164.77731695731757\n",
            "67     \t [ 4.69081604  4.38259879 -4.47774263  0.18879334 -2.22333705  1.54113902\n",
            "  0.56645757  2.19757558]. \t  -200.55882995149457 \t -164.77731695731757\n",
            "68     \t [-3.13987731 -4.02171869  3.02062262 -4.84994764 -4.75507788  0.53491042\n",
            "  2.01664614  4.2329092 ]. \t  -450.2465206404489 \t -164.77731695731757\n",
            "69     \t [ 4.49166257 -2.59677196 -0.71946391  4.90532044  3.95603296 -1.46414331\n",
            " -3.46798448  4.90270152]. \t  -499.05659099512377 \t -164.77731695731757\n",
            "70     \t [ 5.03701549 -2.12170286 -3.04755621 -4.13363444 -3.57025602 -3.90390314\n",
            " -4.67196816 -2.73072142]. \t  -498.2074220358934 \t -164.77731695731757\n",
            "71     \t [ 3.99210286e+00 -2.03607804e+00 -4.37636292e+00  2.13002277e+00\n",
            "  4.36836550e+00 -3.24100427e+00  3.93992511e+00 -1.54390142e-03]. \t  -366.93258342016946 \t -164.77731695731757\n",
            "72     \t [-4.56660937  4.61184174  3.5617901   2.1830261  -4.57131176  4.76213432\n",
            "  4.63344733  3.41519756]. \t  -604.6559768118517 \t -164.77731695731757\n",
            "73     \t [ 3.76989209 -3.20440863 -4.51149648 -5.01976077  4.71392754  1.09343188\n",
            "  3.94347109  4.99216772]. \t  -623.1111316240895 \t -164.77731695731757\n",
            "74     \t [ 0.34156989 -3.50860479  5.0579587   2.88332466 -4.87390095  3.20755587\n",
            " -4.18009029  1.36208166]. \t  -452.3996240758148 \t -164.77731695731757\n",
            "75     \t [-2.67215195  3.12196812 -1.70834009 -4.75781378  3.3721822   0.17024068\n",
            " -2.87639085 -4.95151899]. \t  -437.02385921851914 \t -164.77731695731757\n",
            "76     \t [-4.56461353  4.56773838  4.8215984  -1.80008782  4.22542264 -4.73318172\n",
            "  2.01263406 -4.37974922]. \t  -550.7703965020847 \t -164.77731695731757\n",
            "77     \t [-2.56329076  1.7143444   1.77397986 -2.98579189 -2.36599191  3.16801897\n",
            " -4.4408021   3.5463691 ]. \t  -384.41582701193596 \t -164.77731695731757\n",
            "78     \t [-1.10745416 -4.3517425   2.47486627 -4.63096435  4.10263452  4.80400395\n",
            "  3.16963913 -2.76799025]. \t  -497.5092118802942 \t -164.77731695731757\n",
            "79     \t [ 2.09530463 -3.87001154  4.71515754  3.18451906  1.03315694 -4.79455116\n",
            " -1.3334075   4.66382263]. \t  -471.3262107144629 \t -164.77731695731757\n",
            "80     \t [-5.12        0.0369175  -4.74827911 -5.12       -4.30543282 -0.03263695\n",
            " -5.12       -1.54770507]. \t  -494.06726692281364 \t -164.77731695731757\n",
            "81     \t [ 2.25173095  4.48113767  1.16911109 -4.18035982  3.44176235 -1.87390548\n",
            "  4.85209595  0.79868741]. \t  -369.4344061896381 \t -164.77731695731757\n",
            "82     \t [-4.81214748  4.01955934 -4.61293662  1.7282114  -1.10258139 -4.79134117\n",
            "  0.17064422  4.55326595]. \t  -441.1367016919699 \t -164.77731695731757\n",
            "83     \t [ 2.9025531   2.58002391 -4.85572936  3.94467787  4.84767866 -2.40743437\n",
            " -3.29760852 -1.02441633]. \t  -391.50348540263235 \t -164.77731695731757\n",
            "84     \t [-1.37872375  5.11431344 -3.90318826  4.09504008  2.90663993  3.72833559\n",
            " -4.04777362 -4.67013918]. \t  -581.8139270024135 \t -164.77731695731757\n",
            "85     \t [ 3.03752022 -4.85355795  4.5615821   2.28558221  4.07741417  2.60555604\n",
            " -2.24873237  3.58234329]. \t  -401.58333026065696 \t -164.77731695731757\n",
            "86     \t [-2.82633902  4.54813943 -1.27954177  4.08092777 -0.72003928  4.56061263\n",
            " -4.49235327  2.57057406]. \t  -442.4057854399488 \t -164.77731695731757\n",
            "87     \t [-2.50652849 -2.50810539 -3.90120215 -4.79781822  1.86139931 -4.04685569\n",
            "  1.21818573  4.9830088 ]. \t  -481.21537555182726 \t -164.77731695731757\n",
            "88     \t [ 2.26170167 -3.61669544 -0.94682333 -5.04574197 -5.06560097  3.90824584\n",
            " -3.7313643   3.71820125]. \t  -563.813337445652 \t -164.77731695731757\n",
            "89     \t [ 4.8788081  -3.70828294 -4.97998389 -5.07402372  4.50915858 -4.30114861\n",
            " -4.54289016 -4.7263046 ]. \t  -764.5195093139696 \t -164.77731695731757\n",
            "90     \t [ 0.81059087 -4.38885446  1.16345233 -1.98624411 -0.71480473 -1.00260754\n",
            " -1.69561105  3.48753838]. \t  -185.03780077924452 \t -164.77731695731757\n",
            "91     \t [-1.78912289 -4.81026107  4.12287438 -3.69302167  0.66383933 -2.09124922\n",
            "  2.46035985 -3.1852997 ]. \t  -307.0121203238552 \t -164.77731695731757\n",
            "92     \t [-4.52882805  1.20606675 -1.0191466  -4.89478489 -3.65871258 -4.62164276\n",
            "  4.48954507  3.25916646]. \t  -543.5289456956048 \t -164.77731695731757\n",
            "93     \t [ 4.56011396  4.69536472 -3.88059314 -3.39949212  5.03493021 -3.62919924\n",
            " -0.40003162 -4.64069524]. \t  -535.4784648050868 \t -164.77731695731757\n",
            "94     \t [3.80014521 2.91481813 1.9742217  0.39544311 4.44403315 5.06662711\n",
            " 4.51648144 1.16898681]. \t  -450.24547658409523 \t -164.77731695731757\n",
            "95     \t [ 4.99784959  4.86717394 -3.82181738  0.19789293  2.89170236  2.31179275\n",
            "  4.53506883 -4.68178066]. \t  -509.5293090006045 \t -164.77731695731757\n",
            "96     \t [-5.035184   -2.53669951 -1.62951499  2.00973233 -2.6072178   5.02153324\n",
            " -3.83811911  4.15821172]. \t  -489.07142557807543 \t -164.77731695731757\n",
            "97     \t [-0.38865628  4.72429546 -0.19672913 -4.47013422  5.05195445  1.34486774\n",
            " -3.46037912  3.1326292 ]. \t  -425.62322149178203 \t -164.77731695731757\n",
            "98     \t [ 4.97449129 -3.83567986 -4.68207321  2.43186988 -2.69823452 -2.60951\n",
            "  2.72939654 -4.47484415]. \t  -433.19251837598927 \t -164.77731695731757\n",
            "99     \t [-2.52782771 -4.23166649  4.07196494 -4.72154985 -4.84994484  4.4192319\n",
            "  4.54262629 -2.00113492]. \t  -592.3907350443759 \t -164.77731695731757\n",
            "100    \t [ 3.19657758  2.46818271  4.61758776  1.91065018  4.58488365  4.92733759\n",
            " -4.33807273  4.51361956]. \t  -646.4625882335883 \t -164.77731695731757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNmoDTuUtdi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00d2224-0375-4c0c-e53d-521b6e3b169f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 7\n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_loser_7 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_7 = dGPGO(surrogate_loser_7, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.55672335 -2.02386832 -4.48474711 -0.4110301   3.43299466  4.37244977\n",
            "  2.3243672   2.74940131]. \t  -353.7866241526368 \t -217.44194749723354\n",
            "init   \t [-2.36334012  1.47485995 -4.16385785 -4.30401653  0.91764484 -1.60419289\n",
            "  5.00609176  1.29508563]. \t  -344.5427966394509 \t -217.44194749723354\n",
            "init   \t [ 1.86141982  0.53510977 -2.36687301 -1.29782388 -2.83721627 -3.21082777\n",
            " -1.11976352 -3.14201697]. \t  -217.44194749723354 \t -217.44194749723354\n",
            "init   \t [ 1.13572794  3.9199585   1.25274956 -2.52806201 -3.27751366  3.23998177\n",
            " -2.8121946   0.17261711]. \t  -234.58737464459995 \t -217.44194749723354\n",
            "init   \t [ 0.18939719  1.02783934  0.33403374 -4.98370509  0.24675597  4.05385947\n",
            "  2.76378925 -3.86199863]. \t  -373.52986721661773 \t -217.44194749723354\n",
            "1      \t [-2.09026361  1.14712145  2.31565437 -0.3737859   2.75569016 -3.15769824\n",
            "  0.59255523  0.51996833]. \t  \u001b[92m-126.06288515837247\u001b[0m \t -126.06288515837247\n",
            "2      \t [ 2.75085748  2.31805411 -0.85031656  3.12431177 -2.44115014  0.01810138\n",
            "  3.95854974  4.53429735]. \t  -363.496045642814 \t -126.06288515837247\n",
            "3      \t [ 0.3197009  -4.24821941  1.44362319  4.43538764 -3.73778765 -4.45035073\n",
            "  0.60134187  0.88561962]. \t  -318.6346160644668 \t -126.06288515837247\n",
            "4      \t [ 2.99171241 -4.16669349  0.06626421 -3.90805164  4.99638945  3.30615025\n",
            " -0.90933644  4.39696134]. \t  -455.6353713631223 \t -126.06288515837247\n",
            "5      \t [ 3.80241898 -4.76561259  3.75477373 -2.31697124  1.95612299 -4.8590656\n",
            "  3.87732368 -4.51857722]. \t  -553.0199071382995 \t -126.06288515837247\n",
            "6      \t [-3.87174622  0.11711937  0.60621965 -2.77389796  3.6777981  -0.61714207\n",
            " -4.44111449 -5.11053133]. \t  -463.8193086344131 \t -126.06288515837247\n",
            "7      \t [-1.62934979 -2.77766743  3.88355824  2.63054964  3.5967524   4.63514942\n",
            " -1.80595721  4.03176121]. \t  -437.4728509815538 \t -126.06288515837247\n",
            "8      \t [-4.87299908 -3.60438804  4.14373037 -3.66711479 -4.11526938 -3.23954251\n",
            " -2.15930292 -5.0851064 ]. \t  -542.1813791428053 \t -126.06288515837247\n",
            "9      \t [ 0.46738539  2.1646163   0.18847445  4.77376931 -2.41808188 -1.00777632\n",
            " -4.68197947  1.61777929]. \t  -310.56511723466554 \t -126.06288515837247\n",
            "10     \t [ 4.58684088 -3.86154213 -5.10238691  3.28477999 -4.2350354   4.4322743\n",
            "  4.27338411 -0.40158936]. \t  -508.7951306576851 \t -126.06288515837247\n",
            "11     \t [ 2.18807677 -3.85838637 -0.14390746 -2.54364233 -3.68109291 -3.85783141\n",
            "  4.56739657  4.76093171]. \t  -544.9135139030769 \t -126.06288515837247\n",
            "12     \t [ 3.65910848 -3.77322784 -4.39092579 -4.04329935  4.92496582 -4.83510266\n",
            "  1.41512293 -1.67248293]. \t  -463.03868968879215 \t -126.06288515837247\n",
            "13     \t [ 3.70463372 -1.6169365   3.99069216 -4.79873113  3.21012622 -3.59582379\n",
            " -3.62529352 -1.33583421]. \t  -394.22057211255174 \t -126.06288515837247\n",
            "14     \t [-4.5894154   4.92798365  2.37548828 -2.76315117 -4.38889546 -2.95023546\n",
            "  4.23062684 -1.37722754]. \t  -406.09845273916767 \t -126.06288515837247\n",
            "15     \t [ 3.03724509 -4.71790039  2.51302555  0.03615994 -4.39481833  2.54450993\n",
            " -1.26899952  0.71522446]. \t  -223.47736072165253 \t -126.06288515837247\n",
            "16     \t [ 1.84266697 -3.35314984 -3.54865233 -4.62317696 -1.38585737 -0.64246734\n",
            " -4.39848531  4.64968205]. \t  -469.6191559661819 \t -126.06288515837247\n",
            "17     \t [-2.50399261  3.09944983 -1.78206992  3.66530073 -0.72521701  0.0927845\n",
            "  4.28994614 -2.16487185]. \t  -257.7483735095152 \t -126.06288515837247\n",
            "18     \t [-2.86542444 -4.683581    0.54115179 -0.39180876 -1.41324475  3.35805496\n",
            " -1.52857118 -4.68463338]. \t  -323.1426418602525 \t -126.06288515837247\n",
            "19     \t [ 2.48184377  4.66551143 -4.9596751  -3.43903238 -4.35518841 -3.3123188\n",
            " -0.54239038  3.58194976]. \t  -436.1657379088569 \t -126.06288515837247\n",
            "20     \t [ 3.50969778 -0.85729815 -3.40613827  5.10070628  3.57291431  0.80937832\n",
            "  1.54976903 -3.34444673]. \t  -326.7162735361845 \t -126.06288515837247\n",
            "21     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -126.06288515837247\n",
            "22     \t [ 3.43654162  2.37720797  5.01669256 -4.95385484 -2.54870646 -3.72425019\n",
            "  1.11165097  2.40658989]. \t  -367.4599120709033 \t -126.06288515837247\n",
            "23     \t [ 1.98387325  1.67275942  4.48981292  4.53543431 -2.80345593  3.62397376\n",
            "  3.75908479 -2.01170598]. \t  -401.674576242779 \t -126.06288515837247\n",
            "24     \t [-0.84293283  3.48913065 -2.68496808 -3.25305769  4.07373554  2.87426449\n",
            " -3.67591306  3.5888769 ]. \t  -419.18694060168053 \t -126.06288515837247\n",
            "25     \t [-4.9925136  -0.04399427 -3.91692885  4.96109248  3.34448879 -1.57934636\n",
            " -2.13194442  0.43900937]. \t  -273.6579910101781 \t -126.06288515837247\n",
            "26     \t [ 2.4707812  -1.48111345  4.44872515  5.07739461  2.90692425 -4.55416511\n",
            " -3.25498266  4.39629928]. \t  -568.4628902261106 \t -126.06288515837247\n",
            "27     \t [-4.91554525  2.89709073 -4.92224896 -1.57136991  0.23902827  4.44092204\n",
            " -4.78237799 -2.25757831]. \t  -442.9989299504249 \t -126.06288515837247\n",
            "28     \t [-3.29513168  4.69703011  4.31837646 -3.82056116  3.60718111  5.05741155\n",
            " -1.5779542  -0.14830569]. \t  -405.44273268819427 \t -126.06288515837247\n",
            "29     \t [-4.76621345 -0.65412886 -4.87480111 -1.43615909 -2.03929788 -4.66702248\n",
            " -3.59241771  4.65398803]. \t  -518.2091927885375 \t -126.06288515837247\n",
            "30     \t [-4.59632758 -3.1197202  -2.35021669  0.46448236 -1.29341086 -4.19166308\n",
            "  3.00681779 -4.53166588]. \t  -399.38449837167275 \t -126.06288515837247\n",
            "31     \t [-3.32995226  2.3566786   4.51740145  3.1274462   4.94979517  3.07521084\n",
            "  1.11387665 -3.93306882]. \t  -434.2220593166157 \t -126.06288515837247\n",
            "32     \t [-4.65600681 -2.33230214  1.9198081   1.94038757 -4.8061165   4.93417478\n",
            " -1.02135168  3.57858206]. \t  -429.99744638214315 \t -126.06288515837247\n",
            "33     \t [ 4.69117852 -4.95966635  4.00120457 -2.61337472 -4.96747111 -3.62216146\n",
            " -4.17873666 -3.67319295]. \t  -578.8223800965548 \t -126.06288515837247\n",
            "34     \t [-4.65891214 -1.8539564   5.08351102 -4.96897638  2.98653259 -4.29999065\n",
            " -4.40106778  2.62358603]. \t  -551.0567434148775 \t -126.06288515837247\n",
            "35     \t [ 3.65070719 -1.61137318  4.39408057  4.62918309  5.09582941 -4.19235121\n",
            " -2.16394287 -4.89988938]. \t  -622.3039941887954 \t -126.06288515837247\n",
            "36     \t [ 3.12270749 -1.10643081 -3.09023247 -4.9150458  -0.38132969  4.85016166\n",
            " -5.02656311 -3.00336982]. \t  -528.376660783285 \t -126.06288515837247\n",
            "37     \t [ 2.82721129  2.83495095 -1.20407627 -2.90812872  4.81537988  4.70444454\n",
            "  5.1014436   3.21891957]. \t  -576.0401084594043 \t -126.06288515837247\n",
            "38     \t [ 4.13421669 -0.00512137 -4.94498531 -3.64718248 -1.98202397  4.88916549\n",
            "  1.48393019  3.71772539]. \t  -432.7101283505503 \t -126.06288515837247\n",
            "39     \t [-3.30183886 -4.06733792  4.98570845 -1.68785371  5.00930643  2.19400339\n",
            "  4.84033579 -1.15056899]. \t  -458.895967565413 \t -126.06288515837247\n",
            "40     \t [ 4.65419152  2.96497799 -4.29522873 -3.98879643  4.01893485 -3.59218847\n",
            " -4.23207094 -4.14766832]. \t  -579.412931213512 \t -126.06288515837247\n",
            "41     \t [ 4.47727712 -2.98415741  2.8484701   3.42727006  3.58423302 -1.73137264\n",
            "  4.98872412  3.46172515]. \t  -461.4819128187171 \t -126.06288515837247\n",
            "42     \t [ 3.49235565  4.59385774  2.11856193  3.31953353  1.84560596  4.37365149\n",
            " -1.34058314  4.01241719]. \t  -385.12607787647903 \t -126.06288515837247\n",
            "43     \t [-1.780762    3.21783638  4.35245659  2.66410558 -4.61218223 -4.19432433\n",
            " -0.78076841 -4.36106615]. \t  -477.43516808029506 \t -126.06288515837247\n",
            "44     \t [-4.065784    1.20726911  2.66026032  4.90416463  4.55847381 -4.54819465\n",
            "  4.82761247 -4.95406689]. \t  -724.3778646935331 \t -126.06288515837247\n",
            "45     \t [ 3.90318603  5.07097627 -0.10464568  0.63693993  3.33421053 -3.13703861\n",
            "  2.97208012 -4.25888474]. \t  -389.88856577581714 \t -126.06288515837247\n",
            "46     \t [ 4.59042452  2.59148526 -4.76062565  4.30692082 -3.96183129 -4.60073579\n",
            "  3.21473751 -1.50255692]. \t  -472.57686026549163 \t -126.06288515837247\n",
            "47     \t [ 4.98919915  5.10956884 -5.09231092 -0.42393897 -0.11551188  3.21894168\n",
            " -0.64974996 -4.06072598]. \t  -352.72870098398147 \t -126.06288515837247\n",
            "48     \t [ 4.55688248  1.45390653 -1.03818276 -1.39634278  4.31766067 -4.17598525\n",
            " -0.2851115   4.53929015]. \t  -399.27977497564814 \t -126.06288515837247\n",
            "49     \t [-4.78423195  4.95905843 -1.66277428 -2.03075737  0.45024421  3.54255237\n",
            "  3.04618687  4.5330511 ]. \t  -402.51861562727595 \t -126.06288515837247\n",
            "50     \t [-3.8874185  -2.44978105 -4.94060571  0.88957022 -3.7487915   0.30518537\n",
            "  4.87566276  4.42803405]. \t  -497.59948507637023 \t -126.06288515837247\n",
            "51     \t [-5.09296222  4.96799341 -4.52982563  3.03126267 -4.41572932 -2.87263242\n",
            " -4.80293809 -4.79659212]. \t  -666.1536519160758 \t -126.06288515837247\n",
            "52     \t [ 0.21333477 -4.73149471 -4.65711115  4.63789876 -2.0291509   2.00698314\n",
            " -3.95285832 -1.22073445]. \t  -361.9783860461043 \t -126.06288515837247\n",
            "53     \t [-1.9410221   0.21852535  4.12099768 -4.56116732 -2.98588166  5.04643513\n",
            "  4.42520396  4.9653252 ]. \t  -669.7170658576059 \t -126.06288515837247\n",
            "54     \t [ 0.21132943 -5.10511174  4.51228662  4.83588805  1.41358262  1.69116063\n",
            "  0.87885281 -2.68200595]. \t  -296.89758474715273 \t -126.06288515837247\n",
            "55     \t [-1.51377082  4.89936992 -2.22819918  3.82817464  5.04829218  2.79478747\n",
            " -4.84967274 -2.46540537]. \t  -511.3658134198294 \t -126.06288515837247\n",
            "56     \t [-4.21897914 -4.9173616  -4.00305383 -4.57367384 -2.96322354  1.99627995\n",
            "  1.02030834  0.42090534]. \t  -274.4267293311488 \t -126.06288515837247\n",
            "57     \t [ 4.15002035  1.95299292 -4.29935879  4.81983136 -4.61776232  3.07831746\n",
            " -4.18384218 -3.27403162]. \t  -544.9884736173814 \t -126.06288515837247\n",
            "58     \t [ 2.92868122 -1.09771224  4.06113147 -3.15913434  4.30646556  5.06695085\n",
            " -4.91937638 -0.85739819]. \t  -522.4410781781945 \t -126.06288515837247\n",
            "59     \t [-2.86875847 -3.13273465  3.22986442 -1.03989463 -4.9467127  -0.31051717\n",
            "  5.01843137  0.27389569]. \t  -363.30050649793765 \t -126.06288515837247\n",
            "60     \t [ 2.33153758 -1.55717918 -3.56607654  3.65990967  4.80507923  1.37613077\n",
            " -0.46146438  4.80986581]. \t  -415.39160854073805 \t -126.06288515837247\n",
            "61     \t [-3.81949502  4.42035831 -4.84371314  0.34579591 -4.3421587   5.05168267\n",
            "  1.3665522  -2.93232746]. \t  -453.7799539899686 \t -126.06288515837247\n",
            "62     \t [ 2.60951563 -4.32394621 -3.80127125 -4.05921208 -3.67342125  4.82319883\n",
            "  4.15400133 -3.89178641]. \t  -602.4680955160921 \t -126.06288515837247\n",
            "63     \t [-4.47876487 -4.96344251 -2.44493728 -4.45738918  0.13136297  4.77609192\n",
            " -4.86132036  4.62884175]. \t  -640.5263486535432 \t -126.06288515837247\n",
            "64     \t [ 1.33934797  3.35747308  4.68510374  4.20538712 -3.30070613 -4.99037399\n",
            "  4.99296417  0.78696891]. \t  -544.2895174786909 \t -126.06288515837247\n",
            "65     \t [-2.02214105 -4.02564771  3.57057198  1.55142368  4.76549851 -3.40204489\n",
            " -4.87366691 -1.3837977 ]. \t  -448.956257274611 \t -126.06288515837247\n",
            "66     \t [-3.04623207  4.52202737  4.30068507 -1.80477247 -3.86190095 -3.27446762\n",
            " -3.46901151  2.27460177]. \t  -383.22649901159787 \t -126.06288515837247\n",
            "67     \t [-4.62653169  1.48564364  4.67192103  3.98812018 -1.25397528  3.08672166\n",
            " -3.7300208  -4.32496147]. \t  -466.98311163273183 \t -126.06288515837247\n",
            "68     \t [-4.22782405 -3.86891848  4.04034044 -1.081632   -4.12876997 -1.92296927\n",
            " -2.96917765  4.76147554]. \t  -451.97019874920056 \t -126.06288515837247\n",
            "69     \t [-4.16271264  3.34180653  3.03449541  5.00894337  5.08251494 -1.9322614\n",
            " -0.79575239  4.94075921]. \t  -518.9290211815734 \t -126.06288515837247\n",
            "70     \t [ 4.27488555 -4.37630749 -3.10725494  3.04132314  4.78323047 -3.2012495\n",
            " -4.64583011 -2.53620746]. \t  -500.97187338004613 \t -126.06288515837247\n",
            "71     \t [ 4.78986392  4.24036657 -3.47661256  5.00696868  3.98791566 -3.6694881\n",
            "  3.58510011  4.47082557]. \t  -605.6287232414135 \t -126.06288515837247\n",
            "72     \t [-3.67687556 -4.87562151 -4.3588536  -3.84573594  4.743902   -3.4655177\n",
            " -0.17593116  3.05093843]. \t  -436.4847110478042 \t -126.06288515837247\n",
            "73     \t [ 1.30662715 -2.90787154  4.51713971  4.51151038 -3.68401654  3.06292146\n",
            "  4.74784002  4.56856917]. \t  -610.1645698126301 \t -126.06288515837247\n",
            "74     \t [ 2.86825292 -4.53439682 -2.40124625  4.62111583 -1.36833296 -1.87564634\n",
            " -3.537974    5.08206356]. \t  -476.77493195227044 \t -126.06288515837247\n",
            "75     \t [-2.67808046  4.21166453 -2.51840833  2.79223596  4.93559453 -4.89335419\n",
            " -0.48652248 -3.97160481]. \t  -486.1778644746092 \t -126.06288515837247\n",
            "76     \t [-1.12235943 -4.73997626  4.73307374 -4.38385113  2.48524489 -5.01922093\n",
            "  5.07363928  3.38849048]. \t  -644.358337742447 \t -126.06288515837247\n",
            "77     \t [-3.78807237 -4.24635998 -2.44984338  0.30909451  4.11007227  2.006032\n",
            "  5.11138163 -5.09499145]. \t  -567.9635086664478 \t -126.06288515837247\n",
            "78     \t [ 5.08877951 -3.34715522  3.22950498  0.85640496 -4.45058261 -1.4546155\n",
            "  4.04398904 -3.22470736]. \t  -391.92609521088815 \t -126.06288515837247\n",
            "79     \t [-1.03177339  4.65296111 -4.64498302  3.38824998 -2.23998182  3.78818925\n",
            " -0.89103366  4.75437208]. \t  -452.59308128993393 \t -126.06288515837247\n",
            "80     \t [ 4.50300717 -1.37760092  4.69743853 -5.07792934 -2.45850812  2.55355818\n",
            "  4.75528184  0.38284992]. \t  -422.2186914083558 \t -126.06288515837247\n",
            "81     \t [ 3.20480929  3.3823284   4.88155553 -4.61373431  4.02454506  0.71536562\n",
            "  3.3028888   0.28603592]. \t  -350.85938005809885 \t -126.06288515837247\n",
            "82     \t [-3.91452618 -4.16884238  4.28349512  3.20233929 -0.17494882 -4.72364108\n",
            "  5.02491138  2.92999368]. \t  -525.6036979195742 \t -126.06288515837247\n",
            "83     \t [-3.51881716  3.94282401  2.07219909  3.81830004 -2.79291345 -3.5660105\n",
            "  1.34800352  4.7205906 ]. \t  -420.9654974046708 \t -126.06288515837247\n",
            "84     \t [-1.52849504 -5.12       -1.96973121 -5.12       -5.12       -5.12\n",
            "  0.83143643 -2.27735981]. \t  -505.95056754022005 \t -126.06288515837247\n",
            "85     \t [ 4.18968297 -4.99942498 -4.35214793 -0.18405964  2.66485755  3.80327547\n",
            "  2.73488485 -1.2653633 ]. \t  -311.9641053143754 \t -126.06288515837247\n",
            "86     \t [ 4.76185354  0.12175905  2.0807318   0.22008519 -4.16994702 -4.04494669\n",
            " -3.72082423  4.9549801 ]. \t  -514.3251904500883 \t -126.06288515837247\n",
            "87     \t [ 0.7208291   3.34579002  5.09850784 -2.06934781  3.13668952  0.32632027\n",
            " -3.01173659  4.6904147 ]. \t  -407.34820110392843 \t -126.06288515837247\n",
            "88     \t [-2.84986281  3.78981458 -2.83082885  3.47552879  4.75490856 -4.60867961\n",
            "  4.53221657  3.13290947]. \t  -571.9983114767854 \t -126.06288515837247\n",
            "89     \t [-2.14367027  4.7017305  -4.25665275 -1.21138091  3.39494905  2.70296224\n",
            "  1.47980811 -2.44303715]. \t  -273.5756074542297 \t -126.06288515837247\n",
            "90     \t [-0.78361085  4.54534188 -2.78972516 -4.92274513 -0.76805186 -3.07562192\n",
            "  4.92575081 -5.03567555]. \t  -594.6272822665569 \t -126.06288515837247\n",
            "91     \t [ 2.93788574  1.78682512  4.52781582  1.1774453  -0.00639281  3.72267093\n",
            " -2.79369627 -4.61513795]. \t  -390.24455484064515 \t -126.06288515837247\n",
            "92     \t [ 3.59241536  5.03326922  3.38086681 -4.0128877  -4.93650218 -4.64194681\n",
            "  0.73229589 -4.68993144]. \t  -593.1256449843719 \t -126.06288515837247\n",
            "93     \t [-3.29854367 -4.3411339  -1.31607687 -5.11357998  2.52638824 -1.56475802\n",
            "  0.40255217 -3.92806505]. \t  -329.5381450351533 \t -126.06288515837247\n",
            "94     \t [-4.90308625  0.41950708 -4.65058619  5.00329717  2.80633317  4.31601731\n",
            "  1.13819925 -3.75760538]. \t  -462.5788439633349 \t -126.06288515837247\n",
            "95     \t [-4.70532271  2.31378937 -4.87202588 -4.97958658 -3.53818867  2.54817121\n",
            " -2.54998583  3.70129485]. \t  -459.90895996296365 \t -126.06288515837247\n",
            "96     \t [ 4.94426616  3.24622917  4.1812172   1.55380944 -0.80270773 -4.2786256\n",
            " -3.32407581 -4.76591838]. \t  -479.7465065568298 \t -126.06288515837247\n",
            "97     \t [-3.48699102  2.04363098 -5.12       -1.34472934  1.76201523 -5.12\n",
            " -5.12       -4.37138234]. \t  -615.5709065163586 \t -126.06288515837247\n",
            "98     \t [-3.92941469  4.32504803 -4.81650143 -0.87210949 -4.38215511 -3.0210166\n",
            "  1.24209859 -1.36174031]. \t  -301.9007594772047 \t -126.06288515837247\n",
            "99     \t [-0.8982652  -4.64122505 -2.97075063  2.08253987  5.09925702  2.55800324\n",
            " -4.62780396 -0.38757107]. \t  -408.10285900453965 \t -126.06288515837247\n",
            "100    \t [-1.61693608  4.57551691  5.02363779 -3.72816625  5.07604642 -4.43971945\n",
            "  4.68170426 -4.73426912]. \t  -755.6257013921371 \t -126.06288515837247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_21yVprtdlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75184ec-47ca-4c70-cb25-4deda565d9b5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 8\n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_loser_8 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_8 = dGPGO(surrogate_loser_8, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.99872128 -4.68771825  1.02085207 -2.04932398  3.03730465 -1.37015168\n",
            "  3.89742944 -2.07010168]. \t  -277.86676122742784 \t -180.51916289603517\n",
            "init   \t [-1.74998258  0.70366122  2.49781681 -4.56854645  1.04524157 -0.72377777\n",
            " -3.01595019  0.49815264]. \t  -180.51916289603517 \t -180.51916289603517\n",
            "init   \t [-1.18004907 -0.43124987 -2.23607519  0.87291919  1.19692315  0.82388062\n",
            "  4.34999751 -2.6686217 ]. \t  -220.47800037058124 \t -180.51916289603517\n",
            "init   \t [ 3.35954485  4.67643031  4.19598825  2.82329052 -0.36849066 -1.29661262\n",
            "  4.62746655  4.05379841]. \t  -431.85390329456686 \t -180.51916289603517\n",
            "init   \t [-0.2416498   4.43676172  4.77427222  3.16353515  1.62974284 -3.16385107\n",
            "  1.99781252 -1.93490553]. \t  -279.0706376092465 \t -180.51916289603517\n",
            "1      \t [-0.80689796  0.12979216 -3.32388196  5.07613741 -3.43250948 -2.05510194\n",
            " -3.97044354  3.43910665]. \t  -426.1198945095334 \t -180.51916289603517\n",
            "2      \t [-2.47747564  2.99675238 -3.50374538 -1.80117914 -3.5161839  -4.45826655\n",
            "  3.67687843  2.14617347]. \t  -386.46373501095024 \t -180.51916289603517\n",
            "3      \t [ 0.67811681 -1.3781688  -2.58692023  3.85333047  3.25130113  4.04155624\n",
            " -2.06044078  1.40198962]. \t  -280.03000154622777 \t -180.51916289603517\n",
            "4      \t [ 4.42454388  2.4188757  -3.21525657 -3.20344997 -1.04051026  5.10245349\n",
            " -0.18691581  2.84253024]. \t  -329.8483850739637 \t -180.51916289603517\n",
            "5      \t [-3.07302883 -2.35748372 -4.76094872 -3.54574189  0.41804042  1.01804191\n",
            " -4.13688486 -2.82255427]. \t  -329.47146503033844 \t -180.51916289603517\n",
            "6      \t [ 4.36422087  1.90391934  0.09991155  1.48583163 -5.11736914  0.78996386\n",
            " -3.71360948 -0.80410969]. \t  -271.54756978806927 \t -180.51916289603517\n",
            "7      \t [ 3.91575324  4.44584808 -4.68483153 -1.3300073   3.96829654 -2.30847028\n",
            "  3.63052491  2.20115262]. \t  -369.5195285564901 \t -180.51916289603517\n",
            "8      \t [ 2.83791722 -1.84109194 -0.18336038  5.05505168 -2.27716459 -4.66250782\n",
            "  2.86358311 -0.56762536]. \t  -333.48768015256735 \t -180.51916289603517\n",
            "9      \t [-4.34829873  4.8056149   2.63278856  2.70249436 -3.33886902  3.32420497\n",
            " -1.98131952 -3.03250746]. \t  -338.1946658605332 \t -180.51916289603517\n",
            "10     \t [-4.86997064  3.74258529 -3.20639472 -0.45958993 -4.35843637  4.8523993\n",
            " -4.34311529  4.90084006]. \t  -643.8572272382727 \t -180.51916289603517\n",
            "11     \t [-5.00411946  0.44264128  3.47943139  1.31201606  1.59913651  3.50610765\n",
            " -1.3911044   4.64701043]. \t  -341.4847277527873 \t -180.51916289603517\n",
            "12     \t [ 0.00548086 -4.23465739  4.71059857  4.19732566  0.82693307 -0.63428372\n",
            " -1.78653781 -2.22242468]. \t  -240.5924435082622 \t -180.51916289603517\n",
            "13     \t [-0.57223471 -3.8222528   1.07901006 -2.63093396 -2.58877446  4.422961\n",
            "  0.11753285  3.42507695]. \t  -305.5569122434089 \t -180.51916289603517\n",
            "14     \t [ 4.03761438  2.56133194  5.1197742   2.35660972  4.75332242 -2.77386776\n",
            " -3.83140306  4.55349137]. \t  -558.0421125100511 \t -180.51916289603517\n",
            "15     \t [ 5.07002423 -3.07341682  2.03370618 -2.97540296 -1.19482646  4.04468259\n",
            " -1.72924441 -3.91197777]. \t  -341.07226021043425 \t -180.51916289603517\n",
            "16     \t [-1.41671202  2.55666195 -2.3853693   1.08516009  4.30765662 -3.68324439\n",
            " -4.13221178 -2.44338018]. \t  -378.32469967994336 \t -180.51916289603517\n",
            "17     \t [-1.86728783 -0.80945079  1.84517462 -2.62059911 -5.04656418 -1.09871244\n",
            "  1.57935526 -4.31856167]. \t  -343.7237567008143 \t -180.51916289603517\n",
            "18     \t [ 3.66966602 -0.99814995  2.15291433 -4.92866581  2.78887625  0.68641935\n",
            "  3.51008714  1.89619243]. \t  -283.2566926789915 \t -180.51916289603517\n",
            "19     \t [ 3.97405564 -4.75710002 -2.01610248  5.07982104  3.97698667 -2.99383872\n",
            "  4.55425869  4.69086357]. \t  -630.5485044279746 \t -180.51916289603517\n",
            "20     \t [ 4.89167444 -4.35507446  3.93944184 -4.28192575 -5.07746683 -3.77769739\n",
            " -1.03928419  1.60291329]. \t  -424.40374657480845 \t -180.51916289603517\n",
            "21     \t [ 5.01960078  4.66343278  2.47908295 -0.1380686   2.4412476   0.91037699\n",
            " -4.27646892 -4.63889164]. \t  -422.1484084919773 \t -180.51916289603517\n",
            "22     \t [ 1.46921301 -1.90240606 -3.84335063 -5.06810438 -3.31266033 -4.81007936\n",
            " -0.85475063  4.40766578]. \t  -510.6777487454212 \t -180.51916289603517\n",
            "23     \t [-5.07574257  0.9567305   2.26465    -4.88807507  3.91342817 -4.93868051\n",
            "  4.90344371  2.79780682]. \t  -592.3989559199782 \t -180.51916289603517\n",
            "24     \t [ 4.42185871 -4.04838897 -3.40680335 -0.43441359 -2.34356268  3.1813517\n",
            " -4.88664142  5.0991389 ]. \t  -551.257541467041 \t -180.51916289603517\n",
            "25     \t [ 3.02005946 -0.28946757  4.46799786  0.86269113 -2.46440069  4.94345878\n",
            "  5.04534233 -2.35245246]. \t  -471.60797757980407 \t -180.51916289603517\n",
            "26     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -180.51916289603517\n",
            "27     \t [ 4.79720828 -4.22946252 -4.0281915  -0.80296819 -3.82216182 -3.2698492\n",
            "  0.43511803 -3.92789985]. \t  -371.99648514497284 \t -180.51916289603517\n",
            "28     \t [-2.45652141  4.69621567 -4.35725831  5.04561852 -4.30274899  4.941271\n",
            "  4.0771041   0.94008965]. \t  -571.428338267913 \t -180.51916289603517\n",
            "29     \t [ 3.87333974 -4.16740068 -3.883898    1.18395794 -3.03775313  5.0025232\n",
            "  3.33771536 -4.93527906]. \t  -569.7276263414255 \t -180.51916289603517\n",
            "30     \t [ 4.08890417  4.94345227  0.8273562  -3.77103829 -2.75423202 -3.62028656\n",
            "  0.93923661  1.48437471]. \t  -264.900974636553 \t -180.51916289603517\n",
            "31     \t [ 2.63656256 -5.08585994 -2.03710373 -2.5078634   2.50053278 -3.18902679\n",
            " -3.85469637 -0.41079712]. \t  -293.93378992559553 \t -180.51916289603517\n",
            "32     \t [-2.8617014  -2.65212229 -0.44945493  4.64340813 -0.81896431 -0.53157431\n",
            "  4.37606182  4.14663878]. \t  -385.76309067404435 \t -180.51916289603517\n",
            "33     \t [-3.67364611  3.58284625 -2.05438179 -5.02332146 -3.28970817  3.72997149\n",
            "  2.76318082  3.28523873]. \t  -430.1412870166693 \t -180.51916289603517\n",
            "34     \t [ 3.88985138  3.15756992 -4.96071759 -4.74637069  3.58417391 -3.86575799\n",
            " -2.0904379  -4.99028775]. \t  -582.7190459077771 \t -180.51916289603517\n",
            "35     \t [-0.87522108  5.07922594 -1.29272057  4.93410574 -4.0126065  -4.3584217\n",
            " -4.3870108  -3.14365793]. \t  -563.0198818743911 \t -180.51916289603517\n",
            "36     \t [-4.10480064 -3.92466462 -4.45138043  0.78043132  3.84921301 -4.08494889\n",
            " -4.33965454  2.76404217]. \t  -476.6867208590488 \t -180.51916289603517\n",
            "37     \t [-4.02738225  1.92634882  4.84539184 -2.5866606   0.14153928  3.54521975\n",
            "  5.00865971 -4.31977319]. \t  -521.2400592606305 \t -180.51916289603517\n",
            "38     \t [ 4.74248688  4.41156993 -4.50417805  3.37436951 -3.61370696 -4.09590624\n",
            "  3.44967939 -3.98960231]. \t  -544.4139241090639 \t -180.51916289603517\n",
            "39     \t [ 4.48023166  4.86333126 -4.30722253  4.65419032  0.0661146  -4.69857936\n",
            "  0.06780351  4.85563852]. \t  -530.8106334453986 \t -180.51916289603517\n",
            "40     \t [-4.25294219  4.52639591  4.18726302  4.8264791  -0.02761229 -3.19252306\n",
            " -2.70449292  4.53849168]. \t  -481.9834142207267 \t -180.51916289603517\n",
            "41     \t [ 4.29894557 -3.1371144  -4.2468848  -4.38761864  4.8244412   2.05386982\n",
            "  0.91278778 -3.63419963]. \t  -422.4547657402016 \t -180.51916289603517\n",
            "42     \t [-5.0417793  -4.83906763  3.40145714  4.66843181  0.21828891 -3.69802087\n",
            " -3.84373455  4.54335417]. \t  -544.9864482112325 \t -180.51916289603517\n",
            "43     \t [-5.12       -1.72424602 -5.12       -2.41134048 -0.75856483 -4.58494294\n",
            "  1.70247613 -4.83572411]. \t  -470.4320104878843 \t -180.51916289603517\n",
            "44     \t [-2.53091057  4.59401986  4.93133433 -3.88337755 -4.93149815 -5.10021546\n",
            "  3.44199404  4.33344787]. \t  -692.7251862242503 \t -180.51916289603517\n",
            "45     \t [-2.91672448  4.04522193 -5.01281992  0.80993504  4.77106101  4.84356204\n",
            "  4.03856252  2.35564681]. \t  -532.3821531215153 \t -180.51916289603517\n",
            "46     \t [ 3.20405848 -2.95918097  4.9198676   3.23456556  4.31471242 -2.87814545\n",
            "  4.74362933 -3.70096053]. \t  -552.1214922769788 \t -180.51916289603517\n",
            "47     \t [-3.20403481 -5.11301229 -3.89350589  3.67293555 -2.24733544  4.55634521\n",
            " -4.28801809 -4.38970784]. \t  -594.6718611860366 \t -180.51916289603517\n",
            "48     \t [-1.33421434 -4.29727091  4.82187183 -2.6334693   3.22263362  4.87272422\n",
            "  0.98684594 -4.3639148 ]. \t  -489.75974725087883 \t -180.51916289603517\n",
            "49     \t [ 4.69746669  4.59969471 -4.06289378 -1.99653753  3.89209236 -0.66418485\n",
            " -4.91913236  2.07088867]. \t  -411.9289870185117 \t -180.51916289603517\n",
            "50     \t [ 4.61551064 -3.58884404  3.15499749  4.27739454 -3.93798212 -5.0649973\n",
            " -4.13043317  3.97675662]. \t  -627.5127799367586 \t -180.51916289603517\n",
            "51     \t [ 3.65691747 -4.96121519 -1.44086027 -2.87224888  4.8053054   5.01246607\n",
            " -0.95906364  4.5712296 ]. \t  -541.6392857541672 \t -180.51916289603517\n",
            "52     \t [-4.41779186 -5.02354276 -1.9267254   1.65496306 -1.53905592  3.11515467\n",
            " -4.90148497  4.87031203]. \t  -520.0812675473336 \t -180.51916289603517\n",
            "53     \t [-2.15961732  4.73973166 -4.8427031  -1.9939927  -4.70679312 -1.64738883\n",
            " -0.90701478 -4.73970313]. \t  -448.3832707161231 \t -180.51916289603517\n",
            "54     \t [ 0.41053538  4.78871453  4.01407292  0.43179899  4.33826345  4.72002531\n",
            "  1.48475191 -1.19115042]. \t  -349.67287340916636 \t -180.51916289603517\n",
            "55     \t [3.40852894 0.84640147 4.19082071 4.98261933 4.59525337 4.58397842\n",
            " 3.23434812 3.5568389 ]. \t  -571.1405710588766 \t -180.51916289603517\n",
            "56     \t [-3.26090619 -4.56978756  2.31122861 -2.02490321 -3.83858586 -4.24870128\n",
            "  4.38919359  4.57717492]. \t  -569.2675579045233 \t -180.51916289603517\n",
            "57     \t [-4.98279035 -0.94658226  0.71207746  4.91634023  3.19920625 -4.49243244\n",
            "  1.45021648 -2.92869979]. \t  -380.42945674746494 \t -180.51916289603517\n",
            "58     \t [-3.7002203  -3.53639538  2.96920475  4.18786206  3.73296785  4.13661773\n",
            "  3.5985261  -1.09529143]. \t  -407.8930191954427 \t -180.51916289603517\n",
            "59     \t [ 0.66768193  4.81327348 -2.98950175 -3.18512968  4.85446779  3.58431762\n",
            " -0.89507706 -3.35771093]. \t  -404.8877753906416 \t -180.51916289603517\n",
            "60     \t [ 3.60735668  3.98944168  4.24373512 -4.68386298 -4.76123928  3.6361193\n",
            " -0.89065409  2.26770074]. \t  -425.99422986699096 \t -180.51916289603517\n",
            "61     \t [ 1.80389593  4.28207573 -4.68145142 -3.72429221 -4.00528234  2.26810585\n",
            "  5.00729371 -4.05898658]. \t  -579.5469244072606 \t -180.51916289603517\n",
            "62     \t [-4.46664434  4.24054045 -3.31205249 -2.49158715 -0.79215676 -4.1930179\n",
            " -4.6436345   4.53861346]. \t  -538.0178220607838 \t -180.51916289603517\n",
            "63     \t [ 5.073687   -0.10875756  3.2241455  -5.05723637 -1.90530492 -4.21611253\n",
            "  3.0490301  -4.24304549]. \t  -493.1619936929178 \t -180.51916289603517\n",
            "64     \t [-2.8733783  -0.36654651 -4.46389974 -4.91875701  3.21633001 -1.09005506\n",
            "  0.37128799  5.02186364]. \t  -426.6520131600044 \t -180.51916289603517\n",
            "65     \t [-4.21033787  0.99864495  1.24715702 -0.5525815   3.95452187  5.0304965\n",
            " -4.38781839 -4.64712157]. \t  -563.1722650356618 \t -180.51916289603517\n",
            "66     \t [-3.871599    4.96183133 -4.13832787 -3.89763196  4.25588026 -2.79717908\n",
            "  2.60763155 -0.61508813]. \t  -364.5049434145085 \t -180.51916289603517\n",
            "67     \t [-2.87582586  2.56800254 -1.90396267  1.93041505  4.38661324 -2.83320784\n",
            "  3.65768789  4.61281542]. \t  -455.4904508538041 \t -180.51916289603517\n",
            "68     \t [-4.66209293 -5.12       -4.86197377  1.6470031  -5.12       -5.12\n",
            " -5.12        1.36461084]. \t  -642.6872560610368 \t -180.51916289603517\n",
            "69     \t [-4.87216964 -0.81424955  4.1851601  -4.08526562 -4.44297948  3.92313186\n",
            " -5.05470158  3.61490862]. \t  -618.8050034970271 \t -180.51916289603517\n",
            "70     \t [ 2.16970197 -3.90771259 -4.49166884  4.62797911  4.68388094 -4.98876578\n",
            "  4.31800882 -4.77940886]. \t  -753.7248720360345 \t -180.51916289603517\n",
            "71     \t [-4.75040175 -4.78498299 -0.69751648  3.58924281 -4.27229849  3.52354718\n",
            "  3.41244318 -2.37585398]. \t  -413.7745018753404 \t -180.51916289603517\n",
            "72     \t [ 2.91594066 -4.12190301 -3.39118197  1.06416192 -4.96826525  3.07985091\n",
            "  3.86361122  3.3150941 ]. \t  -454.2554072656625 \t -180.51916289603517\n",
            "73     \t [ 3.07146796 -3.29339482  4.99516458 -4.97031689  4.44484219  4.73137693\n",
            " -4.79831945  2.79339377]. \t  -661.4881752822587 \t -180.51916289603517\n",
            "74     \t [-2.67027406  0.24169695  4.02183328  4.96571973 -3.60509935  4.25820567\n",
            "  4.85022786  2.01633401]. \t  -525.3815116034853 \t -180.51916289603517\n",
            "75     \t [ 0.70828226 -3.78050201  4.72533157  4.42378306  2.5019428   3.971857\n",
            " -5.01685353  4.28400585]. \t  -623.3076173360197 \t -180.51916289603517\n",
            "76     \t [-1.95868951 -4.87930124  4.50039175 -1.27101221 -4.18822026 -1.34491002\n",
            " -4.89327681 -3.84299519]. \t  -502.99073525514166 \t -180.51916289603517\n",
            "77     \t [ 3.27922664 -4.97055446  4.7165529  -0.15251545  4.32784927 -1.70024567\n",
            " -2.71999352  2.58205102]. \t  -343.117669905067 \t -180.51916289603517\n",
            "78     \t [-4.38379774 -1.32270302 -0.59706414 -4.22944     5.10161609  4.98451408\n",
            "  2.42834244  0.12194633]. \t  -415.9404908724171 \t -180.51916289603517\n",
            "79     \t [ 5.06948689  0.89913792 -4.6196479   2.05843386  4.80673524  1.73973804\n",
            " -2.85670658 -3.80731894]. \t  -415.06311190911237 \t -180.51916289603517\n",
            "80     \t [-4.81503647 -0.63204076  4.93006022  4.62501007  0.13265812 -4.985711\n",
            " -5.08181077 -2.05674957]. \t  -546.3101123920505 \t -180.51916289603517\n",
            "81     \t [ 4.26524678  3.90234042 -1.99139426  4.5744624   0.16434933  2.76673171\n",
            " -2.56241491  4.26334723]. \t  -381.68333731343245 \t -180.51916289603517\n",
            "82     \t [-2.39100646 -2.45716768 -1.10729874  4.49738707 -4.51522765 -3.57554661\n",
            " -1.93274184 -3.22678279]. \t  -390.46561094535434 \t -180.51916289603517\n",
            "83     \t [ 5.00610762  4.44688661 -0.96698398  3.66189603 -4.5750887   4.2827217\n",
            "  4.66793841 -2.88538502]. \t  -554.8923500088598 \t -180.51916289603517\n",
            "84     \t [ 4.9084746  -4.36651305  0.39848413  2.22735887  3.37675488  4.23744326\n",
            "  4.92507312 -2.47951763]. \t  -466.2732730260141 \t -180.51916289603517\n",
            "85     \t [-3.01563797  5.02772589  5.07875667  0.54723638  2.36115048 -0.76855511\n",
            " -4.55357877 -3.43714743]. \t  -409.30594319348694 \t -180.51916289603517\n",
            "86     \t [-2.38238632  2.6354261  -0.03374852 -3.92243918 -3.72543517  4.82208105\n",
            " -3.23015383 -2.81295288]. \t  -426.36025707661673 \t -180.51916289603517\n",
            "87     \t [ 3.97204529  4.16769084  4.94683209 -4.67719334  3.82367013 -4.10337232\n",
            " -2.90233526  0.32752427]. \t  -445.3857108035907 \t -180.51916289603517\n",
            "88     \t [ 4.93125488 -5.08451271  2.23542936  4.58727356 -2.26390486  1.47797484\n",
            "  1.61866377  3.16417927]. \t  -312.35509565968437 \t -180.51916289603517\n",
            "89     \t [ 0.9878966   4.6736112  -4.81039061  3.56570166 -0.02278086  1.74648717\n",
            " -0.30346196 -4.27143342]. \t  -329.84738094551597 \t -180.51916289603517\n",
            "90     \t [ 1.63281423  4.23232303  2.57898496 -4.55500346  4.75379062  3.55235912\n",
            "  0.17709591  4.1471406 ]. \t  -467.954815150169 \t -180.51916289603517\n",
            "91     \t [-3.48603366 -3.94337236  3.96486088  4.94272779 -2.53739025 -2.74963249\n",
            "  4.67288529 -2.07772495]. \t  -453.0765453672152 \t -180.51916289603517\n",
            "92     \t [-4.83317842 -3.43113959  3.89323771  4.74085088 -1.98270081  3.82154706\n",
            " -4.71430785 -2.00365641]. \t  -477.25046526519696 \t -180.51916289603517\n",
            "93     \t [-1.40894043  1.46383468  3.30197162 -0.65706864 -3.55951    -3.47432765\n",
            " -4.79883473  4.90098316]. \t  -529.8418069966219 \t -180.51916289603517\n",
            "94     \t [ 3.54590851  3.00395829  1.87559367  4.57103718 -1.25281449  5.0786582\n",
            " -2.21361287 -3.62699126]. \t  -426.89751018465296 \t -180.51916289603517\n",
            "95     \t [-5.10417084 -4.78876116 -4.66471104 -1.04707016 -4.88517546  1.02658504\n",
            "  2.48866573  3.53205072]. \t  -410.3862536397909 \t -180.51916289603517\n",
            "96     \t [ 4.52160448 -5.11309196  0.688394   -3.87756003  3.85860037 -5.05677358\n",
            "  4.95959878 -4.04195978]. \t  -665.0484614557234 \t -180.51916289603517\n",
            "97     \t [ 4.97249523  1.29958396 -3.19757959  1.46867798 -5.04818421 -4.19164966\n",
            "  3.88949674  4.76670775]. \t  -587.9148479074973 \t -180.51916289603517\n",
            "98     \t [-4.60992847 -1.23219726 -4.69831546 -2.05616496 -4.61742776  2.25973389\n",
            "  2.19772287 -3.8972303 ]. \t  -399.9805344059411 \t -180.51916289603517\n",
            "99     \t [-3.08645235  4.4468406  -4.893456   -3.38305854  2.71217414  4.62214867\n",
            " -4.66198909  1.55878858]. \t  -503.2356092947565 \t -180.51916289603517\n",
            "100    \t [-4.80945496  4.14509577 -4.52127268  4.3672397   2.96209179 -1.0399465\n",
            " -3.65458383  3.43232919]. \t  -433.2091667782506 \t -180.51916289603517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkq32q1utdoO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b90503-ea77-4c54-ea7c-780414d1cabb"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 9\n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_loser_9 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_9 = dGPGO(surrogate_loser_9, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.76413244 -0.12207719  3.33307058 -4.79798899  3.15443162  0.67192238\n",
            " -2.07234561 -4.64183582]. \t  -383.4493461208245 \t -276.8057458851627\n",
            "init   \t [ 5.02402457 -5.05010449  2.76268061  2.52689511 -1.25502529 -0.05993009\n",
            "  4.39243154 -1.07055059]. \t  -276.8057458851627 \t -276.8057458851627\n",
            "init   \t [ 4.85331248  0.25000669 -4.16140192  3.20827815 -2.95232732  0.55650083\n",
            " -2.12716425  3.23729777]. \t  -277.7575521997104 \t -276.8057458851627\n",
            "init   \t [ 3.35915588 -2.85104771  1.48310734 -4.14534019 -0.90456843 -4.12809972\n",
            " -3.64532737 -2.94711116]. \t  -371.7161372605202 \t -276.8057458851627\n",
            "init   \t [-0.23904098 -4.32523431 -2.71315168 -5.05289725  4.08211648  0.53488053\n",
            " -3.40432253  4.3917126 ]. \t  -482.1410604064339 \t -276.8057458851627\n",
            "1      \t [-0.3457215  -2.41570642  0.505635   -1.25610202 -3.03382172  4.25433599\n",
            "  4.49717681  3.45593439]. \t  -410.6056418678222 \t -276.8057458851627\n",
            "2      \t [-1.35161709  4.3664537   3.4113556  -0.0757769   0.37398872 -4.76755028\n",
            "  1.94154011  3.49268818]. \t  -335.948278022135 \t -276.8057458851627\n",
            "3      \t [ 0.81711508  0.33401963  5.0650915   3.97129991  1.53230457  1.60569378\n",
            " -0.18323784  2.41800804]. \t  \u001b[92m-215.1596001270892\u001b[0m \t -215.1596001270892\n",
            "4      \t [-1.3419182  -4.98099454  2.81282579  3.21247481 -4.59772652  0.1103174\n",
            "  0.69095709 -4.7923155 ]. \t  -409.27802251836886 \t -215.1596001270892\n",
            "5      \t [-3.52610438  2.60047911 -2.01214225  0.72809513 -4.0107663  -1.51047699\n",
            "  3.81781734  0.44716805]. \t  -237.97528955990038 \t -215.1596001270892\n",
            "6      \t [ 4.12518634  3.19557651  1.66287169  3.82650865 -0.71435422  0.77049356\n",
            " -0.28518656 -4.91973347]. \t  -304.61769228244486 \t -215.1596001270892\n",
            "7      \t [-2.23790816 -0.46011833 -2.39554865  2.53065697  4.38763037 -0.14848842\n",
            "  0.84515017  3.58226126]. \t  -252.3140210243721 \t -215.1596001270892\n",
            "8      \t [ 0.7956411   1.76197212  5.05433518 -1.20533783 -2.57597512  4.1866622\n",
            "  5.01793143 -2.64606205]. \t  -459.9100931774228 \t -215.1596001270892\n",
            "9      \t [-4.86249768  0.46857535 -4.90416126 -5.00670057  4.21126596  4.49766511\n",
            " -2.28241394 -4.645285  ]. \t  -615.6466340589916 \t -215.1596001270892\n",
            "10     \t [ 3.42804641  4.24233712 -0.34390994 -3.32234534 -3.80280091  2.71517718\n",
            " -0.64780622  1.05682285]. \t  -220.66525022977282 \t -215.1596001270892\n",
            "11     \t [-3.7820612  -3.27616661 -3.99861302  4.16631422 -2.5278151  -3.04856967\n",
            "  4.81156379 -4.92976666]. \t  -597.3606624524207 \t -215.1596001270892\n",
            "12     \t [ 4.86537819 -4.56124212 -2.87810914  1.37232581  2.33728351 -3.6658278\n",
            " -0.87311764  1.85615356]. \t  -238.50843437027828 \t -215.1596001270892\n",
            "13     \t [-4.01741287  4.69215646 -4.87405369  3.88468691 -0.32433668  3.75379162\n",
            " -2.5003732  -0.34545711]. \t  -321.59410669786985 \t -215.1596001270892\n",
            "14     \t [ 3.02623357 -0.71461655 -4.3767601  -1.05086848 -3.41362989 -3.5739232\n",
            "  3.23816667 -2.70184432]. \t  -338.7665012562862 \t -215.1596001270892\n",
            "15     \t [-0.33361407 -1.17981279 -4.15972585 -0.08067727  4.33211474 -2.27479101\n",
            " -3.38603215 -4.65938743]. \t  -433.65096892136313 \t -215.1596001270892\n",
            "16     \t [-1.42452928  4.93633171 -3.16346043  2.56519148  5.06202491  0.27091926\n",
            "  1.93251969 -4.35163063]. \t  -413.30410475391915 \t -215.1596001270892\n",
            "17     \t [ 2.80256913 -1.47692834 -4.43161086 -2.74455277  4.42278224  1.12432781\n",
            "  4.22242405 -1.97869899]. \t  -362.7785759140599 \t -215.1596001270892\n",
            "18     \t [-3.28036773  0.43588521  4.36740483  3.1884057   4.67699512 -2.90577958\n",
            " -3.99721127 -2.1427701 ]. \t  -417.63554461807126 \t -215.1596001270892\n",
            "19     \t [-2.07972875 -0.35682558 -0.92728781  0.5197243  -4.70000537 -3.89554146\n",
            " -3.61371954  3.22850779]. \t  -384.54055694393685 \t -215.1596001270892\n",
            "20     \t [-4.92597471 -4.35804261  2.93577725 -0.90622571  3.6984092   2.24465228\n",
            "  4.39178596 -0.06177478]. \t  -325.05859422412584 \t -215.1596001270892\n",
            "21     \t [-4.75131045  4.49013326 -0.84395903 -2.78796759  1.65499738 -1.31700467\n",
            " -4.75332119  4.66422201]. \t  -452.425659674541 \t -215.1596001270892\n",
            "22     \t [-4.69739057  4.63977616 -3.46955173 -4.87083258  2.04906211 -4.84545567\n",
            " -5.05156713 -2.6866391 ]. \t  -594.370403320813 \t -215.1596001270892\n",
            "23     \t [-3.5753902  -1.84660188  4.41344412 -4.0087312  -3.94613081 -5.03089032\n",
            "  3.62321194 -0.52165871]. \t  -466.1080245743258 \t -215.1596001270892\n",
            "24     \t [ 3.85901116  3.75906354 -4.87059442 -4.94569808  4.37391411  4.40165693\n",
            " -1.4786638   2.23749993]. \t  -479.42037223824235 \t -215.1596001270892\n",
            "25     \t [-3.73875982 -1.39409943  3.99171915 -4.19380959 -3.24473476  3.02857305\n",
            " -3.76385929 -2.16780508]. \t  -380.4555070822014 \t -215.1596001270892\n",
            "26     \t [4.45199177 4.1369171  1.62419417 1.87963566 4.70791789 1.93669766\n",
            " 4.54951253 2.93701543]. \t  -423.31670616303126 \t -215.1596001270892\n",
            "27     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -215.1596001270892\n",
            "28     \t [-4.8674541   1.06661946  2.83419957  3.03796376  2.13799797 -2.80165628\n",
            "  4.70106602 -3.32550575]. \t  -400.1053244590762 \t -215.1596001270892\n",
            "29     \t [ 3.28543029 -4.49132334  1.28066734  4.25786842  0.44003471  1.79758317\n",
            " -5.07415009 -4.70770804]. \t  -506.46122208216616 \t -215.1596001270892\n",
            "30     \t [-4.26034594 -4.54161102 -1.57372269 -3.59934132  3.18179096 -3.85134594\n",
            "  3.06904802 -3.138039  ]. \t  -402.9817121682645 \t -215.1596001270892\n",
            "31     \t [ 2.0172223  -5.0394335  -4.26095239 -4.34374605 -5.08975548  4.34460561\n",
            " -1.14285371 -1.31456971]. \t  -450.5498226375551 \t -215.1596001270892\n",
            "32     \t [ 4.90713701 -3.66603338 -4.82484168 -1.08290572  2.1488922   4.67507251\n",
            " -3.51950639  1.27009031]. \t  -379.3276437098469 \t -215.1596001270892\n",
            "33     \t [-3.12508401 -2.04760938 -4.70465607  4.13969736  3.10905954  3.31772538\n",
            "  5.10565609 -2.27811146]. \t  -491.4687706202922 \t -215.1596001270892\n",
            "34     \t [-2.49258448  2.93631603  3.99584623  4.59617874 -0.91825304  5.00035657\n",
            " -3.26024731 -5.00235163]. \t  -584.6866796610559 \t -215.1596001270892\n",
            "35     \t [-1.02243468 -4.04852373  0.99012479  3.36615209  4.68444422  5.11172453\n",
            " -4.22056359  3.11995063]. \t  -551.1547113026895 \t -215.1596001270892\n",
            "36     \t [ 4.51438495  4.87825066 -2.93459083  4.02808873  4.36673971 -1.52213476\n",
            " -2.30875102  4.02392158]. \t  -434.80311714594416 \t -215.1596001270892\n",
            "37     \t [-1.57211395 -4.45816047  5.00649835 -2.10853491  3.27778731 -4.97136605\n",
            " -1.9687608   4.96428168]. \t  -561.4918922129687 \t -215.1596001270892\n",
            "38     \t [-5.09930328  3.59705329  2.23228703 -2.75377166  5.0565122   2.90516767\n",
            " -4.98698563 -1.53729463]. \t  -468.6407795396418 \t -215.1596001270892\n",
            "39     \t [-0.78519843  0.19677557  4.33682233 -4.58813415  5.01107277  4.61998335\n",
            "  1.28127317  2.6641793 ]. \t  -463.21612714384605 \t -215.1596001270892\n",
            "40     \t [-3.56367772  3.54793394 -4.2707231  -3.958517    4.59656994 -4.73804816\n",
            "  3.26097049  4.04705179]. \t  -601.0755276272299 \t -215.1596001270892\n",
            "41     \t [ 2.25577224 -1.34509628  4.64260525  1.09656894 -4.96662213 -3.19682176\n",
            "  3.07788113  5.11430625]. \t  -538.3954670290433 \t -215.1596001270892\n",
            "42     \t [ 4.56104879  3.48086988 -2.6269377  -2.10245306 -4.39256299 -2.86269512\n",
            " -3.96435058 -4.83968509]. \t  -526.4558482759198 \t -215.1596001270892\n",
            "43     \t [ 1.57370641 -3.87150413  0.69770889 -2.46067035 -4.30052346  2.39213276\n",
            " -4.60901949  5.09673766]. \t  -541.4552352727112 \t -215.1596001270892\n",
            "44     \t [ 2.4974563   4.6755272  -4.79730736 -2.85379405 -2.72739091 -3.42359153\n",
            " -2.96918766  4.90651475]. \t  -513.4002359936112 \t -215.1596001270892\n",
            "45     \t [ 3.8383228   3.61846804  4.29749789 -4.59989905  2.90389495 -3.27344196\n",
            " -4.64014192  1.51828248]. \t  -456.5745289522447 \t -215.1596001270892\n",
            "46     \t [-3.04038756  4.89335566  4.94298576  1.82967356 -0.60201394  3.22764382\n",
            "  4.34615525  4.7454665 ]. \t  -520.5212502165056 \t -215.1596001270892\n",
            "47     \t [ 4.67306872  2.55027165 -4.79229956 -2.32620922  1.5118172  -4.02341425\n",
            "  4.19394171  3.43686725]. \t  -451.5643559635667 \t -215.1596001270892\n",
            "48     \t [-4.89373734 -3.89184973 -0.40658987  3.98546596 -3.58437213 -4.75043867\n",
            "  4.72605469  3.68508725]. \t  -582.900073640577 \t -215.1596001270892\n",
            "49     \t [-2.85656868  3.72704096 -4.4639954  -3.30661774 -1.80717412  5.10210825\n",
            "  4.25782577 -3.82991725]. \t  -556.2264355669847 \t -215.1596001270892\n",
            "50     \t [-3.69973577 -0.60678157 -4.8547538  -2.48508746 -0.9470253   4.80724949\n",
            " -1.58607815  4.21795871]. \t  -412.9140378136958 \t -215.1596001270892\n",
            "51     \t [ 2.33184869 -2.5059905   2.1990503   4.94428135  4.82257505 -3.81727069\n",
            "  2.82528507 -0.45075332]. \t  -391.5051963408349 \t -215.1596001270892\n",
            "52     \t [-0.56495249  3.19365704  0.46261138 -4.56380634  3.00678332 -4.88577363\n",
            "  4.98006496 -4.49711875]. \t  -628.5017814361045 \t -215.1596001270892\n",
            "53     \t [ 1.46345351  3.91895517  3.19382071  5.00123145 -3.89327321 -1.40282975\n",
            " -4.92452889  3.97404902]. \t  -547.2057392854344 \t -215.1596001270892\n",
            "54     \t [-3.39931707  3.02573163  0.845798    4.01348117 -3.76296675 -3.93777845\n",
            " -3.14306843 -3.68163213]. \t  -437.86737089836254 \t -215.1596001270892\n",
            "55     \t [ 3.5228626  -2.60142355  4.6820963  -0.49957507 -3.51825176  3.34320903\n",
            " -1.78300048 -1.75790857]. \t  -268.6380806258051 \t -215.1596001270892\n",
            "56     \t [-4.37848061  4.77091957  2.18434887 -4.53741654 -4.49405832  0.7868325\n",
            "  0.60688752  4.84916744]. \t  -456.7521944596438 \t -215.1596001270892\n",
            "57     \t [ 4.94183279 -0.88209961  2.92294621 -3.84577913  0.54462445  1.44678763\n",
            " -0.74206089  4.73047205]. \t  -307.6845755233761 \t -215.1596001270892\n",
            "58     \t [-5.05338991  3.15555397  5.07223684 -3.01386577  4.13554004  2.29126639\n",
            "  4.64902811 -4.42956067]. \t  -584.2432643422442 \t -215.1596001270892\n",
            "59     \t [-5.10772308 -2.88386558 -4.70534939 -4.19234191 -2.81828784 -3.19495019\n",
            "  3.99193808  4.47001513]. \t  -551.8032992770267 \t -215.1596001270892\n",
            "60     \t [-2.56595724 -5.10333876 -3.68760868  4.09598259 -4.70016203  1.04762091\n",
            " -2.24935117 -0.20988791]. \t  -319.38809786768337 \t -215.1596001270892\n",
            "61     \t [-4.51350178 -0.02404704  3.01924404  2.62439881 -3.20170102  4.35550597\n",
            " -3.02280083  4.72820563]. \t  -483.1559778521982 \t -215.1596001270892\n",
            "62     \t [ 4.1899942   0.7253606   2.80634496 -4.34901279  2.22306145 -4.1779043\n",
            "  4.69156468  4.19406013]. \t  -542.1266059049262 \t -215.1596001270892\n",
            "63     \t [ 4.7947939   4.02236964 -3.40360985 -1.21186691  0.78013997  4.47437299\n",
            "  2.4124652  -3.2285247 ]. \t  -343.26719505082986 \t -215.1596001270892\n",
            "64     \t [ 4.89893004 -4.57965195 -4.84623626  3.48572519 -3.33202218  4.79146837\n",
            "  2.38821125 -4.56065756]. \t  -584.5876015211396 \t -215.1596001270892\n",
            "65     \t [-4.8524869  -3.7845035  -4.72050887  4.8374618   4.84940729  3.37791892\n",
            " -3.38784089 -1.57994562]. \t  -499.00318067739823 \t -215.1596001270892\n",
            "66     \t [ 4.87848648 -1.88213044  2.16743842 -0.09695157  4.58727693  4.45309438\n",
            "  2.46536385 -4.4160374 ]. \t  -467.7684954652906 \t -215.1596001270892\n",
            "67     \t [ 2.79781725 -2.45312844 -3.134766    4.99003133 -4.03158928 -4.0603559\n",
            " -1.99425154 -3.76388243]. \t  -470.30664725462003 \t -215.1596001270892\n",
            "68     \t [ 3.87194979 -4.18981782 -4.31922326 -3.4298232  -4.35450372 -2.34721459\n",
            " -1.42813198  3.48940789]. \t  -392.67263661558206 \t -215.1596001270892\n",
            "69     \t [-3.73083426 -3.51410455  0.9269929  -3.10726087 -4.87924577  4.22888285\n",
            "  4.30702923 -4.55212125]. \t  -601.7790799718272 \t -215.1596001270892\n",
            "70     \t [ 3.66392114  3.19346291 -4.61290324  1.8655768  -4.41898693  4.65857344\n",
            " -3.80540963 -2.89296212]. \t  -507.75176712056947 \t -215.1596001270892\n",
            "71     \t [-5.12       -5.12       -5.12       -0.2234052  -0.95680478 -3.59841602\n",
            " -5.12        0.0333311 ]. \t  -423.2646914375373 \t -215.1596001270892\n",
            "72     \t [ 3.65765988  4.03263269 -2.88746488  5.11753129 -4.03475285 -3.99650779\n",
            "  2.40623545  4.66850563]. \t  -567.7895369618374 \t -215.1596001270892\n",
            "73     \t [-1.19483931 -0.13035155 -5.12       -2.85899923 -5.12        1.74764059\n",
            " -5.12       -4.44760659]. \t  -603.9482511053623 \t -215.1596001270892\n",
            "74     \t [ 4.44205324  2.85101361  3.48912565 -2.31596088 -3.48582793 -2.00389065\n",
            "  2.28624752 -3.13470202]. \t  -294.012882955622 \t -215.1596001270892\n",
            "75     \t [-5.0403143  -4.99662653  3.89567791 -4.81494994  4.17763514  4.00802964\n",
            " -3.89703299  3.31266016]. \t  -591.3480008927907 \t -215.1596001270892\n",
            "76     \t [ 0.95002493  3.04088039 -2.46823937  2.17900753  5.11279382  4.97361775\n",
            " -4.76088836 -3.71923086]. \t  -605.1137424514488 \t -215.1596001270892\n",
            "77     \t [ 4.57045242  1.40206853  4.05252613  4.63194447 -0.22265301 -4.95625465\n",
            " -4.08268568 -1.24004819]. \t  -436.52381543478776 \t -215.1596001270892\n",
            "78     \t [-4.36904034 -4.15354976  2.39321873 -1.21048547 -4.72495976 -3.95045638\n",
            " -4.07786396 -3.33261237]. \t  -487.1521731393375 \t -215.1596001270892\n",
            "79     \t [ 4.93757155 -1.11936227 -4.56256271  5.02405675  4.20117445 -2.86467978\n",
            "  1.55470051 -4.10342043]. \t  -479.4128816524046 \t -215.1596001270892\n",
            "80     \t [-4.99306037 -4.87494749 -3.06268231  3.08537043  0.51210351  4.40696832\n",
            "  3.50646822  4.73791522]. \t  -522.1684191351305 \t -215.1596001270892\n",
            "81     \t [-1.82679457 -3.84027518  3.92363807  4.5592633  -0.50302006 -3.48841857\n",
            " -3.21262829  4.60845637]. \t  -478.59429492255543 \t -215.1596001270892\n",
            "82     \t [-2.15215873  3.21169292  0.40568234 -5.08485653 -4.81801765 -2.43361691\n",
            " -4.37924567 -2.23884087]. \t  -455.123761854174 \t -215.1596001270892\n",
            "83     \t [ 2.19587939  3.58470404 -2.45574836  2.94534773  0.20133369 -4.93950652\n",
            "  2.96887674 -5.0932835 ]. \t  -499.14140814285986 \t -215.1596001270892\n",
            "84     \t [ 1.7497044  -3.89554297  3.74915659  4.09867445  4.48993041  2.06222303\n",
            "  4.84978164  4.00633318]. \t  -562.1393062083291 \t -215.1596001270892\n",
            "85     \t [ 4.87477376  5.02090478  5.03614496 -0.07894825  3.07030107 -4.73926569\n",
            "  2.49337535 -2.42304225]. \t  -422.68068188766756 \t -215.1596001270892\n",
            "86     \t [ 4.07098763  0.36432648 -4.74851592  4.95454497 -0.6951275   2.60101774\n",
            "  4.68052319  1.92902737]. \t  -408.80170636890534 \t -215.1596001270892\n",
            "87     \t [ 1.74810329 -2.2068237   4.39789079 -0.72047757  2.42018271 -4.79045599\n",
            "  5.0480237  -4.63006465]. \t  -589.7517143957527 \t -215.1596001270892\n",
            "88     \t [-4.89178872 -4.2323776   3.45311062  3.33021271  1.44143927  2.83271883\n",
            " -4.5916795  -4.18835309]. \t  -486.34639203373854 \t -215.1596001270892\n",
            "89     \t [ 1.7709844  -3.35727584 -4.8725343   1.91194668 -4.75539056 -4.39976293\n",
            "  4.48669934  5.11005926]. \t  -690.5570418396853 \t -215.1596001270892\n",
            "90     \t [ 3.12258894  3.37546345 -4.98439733  4.49881654  1.36909273 -1.79101024\n",
            " -4.84428191 -4.30143564]. \t  -528.9347600118692 \t -215.1596001270892\n",
            "91     \t [ 3.29814024  0.5288641  -0.02499639  0.3745965   1.2371399   0.07758806\n",
            " -4.7198202   0.06190709]. \t  \u001b[92m-175.65656232870992\u001b[0m \t -175.65656232870992\n",
            "92     \t [ 0.23426021  4.81502299  4.51883988 -4.2539441  -0.86185419  4.96913008\n",
            " -4.82854    -0.62447836]. \t  -498.25853521017336 \t -175.65656232870992\n",
            "93     \t [-1.77353994 -4.21190593  2.19562439  4.46618985  3.61917921  3.78965259\n",
            "  2.8105315  -4.90802128]. \t  -532.5395387096512 \t -175.65656232870992\n",
            "94     \t [-5.11201931  4.68262126  4.25785347 -1.36957272 -3.03453211  2.06394368\n",
            "  0.18847429 -1.9472486 ]. \t  -234.06147311268296 \t -175.65656232870992\n",
            "95     \t [-2.80607267 -4.95079501 -2.35036346 -0.52846899  2.86476804  3.80809491\n",
            " -0.36033694 -4.32478495]. \t  -353.16754754838024 \t -175.65656232870992\n",
            "96     \t [ 1.11656045 -3.44406136 -4.98962471 -0.56713301  2.72062732  3.74184399\n",
            "  4.83959111  4.80234853]. \t  -570.4147983062993 \t -175.65656232870992\n",
            "97     \t [ 3.87583449  5.06280899  2.42621924 -1.72948564  4.03682519  4.72462872\n",
            " -5.06042594  4.51282841]. \t  -653.5030889197344 \t -175.65656232870992\n",
            "98     \t [-1.35997698 -3.61518917 -4.98452172  4.88787293  4.41797871 -4.40046808\n",
            " -3.79559382  3.87962007]. \t  -633.1250382269823 \t -175.65656232870992\n",
            "99     \t [-4.67593671  3.33085226 -4.66700709  3.24107965  2.68704998 -3.32730995\n",
            "  4.59686298  0.72463536]. \t  -406.06074551437223 \t -175.65656232870992\n",
            "100    \t [-1.48460938  4.35975709  0.80449963 -3.699248    0.89030009  5.03509595\n",
            "  4.86139161  2.10569476]. \t  -453.8782510624534 \t -175.65656232870992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5Aur-aRtdq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16a0e5b-35fa-44a2-e4f4-ee4e46fe65a5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 10\n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_loser_10 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_10 = dGPGO(surrogate_loser_10, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.57275736 -3.9423289   4.61089653 -0.18236005  3.81413924 -2.94571335\n",
            " -4.70313344 -1.05272872]. \t  -385.9754059539706 \t -352.16802530271787\n",
            "init   \t [-2.7327263   3.49942502 -2.99947679  2.48288802 -1.10434173 -3.25369324\n",
            "  2.49384361 -4.40747949]. \t  -352.16802530271787 \t -352.16802530271787\n",
            "init   \t [ 3.94585297  4.63507865  4.41490877 -0.86598704 -4.82322781  4.93596144\n",
            " -1.64211012  2.11647687]. \t  -437.2230551014739 \t -352.16802530271787\n",
            "init   \t [-1.41437883 -4.7605156   3.63579651  1.61027592  2.72059386  0.55385332\n",
            "  3.94335167  4.13898358]. \t  -382.1028014270721 \t -352.16802530271787\n",
            "init   \t [-5.01328179 -4.35653902 -2.61499689 -3.75495933  2.02675303 -1.04238199\n",
            "  3.92317124 -3.26648309]. \t  -360.16156644546146 \t -352.16802530271787\n",
            "1      \t [-0.69120848 -4.9342136   1.9603237  -0.31036772 -3.80700478  4.00729141\n",
            "  4.28240511 -4.37124102]. \t  -511.13628956580146 \t -352.16802530271787\n",
            "2      \t [-3.86842882  1.46678813  4.99960309 -2.4831348   2.4968462   3.15039041\n",
            "  5.02108701 -1.33889878]. \t  -400.46096949127036 \t -352.16802530271787\n",
            "3      \t [ 5.08639972  0.59547281 -4.35771525 -0.91677037 -3.63032957  1.36330471\n",
            "  0.06774278 -0.91962543]. \t  \u001b[92m-170.7574293822782\u001b[0m \t -170.7574293822782\n",
            "4      \t [-2.83991747  4.95529941  0.81210737 -5.05728904 -2.46957144  3.87928032\n",
            "  0.68677571  3.8274095 ]. \t  -402.7393046428011 \t -170.7574293822782\n",
            "5      \t [-4.78297483  0.9384769  -3.4383774   1.8608363   1.81977827  2.42169935\n",
            " -0.95936305  2.02437623]. \t  \u001b[92m-164.9296567609566\u001b[0m \t -164.9296567609566\n",
            "6      \t [ 0.12341074  4.54186746  3.11452712  2.81407137  1.9287183   1.45984277\n",
            " -4.13199064  3.21849354]. \t  -335.81882752614865 \t -164.9296567609566\n",
            "7      \t [-4.20538034  4.05601237 -1.05842507 -1.02069306  0.01430092 -4.79109053\n",
            " -3.54033371  4.116951  ]. \t  -419.1760821638135 \t -164.9296567609566\n",
            "8      \t [-0.91570811  5.08597627 -1.60534636 -2.0596013   1.48205846  0.4870594\n",
            " -2.64369806 -2.85935751]. \t  -204.00929831470415 \t -164.9296567609566\n",
            "9      \t [ 0.44337387 -2.12434014  1.33594503 -3.46985162 -2.48584606  1.69932882\n",
            " -4.18127858 -4.91228807]. \t  -426.38564089718784 \t -164.9296567609566\n",
            "10     \t [-0.65116081 -1.60635209 -4.70549384 -3.22611311 -0.03412151 -2.98445577\n",
            " -3.93598434  0.31416276]. \t  -276.3220583911353 \t -164.9296567609566\n",
            "11     \t [ 1.42052082  1.29703507 -3.81453734 -3.5177973   1.73163558  2.21093581\n",
            "  2.05625557  4.63066838]. \t  -343.9984138154799 \t -164.9296567609566\n",
            "12     \t [-1.60941423 -2.82491091 -0.98142108 -0.01883512 -3.65427762 -4.17298134\n",
            "  3.47763998  4.68649525]. \t  -453.0565633245601 \t -164.9296567609566\n",
            "13     \t [ 2.99380686 -1.50053952 -2.7035087  -4.29804816  4.31467208  1.10011192\n",
            "  4.62027106 -2.66535793]. \t  -415.89071625609967 \t -164.9296567609566\n",
            "14     \t [ 2.02806307 -4.78319908  0.68412069  4.6111561  -3.13484279  4.8311571\n",
            " -3.01463496 -1.11576249]. \t  -399.07837772597856 \t -164.9296567609566\n",
            "15     \t [-1.99262461 -2.08960012  3.25436987 -1.79854657 -4.70001473 -3.87339678\n",
            " -3.54777849  2.39136055]. \t  -391.74113438840425 \t -164.9296567609566\n",
            "16     \t [ 1.74285833 -3.58288483 -1.67449356  3.94202292  4.67125838  4.57693891\n",
            " -1.66537555 -5.03651194]. \t  -556.4210907963367 \t -164.9296567609566\n",
            "17     \t [ 1.91504342  4.39092188  0.28741722  4.53015261  0.58630604 -1.11371379\n",
            "  4.72409298  1.56795205]. \t  -309.61283245614425 \t -164.9296567609566\n",
            "18     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -164.9296567609566\n",
            "19     \t [-3.28986647  3.10911714 -3.26390187  2.60047567 -4.52223851  3.7419\n",
            "  4.49561109  2.67039795]. \t  -473.95143567504294 \t -164.9296567609566\n",
            "20     \t [-2.69188145  4.27423623  4.45650448  1.33998599 -4.74747398 -2.22928774\n",
            " -3.25792358 -2.97792105]. \t  -398.30142386704057 \t -164.9296567609566\n",
            "21     \t [-0.74999857  4.56913275  2.81802739 -4.87014588  4.24577422 -0.87689028\n",
            "  0.52922959  3.68742668]. \t  -366.49768909696553 \t -164.9296567609566\n",
            "22     \t [ 3.23194654 -3.74126463 -0.34501769  4.88418946  1.41302239 -1.10846456\n",
            " -1.45233236  3.10603409]. \t  -243.51772956650711 \t -164.9296567609566\n",
            "23     \t [-4.74432089 -2.60738194  1.1748746   2.46250407  1.42620077 -4.88127701\n",
            "  1.00603728 -0.81798933]. \t  -230.0712224150592 \t -164.9296567609566\n",
            "24     \t [ 3.77755537 -4.19561354 -2.55604946  2.78570997 -2.02274327 -5.08893234\n",
            "  4.60915514 -3.56419073]. \t  -526.2958250274548 \t -164.9296567609566\n",
            "25     \t [ 4.9712413  -1.16638858  4.43599367  2.39421648 -2.72681507  1.41182924\n",
            "  3.65407669  0.96408155]. \t  -259.4361086548463 \t -164.9296567609566\n",
            "26     \t [ 3.73939414  0.20456631  1.08307937 -2.3238558  -1.12109962 -4.54351089\n",
            "  0.21174279 -4.48071971]. \t  -330.2610760317743 \t -164.9296567609566\n",
            "27     \t [ 3.19225917 -5.00474448  3.51592727  3.11211588  4.34287793 -3.89939365\n",
            "  2.653807   -3.6056679 ]. \t  -474.9518860303458 \t -164.9296567609566\n",
            "28     \t [-4.56000519 -4.79898054 -0.89750564  1.61955305 -4.79183665  2.75269966\n",
            " -4.22367396  4.36725213]. \t  -517.4941394071767 \t -164.9296567609566\n",
            "29     \t [ 1.78467075 -3.74457715 -4.63029271  2.95238565  4.30881267  3.67790078\n",
            "  3.5189734   3.70886495]. \t  -501.1326298439502 \t -164.9296567609566\n",
            "30     \t [ 3.00004406  1.99933581  3.67365671 -4.21466616  0.23611045  3.85742467\n",
            "  1.92087046 -4.53796333]. \t  -408.666040188667 \t -164.9296567609566\n",
            "31     \t [ 3.7886124   1.74411675  2.56836952  3.03186856  0.56925454  3.61086139\n",
            " -4.58568272 -5.04040046]. \t  -507.2906136391273 \t -164.9296567609566\n",
            "32     \t [-3.96380958 -3.52805202 -4.9443913   4.08614082 -1.96712467  4.72790195\n",
            " -0.78515986 -4.10835311]. \t  -473.54338444402185 \t -164.9296567609566\n",
            "33     \t [ 1.95501753  5.04494152 -4.2516212   4.56701904  1.3606753  -4.47485635\n",
            " -1.65925342  4.20316154]. \t  -482.39207469922826 \t -164.9296567609566\n",
            "34     \t [ 5.01830868  1.61380025  1.25435128  2.69172909 -4.34279457 -1.37050802\n",
            " -2.22509129  4.78957914]. \t  -387.8407799399921 \t -164.9296567609566\n",
            "35     \t [ 0.40343795 -4.91016615 -2.20275049  3.06424478 -3.61668931 -3.85600857\n",
            " -4.9946751  -3.52733295]. \t  -529.276036626093 \t -164.9296567609566\n",
            "36     \t [-2.06285692  4.02920248 -2.7925518  -3.06083195 -4.76765896  4.7805904\n",
            "  3.03606969 -3.66136967]. \t  -520.1403135585301 \t -164.9296567609566\n",
            "37     \t [ 4.01139259 -0.96217271  3.01491578 -3.5676155   0.66311124 -3.65098409\n",
            "  4.60728893  2.55431008]. \t  -379.0859663500136 \t -164.9296567609566\n",
            "38     \t [ 0.50571972  4.3670331  -0.12078505  4.05226057  1.02718992 -4.9311036\n",
            " -4.77285042 -4.32381862]. \t  -564.318998041207 \t -164.9296567609566\n",
            "39     \t [ 4.58718608 -0.91988951  4.86713593  5.06075614 -4.32873737 -4.34145707\n",
            "  1.29430588 -4.09500938]. \t  -548.9054589497778 \t -164.9296567609566\n",
            "40     \t [-4.66830995 -3.21814131  2.66487204 -0.99010415  3.3318051   4.33986223\n",
            " -3.40501789 -0.71749223]. \t  -321.52027825766896 \t -164.9296567609566\n",
            "41     \t [ 4.14013026  0.48979685 -5.08780122  1.66391074  4.24270768  2.08662326\n",
            " -4.72017725  4.84453893]. \t  -566.1958339774443 \t -164.9296567609566\n",
            "42     \t [-4.97288499  4.09407438 -4.16220019 -0.98144936  0.65027037 -3.62468336\n",
            "  4.47057278  4.90484816]. \t  -527.3838428514438 \t -164.9296567609566\n",
            "43     \t [ 4.8602786  -4.29786527 -2.87190641 -4.31566735 -4.47827253 -4.03284941\n",
            " -0.09682835  3.48748381]. \t  -455.0329255526204 \t -164.9296567609566\n",
            "44     \t [-3.64698256  0.56690283  4.79185484  3.60573525 -0.34742397  3.0579379\n",
            "  1.06892692 -5.09536704]. \t  -407.2439420821917 \t -164.9296567609566\n",
            "45     \t [-0.78922005  4.77614772  3.37828843 -4.84461839 -4.69614351 -4.7867719\n",
            "  1.78774744  1.42368443]. \t  -460.701086057514 \t -164.9296567609566\n",
            "46     \t [-3.79382008 -3.51279097 -4.51236892 -4.13047788 -3.64617855  3.56900135\n",
            " -4.92058571 -1.13026336]. \t  -491.0051039211172 \t -164.9296567609566\n",
            "47     \t [-1.93433162  4.87134992 -4.60131636  4.08599251 -4.6663398   0.55488158\n",
            " -3.52156616  0.01652506]. \t  -379.03259385746844 \t -164.9296567609566\n",
            "48     \t [ 4.70159964 -3.70014541  5.065524   -4.34484637  1.8215861   4.93289159\n",
            "  2.77427167  3.71495239]. \t  -528.8510009808648 \t -164.9296567609566\n",
            "49     \t [ 4.18525776 -3.8182224  -1.05323788 -5.06156923  4.37743139  0.84148478\n",
            " -5.09233623  1.19187424]. \t  -445.4257291124625 \t -164.9296567609566\n",
            "50     \t [ 2.24429408  4.56257702 -4.54984175 -1.70256298 -4.02449888  4.77606897\n",
            " -4.13870299  4.08685305]. \t  -591.7380815505364 \t -164.9296567609566\n",
            "51     \t [ 0.12002096 -4.65765328 -1.74889937 -3.61881159  3.90790034 -4.44213519\n",
            "  1.28290065  1.62134139]. \t  -332.26564709434564 \t -164.9296567609566\n",
            "52     \t [-2.83535768 -1.52017641  3.75679825  1.59801881 -4.92813529 -4.54141413\n",
            "  4.78296137 -4.51357878]. \t  -633.5118062770609 \t -164.9296567609566\n",
            "53     \t [-2.19250156  4.4192478   4.39757247 -2.56358594 -1.05084538  4.88244658\n",
            " -4.25104821 -4.91103012]. \t  -596.1670859393462 \t -164.9296567609566\n",
            "54     \t [ 2.54177346  4.68327837 -2.22650556  1.97892932  4.00503065  4.07986562\n",
            "  3.39229957 -4.96196872]. \t  -538.4595471317298 \t -164.9296567609566\n",
            "55     \t [-4.04952141  0.6314348   4.54533072 -3.6380375   2.11583549 -2.13978734\n",
            " -2.51249727 -3.61511616]. \t  -330.71435971675083 \t -164.9296567609566\n",
            "56     \t [-1.67747922 -4.60329892  1.84726459  4.73676407  3.31202317  4.21433318\n",
            " -4.22328151  4.54043983]. \t  -596.3681629941359 \t -164.9296567609566\n",
            "57     \t [-4.99418608 -4.93518269 -4.53590799  3.82462307  2.45854959 -1.7302887\n",
            " -4.2726901  -4.23844027]. \t  -513.580197488156 \t -164.9296567609566\n",
            "58     \t [-4.49443427 -4.84973788 -0.45062436 -3.85281247  0.50226704  3.86113561\n",
            "  1.7740285   5.00113037]. \t  -440.0579463090262 \t -164.9296567609566\n",
            "59     \t [ 0.74570396 -4.48131008  0.17974843  1.37462165 -5.05250997  3.59365916\n",
            "  3.25941567  4.00352951]. \t  -456.0937456626276 \t -164.9296567609566\n",
            "60     \t [ 3.51664278  5.00398539 -4.3648564   0.13761564  1.36181689 -5.11229729\n",
            "  3.21019339 -0.69541746]. \t  -361.77064456647315 \t -164.9296567609566\n",
            "61     \t [ 4.73262381  3.95897614  1.1625609  -3.21011372  2.00248015  2.77219621\n",
            " -3.19674337  1.02699326]. \t  -245.15063943073943 \t -164.9296567609566\n",
            "62     \t [-4.73443386  3.76342656  4.95573347  2.95964527 -1.10430115  0.3591647\n",
            "  3.77861038  3.54658025]. \t  -366.90003325777525 \t -164.9296567609566\n",
            "63     \t [ 5.10131314  4.10417407 -1.7819537   3.6125857  -4.39207839 -2.58577794\n",
            "  5.04711469 -4.55113482]. \t  -602.0265047890817 \t -164.9296567609566\n",
            "64     \t [ 4.71510634 -3.74424238 -4.26015977 -3.98239918  2.2535702   3.68676972\n",
            " -2.07354688 -4.3918734 ]. \t  -459.50793731857175 \t -164.9296567609566\n",
            "65     \t [-1.39370591 -4.75275483  0.06105716 -4.98927847  3.32611169 -4.2360773\n",
            " -4.86941385 -4.46489937]. \t  -635.144705835031 \t -164.9296567609566\n",
            "66     \t [ 4.05386776 -0.73057196 -4.61742528  4.0138486  -4.72746849  4.97456477\n",
            "  3.63417102 -4.44446144]. \t  -656.6059376812042 \t -164.9296567609566\n",
            "67     \t [-1.27069071 -1.63297419  4.60226039 -4.6357832  -4.08505429  0.53041154\n",
            "  4.67431281  1.16039505]. \t  -405.2951061421491 \t -164.9296567609566\n",
            "68     \t [ 5.08872416  4.90081005 -4.50424174 -4.70202633  2.2433538  -5.08306735\n",
            " -4.40224188 -3.81702369]. \t  -655.6358959961112 \t -164.9296567609566\n",
            "69     \t [-4.91733131  2.50486023 -2.27758841 -1.4776716   3.60315304  3.89016787\n",
            "  2.0138935  -4.6296553 ]. \t  -416.59910749902076 \t -164.9296567609566\n",
            "70     \t [ 4.11248591  4.71319727  2.00601901 -5.04774536 -4.66146735  1.36287264\n",
            "  4.64715555  0.49544858]. \t  -448.25932423144013 \t -164.9296567609566\n",
            "71     \t [-4.55792062  4.44149134  2.85712451  2.325759    4.77044567 -4.8440629\n",
            "  3.65058167  5.04923737]. \t  -658.1754733618596 \t -164.9296567609566\n",
            "72     \t [-0.12073686 -2.58615889  3.04277198 -4.68580671 -4.31333432  4.64958135\n",
            " -2.00366813  3.22680236]. \t  -463.1302701578304 \t -164.9296567609566\n",
            "73     \t [-0.7776191   4.59899902  4.17257247 -0.26311106  0.92335314 -4.86137502\n",
            "  3.60700084 -4.04755804]. \t  -463.6099698647851 \t -164.9296567609566\n",
            "74     \t [-4.92608198 -1.58101527  5.05852303 -0.69382425  3.1092836  -1.56917232\n",
            " -3.11696062  4.5508084 ]. \t  -404.7560304563507 \t -164.9296567609566\n",
            "75     \t [-2.51768383  1.36664952 -4.29659027  1.5117285  -3.23172711 -5.12\n",
            " -5.12       -5.12      ]. \t  -677.3202504788655 \t -164.9296567609566\n",
            "76     \t [ 5.10393082 -0.44440164  1.10414524 -1.60415468  1.31277324 -3.70785204\n",
            " -4.15484407  4.14025501]. \t  -389.47441975435015 \t -164.9296567609566\n",
            "77     \t [-5.12       -5.12        1.39184025 -2.87397273 -5.12       -5.12\n",
            "  0.15903238 -5.12      ]. \t  -615.7443740226106 \t -164.9296567609566\n",
            "78     \t [-0.1301514  -2.94864323 -4.81891753 -3.73145216 -2.66973257  3.21189364\n",
            "  4.94701531  0.79248819]. \t  -416.636720251597 \t -164.9296567609566\n",
            "79     \t [1.57345734 2.37757458 4.98090192 1.5484961  4.39892363 5.03075243\n",
            " 4.31323313 3.64115111]. \t  -582.696179613979 \t -164.9296567609566\n",
            "80     \t [-0.21733048 -2.47376619 -4.76833984  4.9652401   3.41200917 -0.18195604\n",
            "  2.50749215 -2.41372938]. \t  -328.14091770427007 \t -164.9296567609566\n",
            "81     \t [ 1.10509591 -3.53540926 -2.99204416 -5.00520915 -1.16229069  2.39711203\n",
            " -4.76807561  4.90126339]. \t  -545.8372865401344 \t -164.9296567609566\n",
            "82     \t [-4.35061169 -4.80734966 -5.07560401  4.41783998  1.58470777 -2.27432094\n",
            " -0.72113279  4.39839469]. \t  -422.5024946036061 \t -164.9296567609566\n",
            "83     \t [-5.09382952  5.11570076 -1.68074362  4.68393664  0.89349071  4.52196354\n",
            "  4.54490528 -2.08250374]. \t  -480.48791154508234 \t -164.9296567609566\n",
            "84     \t [ 4.55696825 -2.06920744  3.66961325  2.22440303  4.44845546  4.95054624\n",
            "  3.1538199  -4.60266415]. \t  -574.6126844674598 \t -164.9296567609566\n",
            "85     \t [-4.575967   -3.37800052  4.71944532  4.91242903 -3.0692675  -1.27375191\n",
            " -4.90935327 -4.61616513]. \t  -603.1293465657444 \t -164.9296567609566\n",
            "86     \t [-4.86497556  3.66455743  1.89174512 -4.78939837  2.72948255 -4.93757678\n",
            "  4.858316    0.86853342]. \t  -507.80119998281685 \t -164.9296567609566\n",
            "87     \t [ 1.36028945  2.83575425  3.74323117 -3.42619918 -0.90654452 -3.50740705\n",
            " -4.7852403  -0.7437341 ]. \t  -349.5594301932032 \t -164.9296567609566\n",
            "88     \t [ 4.43044843 -1.54021288 -4.32512478  0.43155879  4.66187314 -3.13514155\n",
            " -4.39875683 -4.3983716 ]. \t  -539.0872638836513 \t -164.9296567609566\n",
            "89     \t [-3.00721135 -3.92100198 -2.43377887  4.91445965 -4.08012234 -3.28503946\n",
            "  1.87796921 -4.60153656]. \t  -496.23571155323145 \t -164.9296567609566\n",
            "90     \t [ 1.26090574  4.51186256  2.05067098  2.6415075  -4.39393056  4.04852659\n",
            "  3.47830052 -3.49274851]. \t  -459.99058549261247 \t -164.9296567609566\n",
            "91     \t [-0.40471885 -3.36212816 -4.54524323 -1.6547675  -4.9890206  -4.25542541\n",
            "  1.13492281 -1.89991074]. \t  -366.69947905759636 \t -164.9296567609566\n",
            "92     \t [ 4.66116267 -4.97941518  4.07509121 -3.86547238 -4.42242397 -2.52943742\n",
            " -4.47672536 -0.87822785]. \t  -463.5374545884846 \t -164.9296567609566\n",
            "93     \t [ 0.86230613 -3.21595501 -4.76973083  4.18408254 -4.92454978  0.26849213\n",
            " -2.03161193  4.33771934]. \t  -460.812571118098 \t -164.9296567609566\n",
            "94     \t [-4.58115359 -0.65224914  4.47159564  2.8868637  -4.57559879  4.94849607\n",
            " -0.06073123  3.17498758]. \t  -447.4356451477212 \t -164.9296567609566\n",
            "95     \t [ 4.04476912  0.56396418  4.10318437 -3.58218461  4.89654373 -4.09472281\n",
            "  4.90047942 -4.71229518]. \t  -685.0627490485396 \t -164.9296567609566\n",
            "96     \t [-0.0138998   2.07633557 -4.86896933 -3.78495926  4.95007692 -1.95644341\n",
            " -3.56381831  4.81998321]. \t  -557.2926294819166 \t -164.9296567609566\n",
            "97     \t [ 4.27194214  3.54929062 -4.7321856   5.01530692 -4.98294837 -4.29138231\n",
            "  3.19864322  4.28335751]. \t  -664.2794596548159 \t -164.9296567609566\n",
            "98     \t [-3.91621882  3.25071184 -2.6618189  -4.82444735 -4.96688485 -2.4819023\n",
            " -1.76635195 -0.42176429]. \t  -334.39986799938714 \t -164.9296567609566\n",
            "99     \t [ 1.98568367 -2.37888949  3.37160058  0.97417584  4.96292241 -4.49372534\n",
            " -0.01235119  5.07386095]. \t  -503.4283014785846 \t -164.9296567609566\n",
            "100    \t [-4.11023395  2.235725   -4.71188101 -1.04161491  3.51292698 -3.67805363\n",
            " -2.64240959 -4.54763912]. \t  -455.032492123029 \t -164.9296567609566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMu7U9NNtdtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b758f1b5-017d-450d-eea0-4289831d4ea2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 11\n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_loser_11 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_11 = dGPGO(surrogate_loser_11, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.92580518  3.28957798  1.4939506  -0.78143474 -3.04833558 -0.08287467\n",
            " -3.70116269 -0.4861846 ]. \t  -199.328627991057 \t -199.328627991057\n",
            "init   \t [-3.95535741 -5.09005324  0.23988403 -3.17469533 -3.66878933 -1.68072836\n",
            "  0.85700801  4.66360642]. \t  -371.33373135563875 \t -199.328627991057\n",
            "init   \t [ 4.97602467 -3.51277821  1.50799121 -0.08432225  3.26374507  1.8591538\n",
            "  1.97393801 -3.23583363]. \t  -241.32944618066992 \t -199.328627991057\n",
            "init   \t [ 3.9633366   0.66475842  1.73406641 -4.83201623 -0.61553705  4.24424807\n",
            " -3.088857    4.67305641]. \t  -470.469518894517 \t -199.328627991057\n",
            "init   \t [-2.63594969  1.40305335 -1.97175977  1.69687477 -1.50561156  4.86926807\n",
            " -1.76401693  2.83643699]. \t  -273.80464224498314 \t -199.328627991057\n",
            "1      \t [ 2.27211609  2.02425273 -1.2017534   4.16140797 -1.81853031 -4.31745003\n",
            "  2.0394904   3.25603062]. \t  -329.2676500747198 \t -199.328627991057\n",
            "2      \t [ 0.91195965  4.40131628  0.25601848  2.01131675  4.61880194 -3.48112843\n",
            "  3.42075462 -3.42959209]. \t  -411.3369948951634 \t -199.328627991057\n",
            "3      \t [ 3.4506638  -2.28972411 -4.72154565 -2.03612565 -4.39132286 -1.00741573\n",
            "  4.50346009  0.21594287]. \t  -350.70398565509174 \t -199.328627991057\n",
            "4      \t [-3.38138851 -5.02243145  1.53786308  2.1320223   4.42505211 -2.72288588\n",
            " -1.18446707 -2.93627121]. \t  -308.3448893098524 \t -199.328627991057\n",
            "5      \t [-0.10747918  2.37788089 -4.82420832  1.36302762  4.46107597 -2.00232408\n",
            " -4.31877147  4.4681394 ]. \t  -502.4089925694798 \t -199.328627991057\n",
            "6      \t [-4.68089968 -1.55369369 -3.77643376  4.20342398  1.64474619  2.87231187\n",
            "  1.06318932 -2.79587634]. \t  -273.6731982115635 \t -199.328627991057\n",
            "7      \t [ 3.11322085 -4.48047435 -3.83272114  3.76752102 -3.36685429  4.28679607\n",
            "  1.56134023 -1.11226498]. \t  -344.58737025711645 \t -199.328627991057\n",
            "8      \t [-3.33910255  0.1879076   4.14514181 -4.35915362  1.98010538  4.94389058\n",
            " -5.04313587 -0.54675167]. \t  -485.45615371360304 \t -199.328627991057\n",
            "9      \t [-2.72335001  1.80846448  4.68225647 -0.71121565 -2.78382979 -3.6860239\n",
            " -3.2612813  -2.13435768]. \t  -312.9163374954662 \t -199.328627991057\n",
            "10     \t [-4.32661955  1.33169156  4.91442928  3.31861383 -4.59670139  4.74890091\n",
            "  0.53763197 -3.66295502]. \t  -489.09600808544707 \t -199.328627991057\n",
            "11     \t [ 2.73014082 -4.33539565  1.53521602  0.37490252  1.11809835 -3.89108725\n",
            "  4.53185729  2.81630051]. \t  -356.9884333775324 \t -199.328627991057\n",
            "12     \t [ 0.39771306  4.39811339  4.38376536 -2.10001545  1.35799499 -1.02498673\n",
            "  2.76745678  2.56230497]. \t  -235.79674648457183 \t -199.328627991057\n",
            "13     \t [ 0.20475016 -3.14437524  0.86111427  4.63800503 -4.54627501  1.16215327\n",
            " -4.2603917  -4.77747914]. \t  -529.1827311637971 \t -199.328627991057\n",
            "14     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -199.328627991057\n",
            "15     \t [ 4.70162927  5.06830333  2.62406035  0.94371355 -4.15332766  4.33644674\n",
            "  4.84130568 -4.04657921]. \t  -591.8455608576407 \t -199.328627991057\n",
            "16     \t [-0.75501182  2.48474844 -4.39096584  0.49099478 -2.94496989 -4.60948524\n",
            " -4.45246272 -2.49695418]. \t  -431.2216140122552 \t -199.328627991057\n",
            "17     \t [ 3.10906224 -2.32268673  3.77447827 -4.93681369 -3.81599142  0.17154071\n",
            "  2.32171698  0.81884469]. \t  -276.76674256138216 \t -199.328627991057\n",
            "18     \t [-4.42150285 -3.71026662 -4.12703005 -2.00737679 -4.72365545  2.40941386\n",
            "  2.81646552 -3.88113933]. \t  -436.7267622590048 \t -199.328627991057\n",
            "19     \t [-2.16676392  3.17464234 -4.59474313 -2.12477327  4.16809712  1.99095939\n",
            " -1.374751   -1.63825799]. \t  -251.594593003222 \t -199.328627991057\n",
            "20     \t [ 0.58068745  1.49492322  3.40703585  4.96159875  3.90126186 -0.96404033\n",
            " -4.61008247  1.43700838]. \t  -385.0657478697283 \t -199.328627991057\n",
            "21     \t [ 0.33111923 -2.63411052 -2.52915776 -5.10677829  1.00390686 -1.68168367\n",
            " -2.58888188  1.2018014 ]. \t  -217.9716542711628 \t -199.328627991057\n",
            "22     \t [ 4.17109659  3.09124011 -4.27464474  4.46764442  4.36249458  2.26920503\n",
            "  4.06423703  4.81605764]. \t  -598.4007185191645 \t -199.328627991057\n",
            "23     \t [ 5.09827643 -4.84625138  1.17712716  5.11277683 -1.29107671 -2.6608193\n",
            " -4.2980034   0.98988251]. \t  -369.64648347859026 \t -199.328627991057\n",
            "24     \t [-1.12886035 -4.27177426 -4.61840712 -4.12460173  5.08834478  4.99098554\n",
            " -0.44925863  3.16854203]. \t  -530.4548324657435 \t -199.328627991057\n",
            "25     \t [-1.50892764 -4.76916303 -3.51952957 -3.14992723  3.65441859  3.28455813\n",
            "  3.67218108 -5.02737727]. \t  -552.710510242246 \t -199.328627991057\n",
            "26     \t [ 1.37503239  4.95494644 -4.01076459 -4.49289161 -2.63853009  2.56794199\n",
            "  4.06042182 -0.85967241]. \t  -375.6933328819776 \t -199.328627991057\n",
            "27     \t [-5.05392985  2.11875326  4.50970929  4.62875134 -1.47122248  0.08459035\n",
            "  4.47105378  3.29299213]. \t  -418.7822687603419 \t -199.328627991057\n",
            "28     \t [ 2.6755183  -1.98647734 -1.74041653  4.79612643  4.03395413  4.7603749\n",
            " -1.94362367  2.01321538]. \t  -392.34799147758844 \t -199.328627991057\n",
            "29     \t [ 4.70754776 -4.53131077  3.32266977 -2.69963304 -3.55508263  4.97079414\n",
            " -1.81424267 -4.63570823]. \t  -531.9035279327605 \t -199.328627991057\n",
            "30     \t [-4.48063227  2.25979029 -4.94838719 -2.28817635 -4.16850886 -4.01986049\n",
            "  3.81549318 -4.75776111]. \t  -591.5262249988972 \t -199.328627991057\n",
            "31     \t [-3.73022874 -5.08821378 -3.55211942  4.72320692  2.43630643  3.44280007\n",
            "  3.51794071  4.80476935]. \t  -564.8948321306123 \t -199.328627991057\n",
            "32     \t [ 5.02765887  3.52536108 -3.73223507  4.14542379  2.28002402 -0.93210256\n",
            " -4.22900598 -4.07770956]. \t  -450.0791861534374 \t -199.328627991057\n",
            "33     \t [ 4.00582262  2.77306602 -3.41056683 -3.90677883  3.37979767 -3.90067082\n",
            " -1.67388254 -3.50379771]. \t  -393.6065120823698 \t -199.328627991057\n",
            "34     \t [-5.03700585  1.5746022  -0.27688172  0.53862893  2.27847491 -4.71823776\n",
            "  4.04099057  4.35829649]. \t  -457.51371152380773 \t -199.328627991057\n",
            "35     \t [-4.66805003  4.42539114  0.66936174 -1.67535896 -4.08558839  3.71451126\n",
            "  4.30202257  4.72022216]. \t  -547.5718019602925 \t -199.328627991057\n",
            "36     \t [-3.54870486  4.13637987  0.75240891 -4.978745    2.24861199  4.30183147\n",
            "  4.99689592 -1.48949542]. \t  -476.5099063361178 \t -199.328627991057\n",
            "37     \t [-3.8356487  -4.97812246  2.19809002 -4.052489   -1.16616292 -3.26998652\n",
            "  1.33616451 -4.58812768]. \t  -396.32230009024636 \t -199.328627991057\n",
            "38     \t [-4.29853795 -1.9859553   2.57301425 -1.49928897  3.11935808  4.30179609\n",
            "  3.10554289  4.68744847]. \t  -458.1909753391132 \t -199.328627991057\n",
            "39     \t [-4.88543937  3.14589007 -4.56851771 -1.44153714 -4.03278711 -1.97009944\n",
            " -1.35118475  3.62691797]. \t  -337.2077293017051 \t -199.328627991057\n",
            "40     \t [ 4.87969869 -0.50753287  4.6302514   5.02477134  1.84698656  4.43931\n",
            " -4.34477522 -5.11022416]. \t  -665.9938968721807 \t -199.328627991057\n",
            "41     \t [ 3.79245062  3.99604341 -2.67350106 -5.07589004 -4.86809403 -3.37731489\n",
            " -2.83953983  5.10783848]. \t  -622.9111189794868 \t -199.328627991057\n",
            "42     \t [-3.66166961 -5.12       -4.7638621  -0.38390239  0.13536143 -0.19013504\n",
            " -5.12       -5.12      ]. \t  -528.0338164312703 \t -199.328627991057\n",
            "43     \t [ 5.09277052  3.88384573  5.10662016  1.13952775 -3.36595953 -4.20474107\n",
            "  2.94153392 -1.4007135 ]. \t  -378.52347112819325 \t -199.328627991057\n",
            "44     \t [-1.62853868  2.39223911  0.72334824  4.23987302 -4.26769663 -3.26874532\n",
            "  3.57204591 -3.67028793]. \t  -439.83258513714236 \t -199.328627991057\n",
            "45     \t [ 3.43886988  3.11265643  2.77516174  0.33253253 -2.9192395   5.02823799\n",
            "  4.39631649  4.91305537]. \t  -577.4569208308797 \t -199.328627991057\n",
            "46     \t [ 4.58999125  4.26374237  4.50392723 -0.88947155  4.16012254  0.54234553\n",
            " -4.97420636 -4.15419618]. \t  -521.0035368216272 \t -199.328627991057\n",
            "47     \t [-4.43996599 -3.82300484  4.70161496  2.11441558  1.59419962 -2.87225212\n",
            " -4.42196114  3.84351206]. \t  -450.405810209528 \t -199.328627991057\n",
            "48     \t [ 3.51589433 -3.49046669  3.78808846 -0.90335169  0.95174465 -4.99007236\n",
            " -4.34771931 -3.37277514]. \t  -460.29881026977415 \t -199.328627991057\n",
            "49     \t [-3.72102409 -2.43409768 -0.5408895   4.49491355 -4.46229696 -4.96290126\n",
            " -1.91898951  2.51049655]. \t  -430.93155180392847 \t -199.328627991057\n",
            "50     \t [-4.4498693  -0.35226651  3.21354475  4.28681883  2.69880241  0.84466025\n",
            "  4.6632058  -5.05807284]. \t  -522.126995905093 \t -199.328627991057\n",
            "51     \t [ 1.96451356  2.92953139 -4.17235828 -3.97053073 -4.40617782  3.24065859\n",
            " -4.63858778 -4.0733433 ]. \t  -579.7455043985258 \t -199.328627991057\n",
            "52     \t [-0.81385562 -1.84741528 -2.62982529 -3.15578413  4.37637084 -4.61422331\n",
            "  3.4449655  -4.0293236 ]. \t  -504.53963429129305 \t -199.328627991057\n",
            "53     \t [ 1.50055121 -5.02160583  2.81586618  4.57959069 -2.19397967 -4.38841475\n",
            "  1.74223415 -5.04236194]. \t  -524.630422651405 \t -199.328627991057\n",
            "54     \t [ 4.57889984  3.58902784 -4.76539099 -4.35821057  5.11871192  3.37767021\n",
            "  1.60358364  4.91653745]. \t  -601.6684984443574 \t -199.328627991057\n",
            "55     \t [ 2.99099976  4.97517336  3.78692968 -0.20493246 -0.27760963 -5.07985153\n",
            " -4.74438667  5.04107006]. \t  -617.7194956986906 \t -199.328627991057\n",
            "56     \t [ 0.29830474 -5.02138477  4.73660924  3.48400607 -4.64182109  0.70025609\n",
            " -2.32215111  4.45609003]. \t  -473.65246445512275 \t -199.328627991057\n",
            "57     \t [ 4.7591291  -4.29164018 -3.83274924  0.59784185  0.82451988  0.84716985\n",
            "  1.26814036  4.12264968]. \t  -259.91774927222707 \t -199.328627991057\n",
            "58     \t [-4.85131095 -3.20227627 -3.9708861   3.27122643 -5.03216794  0.83345155\n",
            "  3.75128008  2.38224303]. \t  -408.8386531919021 \t -199.328627991057\n",
            "59     \t [ 4.86049252 -2.88407583  4.72868963  4.5177395  -3.53501586  2.22565107\n",
            "  4.4558937  -3.91951126]. \t  -543.0698630399314 \t -199.328627991057\n",
            "60     \t [-2.44141255  4.82450578  4.95731789 -0.60232352  0.16393643  3.3598048\n",
            " -3.31583265  4.70452306]. \t  -449.57601062211813 \t -199.328627991057\n",
            "61     \t [ 3.96327713 -2.82099552 -4.9729425  -5.05055313  4.18105902  4.08161107\n",
            " -3.52304931 -2.19567528]. \t  -520.6610366823375 \t -199.328627991057\n",
            "62     \t [-2.41749475  2.70418783 -0.43855343  3.10096574  2.08239818  4.29418081\n",
            "  5.07493653  1.92989579]. \t  -401.91317708628105 \t -199.328627991057\n",
            "63     \t [ 4.26298322 -3.40775042 -4.73429139 -4.31178329 -4.09909803  4.47546595\n",
            " -3.12858469  3.30331435]. \t  -543.0081741816593 \t -199.328627991057\n",
            "64     \t [ 4.57026954  4.81315873 -1.67973714  1.78761816  2.48731997  4.81501442\n",
            " -0.32498515 -1.28481887]. \t  -272.45259286750763 \t -199.328627991057\n",
            "65     \t [-4.01111897 -1.89071159 -4.86689568  4.40511224  1.08873669 -4.97631715\n",
            "  4.82651859 -4.56674285]. \t  -656.335959152263 \t -199.328627991057\n",
            "66     \t [-2.69275217  2.62419831 -4.8342971  -4.39079418  2.73816442  2.60017717\n",
            "  4.73974265  4.65360586]. \t  -576.8090799549441 \t -199.328627991057\n",
            "67     \t [-3.6535286   3.06781182  2.45828933 -3.35539503 -3.49148733  3.81331162\n",
            " -3.3884564  -5.10810189]. \t  -532.6490603637776 \t -199.328627991057\n",
            "68     \t [-4.69786975  2.44662546  0.81801081 -2.93530213  2.68848079 -4.23691038\n",
            " -3.8870037   3.55618147]. \t  -421.2944517612834 \t -199.328627991057\n",
            "69     \t [-4.95529932  1.91863573  4.49417651 -4.96938841 -4.11310343 -4.91466597\n",
            "  1.08274455  3.18573443]. \t  -510.1987991035748 \t -199.328627991057\n",
            "70     \t [-4.78246302  4.12529791 -4.87301644  4.4478481   2.18747371 -0.78692443\n",
            "  0.30146455  4.7885161 ]. \t  -418.996360511293 \t -199.328627991057\n",
            "71     \t [-2.39611438 -1.74783099  4.58869734 -3.67783363  4.54242949 -4.96471987\n",
            "  2.3124593   0.68050637]. \t  -421.32143764565916 \t -199.328627991057\n",
            "72     \t [-4.03665559 -4.5874477   1.03994962  2.65818817  4.19031283  5.00161327\n",
            " -4.72002259  2.66857244]. \t  -540.7032276432004 \t -199.328627991057\n",
            "73     \t [ 3.85804169  3.78920071 -2.57437615 -2.80814037 -0.46187426 -4.88532472\n",
            "  4.46131827  4.88028893]. \t  -569.1517265105911 \t -199.328627991057\n",
            "74     \t [ 1.88827201 -4.68853263 -4.98573467  0.14870837 -4.80591589 -2.15451787\n",
            " -2.89120441 -2.75011915]. \t  -384.5458597220634 \t -199.328627991057\n",
            "75     \t [-4.66755778  2.06407444 -4.76595753  5.01315948 -4.5118081   3.98359934\n",
            " -3.052588   -3.399693  ]. \t  -553.6648259263906 \t -199.328627991057\n",
            "76     \t [-3.43083088  4.62732346 -3.25576651  4.65134526  3.97814331 -2.50399822\n",
            " -4.4466323  -3.5606772 ]. \t  -529.5182554193748 \t -199.328627991057\n",
            "77     \t [-3.55714183  3.97059924  4.21900669 -3.784008    0.5806806  -4.29785714\n",
            "  3.49525968 -4.02044395]. \t  -482.2045370588263 \t -199.328627991057\n",
            "78     \t [-1.2479536  -4.57073799  4.58994582 -2.84926314  1.00278578  4.95981268\n",
            "  2.35297867 -3.14152654]. \t  -409.35210936722615 \t -199.328627991057\n",
            "79     \t [ 4.2141017  -4.44374139  2.82893223 -1.59712967  2.20519773  4.25929854\n",
            "  1.55103357  5.0397645 ]. \t  -444.6621686604658 \t -199.328627991057\n",
            "80     \t [ 4.56025907 -3.24055407 -2.21281461  4.40861983  4.85757005 -4.63956528\n",
            "  1.14885107  0.5003506 ]. \t  -392.60685208467424 \t -199.328627991057\n",
            "81     \t [-2.6950374  -5.12        0.47850569 -1.48633337 -5.12       -0.52580466\n",
            " -5.12       -0.69141162]. \t  -389.27170069134337 \t -199.328627991057\n",
            "82     \t [ 1.62504885 -4.54464298  4.27566977 -2.93690301  0.58785046  0.2062236\n",
            " -4.45520045  4.15187038]. \t  -412.12290474753365 \t -199.328627991057\n",
            "83     \t [ 5.09517807  3.07308404 -4.7486721   4.05115988 -1.81849747  3.39199317\n",
            " -5.10224056  3.07658263]. \t  -521.6670444137867 \t -199.328627991057\n",
            "84     \t [ 3.2394747   2.30387982 -1.10780594 -4.9327917  -2.39703395 -4.56813511\n",
            "  2.41004417 -2.28551908]. \t  -358.5043380527987 \t -199.328627991057\n",
            "85     \t [ 3.20362232  2.61662464  0.61462298 -3.75327432  5.09026598  1.77085406\n",
            "  4.97081257 -4.27676526]. \t  -549.0963968154904 \t -199.328627991057\n",
            "86     \t [ 0.13845161 -1.42596392  1.8237473  -1.36513556 -5.01053714  0.53186998\n",
            "  4.36450109 -4.90943348]. \t  -474.90556917373976 \t -199.328627991057\n",
            "87     \t [ 4.02500314  4.91881731 -3.34469545  4.92060891 -1.16335306 -1.44533235\n",
            "  4.72999713 -4.49713758]. \t  -532.7056552247319 \t -199.328627991057\n",
            "88     \t [4.11080767 0.61624851 4.6075762  3.78110595 2.84568461 1.36559695\n",
            " 4.52078895 1.47510646]. \t  -350.6835644588938 \t -199.328627991057\n",
            "89     \t [ 4.12302356 -4.9075763  -2.54303137 -1.01909761 -3.72559156 -3.34306725\n",
            " -5.11276942  3.81818157]. \t  -524.7909156390481 \t -199.328627991057\n",
            "90     \t [ 2.85865196 -3.89969748 -2.9383378   3.99986476  4.77243265  1.82793487\n",
            " -4.37956574 -4.7299834 ]. \t  -575.6590896707996 \t -199.328627991057\n",
            "91     \t [ 5.05563461  0.34005688  2.29926957  0.5784583   3.17729095 -2.08261724\n",
            " -1.10186321  4.57561165]. \t  -295.477246393463 \t -199.328627991057\n",
            "92     \t [-4.58013801 -1.5039288  -2.26387171 -4.88754123  3.52293467 -4.74853\n",
            " -4.35727361 -3.75868024]. \t  -579.6976666117833 \t -199.328627991057\n",
            "93     \t [ 0.54882716  4.78111125 -3.83013317 -2.84173357  4.25576181  5.10526517\n",
            " -5.02556086  4.06306554]. \t  -678.1326042947521 \t -199.328627991057\n",
            "94     \t [ 4.64322397  2.17636967  4.42403321 -3.34882601  1.23081745  4.95892234\n",
            "  0.26706273 -1.1816803 ]. \t  -301.3976779121561 \t -199.328627991057\n",
            "95     \t [ 4.68734838 -4.33523693 -4.20076679 -2.95927829 -3.46982376  4.58766121\n",
            "  5.06890834  4.78903152]. \t  -697.342033003091 \t -199.328627991057\n",
            "96     \t [-1.8355062  -2.17414224  4.89962266  4.91542205 -3.15531936  4.97186678\n",
            "  3.71094177  3.69560541]. \t  -585.2418483579252 \t -199.328627991057\n",
            "97     \t [-1.11226165  2.15142168 -4.40432107  1.3952024  -4.64222232  3.24407368\n",
            "  4.40044056 -2.77549023]. \t  -444.5439804803216 \t -199.328627991057\n",
            "98     \t [-5.07116582  4.79806526  4.57435633  3.47890328  1.76679648  2.74329837\n",
            " -2.21495669 -3.83623858]. \t  -395.7828708321092 \t -199.328627991057\n",
            "99     \t [ 2.89411371  4.48566312  3.71667277  5.11826466  4.13674145 -5.10938603\n",
            " -2.8072336  -4.97227298]. \t  -689.9957579098605 \t -199.328627991057\n",
            "100    \t [ 1.72015807  1.68362142 -4.49200517  1.24536005 -3.30419123  3.03205972\n",
            "  5.00044417  4.9625242 ]. \t  -557.1591038649103 \t -199.328627991057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEjKllHqtdwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b61f69f-8b44-4920-8335-ae379ca941e9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_loser_12 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_12 = dGPGO(surrogate_loser_12, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.15884083  1.25039382 -0.63766795  2.9220719   2.86695228 -2.32865172\n",
            " -2.28900603  3.0911711 ]. \t  -235.23146270653385 \t -119.61569010596395\n",
            "init   \t [ 4.69134698  3.84955018 -1.45595116  0.01019009  1.87866046  2.17806876\n",
            " -1.32863227  0.62664895]. \t  -119.61569010596395 \t -119.61569010596395\n",
            "init   \t [ 0.03157161 -4.97901108  2.79374461  3.91824579 -1.38356752  1.18165687\n",
            " -4.34809609 -1.34324218]. \t  -299.1328730459762 \t -119.61569010596395\n",
            "init   \t [ 4.43535464  1.55011219 -1.0526456   2.95659666 -1.87559811  0.6973302\n",
            "  3.77986447 -0.65358414]. \t  -186.70407348837227 \t -119.61569010596395\n",
            "init   \t [ 3.09399185 -3.64782772  2.09163234  2.0949126  -2.87956884  4.35064452\n",
            " -0.59247866  4.19139542]. \t  -364.893303476081 \t -119.61569010596395\n",
            "1      \t [-1.20506929 -4.56833346 -0.4951203   4.93572855 -3.85082675 -3.89753961\n",
            "  2.44247609  0.89398921]. \t  -354.81541396698753 \t -119.61569010596395\n",
            "2      \t [-2.38467024  3.09418413  4.09227155 -4.07974036 -0.4732923  -1.0852054\n",
            "  1.75762856  0.55084604]. \t  -173.89009841197802 \t -119.61569010596395\n",
            "3      \t [ 2.1739345  -2.49536672  4.13333698 -1.34769672 -1.32567707 -4.38533973\n",
            " -0.8338263   0.10596233]. \t  -204.82928530268254 \t -119.61569010596395\n",
            "4      \t [-4.28283748 -4.03035474  0.77209587 -4.45030519  4.58851259  3.16061079\n",
            "  2.08538216  3.90087255]. \t  -449.2246638075243 \t -119.61569010596395\n",
            "5      \t [-4.99777619  3.54079835 -4.03410463 -2.99367945  5.08636374  3.52706711\n",
            " -4.2657072  -5.00335179]. \t  -666.361473147168 \t -119.61569010596395\n",
            "6      \t [-4.53464654 -1.56248049 -0.41370416 -5.09190083 -3.88745964  5.07348747\n",
            "  3.98846791 -0.94528333]. \t  -478.1759603715879 \t -119.61569010596395\n",
            "7      \t [ 2.41797118 -4.07927895  5.00574416 -4.24357528  4.15780498 -0.50754755\n",
            "  4.66423605  3.35380286]. \t  -516.5837390836538 \t -119.61569010596395\n",
            "8      \t [-4.65113843 -4.83090942 -4.48180969  2.31592624 -3.86434763  3.05934343\n",
            "  0.93189694 -3.5509208 ]. \t  -387.7971101154641 \t -119.61569010596395\n",
            "9      \t [-3.3457227   2.99220584  4.07970672  5.04320906  3.9459153   2.27190385\n",
            " -1.71752197 -2.65150847]. \t  -366.481973301136 \t -119.61569010596395\n",
            "10     \t [-0.04881348  1.29047429 -3.30598216  4.56425483  1.87189603  1.96088007\n",
            " -2.11009969 -4.7629117 ]. \t  -372.6918189092081 \t -119.61569010596395\n",
            "11     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -119.61569010596395\n",
            "12     \t [-3.89115394  3.15385761 -2.35969335 -1.87583412 -4.04283193 -4.7513417\n",
            "  3.66066312  2.07645382]. \t  -411.2845897200651 \t -119.61569010596395\n",
            "13     \t [ 4.84174076 -1.19773913 -3.75090117  4.48049533  3.71926069 -2.9171414\n",
            " -2.01470603  1.29478388]. \t  -310.86653309339977 \t -119.61569010596395\n",
            "14     \t [ 1.8834428  -4.6809482   3.67236598 -1.12200019 -4.11002182  3.92939418\n",
            "  3.01146371 -4.32536341]. \t  -483.1190353889024 \t -119.61569010596395\n",
            "15     \t [ 4.60941179  2.39162672  0.46579179  4.74370039 -4.11531291 -4.28910187\n",
            " -3.76293416  4.82577056]. \t  -603.8276708088412 \t -119.61569010596395\n",
            "16     \t [-1.4481891  -0.42387069  2.361129   -3.06945072 -2.19770974  3.64165384\n",
            " -4.48783581 -3.2006355 ]. \t  -383.5242147972915 \t -119.61569010596395\n",
            "17     \t [ 4.86812743 -3.61332722 -3.22371878 -4.74041688 -1.86285629 -4.8707853\n",
            "  0.26677496  4.22036275]. \t  -473.5625696622485 \t -119.61569010596395\n",
            "18     \t [ 2.21465442 -1.54112163 -4.17252666 -1.82794977 -5.08650831 -0.85583905\n",
            " -3.69827473 -1.18580599]. \t  -315.9976794000959 \t -119.61569010596395\n",
            "19     \t [ 0.12386132 -1.71798756 -3.84469438 -3.69630312  3.28894266 -4.59050742\n",
            "  2.14167417 -0.72608498]. \t  -321.76119790737573 \t -119.61569010596395\n",
            "20     \t [-2.66960533 -0.27199601  3.61557266  0.07247849  4.28190583 -4.87567018\n",
            " -1.32953305 -5.00146254]. \t  -493.31003866766764 \t -119.61569010596395\n",
            "21     \t [ 3.60983689 -0.64498271 -4.81986754 -4.29906179 -3.91759121  4.41165747\n",
            "  4.55521982 -1.42885215]. \t  -512.5811009368408 \t -119.61569010596395\n",
            "22     \t [-3.20270292 -3.10286729 -4.17958828  3.23529211  1.66462091  4.55757442\n",
            " -2.96006343  3.08691997]. \t  -399.8383603757665 \t -119.61569010596395\n",
            "23     \t [ 0.00892258  3.45698498  3.43566616  2.6471631  -5.02308915 -3.83375341\n",
            "  1.80228951 -1.00409922]. \t  -332.4894344224326 \t -119.61569010596395\n",
            "24     \t [ 0.11130335  4.96719695 -5.10605507 -5.08875359  3.33974552  3.5274559\n",
            "  4.23351711 -2.89351758]. \t  -554.020920438892 \t -119.61569010596395\n",
            "25     \t [-4.57145227  4.48070001  1.96326245  3.29566182 -2.96404956  3.51332028\n",
            "  2.87913871  4.95573705]. \t  -488.5494475969441 \t -119.61569010596395\n",
            "26     \t [-4.49259941 -2.63914006  3.12745705  1.45982917  4.49580082 -2.91222262\n",
            "  5.11619372  2.46272128]. \t  -455.67634289578046 \t -119.61569010596395\n",
            "27     \t [-5.06512487  3.07177887 -3.24550166 -3.17001906  4.07067904 -2.78306348\n",
            "  5.09402638  3.46370695]. \t  -523.2697202123925 \t -119.61569010596395\n",
            "28     \t [ 3.45116782  4.2883336  -1.06827961  1.08873399  5.0482606  -4.51058891\n",
            "  4.35722921  0.96994416]. \t  -446.77680784324997 \t -119.61569010596395\n",
            "29     \t [ 3.63530343 -3.46557873  3.61802128 -3.36749831  3.83014402  1.62343264\n",
            " -3.95296799 -3.58858177]. \t  -423.43457792204293 \t -119.61569010596395\n",
            "30     \t [ 4.01934274  4.05770044  4.31710837  1.5774679  -4.35556493  5.07412149\n",
            "  3.58722918  4.13308112]. \t  -591.0222272976584 \t -119.61569010596395\n",
            "31     \t [-2.25591213  4.96561887  0.0795036  -1.15454996 -4.41063091  4.84978558\n",
            " -4.34250862  3.7355073 ]. \t  -541.7794187817939 \t -119.61569010596395\n",
            "32     \t [ 0.12727565 -2.79689264  1.320464    4.54198801  4.87337276  4.71576159\n",
            "  4.49149952  1.50626835]. \t  -514.9558968982748 \t -119.61569010596395\n",
            "33     \t [-5.02751618  5.06491973  2.48064034 -3.42349431  4.74146408 -4.03937258\n",
            " -3.09039151  4.51412148]. \t  -582.1032982837494 \t -119.61569010596395\n",
            "34     \t [ 4.90962147  3.6406731   2.26649059  4.77802827  4.12003519 -3.1547146\n",
            " -3.56596834 -4.88897631]. \t  -582.1589605949364 \t -119.61569010596395\n",
            "35     \t [-4.51222064  2.33705836 -3.9204912   4.61050437 -2.67519101 -0.6533826\n",
            "  4.50473942 -3.81968648]. \t  -459.5350415752135 \t -119.61569010596395\n",
            "36     \t [-3.35706119 -4.51837979 -4.82198262 -4.46867791 -4.70974965 -2.79849575\n",
            "  2.66466126 -1.51186134]. \t  -427.6191642521146 \t -119.61569010596395\n",
            "37     \t [ 3.84228276  4.43963589  3.00532598 -4.69185779 -4.82136851  2.026124\n",
            "  0.90323042 -2.91310454]. \t  -383.793184410653 \t -119.61569010596395\n",
            "38     \t [ 4.0849197   4.51858529  2.23105834 -3.98594242  2.08804225 -2.13970217\n",
            " -4.23085577 -3.89163271]. \t  -431.7345860806727 \t -119.61569010596395\n",
            "39     \t [-2.58586098  3.937282   -4.69349589 -4.37725799  1.26492357 -3.04887726\n",
            " -4.71377433 -1.02492612]. \t  -408.1348576606018 \t -119.61569010596395\n",
            "40     \t [-4.79679262 -1.19101782 -0.51873672 -2.8827882   3.7406016   3.05765609\n",
            "  3.9684925  -4.92961487]. \t  -490.6028176618996 \t -119.61569010596395\n",
            "41     \t [-4.80601553  2.20230062 -2.91346795  2.62611651 -4.66656923 -1.78269697\n",
            " -3.65609417 -1.06728291]. \t  -316.48318660748 \t -119.61569010596395\n",
            "42     \t [-4.58233729 -2.90182292  4.18639     1.96485379 -4.12704142 -4.49972084\n",
            " -1.87098357 -3.40777068]. \t  -429.91369741773246 \t -119.61569010596395\n",
            "43     \t [ 1.85553758  0.70934102  4.57936536  1.53530059  4.62761911  2.88316442\n",
            " -1.29195595  5.04286473]. \t  -448.86774655317276 \t -119.61569010596395\n",
            "44     \t [-1.32771388 -0.2500952   4.93199565  5.10576033 -2.89496113  4.94507599\n",
            "  3.49541808 -1.29531971]. \t  -466.7119336269132 \t -119.61569010596395\n",
            "45     \t [ 1.49138855  4.95353482  2.70965969 -4.3719624  -4.30373962 -4.79730833\n",
            " -1.6265383   4.89221536]. \t  -590.4676764687233 \t -119.61569010596395\n",
            "46     \t [-4.69146875 -2.55212666  1.61423304 -3.04996153 -2.78637926 -2.63244311\n",
            " -4.19224647  5.03851802]. \t  -486.57879804898437 \t -119.61569010596395\n",
            "47     \t [-1.58766871  3.93152255 -4.80561093  0.0477454  -2.59576839  5.01392316\n",
            "  0.63058118 -3.11782905]. \t  -367.80215136278736 \t -119.61569010596395\n",
            "48     \t [ 4.83577951 -4.14582824 -4.2095003   4.87111583 -3.66027066  3.02391713\n",
            " -4.87528283  2.65473701]. \t  -550.4433660626951 \t -119.61569010596395\n",
            "49     \t [-2.45727121 -3.57800376 -3.59498248 -4.5356804   4.49369616 -3.25401084\n",
            " -3.77456599  4.73843533]. \t  -596.5553265616473 \t -119.61569010596395\n",
            "50     \t [-4.16286711 -3.69571401 -4.56928156  4.38057808  1.42459829 -4.83612759\n",
            " -4.27769809 -4.85059119]. \t  -650.8318927255907 \t -119.61569010596395\n",
            "51     \t [ 3.72565307  5.07908191  4.20306074  0.93294167  3.46961807 -3.53360348\n",
            " -4.77765217  4.17653564]. \t  -556.3920068901169 \t -119.61569010596395\n",
            "52     \t [ 1.96215566 -5.01921275 -4.27992667 -1.49164408  3.82112879  4.06734282\n",
            " -2.78202234 -4.85994376]. \t  -533.4831303333021 \t -119.61569010596395\n",
            "53     \t [ 3.32885076 -4.6174408   0.66677819 -2.88698938  3.92340624  5.08250655\n",
            "  4.64415165 -2.58280436]. \t  -524.69623444286 \t -119.61569010596395\n",
            "54     \t [-4.43426871  3.39581796  4.80950651 -0.12177342  4.85921831  4.6801906\n",
            "  4.04913208  3.46789064]. \t  -572.6428073892683 \t -119.61569010596395\n",
            "55     \t [-1.3144322   2.96648225 -4.58685033  4.27089243  4.58276043  5.03228427\n",
            "  3.66179339  4.67473979]. \t  -681.0458697561622 \t -119.61569010596395\n",
            "56     \t [ 4.05203906 -4.21109401 -2.13644382 -2.70952507  3.03805882  1.79218409\n",
            " -1.97175147  4.85028713]. \t  -375.7823862622354 \t -119.61569010596395\n",
            "57     \t [ 4.63331836 -1.95437578  3.84273577  3.54908259  4.84142131 -2.93418267\n",
            "  3.23686355 -3.18612378]. \t  -447.19605855873607 \t -119.61569010596395\n",
            "58     \t [ 4.37699147  3.24575379 -4.61856717  1.35844937  4.20572821  5.0261401\n",
            "  2.90341528 -4.03502739]. \t  -540.8764815845917 \t -119.61569010596395\n",
            "59     \t [-2.13666398 -1.89056294 -3.77183433  3.62257442  4.71095701 -2.48780523\n",
            "  4.01273599 -3.8256525 ]. \t  -484.7860904299998 \t -119.61569010596395\n",
            "60     \t [ 4.38496674 -4.75994312 -2.71438515 -3.53401599 -2.61001885 -4.72547717\n",
            "  4.68406694 -4.09403551]. \t  -592.3169811999504 \t -119.61569010596395\n",
            "61     \t [ 4.3602157   5.07200701  4.7338835   3.01006059 -3.03877778  4.75462603\n",
            "  1.61440406 -4.33555198]. \t  -524.362664535086 \t -119.61569010596395\n",
            "62     \t [ 3.41765089  2.85348111  2.54975684  5.04341102  4.83071143  5.00798745\n",
            "  5.02443586 -4.95777922]. \t  -789.7225877312676 \t -119.61569010596395\n",
            "63     \t [-2.69954804 -4.46287853 -4.23069558  0.36349683 -3.72794826  0.11450906\n",
            "  5.02891815  4.53679254]. \t  -512.6036856291286 \t -119.61569010596395\n",
            "64     \t [ 2.25407296  2.09863361  1.2056268  -4.22691632  3.24260324 -2.15333643\n",
            "  4.6968155  -5.05592858]. \t  -529.0306323308363 \t -119.61569010596395\n",
            "65     \t [ 4.42766808 -1.8731146   3.3837943  -4.21691074  5.02717513 -4.61806203\n",
            " -4.2682243   4.14513372]. \t  -651.4035669577154 \t -119.61569010596395\n",
            "66     \t [-4.87653697 -3.4591322   4.67985395 -2.97801734 -5.0026146   0.06395157\n",
            "  3.10169794  4.10619321]. \t  -476.27484728999866 \t -119.61569010596395\n",
            "67     \t [ 1.52254561 -4.65782919 -1.54703882 -4.85066697 -4.56810949  5.03981034\n",
            " -4.3682913   4.80009625]. \t  -721.6421841155051 \t -119.61569010596395\n",
            "68     \t [-5.0236938   3.56177448 -2.85075031 -4.31615219  1.6758355   1.89854621\n",
            " -1.51048651  4.25120001]. \t  -345.728573452506 \t -119.61569010596395\n",
            "69     \t [ 4.39877122  4.6709328  -3.30451996 -5.01338339 -3.04256108 -4.41372026\n",
            "  1.41831267 -2.98195489]. \t  -444.66918738750456 \t -119.61569010596395\n",
            "70     \t [ 4.4099775  -3.89112291 -0.66338834  1.58127051  0.51280406 -2.11500171\n",
            "  4.21486326  4.1931665 ]. \t  -354.2223966934372 \t -119.61569010596395\n",
            "71     \t [ 3.78164131e+00 -2.75879113e+00  5.04971616e+00 -4.80148366e+00\n",
            " -2.90394801e-03  2.13616263e+00 -4.78734226e+00  4.85636375e+00]. \t  -574.722408090049 \t -119.61569010596395\n",
            "72     \t [-1.1888317   2.47677283  5.02956862 -4.91262096  4.77116956  3.48648636\n",
            " -0.84774462 -4.55836486]. \t  -544.1212239869448 \t -119.61569010596395\n",
            "73     \t [-4.81380688  4.40095768  4.6372785   2.66916271  0.60511201 -3.68965254\n",
            "  4.14124048  4.95759338]. \t  -555.1033510349539 \t -119.61569010596395\n",
            "74     \t [-4.69774019 -2.79686205 -2.33534836 -1.71876288  0.90641727  0.45175075\n",
            " -5.00093654 -4.91022451]. \t  -439.1722125515285 \t -119.61569010596395\n",
            "75     \t [ 2.76049122  2.60794099 -3.21360673 -3.88550279  2.63956389  2.43575859\n",
            "  4.1644981   5.08500529]. \t  -511.28690505606653 \t -119.61569010596395\n",
            "76     \t [-0.09492567 -5.10410069  0.36971532  4.23057259  1.92946279 -4.9032992\n",
            " -5.11414683  1.48635148]. \t  -487.73734709015173 \t -119.61569010596395\n",
            "77     \t [ 2.03954544 -3.32999415  1.43916871 -4.95919099 -0.21625796  4.76329818\n",
            "  2.32801955  4.10051141]. \t  -439.7445594302609 \t -119.61569010596395\n",
            "78     \t [ 2.57636467  5.02342908 -2.37756192 -2.93847746  0.50045822  5.0847148\n",
            " -4.54187401 -4.50530948]. \t  -571.7654198546909 \t -119.61569010596395\n",
            "79     \t [ 4.43072458 -4.01521381 -4.64425104  3.56849406 -0.40054708  4.97867613\n",
            "  4.03903062  3.18834337]. \t  -512.5651391022285 \t -119.61569010596395\n",
            "80     \t [-3.76847142 -5.11580824  4.95702718 -1.12872395  3.87507869 -1.06959931\n",
            " -4.92375007  2.7875099 ]. \t  -459.16711663123397 \t -119.61569010596395\n",
            "81     \t [ 4.66432852  4.46011058  4.42153771  3.77185029 -4.05541712 -2.3542377\n",
            " -4.62271594 -3.19432935]. \t  -523.8016287658669 \t -119.61569010596395\n",
            "82     \t [-4.78187785  5.06164818 -5.10414907  4.19615545 -3.8777821   5.05398983\n",
            " -0.34790846  3.43521957]. \t  -546.3908150278638 \t -119.61569010596395\n",
            "83     \t [-2.16941915 -2.81639958  4.05388077  4.80758435  1.70841054 -0.24562682\n",
            "  4.49803877 -4.96894947]. \t  -516.4293779313089 \t -119.61569010596395\n",
            "84     \t [-1.13659813  4.91724279 -4.52887486  2.75497127  0.94257282 -0.85037824\n",
            "  3.90979948  1.51057142]. \t  -275.5834065859605 \t -119.61569010596395\n",
            "85     \t [ 3.5497139   1.06943833  4.30708745  4.89389749  2.28373713  3.65243496\n",
            " -4.20007608 -2.49406868]. \t  -445.7082689052508 \t -119.61569010596395\n",
            "86     \t [-1.55161774  3.88797074  0.65349205 -3.9343768  -4.68901362 -4.35292164\n",
            " -2.22296652 -3.93622571]. \t  -478.0024378752458 \t -119.61569010596395\n",
            "87     \t [ 2.19850184  0.71295528  1.54234669 -2.66137892 -3.3907862  -0.67471188\n",
            "  4.53051191  4.07030304]. \t  -377.75454525282913 \t -119.61569010596395\n",
            "88     \t [-2.89644519  1.55077603  3.20210184  4.29002644 -4.52623113 -1.31857381\n",
            " -4.62565324  4.90192683]. \t  -572.4503138056587 \t -119.61569010596395\n",
            "89     \t [ 3.00701408 -4.78789918 -0.08136961  2.82742854 -2.22148223 -3.7171299\n",
            " -2.65996436 -5.02917869]. \t  -446.333586191535 \t -119.61569010596395\n",
            "90     \t [-2.51330132  4.36437832  1.8484944  -4.51742992 -4.20544175  4.65840367\n",
            "  4.68480609  3.06610622]. \t  -583.7647324287566 \t -119.61569010596395\n",
            "91     \t [-3.93651304 -4.69518481 -4.67837002  0.82149603 -3.66608794 -3.94261408\n",
            " -4.72196834 -0.54928533]. \t  -446.9053650288446 \t -119.61569010596395\n",
            "92     \t [ 1.87613561  1.11711224 -3.73754997  2.8108412  -3.91126923 -2.82719412\n",
            "  2.89826458  4.94342964]. \t  -458.27474726177013 \t -119.61569010596395\n",
            "93     \t [-0.52458594  4.00859365  4.73128611  3.86102982  1.08881308  0.12677837\n",
            "  4.84113317 -2.06757064]. \t  -363.4770316563106 \t -119.61569010596395\n",
            "94     \t [ 1.05071607  4.72319436 -1.05967067  4.07827081  2.16967499  3.76414704\n",
            " -4.51400443  4.70968762]. \t  -544.2521882164513 \t -119.61569010596395\n",
            "95     \t [-4.77623035  4.05415869  2.35335882  0.34537232 -3.80388726  3.91175014\n",
            "  1.96184682 -4.9849692 ]. \t  -462.6765738519008 \t -119.61569010596395\n",
            "96     \t [-3.69108235 -5.07967852 -3.31286671  1.30650741  2.33721514 -4.81835254\n",
            "  2.56424839  4.17876319]. \t  -457.3195435869162 \t -119.61569010596395\n",
            "97     \t [ 1.10714079  2.55375662  1.36694606 -4.75277817  4.48884508  3.13599508\n",
            " -4.46376241  3.57316395]. \t  -511.602002727578 \t -119.61569010596395\n",
            "98     \t [-4.41883529  1.38836372 -0.62223402  4.43825563 -4.88719983  4.96205252\n",
            " -4.93269083 -4.42464843]. \t  -697.4307744298263 \t -119.61569010596395\n",
            "99     \t [-2.07031872 -4.14012415  1.79686442 -3.67769852 -0.83807508 -0.82204313\n",
            "  0.98007769 -3.78067058]. \t  -230.99351113391037 \t -119.61569010596395\n",
            "100    \t [ 4.6136852   0.5995698   3.70700385 -3.61393916 -4.19489706 -4.20717943\n",
            "  4.98718168 -4.72878863]. \t  -662.6562790548289 \t -119.61569010596395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoONg4VEtdy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe4041d-9e70-456e-a75d-1000eb10f5d9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 13\n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_loser_13 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_13 = dGPGO(surrogate_loser_13, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.64499773 -0.88472932  1.72137019 -2.76537936  3.15062616  1.40102108\n",
            " -3.35673495 -2.45364871]. \t  -232.19635670005127 \t -232.19635670005127\n",
            "init   \t [ 4.2528767  -0.38076919 -3.88924462  3.90026757 -2.80351794  3.18914893\n",
            " -0.55419986 -4.1015814 ]. \t  -361.66026260752943 \t -232.19635670005127\n",
            "init   \t [ 4.03920839  1.42981319  4.41130989  3.62084556  3.50044048  0.52242587\n",
            " -2.97909353  3.81846156]. \t  -372.8981589252669 \t -232.19635670005127\n",
            "init   \t [ 3.80219612  2.41871092 -4.9313143   3.0755089  -1.83535427 -0.17449361\n",
            "  2.95749718 -3.92317458]. \t  -338.32885418149425 \t -232.19635670005127\n",
            "init   \t [-2.96300648  4.98598367  2.14768853 -4.67440231  5.05344835  0.67544515\n",
            "  0.4351207  -3.01593487]. \t  -364.25359293813665 \t -232.19635670005127\n",
            "1      \t [-1.41587684  0.6866087  -4.2572567  -4.43835538 -3.85825728  2.59858633\n",
            " -1.34170499 -2.82749095]. \t  -327.62176614819333 \t -232.19635670005127\n",
            "2      \t [-3.07473092 -0.85317005 -1.50250422 -0.57720119  3.33558361 -3.93578852\n",
            "  2.61338059 -5.03677065]. \t  -418.34892386367665 \t -232.19635670005127\n",
            "3      \t [-3.39709501 -0.75844229 -0.28988583  0.01269954  5.05807698  4.77249476\n",
            "  1.49596497  2.4718132 ]. \t  -342.06868330388926 \t -232.19635670005127\n",
            "4      \t [ 1.27516357 -4.34285698 -4.80891717 -4.72525807 -4.64386877 -2.90111663\n",
            "  4.22750682 -2.79713746]. \t  -544.0571374073245 \t -232.19635670005127\n",
            "5      \t [-1.28755561  2.49550924 -3.16338938  4.97284539  2.94658354 -2.94783466\n",
            "  3.99040857  0.75239783]. \t  -354.59328624675135 \t -232.19635670005127\n",
            "6      \t [ 4.21114748  3.71785746 -0.43186403 -1.16578161 -1.21755106  3.28643373\n",
            " -0.5463672   3.41384411]. \t  \u001b[92m-218.914703726932\u001b[0m \t -218.914703726932\n",
            "7      \t [-3.40987577 -2.26485888 -3.91690985 -0.58734748 -2.26892898 -4.81818994\n",
            " -4.72729877 -0.05610511]. \t  -390.77945760778687 \t -218.914703726932\n",
            "8      \t [ 2.86595514  0.92351583  2.81782962 -2.44988057 -4.50628865  3.57859906\n",
            " -3.68028052 -4.82083464]. \t  -516.8538522864185 \t -218.914703726932\n",
            "9      \t [-4.42963778  4.62707615  2.80169529 -2.14225784 -2.24188875 -4.43196144\n",
            " -2.56287418 -3.89458016]. \t  -414.6512467628057 \t -218.914703726932\n",
            "10     \t [ 3.18435631 -0.11660101 -1.88130665  4.6712052  -2.63434937 -4.84577943\n",
            " -2.16305908  2.98027432]. \t  -387.46239786721355 \t -218.914703726932\n",
            "11     \t [ 2.0374149  -4.18202871  1.36279378  4.41193347  2.79823539  4.3554836\n",
            " -1.43537589 -1.16427415]. \t  -300.80046956494806 \t -218.914703726932\n",
            "12     \t [ 1.11694286 -0.65880005 -1.89749913 -1.52252305 -4.61147313 -1.64357992\n",
            "  3.37238444  4.35249061]. \t  -375.89019619004796 \t -218.914703726932\n",
            "13     \t [-2.37554244  1.65647281  1.78721759  0.78783508 -3.4807812   4.77606073\n",
            "  2.24984424  0.79155457]. \t  -261.08497103385497 \t -218.914703726932\n",
            "14     \t [ 1.51688878 -4.11072603 -4.96940342  3.66824351  3.21889152 -3.84000432\n",
            " -1.66926281 -0.67132266]. \t  -327.3966147081477 \t -218.914703726932\n",
            "15     \t [-4.60314753 -3.19706748  2.87981804  2.67582955 -4.56568783 -1.74633567\n",
            " -0.21209673  2.15431485]. \t  -255.12089049617902 \t -218.914703726932\n",
            "16     \t [-2.96135533 -4.85764355 -2.94721908 -4.60857792  1.58976376 -0.30365672\n",
            "  3.32644401  0.83058005]. \t  -263.1427925078817 \t -218.914703726932\n",
            "17     \t [-0.11834623  4.92705116 -4.3604005  -1.37430597  3.76924904  3.35299698\n",
            "  4.46322323 -0.04754562]. \t  -391.11215712334564 \t -218.914703726932\n",
            "18     \t [ 1.85638398  2.02163281 -3.01735059 -3.35023212  2.68954594 -4.21881992\n",
            " -3.79772488  4.05487191]. \t  -459.28342052219034 \t -218.914703726932\n",
            "19     \t [-4.09844455 -1.48850034  3.67572703 -4.52659048 -3.40363089 -2.71521557\n",
            "  3.96260847 -1.02038732]. \t  -364.1247802550225 \t -218.914703726932\n",
            "20     \t [ 3.86465122  3.95113312  3.73758623 -1.76710627  3.5476809  -0.9302056\n",
            "  4.03393956  3.46199849]. \t  -378.47178663185707 \t -218.914703726932\n",
            "21     \t [-0.14475583  4.40134478 -2.4354744   4.15154633  5.02401187 -0.65413913\n",
            " -3.96422916  2.6485566 ]. \t  -420.39605126823034 \t -218.914703726932\n",
            "22     \t [-3.01708331 -1.83975134  4.04441597  1.36291376  4.42434258 -4.59618585\n",
            " -3.79944945  3.34001622]. \t  -487.2941611598006 \t -218.914703726932\n",
            "23     \t [ 3.47946079 -0.20865945  4.22764831  4.30667176 -2.24080282 -3.49752172\n",
            "  2.220785   -3.18623894]. \t  -354.2445288327723 \t -218.914703726932\n",
            "24     \t [ 4.74911553 -3.57355147  2.02881433 -1.20139555 -4.06427082 -0.71396603\n",
            " -2.84554848  1.88910129]. \t  -237.09593014417555 \t -218.914703726932\n",
            "25     \t [-4.09322692 -2.34029456 -3.2497013   1.37033171  0.52246424  4.10258651\n",
            " -4.94870218 -2.27470096]. \t  -382.0752047369767 \t -218.914703726932\n",
            "26     \t [-2.33069311  0.2571237   4.97181179  3.79574058 -0.63447703  2.27175691\n",
            " -3.22162417 -3.1984963 ]. \t  -324.8248265532207 \t -218.914703726932\n",
            "27     \t [ 5.00982906  0.29139707 -4.86258337  0.62785031  4.62078153  3.29058204\n",
            " -3.70077923 -3.91692044]. \t  -488.1133321959023 \t -218.914703726932\n",
            "28     \t [ 0.96147075  0.71808488  4.03788557  0.81071344  5.04648547  1.88523024\n",
            "  4.03905975 -3.19193624]. \t  -397.8636198609694 \t -218.914703726932\n",
            "29     \t [ 2.37876615 -4.7934043   4.04810257 -4.82678313  2.31603498 -1.40095132\n",
            "  3.12687723 -4.16146587]. \t  -439.5447139689047 \t -218.914703726932\n",
            "30     \t [-0.31316826 -4.5438875   2.71646621  3.55272862  3.36556525 -2.84166133\n",
            "  4.88572693  0.49992637]. \t  -388.1940765381305 \t -218.914703726932\n",
            "31     \t [ 2.86080125 -4.19491364  3.57636436 -2.39688061 -3.95370563  4.04962494\n",
            "  5.04867728  2.41988035]. \t  -506.55635420725207 \t -218.914703726932\n",
            "32     \t [ 3.6511972  -5.03374778 -4.16733946 -1.67855127  0.48921985  2.86461262\n",
            "  4.52631586  4.22006982]. \t  -463.6961404211157 \t -218.914703726932\n",
            "33     \t [-1.09730036 -3.39607373 -2.77900487  0.95615668 -1.66003768  3.28861249\n",
            "  4.98040889 -4.86698593]. \t  -492.89643186493845 \t -218.914703726932\n",
            "34     \t [-3.29975062  3.92545999  2.91690979 -4.60120503 -0.97329617  0.40209428\n",
            " -2.21337405  4.70319976]. \t  -368.8767482469296 \t -218.914703726932\n",
            "35     \t [-3.7686316  -4.08028438  0.30472636 -4.5852498  -1.54312407  1.44566465\n",
            " -3.91871594  2.36510598]. \t  -308.5666527346285 \t -218.914703726932\n",
            "36     \t [-4.92270405  4.18624686  3.6789746   2.31171986 -1.75335782 -4.22286838\n",
            " -4.03551917  3.95534365]. \t  -482.78597177086925 \t -218.914703726932\n",
            "37     \t [-0.69447295  4.63936981  4.656429    1.53212369 -4.01220939 -1.84999725\n",
            "  4.13752413  3.969915  ]. \t  -464.90600415003667 \t -218.914703726932\n",
            "38     \t [ 1.500391    2.60925601 -4.79534013  4.64623327 -3.24564792  2.57456044\n",
            "  3.87995082  4.4837204 ]. \t  -529.8528405595223 \t -218.914703726932\n",
            "39     \t [-1.40372927 -4.73470966  2.53460916 -4.8436032   1.47672351 -5.03046556\n",
            " -3.6855238  -4.59345994]. \t  -586.5377630779865 \t -218.914703726932\n",
            "40     \t [ 3.42131001  3.95906691 -3.89151245 -3.33237951 -3.5193837  -5.09007799\n",
            "  0.47887731 -1.32289051]. \t  -365.89365484706354 \t -218.914703726932\n",
            "41     \t [ 0.3996688  -4.39948801  4.9595373   3.62139896 -5.02722575 -3.64635216\n",
            " -4.11544432 -3.22666025]. \t  -573.1090398162095 \t -218.914703726932\n",
            "42     \t [-4.63089419 -3.1455169  -4.46287324  4.97289747 -1.54719736  0.78884096\n",
            "  3.11348454  4.01979997]. \t  -412.7338394137357 \t -218.914703726932\n",
            "43     \t [-1.99467581 -2.96792392 -1.03156545  4.47596395 -4.89937718 -5.06134685\n",
            "  4.61541597 -1.80075008]. \t  -553.7042056499283 \t -218.914703726932\n",
            "44     \t [ 4.64164756  3.38232408  4.98205018 -4.937466    4.79315032  5.10542375\n",
            "  0.54066893 -0.60416901]. \t  -492.63186073632033 \t -218.914703726932\n",
            "45     \t [-4.11113414  4.92529484 -2.37974349 -1.20444112 -4.61191074 -2.79364156\n",
            " -0.42522285  2.34342637]. \t  -286.5848137830881 \t -218.914703726932\n",
            "46     \t [-4.33307394 -5.12       -2.84336104 -5.12       -5.12       -1.96813536\n",
            " -5.12       -5.12      ]. \t  -747.8453766535582 \t -218.914703726932\n",
            "47     \t [ 2.8386759   4.07371588 -0.04039553 -1.69863771  4.58955791 -4.3577661\n",
            " -4.01584047 -4.02287492]. \t  -514.4127439552744 \t -218.914703726932\n",
            "48     \t [ 3.60448473  4.74876479 -4.75996018  3.80882696 -4.75619547 -3.90247562\n",
            " -4.1549231  -3.63165535]. \t  -614.9320971910101 \t -218.914703726932\n",
            "49     \t [ 2.15955109 -4.05189858 -5.01590558 -3.57594626 -4.29361589  4.13431427\n",
            " -4.57492592  3.64985029]. \t  -611.9388195503122 \t -218.914703726932\n",
            "50     \t [-3.01743009  3.50183111 -4.68174825  0.22061144 -2.72389007  4.3426914\n",
            " -3.95360149  2.99087097]. \t  -430.81242785547227 \t -218.914703726932\n",
            "51     \t [-3.72821021  4.63152432 -1.89662469 -4.40029358  3.73398383 -3.64050016\n",
            "  4.3849761   4.93532945]. \t  -623.7320230870259 \t -218.914703726932\n",
            "52     \t [ 3.33725079  4.4466726   4.98405523 -3.98191892 -4.10027891 -3.83075998\n",
            " -1.15360313  3.30191013]. \t  -457.2744233230236 \t -218.914703726932\n",
            "53     \t [ 2.42755775  3.32084179  3.95034979 -5.00861294 -2.69706913 -1.52368546\n",
            "  2.96307227 -3.82003964]. \t  -403.6104385354229 \t -218.914703726932\n",
            "54     \t [ 4.30731796 -4.44754421  3.08111473 -5.01000714 -1.45470083 -4.3840288\n",
            "  3.78353423  5.03483422]. \t  -615.8961647362689 \t -218.914703726932\n",
            "55     \t [ 3.53190624 -5.10439959 -2.29791177  4.66313506 -1.93347286 -2.27808801\n",
            "  4.84462405  3.70569723]. \t  -491.384568810529 \t -218.914703726932\n",
            "56     \t [ 0.44374948 -4.70988466 -3.50924912 -0.12092544  4.54574228  2.11388885\n",
            " -2.92498353  3.69250615]. \t  -380.66145550861677 \t -218.914703726932\n",
            "57     \t [-4.19148775  4.64261347  4.05501822 -2.21915047  3.98903679  2.35350091\n",
            "  4.34972238  4.50032258]. \t  -536.9640140895895 \t -218.914703726932\n",
            "58     \t [ 4.53611898  2.85315605  4.45565713  4.60695918 -2.31998513  4.74683621\n",
            "  1.80620024 -3.52486856]. \t  -465.65278826837687 \t -218.914703726932\n",
            "59     \t [-4.30506814  1.85102595 -4.08866725 -3.59159664 -1.10395128  3.81831987\n",
            "  3.07344941  4.8474996 ]. \t  -474.8156711388732 \t -218.914703726932\n",
            "60     \t [ 0.2184935  -4.91185026  5.11858805  4.44171964 -0.50610567 -0.09972378\n",
            " -3.32829694  4.92280291]. \t  -478.5708252644768 \t -218.914703726932\n",
            "61     \t [2.74950564 3.44225158 1.83771014 4.83349007 2.26423133 4.68386532\n",
            " 4.30327294 4.83362179]. \t  -608.643600053095 \t -218.914703726932\n",
            "62     \t [ 4.53513234 -2.7295825  -3.08814016 -1.92605298 -4.79345157 -5.07188021\n",
            " -3.73619435 -4.65256506]. \t  -619.0318499163855 \t -218.914703726932\n",
            "63     \t [-3.26904232  4.63906088 -4.64581443  4.64324941 -2.18832156  2.13942241\n",
            " -3.89520013 -4.12102535]. \t  -498.195658423227 \t -218.914703726932\n",
            "64     \t [ 3.51097103 -3.00116843  2.62552345  4.99637123  4.67059042 -3.07163905\n",
            " -2.63531271 -4.49418599]. \t  -526.7536093811982 \t -218.914703726932\n",
            "65     \t [ 1.87230074 -3.8513344  -3.48166713  3.99283315  4.65080164  1.11251229\n",
            "  5.09809882 -2.12395188]. \t  -466.9074825667713 \t -218.914703726932\n",
            "66     \t [ 4.09679308  2.76692185 -1.94849683 -2.53703673  3.44517311 -4.85072854\n",
            "  3.93863785 -1.27733718]. \t  -391.3978597208432 \t -218.914703726932\n",
            "67     \t [ 3.39305149 -2.60163602  4.0441825  -3.84306038  3.33412209 -0.45811699\n",
            " -4.92332766  4.6042102 ]. \t  -529.2976840444844 \t -218.914703726932\n",
            "68     \t [ 4.18779157e+00  3.08154908e-03  2.21335656e+00 -4.62109723e+00\n",
            "  1.16381998e+00  3.76683788e+00  4.99774754e+00 -3.50060533e+00]. \t  -482.43567237346394 \t -218.914703726932\n",
            "69     \t [ 4.17254964  4.39168639  4.57237317  4.56953035  3.73122788 -4.31812961\n",
            "  3.7942447  -2.10102442]. \t  -519.8024550399207 \t -218.914703726932\n",
            "70     \t [-3.95433121  1.29686166 -2.01491021 -4.71771435  0.71200371  4.95996316\n",
            "  4.40770278 -4.14953303]. \t  -544.0933946841219 \t -218.914703726932\n",
            "71     \t [-5.03121931  1.96430137 -3.52631814 -5.08343315  4.21579061  4.85786905\n",
            " -2.04320519 -0.30189469]. \t  -434.10979476414707 \t -218.914703726932\n",
            "72     \t [-3.88279736  4.92566386  3.89841038  4.74826305  3.98631984  0.20963136\n",
            "  0.34908598 -0.64906254]. \t  -283.31794859152194 \t -218.914703726932\n",
            "73     \t [ 4.02391581 -4.94543332 -3.4421724  -4.14467667  0.17366159 -3.71483051\n",
            " -1.50141782  1.72526887]. \t  -291.9083467385876 \t -218.914703726932\n",
            "74     \t [-4.86907152  4.81740633  3.30467329 -3.35133793 -5.07559196  0.86952146\n",
            "  2.83042534 -3.71378388]. \t  -447.57237822345525 \t -218.914703726932\n",
            "75     \t [-5.06040861 -4.78834912  4.37638619  3.72693951  4.04424723  4.7214533\n",
            " -4.7482257   4.34471457]. \t  -708.8471848847856 \t -218.914703726932\n",
            "76     \t [-4.42798875  0.36629021 -2.8917049   4.42391222  3.5102884  -3.02908428\n",
            " -2.77770996 -3.60714972]. \t  -398.009964731996 \t -218.914703726932\n",
            "77     \t [ 3.06729971  4.6167786  -2.06024978 -3.99895939  4.35062598  3.07241453\n",
            " -5.0577762   1.07282421]. \t  -468.2916425698801 \t -218.914703726932\n",
            "78     \t [ 4.54919254 -0.72039803 -4.26474196  4.92348162  4.88246938  4.0321738\n",
            " -1.30767974  3.04990948]. \t  -476.38871258845006 \t -218.914703726932\n",
            "79     \t [ 4.19564871 -4.96703752  5.0441952   4.63865379  1.75346031  3.50763686\n",
            "  4.40595652  2.44140767]. \t  -502.1116975434759 \t -218.914703726932\n",
            "80     \t [-0.39853841  4.77424718 -0.62414894  2.99698303 -3.70378766 -4.36871694\n",
            "  4.16449827 -2.37782183]. \t  -432.5799756963927 \t -218.914703726932\n",
            "81     \t [ 2.10606344  1.29166194  4.67166354  2.29708922 -1.38270055 -4.19944863\n",
            " -4.8822017   0.94915946]. \t  -383.7820809018181 \t -218.914703726932\n",
            "82     \t [ 4.02257076  4.86282379 -2.20052268 -3.23205475 -2.59285061  4.67462563\n",
            "  1.17298258 -4.17444486]. \t  -433.55305415718806 \t -218.914703726932\n",
            "83     \t [-2.51014017 -5.04371265  3.78446455 -4.80932512  4.94363722  4.41638185\n",
            "  5.04370332  3.21681811]. \t  -692.7440953840234 \t -218.914703726932\n",
            "84     \t [-3.99884647 -1.39675053 -1.09669086  0.31025644  1.25581469 -4.04307072\n",
            "  4.31561356  4.42463868]. \t  -416.8407659825536 \t -218.914703726932\n",
            "85     \t [-4.15068248  4.75800056  0.95216861 -4.22625018  4.97981415 -4.88038033\n",
            " -3.92911013  4.40024086]. \t  -666.5336613014593 \t -218.914703726932\n",
            "86     \t [-3.82305389  5.08995274 -4.62382086  1.72034971 -3.02769872  3.25705383\n",
            "  4.77791532 -4.95267639]. \t  -607.9250963703118 \t -218.914703726932\n",
            "87     \t [-0.5508932  -4.61347784 -5.11130818 -4.82353419 -4.05459548  4.81691135\n",
            "  2.77637566  0.69217854]. \t  -493.51943509468384 \t -218.914703726932\n",
            "88     \t [ 5.04989603 -5.07940306 -4.79166163  2.40440637 -1.37356409  4.82977272\n",
            " -2.57988864  1.24787177]. \t  -377.54873272403796 \t -218.914703726932\n",
            "89     \t [ 4.58892216 -4.90032411 -4.5098325  -4.65231832  3.4098105  -2.00459347\n",
            "  4.14634386 -2.00070943]. \t  -451.2888750911872 \t -218.914703726932\n",
            "90     \t [-0.27772823 -4.68516644  2.47515865  0.15640653 -1.4554392   4.98473286\n",
            " -5.0199206  -4.86048497]. \t  -587.5244041643667 \t -218.914703726932\n",
            "91     \t [-3.45975698 -0.47378289  5.04778336 -3.45749087  4.407128   -1.97684596\n",
            "  3.93073285 -0.44964181]. \t  -367.00963444648465 \t -218.914703726932\n",
            "92     \t [ 3.96957335  3.7283753   0.94173518  4.60124014 -4.47202478  4.97040644\n",
            " -4.34284439  4.84691051]. \t  -699.092398824805 \t -218.914703726932\n",
            "93     \t [-4.19013545 -4.61385917  2.67100906 -3.74395294  3.46145995  3.28842516\n",
            " -1.73967255 -4.96621793]. \t  -480.88698356431405 \t -218.914703726932\n",
            "94     \t [-2.50050421  0.03977465 -1.04782291 -5.12       -4.42460411 -5.12\n",
            " -0.42825582 -5.12      ]. \t  -580.5781129902467 \t -218.914703726932\n",
            "95     \t [-4.26338279 -3.71667279  3.97133919  2.82627941  0.65424449  2.68508475\n",
            "  3.34072027  3.31476935]. \t  -336.4924821944162 \t -218.914703726932\n",
            "96     \t [ 3.42811619 -4.65411356 -3.9962143  -3.40553722  0.87807929  4.29515793\n",
            " -0.33150548 -4.03843304]. \t  -395.15965630675373 \t -218.914703726932\n",
            "97     \t [-4.90801339  0.00976962 -1.48145107  4.60425836 -3.21537152 -0.09172538\n",
            " -4.89210982  3.33378343]. \t  -423.6552743067479 \t -218.914703726932\n",
            "98     \t [-1.44112249  1.32424354  3.40929845  0.89863282  0.38603974  4.94145343\n",
            " -5.01942729  2.57839382]. \t  -420.4845629187468 \t -218.914703726932\n",
            "99     \t [ 0.12977286 -4.02053372 -3.12359485  4.1858697   3.72601373  4.61831503\n",
            "  5.07048438  4.80279462]. \t  -693.5950443148765 \t -218.914703726932\n",
            "100    \t [ 4.67710543 -4.2942679   4.81633202  0.72812545 -2.15964028  2.12037206\n",
            "  2.55838462 -3.79967135]. \t  -342.08205679853415 \t -218.914703726932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoQHSe2Dtd1m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a09bab8-3e63-4080-a3a0-859437476240"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 14\n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_loser_14 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_14 = dGPGO(surrogate_loser_14, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.51092275  0.07321281  0.29021573  4.05796049  2.04790979  2.19440232\n",
            "  2.22554503 -2.83832871]. \t  -217.39677218415014 \t -198.56808439329558\n",
            "init   \t [-3.32641768 -0.44194316  4.39028154 -5.01876852 -4.19919673  3.58605074\n",
            " -0.14724036  3.85879646]. \t  -454.63061220313574 \t -198.56808439329558\n",
            "init   \t [-1.97290047 -1.14723281  0.83400441 -3.95584327  2.74309309 -1.91932375\n",
            "  1.49514711 -4.78516309]. \t  -329.7622575537801 \t -198.56808439329558\n",
            "init   \t [-3.41610929 -0.71369695 -2.78726175  4.77498845  4.14657954  3.74438823\n",
            " -4.79065311  3.06685697]. \t  -533.1877350004759 \t -198.56808439329558\n",
            "init   \t [ 4.15903244  2.08827731 -2.76774455 -0.90689946  4.90131417 -1.75056937\n",
            "  0.97821769  0.36706653]. \t  -198.56808439329558 \t -198.56808439329558\n",
            "1      \t [-0.39837742 -2.80781146  4.30646237  1.1348259  -2.86625872 -4.7177257\n",
            "  0.49038928 -4.19648802]. \t  -393.90076362444245 \t -198.56808439329558\n",
            "2      \t [ 3.59823797  2.93493829 -2.22286357 -2.31644834 -2.60040072  1.67020778\n",
            " -1.69312657  2.29311986]. \t  \u001b[92m-179.14405714824883\u001b[0m \t -179.14405714824883\n",
            "3      \t [-0.47349161  3.6595987  -0.69062425  3.93976687  0.73643447 -4.52423201\n",
            " -1.53249713  3.04543123]. \t  -306.68823053687424 \t -179.14405714824883\n",
            "4      \t [ 1.41775929  3.17892187 -0.61864258  3.15578588 -2.39206936  2.17862635\n",
            "  4.61888672  4.83006183]. \t  -456.26845971029707 \t -179.14405714824883\n",
            "5      \t [ 4.39589311 -2.63238916 -0.42473053  3.46291368 -4.45295055 -3.32856296\n",
            "  0.33154344  4.17398955]. \t  -387.45788340642343 \t -179.14405714824883\n",
            "6      \t [-3.02903475 -3.64189089  2.97031185  1.27114666 -1.76031793  2.83831373\n",
            " -4.24804996 -4.841301  ]. \t  -446.29010964797953 \t -179.14405714824883\n",
            "7      \t [-3.80204832  1.78051287 -4.825323   -1.75193211 -1.96549208  2.23249824\n",
            "  3.99460947 -1.80533003]. \t  -289.9164660631186 \t -179.14405714824883\n",
            "8      \t [ 0.94625912  4.81600644  3.50275893  4.96812724 -3.02292999  4.53107502\n",
            " -1.11729281 -1.41313361]. \t  -376.4087046229012 \t -179.14405714824883\n",
            "9      \t [ 1.03301786 -4.88160905  5.03337305  2.76125417  2.99418971 -4.11353872\n",
            " -4.01783109  2.03992856]. \t  -447.8742705189637 \t -179.14405714824883\n",
            "10     \t [-4.93530372 -1.17825508  2.51745698  2.51577202  0.61961621  4.23884071\n",
            "  1.92198526  4.47748059]. \t  -367.4300929150804 \t -179.14405714824883\n",
            "11     \t [ 2.85539411 -4.88996184 -4.24883203 -2.0136527  -3.07932454 -1.30324947\n",
            "  4.3001305  -4.89762701]. \t  -505.28745116712275 \t -179.14405714824883\n",
            "12     \t [-2.66371784  3.67836989  4.95734547 -4.11077469  1.54961196 -3.27610606\n",
            " -2.54049005  0.2918652 ]. \t  -297.7397213919187 \t -179.14405714824883\n",
            "13     \t [ 2.40537967 -4.43519619 -2.68785928  5.10874445 -4.67211226  2.06291398\n",
            " -2.27837885 -2.59770597]. \t  -396.19715515339806 \t -179.14405714824883\n",
            "14     \t [-3.98337617 -3.51389608 -2.03891801 -0.53776836 -0.70464394 -3.66682906\n",
            " -0.30620155  4.53500197]. \t  -302.5332422325131 \t -179.14405714824883\n",
            "15     \t [ 4.96704707  0.03520955 -1.33614114 -0.15348861 -4.85467546 -1.36565613\n",
            " -4.22068731 -4.72895031]. \t  -462.7567371690855 \t -179.14405714824883\n",
            "16     \t [ 3.8884749  -3.58714251  4.28048641  3.76979024  2.30220927  2.11091249\n",
            "  2.39658266  3.96726884]. \t  -372.0239677779635 \t -179.14405714824883\n",
            "17     \t [-2.05772009  0.23529643 -3.38742704 -4.61709315  4.0902806   2.40618111\n",
            " -1.75729841  3.45449585]. \t  -359.51436161637804 \t -179.14405714824883\n",
            "18     \t [ 4.45153975  2.42816825  2.0255446  -4.02001109  2.31476411  4.99766206\n",
            "  4.56680765 -4.52874875]. \t  -595.2757253627606 \t -179.14405714824883\n",
            "19     \t [ 0.24115532 -4.94767888 -3.06003454 -4.72047739 -2.84711293 -4.8229136\n",
            "  4.96137231  2.57914121]. \t  -571.8557649366685 \t -179.14405714824883\n",
            "20     \t [-3.94377474 -0.40829514 -3.18736374 -4.91253618 -3.73338331  0.8404564\n",
            " -3.60996468 -1.53359636]. \t  -326.8638925668034 \t -179.14405714824883\n",
            "21     \t [ 1.41894243 -0.42524573 -4.46954293  4.51250395 -3.9897445  -4.25495932\n",
            "  1.98406377 -3.87678392]. \t  -479.7658456196911 \t -179.14405714824883\n",
            "22     \t [ 0.70074988 -3.95743257 -0.94542815 -3.5049789  -2.15340699  4.21862254\n",
            "  2.87921658  0.54949926]. \t  -274.04588443169376 \t -179.14405714824883\n",
            "23     \t [ 4.44013244 -4.81936548 -4.53083105  4.6655052   4.64382385  4.36048038\n",
            " -1.6029142  -4.80458401]. \t  -639.3861808093668 \t -179.14405714824883\n",
            "24     \t [ 0.62839832  4.70889113 -3.46987945  4.39097753 -0.43313369  4.56884717\n",
            " -3.9924195  -4.8522846 ]. \t  -584.1025524241154 \t -179.14405714824883\n",
            "25     \t [-5.12       -5.12       -4.62706439 -5.12       -5.12       -5.12\n",
            " -5.12       -5.12      ]. \t  -929.3043744797287 \t -179.14405714824883\n",
            "26     \t [ 2.71405456  1.73979496  4.238507   -4.52181917 -1.19665743 -3.75980245\n",
            "  4.35815971  0.83328596]. \t  -379.5885325782893 \t -179.14405714824883\n",
            "27     \t [-1.88169217  2.4411314   4.43093553 -1.37298771 -3.59201045  1.52585992\n",
            "  1.82445462 -3.94403153]. \t  -308.12466748606363 \t -179.14405714824883\n",
            "28     \t [-4.61918779 -1.71416302 -4.63372952  4.81013087  4.92743265 -0.62656288\n",
            "  3.566389   -1.27167783]. \t  -409.9020672014811 \t -179.14405714824883\n",
            "29     \t [-5.05526793  3.85003111  0.85595915 -4.57112717  2.96141259 -4.59078442\n",
            "  4.2326201   3.03276799]. \t  -510.2686211429887 \t -179.14405714824883\n",
            "30     \t [-2.85734626 -3.82316818  2.41209825  1.76390832  5.03574366 -4.47459953\n",
            "  3.53423417  0.6311657 ]. \t  -404.8462574991417 \t -179.14405714824883\n",
            "31     \t [-4.97613396  4.82808205 -0.64149981 -4.92414753 -2.2383558   5.05577022\n",
            "  4.20595758  4.19753595]. \t  -612.807219921953 \t -179.14405714824883\n",
            "32     \t [ 3.0518308   1.24544767  5.08487309  3.69177407  4.65216689  1.82436275\n",
            " -4.95668549 -0.58846562]. \t  -447.43506965842164 \t -179.14405714824883\n",
            "33     \t [ 4.53539613  0.21766946  4.31028056 -4.78257865  0.0531777  -4.49769939\n",
            " -4.63729102 -4.67362811]. \t  -614.555978878443 \t -179.14405714824883\n",
            "34     \t [ 4.26428858 -1.77991241  4.76554291 -3.25320422  0.0978536   3.76167624\n",
            " -5.04181401 -1.3317815 ]. \t  -412.0623626301501 \t -179.14405714824883\n",
            "35     \t [-2.16653722  4.27110866  0.94329541  2.29843962 -4.66641501 -4.30631317\n",
            " -4.03115637 -3.06842213]. \t  -474.1957492720553 \t -179.14405714824883\n",
            "36     \t [ 1.29512603  1.47888098 -3.33007366 -1.72259033  3.9461254   1.63102569\n",
            " -5.01164257 -4.32927594]. \t  -470.76693761054173 \t -179.14405714824883\n",
            "37     \t [ 0.36249109 -4.04087781  3.9716324  -4.80012774  3.69841142  1.46039956\n",
            "  0.20787699  4.7816369 ]. \t  -436.67802131557926 \t -179.14405714824883\n",
            "38     \t [ 4.62893912  1.73444535 -4.75375189  5.07622843 -4.80719864  4.80532157\n",
            "  4.56921527 -2.02809013]. \t  -631.4523108470972 \t -179.14405714824883\n",
            "39     \t [-3.7521143   0.5463932   3.91101225  2.75940412 -4.35072823  1.96260847\n",
            " -4.88684403  3.09289761]. \t  -452.47275720769915 \t -179.14405714824883\n",
            "40     \t [ 2.43805178 -2.90848894 -4.80756594  3.13462505  3.82024674  1.38649894\n",
            "  4.07804661  5.10071701]. \t  -540.561742479819 \t -179.14405714824883\n",
            "41     \t [ 4.21692788  4.49744187  2.28745553  3.27520704 -4.41465385 -1.90911654\n",
            "  4.21679914 -4.72172413]. \t  -538.9831240950099 \t -179.14405714824883\n",
            "42     \t [-4.53468821 -1.86958044  2.87498851 -2.01477772  3.72749079  5.04471485\n",
            " -4.57703112  0.27408732]. \t  -437.9993668596513 \t -179.14405714824883\n",
            "43     \t [-4.91342259  2.62611451  0.71846968 -2.64334385  5.05335564  5.114367\n",
            "  2.50444874 -4.31667766]. \t  -545.0303469021718 \t -179.14405714824883\n",
            "44     \t [ 5.03107414  3.60751295 -1.87033468  3.28919038  4.5931785   4.67371106\n",
            " -1.56049707  4.69641484]. \t  -535.1540056712837 \t -179.14405714824883\n",
            "45     \t [ 1.0767427   4.40760861  4.52120955  1.42219011  3.80705507 -2.22642263\n",
            "  4.23816896  4.9590656 ]. \t  -534.1111824113534 \t -179.14405714824883\n",
            "46     \t [-2.39316689  5.04331684  4.48235917  2.88997186 -3.27572529 -4.33473121\n",
            "  4.76793416  1.53184911]. \t  -494.57583353021437 \t -179.14405714824883\n",
            "47     \t [ 4.72913934 -2.30645511  4.53339207  1.44889222  5.01472892 -3.84339652\n",
            "  0.12255293 -4.31172367]. \t  -466.2568491549189 \t -179.14405714824883\n",
            "48     \t [ 0.57337198  3.18113248 -2.66678336 -4.89972848 -2.97719009 -4.94382051\n",
            " -1.02518221 -5.10991161]. \t  -545.1455555963 \t -179.14405714824883\n",
            "49     \t [ 4.49256633 -4.52634403 -2.43030459  1.89578855  4.81941591  1.4089427\n",
            " -3.68532017  3.99687468]. \t  -444.1696475996963 \t -179.14405714824883\n",
            "50     \t [ 3.8432084  -4.92276179 -4.73770622 -3.75932111 -2.5553544   2.47073133\n",
            " -4.51454486  3.34232761]. \t  -488.41827795363776 \t -179.14405714824883\n",
            "51     \t [-4.02511284 -3.73321252 -2.21736677  4.67332679  0.24321705 -3.47289547\n",
            " -3.09987026 -3.41542577]. \t  -379.43258933083496 \t -179.14405714824883\n",
            "52     \t [-4.89797297  4.48759638 -3.73944483 -1.50477039  1.60862279 -5.11884516\n",
            "  3.84844384 -5.09163062]. \t  -596.4999107267595 \t -179.14405714824883\n",
            "53     \t [ 4.771063    4.81496753 -5.1071876   1.42660585  1.632507    3.11050024\n",
            "  2.35882265 -4.69609576]. \t  -442.27327847494394 \t -179.14405714824883\n",
            "54     \t [-1.78359804 -3.56533645 -5.11561824 -3.23624435  4.64091845  2.86713653\n",
            "  4.99335662  1.26437364]. \t  -493.34407883840913 \t -179.14405714824883\n",
            "55     \t [ 3.98616068 -5.08580557  2.35517152  0.80369527 -1.84277488  4.16824202\n",
            "  0.06114862 -4.5327869 ]. \t  -372.4644925541079 \t -179.14405714824883\n",
            "56     \t [ 2.68550492  2.77767643  3.34967004 -3.29286456  3.18264289  4.59653131\n",
            "  2.58046316  3.60337845]. \t  -427.57650599826684 \t -179.14405714824883\n",
            "57     \t [-4.73086641 -4.8650459   3.76321574  3.64878882  0.71375156  2.87814596\n",
            "  4.32625023 -3.96473092]. \t  -474.4758263296067 \t -179.14405714824883\n",
            "58     \t [-0.42020953  3.95263994 -4.37718627 -1.33024026 -4.19488311 -4.70719731\n",
            "  1.10442916  4.40034564]. \t  -480.354877841665 \t -179.14405714824883\n",
            "59     \t [-4.69740763  3.39407234 -4.29508772  3.39127108 -0.94162195  4.63780908\n",
            "  1.453522    3.87084505]. \t  -414.5968187340818 \t -179.14405714824883\n",
            "60     \t [ 4.21064505 -3.34148542  2.7020819  -4.56108997 -4.52883799 -0.14669129\n",
            " -1.11600463  5.00671974]. \t  -457.1156703599248 \t -179.14405714824883\n",
            "61     \t [-3.85824556 -4.99363423 -3.46708016  3.90588437 -3.65390657  0.55741923\n",
            " -5.09291403  3.62016295]. \t  -516.8730050417385 \t -179.14405714824883\n",
            "62     \t [-2.49451252  3.58335156  4.85724406  4.98315878  4.70224216 -2.67279823\n",
            " -1.46555541 -3.59601244]. \t  -473.91327636426394 \t -179.14405714824883\n",
            "63     \t [-1.63610083 -4.8981661   5.03819628 -4.99796292 -1.10176614 -5.05986929\n",
            " -2.13386807  1.6503702 ]. \t  -440.0763182644959 \t -179.14405714824883\n",
            "64     \t [-4.94849447  0.92474297 -2.55703905 -3.88002598  4.32980955 -4.19050488\n",
            " -4.73707916 -0.97570857]. \t  -469.82538032632505 \t -179.14405714824883\n",
            "65     \t [-4.88997421 -1.99280877  5.05870473 -1.9490197  -2.98771215 -2.3053063\n",
            "  4.03414821  4.38903541]. \t  -468.36887289365717 \t -179.14405714824883\n",
            "66     \t [ 3.37997778  3.04065289  3.29233212 -4.19832427 -4.90921256 -3.87011687\n",
            " -5.04176351  2.73076071]. \t  -580.8982034373284 \t -179.14405714824883\n",
            "67     \t [ 4.32968656  3.45339146 -4.05245593  5.09514289  4.97427354 -4.00447404\n",
            "  5.11281255 -4.93247031]. \t  -793.2590646170327 \t -179.14405714824883\n",
            "68     \t [-4.2228092   3.65849036  1.45442504  4.42288911  4.74794207  1.28583452\n",
            "  2.95418795  0.31777541]. \t  -313.7284966025756 \t -179.14405714824883\n",
            "69     \t [-3.36445458 -1.83407205 -4.6426502  -1.45973175 -4.5287885   3.34815867\n",
            " -0.28661236  4.79174726]. \t  -445.3054511105204 \t -179.14405714824883\n",
            "70     \t [ 3.441201   -4.93389218  4.00239115 -4.82207135  1.19339669  1.88564925\n",
            "  5.00589676 -4.62148472]. \t  -576.3283435470056 \t -179.14405714824883\n",
            "71     \t [ 1.76701872  4.25654233  2.42072924 -0.06442414  4.61877374 -3.58708791\n",
            "  4.30936891 -4.84583442]. \t  -558.6751167742981 \t -179.14405714824883\n",
            "72     \t [-2.74088177 -3.78574713 -4.04076239  3.96037975 -4.94204006  3.23688632\n",
            "  5.06362139  0.56729469]. \t  -514.9377245514424 \t -179.14405714824883\n",
            "73     \t [-5.12       -0.81980531 -1.77527983 -1.03131716 -5.12       -5.12\n",
            "  1.35562443 -1.96698035]. \t  -373.4423940942729 \t -179.14405714824883\n",
            "74     \t [ 4.81031564 -5.08391902  3.49827193  4.63447174 -5.0881809  -1.51392905\n",
            "  4.82029677 -4.99830449]. \t  -703.1696546458896 \t -179.14405714824883\n",
            "75     \t [ 3.66068974 -4.92065277 -4.96439345 -4.68150019  4.57475894 -2.97041579\n",
            " -0.58754284  2.4109378 ]. \t  -429.9274110601041 \t -179.14405714824883\n",
            "76     \t [ 1.90514061 -3.56665686 -2.48619388  4.96112818  1.99236446 -4.3460203\n",
            "  3.72769311 -0.23812272]. \t  -376.9647206816334 \t -179.14405714824883\n",
            "77     \t [ 4.1692792  -0.01792313 -4.54331288 -4.334793   -1.22002147  4.74921092\n",
            "  0.84408284 -4.31460306]. \t  -451.156344419428 \t -179.14405714824883\n",
            "78     \t [ 4.81185495  2.37724727  4.68236884  5.04044024  0.45388768 -4.0274404\n",
            " -5.11057486  2.92887938]. \t  -551.6586730683501 \t -179.14405714824883\n",
            "79     \t [-4.65855077 -3.72138799 -1.70208876  3.51791609  4.71267411 -3.60764385\n",
            " -4.9550391   3.79261869]. \t  -583.6693961163407 \t -179.14405714824883\n",
            "80     \t [ 3.49601248 -4.60329464 -3.93648965  0.06654299  4.48151044 -0.42751887\n",
            "  4.25013556 -5.03134999]. \t  -531.5860515258532 \t -179.14405714824883\n",
            "81     \t [-0.45030723  3.89670983 -4.4545308   3.51665063 -4.50201133  0.23788106\n",
            " -3.10018841  2.45583487]. \t  -356.77456307545657 \t -179.14405714824883\n",
            "82     \t [-4.62925488 -4.65830939 -4.69568575 -2.81068809  0.61858217  1.266126\n",
            "  1.00085723 -4.89777432]. \t  -373.0271794618299 \t -179.14405714824883\n",
            "83     \t [ 3.91174128 -4.96714668 -1.04424025  1.76556003  0.39038672 -3.51964323\n",
            " -1.22148492 -5.01897756]. \t  -367.44153754722964 \t -179.14405714824883\n",
            "84     \t [-1.97065527 -4.04518494  3.23799606 -4.82201921  4.99549362 -4.54950457\n",
            " -4.77208749 -4.48426194]. \t  -730.3131653528321 \t -179.14405714824883\n",
            "85     \t [-0.76202844  4.92185364 -4.95210008  0.86343595  4.31971545  1.81380413\n",
            "  3.22623966  4.67118967]. \t  -486.04142642702453 \t -179.14405714824883\n",
            "86     \t [ 4.2219614  -1.678051   -3.75672675  4.3989763  -2.95560368  3.28417323\n",
            " -2.04024116  4.65335154]. \t  -453.95988681255125 \t -179.14405714824883\n",
            "87     \t [ 3.65986976 -0.5200619   1.03836117 -4.59257531  2.88866798 -3.66163716\n",
            " -4.7787233   3.39918589]. \t  -475.9937752949539 \t -179.14405714824883\n",
            "88     \t [ 3.77031213  4.66895776  2.58877271  1.17168763  3.96127035 -3.44440593\n",
            " -4.44489887 -5.07504402]. \t  -577.4005903387597 \t -179.14405714824883\n",
            "89     \t [ 1.97425396  4.64988637  4.21210059  0.11746943 -0.28979976  1.89255958\n",
            " -3.60804876  4.92181016]. \t  -407.25157871369015 \t -179.14405714824883\n",
            "90     \t [ 4.78468201  5.05985565  1.95309432 -1.41521906  1.17830244  4.22080685\n",
            " -2.26715798 -2.60530115]. \t  -297.6666083709912 \t -179.14405714824883\n",
            "91     \t [-2.45326184 -5.0957297  -4.87587091 -2.16638384  5.05977101  4.56249854\n",
            " -4.15872039 -4.46790736]. \t  -681.7136707245561 \t -179.14405714824883\n",
            "92     \t [-3.6651111  -4.91613935  1.30416596  3.81318564 -4.63741842 -4.94843592\n",
            "  5.01722023 -0.50824301]. \t  -557.7583124270807 \t -179.14405714824883\n",
            "93     \t [-1.4239411  -4.7338776   4.31109927  3.61955585  0.30515646  3.48285724\n",
            " -3.79108851  3.80731421]. \t  -444.8272376599396 \t -179.14405714824883\n",
            "94     \t [ 1.16339724 -4.82410115  0.36805958 -4.58323521  4.160855    5.08733571\n",
            " -2.14943321 -0.40490825]. \t  -407.8295073673714 \t -179.14405714824883\n",
            "95     \t [ 4.92272731  0.38316357 -5.03798328 -4.43720451  1.23262551 -3.57980692\n",
            "  2.38851832 -4.04656153]. \t  -434.84518870362996 \t -179.14405714824883\n",
            "96     \t [-4.71506588  4.78624144 -2.07916208 -0.09679898  4.01990392  4.55815533\n",
            " -5.02384676  4.67079592]. \t  -637.7170327090826 \t -179.14405714824883\n",
            "97     \t [ 3.1331172  -3.2775418  -3.88179948 -2.72435105 -4.6778556  -4.24239834\n",
            " -1.91397755  1.339144  ]. \t  -363.58339096731277 \t -179.14405714824883\n",
            "98     \t [ 4.06988253  4.28607066 -3.92501593 -0.84741056  0.04355286 -4.83972126\n",
            " -4.30530229  0.36578398]. \t  -373.7610890673372 \t -179.14405714824883\n",
            "99     \t [-4.70283868  2.4490052   3.71087316 -4.66854486 -4.70261392 -2.64076854\n",
            " -3.66473805  3.9545065 ]. \t  -534.1368747949849 \t -179.14405714824883\n",
            "100    \t [ 4.34039325 -5.00166443  3.49363536 -2.57730285  5.05973456 -4.13235133\n",
            "  3.4239275   0.99677863]. \t  -452.5327632773219 \t -179.14405714824883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq4J_FTytd4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a57bb7d-86e4-494a-8b1c-48f741f24cbc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 15\n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_loser_15 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_15 = dGPGO(surrogate_loser_15, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.79751023 -2.50366638 -2.53412486  2.14942059 -0.5370638  -2.79610411\n",
            " -1.00649405  3.91431921]. \t  -228.93586258775446 \t -111.84379356128198\n",
            "init   \t [-0.6429341   3.87507385  2.87260414  0.35035432 -4.99985399 -2.39865368\n",
            " -1.72857241  1.17580582]. \t  -247.18214418832017 \t -111.84379356128198\n",
            "init   \t [ 3.84255585 -0.47241396 -1.33929378  0.83608715  1.37927538 -3.11654164\n",
            " -0.55786658  1.52017343]. \t  -111.84379356128198 \t -111.84379356128198\n",
            "init   \t [ 3.74892071 -4.8478471  -1.40433719  2.34767012  1.9855191   0.6647632\n",
            " -3.76057172  2.51723021]. \t  -261.0681305251046 \t -111.84379356128198\n",
            "init   \t [-0.55198121 -0.67596996 -3.19596718 -4.19216237 -1.4139613  -0.32482896\n",
            " -2.05442948  4.53772941]. \t  -307.060259396398 \t -111.84379356128198\n",
            "1      \t [-0.52388747 -3.42929075  2.89517266  2.53504193  3.75358406 -1.1432719\n",
            "  4.15543613  4.50271513]. \t  -436.00483739485145 \t -111.84379356128198\n",
            "2      \t [ 4.14774515 -2.73925931 -3.09753322  0.4526622  -1.29476026  3.69406409\n",
            "  2.49410568 -2.35661698]. \t  -240.046390335786 \t -111.84379356128198\n",
            "3      \t [-2.09525434  2.85625188 -3.14465335 -4.11513009  1.1189636  -3.74713359\n",
            " -0.04451839 -3.50225484]. \t  -306.7568005812394 \t -111.84379356128198\n",
            "4      \t [ 2.30794585 -0.47809431 -1.98766893 -1.37636588  1.56641173  4.94587112\n",
            " -4.88684159 -4.82172875]. \t  -537.4129435681026 \t -111.84379356128198\n",
            "5      \t [ 5.02549587  1.117597    1.81591151 -2.3410321  -1.93506609  3.81286408\n",
            " -4.19099904  2.61844649]. \t  -343.3193897552946 \t -111.84379356128198\n",
            "6      \t [-4.0263796  -0.77383161 -2.05286055 -2.28787167 -4.97897206  0.38624297\n",
            "  0.90446435 -1.91092299]. \t  -210.77481949407985 \t -111.84379356128198\n",
            "7      \t [ 3.48232154  5.03687354 -3.01147096 -4.79352379  3.57661824  2.15634808\n",
            " -0.11212276  0.33631896]. \t  -274.83800310365143 \t -111.84379356128198\n",
            "8      \t [-5.03768506  3.53829612  2.48836388  3.38450011 -2.01893507  2.35152248\n",
            "  2.86583985  1.59267601]. \t  -246.1552212800262 \t -111.84379356128198\n",
            "9      \t [ 4.56854819  3.8372487  -3.63580412  4.98694191  4.41237249 -2.98081678\n",
            "  3.82862467  4.74467935]. \t  -622.8173527283325 \t -111.84379356128198\n",
            "10     \t [ 3.59897245 -0.60075779  5.05301321  4.3095355   0.26046326  2.61185244\n",
            " -2.46882197 -2.65365376]. \t  -304.8320789906985 \t -111.84379356128198\n",
            "11     \t [ 2.34833021 -5.11988695  5.07172838 -4.85377777 -0.17599614 -3.46856202\n",
            " -5.06975064  4.89663465]. \t  -673.4183168441568 \t -111.84379356128198\n",
            "12     \t [ 5.09447593 -2.1872201   0.59197015 -3.25114595 -4.50772758  4.63927925\n",
            "  4.97145223  4.47246255]. \t  -642.6188773944903 \t -111.84379356128198\n",
            "13     \t [-2.92054175  3.28229322  3.57371098 -4.78653471  0.05386906  2.83419154\n",
            "  1.84121191 -0.31830194]. \t  -232.78566767263152 \t -111.84379356128198\n",
            "14     \t [ 4.15875321  4.65001999 -4.70729707  4.66087436 -4.94228845  3.54640908\n",
            " -3.71048765  3.20555839]. \t  -590.0835839670559 \t -111.84379356128198\n",
            "15     \t [ 3.91212021  2.52773945  5.02637985 -3.48026889  4.07280558 -3.9793234\n",
            "  2.09866032  1.4711016 ]. \t  -378.4187476887283 \t -111.84379356128198\n",
            "16     \t [-2.92403523 -4.91169199 -0.56219093  3.87738452  3.57144051  3.22206089\n",
            "  3.91601104 -2.57059904]. \t  -404.15986524839275 \t -111.84379356128198\n",
            "17     \t [-2.8914385   1.08671104  3.7202034   0.68563558  4.35023604 -0.03197702\n",
            " -3.50651755 -1.97592856]. \t  -266.0553330118174 \t -111.84379356128198\n",
            "18     \t [-4.8710636   1.60582181 -4.29871524  4.60869162 -5.07769462  3.98908283\n",
            " -3.5168841   2.89989052]. \t  -547.5274404992564 \t -111.84379356128198\n",
            "19     \t [-1.73553666 -3.76103147  4.0475593   4.85195193 -2.9234933  -1.81836727\n",
            " -5.04424237 -0.95725435]. \t  -422.630938688367 \t -111.84379356128198\n",
            "20     \t [ 3.53749095  1.95014947 -4.63373577  5.06689628 -3.92876546 -1.1318539\n",
            "  4.3010156  -4.72593657]. \t  -580.2577885298107 \t -111.84379356128198\n",
            "21     \t [-5.00145947  4.84147102 -2.93288088  1.90710026  2.93749625  3.19723667\n",
            "  3.06872419 -4.14895115]. \t  -420.355973609686 \t -111.84379356128198\n",
            "22     \t [-4.89321921  0.67044909  2.6694813  -4.60746628  4.95292806 -4.66246971\n",
            " -2.74345119  3.79111633]. \t  -551.8913716105942 \t -111.84379356128198\n",
            "23     \t [ 3.80548816 -4.47297591 -0.52990148  3.62690297  1.17080698 -4.8662134\n",
            "  4.28426652 -3.65129538]. \t  -492.03123728392444 \t -111.84379356128198\n",
            "24     \t [-0.27212989 -4.02762662  0.0203437   4.23691424 -5.06801587  3.38706751\n",
            "  0.97670144  2.99291017]. \t  -379.91960993990267 \t -111.84379356128198\n",
            "25     \t [ 3.28280408 -4.86004996 -0.7300239  -3.3400747  -3.07250941 -2.19064267\n",
            " -2.46960669 -3.10817468]. \t  -300.21393579612385 \t -111.84379356128198\n",
            "26     \t [-2.42093556 -5.01489239  1.34351716 -2.44410711  0.69909453 -1.57665508\n",
            "  4.61405725 -3.99563531]. \t  -379.5751691687568 \t -111.84379356128198\n",
            "27     \t [-0.8704956  -2.07558054  3.77990911  3.14272296 -3.37821305 -4.63127811\n",
            "  4.8646515   0.00855032]. \t  -443.15226354920077 \t -111.84379356128198\n",
            "28     \t [ 0.18311197  4.71195689 -4.33448788  3.62255249  1.34858027  0.21366078\n",
            " -4.48232174 -3.67064753]. \t  -411.08844001015143 \t -111.84379356128198\n",
            "29     \t [ 1.65534033e+00  4.28605139e+00  1.57839601e+00  3.96939257e+00\n",
            " -2.06143120e-03  2.70495997e+00  5.10221935e+00 -3.56517399e+00]. \t  -437.7920290869329 \t -111.84379356128198\n",
            "30     \t [-4.56197848 -0.86663745  3.36407686 -2.91185916 -5.04540774 -3.45255604\n",
            "  2.43655697  4.8993994 ]. \t  -522.5726431581137 \t -111.84379356128198\n",
            "31     \t [ 4.53539239  3.39991656 -0.6703452  -4.57618355 -3.38267353 -1.26478534\n",
            "  3.32818324  1.0108024 ]. \t  -281.32445169974125 \t -111.84379356128198\n",
            "32     \t [ 5.02543486  4.27410741  4.12383291 -1.63413416 -3.8739765  -5.04322147\n",
            "  0.50570804 -3.97371061]. \t  -479.24671412225086 \t -111.84379356128198\n",
            "33     \t [-4.78838861 -4.64956131 -0.31229648 -2.69376485  4.91451828  4.02382978\n",
            " -2.25394018  0.57420334]. \t  -351.59265589106974 \t -111.84379356128198\n",
            "34     \t [ 4.81522095 -2.46836897  4.65725296 -3.49644325  4.35755382  0.2256203\n",
            " -3.9958259  -0.63123948]. \t  -359.5434023102729 \t -111.84379356128198\n",
            "35     \t [-0.04673122 -3.69781812 -2.92304684  3.41706583 -4.03134954  2.90759612\n",
            " -3.22770287 -4.1467515 ]. \t  -442.16229711771615 \t -111.84379356128198\n",
            "36     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -111.84379356128198\n",
            "37     \t [-2.58899936  3.25967556 -4.7156334   2.84133365 -0.15730322  0.58552946\n",
            "  4.47228926  4.71411969]. \t  -446.931973766469 \t -111.84379356128198\n",
            "38     \t [ 3.18211897 -3.63665185  4.93957302 -2.54564036 -4.76691554  0.01110285\n",
            "  4.52251456 -2.5745226 ]. \t  -445.5110956933015 \t -111.84379356128198\n",
            "39     \t [-4.59329134  2.13593618 -1.81428154 -4.75754736  1.27257425 -2.11006319\n",
            "  4.73482626  4.04505591]. \t  -453.27595434784484 \t -111.84379356128198\n",
            "40     \t [-4.87865974  2.0568111   1.74268696 -0.96811094  2.55981296  4.90345505\n",
            " -3.21551005  5.09561797]. \t  -502.24764839181046 \t -111.84379356128198\n",
            "41     \t [-3.8252446   4.61867952  0.72879989  3.56165727  3.18761879 -4.82491429\n",
            "  4.01281724 -4.65910072]. \t  -586.4919816007132 \t -111.84379356128198\n",
            "42     \t [-0.97249616 -4.38149479  4.61478275 -2.09220744 -0.73753982  4.7757387\n",
            "  0.68324453  1.67282229]. \t  -285.9590721654871 \t -111.84379356128198\n",
            "43     \t [-2.90091859  1.4314858  -4.44699515  4.36202213 -4.45102415 -4.60644161\n",
            " -4.5998389  -1.36446823]. \t  -537.3275966084966 \t -111.84379356128198\n",
            "44     \t [ 2.99832713  4.11968562  4.03696557 -1.08231237  0.72910515  3.95637247\n",
            "  4.90205191  3.54258301]. \t  -461.6956741486083 \t -111.84379356128198\n",
            "45     \t [ 3.71385474 -3.85925183 -1.44752699 -4.26284028  5.07158618  1.58542692\n",
            "  3.58020855 -4.98736208]. \t  -554.9554981681046 \t -111.84379356128198\n",
            "46     \t [-5.04238036 -4.88809143 -0.54100923  2.08000101  4.1893676  -3.63764978\n",
            " -4.92682848  1.90726756]. \t  -457.56197398231984 \t -111.84379356128198\n",
            "47     \t [-2.7548247   4.93410299  4.39440329  1.73918059  4.25476724 -4.23023732\n",
            "  4.32684802  4.97459614]. \t  -653.219959582728 \t -111.84379356128198\n",
            "48     \t [-2.28313577  3.4638722   0.05942026 -3.79567822 -4.93569353  4.98100222\n",
            " -5.02074166 -2.58659419]. \t  -587.4951505924079 \t -111.84379356128198\n",
            "49     \t [-4.07108799 -3.71071716 -2.82679607  4.5117079   4.76664006 -4.79790564\n",
            "  1.06599681 -3.44515064]. \t  -504.1375879151029 \t -111.84379356128198\n",
            "50     \t [ 3.18353106  2.69173732 -3.57434783  3.91161205  4.2087033   2.66152804\n",
            " -2.96533841  4.83540445]. \t  -503.8265114881208 \t -111.84379356128198\n",
            "51     \t [ 3.75589978 -4.28122825 -0.68589981 -3.48095504  3.82642022  4.47457953\n",
            "  2.94167574  4.86297022]. \t  -543.7448397382238 \t -111.84379356128198\n",
            "52     \t [-4.14529525  3.5962076  -3.54291897  2.92682512 -5.03473052  4.95409222\n",
            "  1.06475549 -3.86938704]. \t  -516.6848494340381 \t -111.84379356128198\n",
            "53     \t [-2.42580509  4.99553759 -4.04803476 -4.88732997 -1.70305538  3.32118679\n",
            "  3.69734561 -3.54122068]. \t  -477.19723618591763 \t -111.84379356128198\n",
            "54     \t [ 1.62833622  2.47427543 -4.82660524 -3.23014043 -3.03521305 -5.00519476\n",
            " -5.00318892  0.43865973]. \t  -499.6562533540806 \t -111.84379356128198\n",
            "55     \t [-3.22190568  3.4231673   4.20469012  3.80506017  2.100239   -4.64731895\n",
            " -4.11250987  4.96436387]. \t  -611.9579044185905 \t -111.84379356128198\n",
            "56     \t [-2.15618599 -4.15219492  4.73435744 -4.4914121  -4.76604735  0.38260198\n",
            " -4.66354546 -4.50546658]. \t  -616.1529045970638 \t -111.84379356128198\n",
            "57     \t [-2.13515405 -5.06611742 -4.89726449 -4.51830975  4.44597771 -4.22161232\n",
            "  2.76601529  1.01744175]. \t  -477.10310285433957 \t -111.84379356128198\n",
            "58     \t [-3.89806297 -3.39803779 -2.20456949 -3.64763333 -3.67342538  5.07928209\n",
            "  4.27258988  3.46729673]. \t  -552.3167639964997 \t -111.84379356128198\n",
            "59     \t [-0.49574855 -2.31321682  3.62655349  3.1124392  -3.92125912  4.3062726\n",
            "  3.20802661 -3.98634421]. \t  -476.46532416698744 \t -111.84379356128198\n",
            "60     \t [ 4.0677319   4.81468048 -0.50376172  4.67882702 -5.09143165  2.2509964\n",
            "  4.69718871  4.47498573]. \t  -625.9000968496756 \t -111.84379356128198\n",
            "61     \t [ 1.75961659 -3.63082762  2.56378848  4.07376943  3.41696135 -4.57459943\n",
            " -4.85259203 -4.97553359]. \t  -662.3843987004384 \t -111.84379356128198\n",
            "62     \t [ 4.59290591  1.76692903  4.3288903  -2.96907024  1.57168141  4.85828826\n",
            "  3.9603661  -4.94172708]. \t  -577.9437779934655 \t -111.84379356128198\n",
            "63     \t [ 4.94596929  4.34570262  5.08515199  4.56942148  2.61788413  5.06618136\n",
            " -3.79258788  4.03904455]. \t  -642.7884916814609 \t -111.84379356128198\n",
            "64     \t [ 4.0152087   4.43131066  2.7792571  -1.10596144  4.00887011 -4.50788763\n",
            " -4.72026993 -3.77276592]. \t  -555.5785844004531 \t -111.84379356128198\n",
            "65     \t [-3.44251966 -3.44648302 -4.20540773  4.5928151  -3.57582828  4.00222464\n",
            "  4.9457755  -2.90784706]. \t  -571.9486116679466 \t -111.84379356128198\n",
            "66     \t [ 5.06547664  3.54048027 -2.85280567 -0.84390675  5.11912781 -4.72578366\n",
            "  4.92550957 -3.4633796 ]. \t  -608.8033021647027 \t -111.84379356128198\n",
            "67     \t [ 2.34024548  4.78869672  2.64164414  2.29347154 -4.89836353  4.46059316\n",
            " -3.28282844 -3.85518285]. \t  -527.0042708316516 \t -111.84379356128198\n",
            "68     \t [-3.13848084 -4.51040857  4.76085833  4.51733385 -3.65493432  4.09797585\n",
            " -4.5592153   5.04648278]. \t  -716.954347188027 \t -111.84379356128198\n",
            "69     \t [ 3.83340596 -3.45366139  4.47254192  4.17294849  2.81400313  4.70002725\n",
            "  0.12699249  4.31329085]. \t  -489.29876376215896 \t -111.84379356128198\n",
            "70     \t [-4.23971411  2.2943966  -3.89109097 -4.54815718  3.18222485  2.61584967\n",
            " -0.49764297  1.00933439]. \t  -258.240767569897 \t -111.84379356128198\n",
            "71     \t [ 4.37734239 -1.62010583  4.83529512  3.73050474 -1.66107753 -1.66681097\n",
            " -2.03778991  4.33896981]. \t  -360.36434283295705 \t -111.84379356128198\n",
            "72     \t [-5.02123426 -4.22060935 -4.29334428  3.39530342  3.39629229  0.83537104\n",
            "  4.98079521  5.01755356]. \t  -599.17670781965 \t -111.84379356128198\n",
            "73     \t [ 3.55849609  0.9980438  -4.23442333  3.43860286  4.91930237  3.33429502\n",
            "  5.0402224  -5.03657694]. \t  -684.2086278333484 \t -111.84379356128198\n",
            "74     \t [ 2.44669597  5.03751323  2.81047641  4.72464963 -0.98437864 -5.04780635\n",
            "  1.91100183  3.01483902]. \t  -425.72962039685297 \t -111.84379356128198\n",
            "75     \t [-3.73235149 -4.77472408 -3.52801368  4.37075747  2.75990171  3.90331225\n",
            " -4.79133701 -1.5328906 ]. \t  -482.27792005082875 \t -111.84379356128198\n",
            "76     \t [-5.01143879  2.8699774  -4.70901023  2.4786914   4.75451715  0.43313557\n",
            " -1.91441203  4.91897279]. \t  -466.0660014508526 \t -111.84379356128198\n",
            "77     \t [-4.01340618  4.21062938  4.69371418 -3.38697388 -0.37030101 -3.08328625\n",
            " -3.08086918 -4.35898459]. \t  -439.7192520000723 \t -111.84379356128198\n",
            "78     \t [-4.31921884 -2.44050708  3.00849626 -4.39896651 -2.7103623   4.6276208\n",
            "  4.46257633 -4.78978075]. \t  -623.2822493041523 \t -111.84379356128198\n",
            "79     \t [-4.49874981  1.16546326 -4.59986117  1.57179277 -1.94251442 -4.85595152\n",
            "  4.99474781 -1.67829471]. \t  -453.82798477007503 \t -111.84379356128198\n",
            "80     \t [-1.89269169  4.90881099  2.72448039 -1.9495385  -5.05030912 -0.1814311\n",
            "  4.79756482 -4.79759849]. \t  -562.2239360133948 \t -111.84379356128198\n",
            "81     \t [ 4.26665992 -4.84080503 -0.36891454 -4.68797696  0.28079093 -4.48212392\n",
            "  2.27294455  2.99335605]. \t  -382.1641878536109 \t -111.84379356128198\n",
            "82     \t [ 1.27040319 -1.42042754 -4.30060053 -4.04015395  4.39865438 -4.47069341\n",
            " -4.99108775  0.23026219]. \t  -517.8902864586751 \t -111.84379356128198\n",
            "83     \t [ 3.63806693  1.58823031  0.30972912 -4.92744736 -2.85748717  2.71814113\n",
            " -1.08637682 -4.78621983]. \t  -392.3678441570606 \t -111.84379356128198\n",
            "84     \t [-5.12       -2.58560065 -2.43046406 -3.88938802  0.75319509  0.20914706\n",
            " -5.12       -2.98806343]. \t  -375.8438381851538 \t -111.84379356128198\n",
            "85     \t [-4.38817144 -2.18483043  4.26072436 -1.30472637 -4.90749577 -4.78705908\n",
            " -0.28787049 -3.07782913]. \t  -424.3511014174213 \t -111.84379356128198\n",
            "86     \t [-4.78100315 -3.34659814  3.43073775 -2.81229735  4.99064554  1.69921456\n",
            "  4.76268769  1.59417227]. \t  -433.17351469771495 \t -111.84379356128198\n",
            "87     \t [-2.26873459 -4.30805234 -4.94983089 -0.93676302 -4.40740389 -4.40846993\n",
            " -4.3292443   2.12807384]. \t  -500.4381316509543 \t -111.84379356128198\n",
            "88     \t [-4.63010611  2.91835566  3.19528694  4.98869494 -2.90345445  2.31318501\n",
            " -3.23004553 -3.59963981]. \t  -419.59616820846253 \t -111.84379356128198\n",
            "89     \t [-0.25768145  5.02845623  1.84019905 -2.16881434  3.33678961 -0.71695409\n",
            " -2.51409344  3.59434839]. \t  -285.9655110166432 \t -111.84379356128198\n",
            "90     \t [-4.47633853 -4.25027738  4.85977827  4.43887875  0.64686361 -4.99025723\n",
            " -1.79717551  3.97898228]. \t  -506.6096795039171 \t -111.84379356128198\n",
            "91     \t [ 3.40228584  0.17225395 -4.43869689  3.6978509  -4.87884532 -3.29927473\n",
            "  4.66472545  4.2569522 ]. \t  -607.0551083317055 \t -111.84379356128198\n",
            "92     \t [ 4.5378625  -1.80876201 -3.95117531  2.24705083  0.53434204  3.51827104\n",
            "  3.01191216  4.67405243]. \t  -408.14017154242356 \t -111.84379356128198\n",
            "93     \t [-0.42284189 -0.47297103 -3.73556293  2.41370649  5.07232732  1.75686633\n",
            " -0.8392576  -0.74770289]. \t  -222.35835394533882 \t -111.84379356128198\n",
            "94     \t [-2.72576676 -3.81156201 -4.12643414 -1.57943159 -2.56680335 -4.94562421\n",
            "  4.27985494  4.53068724]. \t  -569.6813199556725 \t -111.84379356128198\n",
            "95     \t [-5.12       -0.97154723 -0.61269536  0.04164009 -5.12       -1.48020696\n",
            " -5.12       -5.12      ]. \t  -566.6694062756596 \t -111.84379356128198\n",
            "96     \t [-4.15963825 -4.09644011  2.67405762 -0.27984747 -4.29195875 -2.36153346\n",
            " -3.96968761  4.43640363]. \t  -465.95719130923317 \t -111.84379356128198\n",
            "97     \t [ 5.03420759  5.05985813  3.90938694  3.21612961 -2.36765556 -1.65188165\n",
            " -4.60619828 -1.22937043]. \t  -368.78294592597354 \t -111.84379356128198\n",
            "98     \t [ 3.22689607 -0.33237271  0.74126573 -1.26206352  5.11724439  3.47968663\n",
            " -3.57609043  3.76776708]. \t  -425.32121827512094 \t -111.84379356128198\n",
            "99     \t [ 2.18951103  3.79632194 -4.70109151 -4.52416869  2.01531603 -2.91719319\n",
            "  2.99415587  4.22945682]. \t  -459.02008810909047 \t -111.84379356128198\n",
            "100    \t [ 1.3215368   1.8356774  -4.02849969  5.08636125  3.1340806  -5.04905694\n",
            "  4.89044952 -1.61192216]. \t  -550.9285763784783 \t -111.84379356128198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tJ-ta9Gtd7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a9f7ea-86ba-487c-c992-473f1f47b4bd"
      },
      "source": [
        "\n",
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 16\n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_loser_16 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_16 = dGPGO(surrogate_loser_16, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.72683092 -1.88041214  1.76282397  0.08101548  2.88420277 -2.21509961\n",
            " -2.72682205  0.65330879]. \t  -156.8066019097497 \t -156.8066019097497\n",
            "init   \t [ 3.84024949  2.2419755  -3.25497095 -2.62348378 -4.23877911  0.35067282\n",
            "  3.47852441 -0.5561546 ]. \t  -261.8650591886947 \t -156.8066019097497\n",
            "init   \t [ 0.26105361  3.64645501 -0.31006696  0.15828746  1.76956804 -4.75312845\n",
            " -1.21380639  1.33368774]. \t  -202.8033628398822 \t -156.8066019097497\n",
            "init   \t [ 1.67575729 -3.93174065 -4.05292123 -2.2111691  -3.83176859  3.19394297\n",
            " -2.91057129  0.66405444]. \t  -300.0085240682813 \t -156.8066019097497\n",
            "init   \t [-1.33059735  4.11084689 -1.25252503 -4.4633888  -4.89127772 -0.62411111\n",
            " -2.74874149  4.74659878]. \t  -475.05316372608854 \t -156.8066019097497\n",
            "1      \t [-4.38660667  1.62450493 -1.22519012  1.94388211  1.6423205   4.26907265\n",
            "  2.26974299  0.96861339]. \t  -210.5421323027258 \t -156.8066019097497\n",
            "2      \t [ 2.61028241 -3.36468155  0.93627224 -0.42091032 -2.46815808  0.35245197\n",
            "  0.09302001 -4.97280011]. \t  -261.8890695362936 \t -156.8066019097497\n",
            "3      \t [ 3.08840881  1.09355518 -2.27221671  0.20362313  5.04563824  3.88780797\n",
            "  4.45226401  4.09078879]. \t  -518.2023890662198 \t -156.8066019097497\n",
            "4      \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -156.8066019097497\n",
            "5      \t [-1.74419421 -2.97566387 -2.51770045 -0.22404063 -2.57004044 -3.18775746\n",
            "  2.26407505  4.33743539]. \t  -320.3539300741578 \t -156.8066019097497\n",
            "6      \t [ 2.96013115 -1.73092944  4.21146258 -2.95046952 -3.23495797  4.98687786\n",
            " -1.2761485   2.59996815]. \t  -369.8019723735642 \t -156.8066019097497\n",
            "7      \t [ 1.06085603  1.66769511  1.968799   -4.40016384  1.25028225  3.81733385\n",
            "  2.80577966 -1.3908571 ]. \t  -261.59302478121987 \t -156.8066019097497\n",
            "8      \t [-5.0154287   4.08468976 -5.10290307  3.05064696 -0.88664699  3.30734321\n",
            " -2.93221677 -3.757143  ]. \t  -416.54463631790196 \t -156.8066019097497\n",
            "9      \t [ 1.36723193  0.52425837 -4.65019601  4.93451875  0.75602746  0.68584194\n",
            "  2.25857245 -2.83815146]. \t  -270.5189253477478 \t -156.8066019097497\n",
            "10     \t [2.80027156 4.68890317 3.61855726 0.29264533 0.82952492 0.13475458\n",
            " 3.5531842  4.90102322]. \t  -375.52314712782993 \t -156.8066019097497\n",
            "11     \t [-4.93635129  2.55766944 -1.25848161  4.96559818 -1.43852606 -4.19444241\n",
            " -3.63998264 -3.7665619 ]. \t  -462.979991392237 \t -156.8066019097497\n",
            "12     \t [ 5.07381016 -0.62423772  3.32699763  4.55494027  2.87215991 -1.83760387\n",
            "  4.50582748 -1.87362703]. \t  -374.427993928474 \t -156.8066019097497\n",
            "13     \t [-2.72961452  4.59025582 -2.96237344 -0.34812156 -3.11193657 -3.98737154\n",
            "  3.84133375 -3.66064947]. \t  -430.7127037238413 \t -156.8066019097497\n",
            "14     \t [-2.96527307 -1.76419803 -3.96077435  4.52370751 -1.63436906  2.15953412\n",
            " -4.7718135   5.11170367]. \t  -553.7014335008497 \t -156.8066019097497\n",
            "15     \t [-4.44703603  4.54410352  4.11500256 -1.08286348  4.70679157  0.0671524\n",
            "  1.95659366  2.65975533]. \t  -310.7526839529857 \t -156.8066019097497\n",
            "16     \t [ 2.05381102  3.48611571  1.32054164  3.83589645  5.10022843  3.38232249\n",
            " -1.55773674 -3.09758995]. \t  -385.06063924382283 \t -156.8066019097497\n",
            "17     \t [-3.27180474  1.18483204  3.52227647 -3.41817601  2.50827484 -2.89990888\n",
            " -4.91003641 -4.66574765]. \t  -522.2942179348121 \t -156.8066019097497\n",
            "18     \t [ 2.64195265  4.08828057  5.11149862  1.50586971 -2.83926318  3.63957421\n",
            " -3.16295414 -2.43981117]. \t  -365.2982787729772 \t -156.8066019097497\n",
            "19     \t [-4.71861438 -4.38219512 -4.52160463 -4.3855915   3.38271861  1.48867488\n",
            "  0.17979007  1.17968276]. \t  -280.81129206841615 \t -156.8066019097497\n",
            "20     \t [-2.92825457  4.37622271 -4.21905334 -1.39039833  4.14848906  1.30862285\n",
            "  3.60128232 -5.05976184]. \t  -499.9303181123679 \t -156.8066019097497\n",
            "21     \t [ 4.04177992  1.47428667 -3.67172479  2.25261872 -4.38548637 -4.39066273\n",
            " -1.00623256 -4.65900297]. \t  -473.99284623621605 \t -156.8066019097497\n",
            "22     \t [-3.74983704 -3.56612205  3.89050857  1.34039754 -2.01613595  2.15190847\n",
            " -4.84291874 -0.28991912]. \t  -305.04830334632646 \t -156.8066019097497\n",
            "23     \t [-4.19854992  0.57139142  3.95725345 -1.67479664 -3.41688133 -0.57872753\n",
            "  3.86077617  0.64648399]. \t  -244.5477616911439 \t -156.8066019097497\n",
            "24     \t [ 4.85984191 -2.58365977  2.46734373  0.87176038 -4.16633707 -5.03058942\n",
            "  2.73456725  0.62874669]. \t  -352.41226651159417 \t -156.8066019097497\n",
            "25     \t [ 4.49795841 -3.69120205 -3.54131365 -3.92642595  3.41119339 -3.05068281\n",
            "  3.6368887   3.59239053]. \t  -456.6236345831135 \t -156.8066019097497\n",
            "26     \t [ 4.63972944  0.11753145 -1.38745268 -2.81489601  4.36834737  4.38362357\n",
            " -3.8424548  -3.07612649]. \t  -448.78522260279846 \t -156.8066019097497\n",
            "27     \t [-1.0595955  -3.55484511 -1.32588813 -4.30273363 -1.5678672  -4.50387203\n",
            "  4.56502399 -3.05128661]. \t  -460.08372011003786 \t -156.8066019097497\n",
            "28     \t [-2.35157916 -3.97864633 -3.75167564  3.06783018  2.74940641 -2.59671001\n",
            " -2.56868701 -3.41527267]. \t  -334.814081806295 \t -156.8066019097497\n",
            "29     \t [-1.07747177  5.00573725  2.54191571 -4.46743956 -3.70664373 -0.55836378\n",
            " -0.61914349 -4.71966964]. \t  -401.94410970687176 \t -156.8066019097497\n",
            "30     \t [-2.55530499 -4.22957844  0.91909462 -4.33924534  0.90277014 -2.86544281\n",
            " -4.40318032  4.49665213]. \t  -470.9732231318807 \t -156.8066019097497\n",
            "31     \t [ 1.19046239 -2.13713324  3.6576483   4.66306061  0.78705052  3.56359559\n",
            "  0.71301848  3.02711458]. \t  -293.822260445507 \t -156.8066019097497\n",
            "32     \t [-3.20429685 -4.07318169  3.37863001 -4.75400043  4.88396739  4.42329491\n",
            " -1.36748758  3.7266871 ]. \t  -528.9512834546574 \t -156.8066019097497\n",
            "33     \t [ 3.46790688 -4.16438465  2.20292265 -2.81898532  4.06417982  0.17076047\n",
            "  5.05171924 -5.00057051]. \t  -554.5033518274639 \t -156.8066019097497\n",
            "34     \t [-4.25167978  4.65469243  2.22069625  4.55644664  5.02231669  0.17278159\n",
            " -4.83861862  1.05240318]. \t  -458.29187996727217 \t -156.8066019097497\n",
            "35     \t [ 4.99763937  0.65772135  2.94094802 -4.23517263 -4.85013069 -4.59565853\n",
            " -2.03430448 -4.69569585]. \t  -573.2404098277572 \t -156.8066019097497\n",
            "36     \t [ 4.34238335  4.56699517  4.76809233 -4.76071053  0.35997674 -1.80077692\n",
            " -2.87997269  3.79957261]. \t  -413.0911716059033 \t -156.8066019097497\n",
            "37     \t [ 1.92571017 -0.21444117 -0.8520663   2.25417202 -4.7728601  -4.2596061\n",
            " -5.09256537  2.69575398]. \t  -488.7462495117321 \t -156.8066019097497\n",
            "38     \t [-2.30198491 -4.114028    3.56192318  3.2929331   2.72420648 -5.01135253\n",
            "  2.64281867 -0.09961387]. \t  -357.3443576764738 \t -156.8066019097497\n",
            "39     \t [-0.12434784  2.0880431   0.82521549  2.30521646 -4.78558349  2.47975489\n",
            "  4.6476726  -4.5208526 ]. \t  -498.149386328132 \t -156.8066019097497\n",
            "40     \t [ 4.67817331  4.55849632  4.85491302  3.7919512   4.54193498 -1.255337\n",
            " -3.44744091  4.47427749]. \t  -547.6195074696037 \t -156.8066019097497\n",
            "41     \t [ 4.35868468  4.81316319 -3.46033865 -3.71173163  4.30990807 -4.98813767\n",
            "  4.05920002 -3.92788529]. \t  -637.2924880100421 \t -156.8066019097497\n",
            "42     \t [-3.05974479 -4.61837211 -3.65231133  4.5489212  -4.32468498 -0.3021903\n",
            "  1.65656208 -4.22256957]. \t  -430.7221812734539 \t -156.8066019097497\n",
            "43     \t [-5.02158726  5.1097137  -0.59690091  3.98036252 -4.34853118 -0.23054776\n",
            " -3.31823151  4.11311684]. \t  -449.16069652107547 \t -156.8066019097497\n",
            "44     \t [ 4.08753094  3.80278865  0.51545972  4.84931683 -2.57791904  2.7718704\n",
            " -4.83079829  4.02783282]. \t  -512.9626120735163 \t -156.8066019097497\n",
            "45     \t [ 2.64335899  3.98200935 -4.07498359  2.42315181 -3.61422848 -3.69307168\n",
            "  2.57443626  4.92295351]. \t  -499.42700953233043 \t -156.8066019097497\n",
            "46     \t [ 0.68933462 -4.67434863 -3.60331356  4.78178738 -0.57047737  4.77416528\n",
            " -2.94450954 -3.95865409]. \t  -499.0294602618772 \t -156.8066019097497\n",
            "47     \t [-4.54712993 -4.26239023 -4.13988938  3.82109803  4.38574439 -0.83199017\n",
            "  1.10828074  4.58755041]. \t  -444.121512449962 \t -156.8066019097497\n",
            "48     \t [-3.72935728 -4.90281907  3.75412801  3.63958098  4.26317254 -0.85318639\n",
            " -3.95705375  4.98193725]. \t  -560.6562795233859 \t -156.8066019097497\n",
            "49     \t [-4.16258209  4.20157019 -3.12697445 -5.06627257  3.02287935  0.05464522\n",
            " -4.93149115 -1.05979617]. \t  -409.56534473368544 \t -156.8066019097497\n",
            "50     \t [-4.36430814 -4.60586277  3.85578681  1.20298627  1.25474422  5.02032013\n",
            "  4.38456929 -4.86674853]. \t  -595.0117747648459 \t -156.8066019097497\n",
            "51     \t [-4.17289804 -4.82385459  3.86174958 -4.4961787   1.51165099 -3.00276542\n",
            "  4.29234611  1.93929009]. \t  -414.1355042642413 \t -156.8066019097497\n",
            "52     \t [ 0.38928272  2.45928827 -3.81558986  2.97925771 -4.01645693  4.30021725\n",
            "  3.49268127  4.85463923]. \t  -556.9705978745857 \t -156.8066019097497\n",
            "53     \t [-4.79228502  0.40138387 -3.11677753 -4.64933422 -3.63985244  4.1161407\n",
            "  0.55276204 -1.77320626]. \t  -334.08757433690084 \t -156.8066019097497\n",
            "54     \t [ 1.56442697  3.6107359   4.78737444  2.57588286 -2.37779314 -4.57260313\n",
            "  3.06106236 -4.01586817]. \t  -472.1498056362909 \t -156.8066019097497\n",
            "55     \t [-1.33749447  3.49192936  0.30925999 -4.34185663 -4.72338305  3.01372465\n",
            "  4.35283366  4.82990019]. \t  -587.1704011304056 \t -156.8066019097497\n",
            "56     \t [ 4.98339761 -4.65246746 -4.93246837  4.40853799 -4.15153762  3.73959306\n",
            " -0.64731686  5.03082798]. \t  -594.3443563388361 \t -156.8066019097497\n",
            "57     \t [ 4.94413429 -3.11209493  4.57092772 -4.81806223 -3.70957362 -5.08477405\n",
            " -4.54286958  4.73206618]. \t  -746.8872643939474 \t -156.8066019097497\n",
            "58     \t [ 0.69067887  3.53713085  5.01788291 -2.76518872  4.46177056 -4.79087156\n",
            "  4.73562403 -2.37873488]. \t  -571.1238146022156 \t -156.8066019097497\n",
            "59     \t [ 5.03193175 -3.74793919 -3.9667936   3.83745279  0.61926464 -3.6318395\n",
            "  4.03096925  2.9993484 ]. \t  -426.29367423756264 \t -156.8066019097497\n",
            "60     \t [ 4.68546823  0.17925963  2.7234062  -3.90654977  5.08516265  4.19331226\n",
            " -4.66180498  4.86634981]. \t  -681.6886945532783 \t -156.8066019097497\n",
            "61     \t [ 0.4763013   4.15421911 -3.38098029 -4.91546583 -4.38445348 -3.62870496\n",
            " -5.02401865 -1.54820463]. \t  -536.6652403478621 \t -156.8066019097497\n",
            "62     \t [ 2.80789369  4.45935277 -5.00207449  3.0289322   4.76926865 -4.66913859\n",
            " -0.82609146 -4.70333051]. \t  -585.6981711694061 \t -156.8066019097497\n",
            "63     \t [ 3.97298031 -4.95943973 -3.53831788 -1.9433322   2.11117481 -1.46898094\n",
            " -4.54042793  5.11999683]. \t  -506.8979638507151 \t -156.8066019097497\n",
            "64     \t [-4.31152103  4.75173366  3.17060533 -3.70875683  2.52846913  4.88450014\n",
            " -4.48256072  4.87463128]. \t  -654.7904083706412 \t -156.8066019097497\n",
            "65     \t [ 2.51703577 -1.35795279 -4.0080319  -3.67928453  3.84941531 -4.31595722\n",
            " -4.98218848 -4.57496353]. \t  -639.4176946091469 \t -156.8066019097497\n",
            "66     \t [-1.49266722 -5.0730271  -5.0154347  -0.07242736  1.2163098   3.07735925\n",
            "  4.72461672 -2.18737341]. \t  -387.93273053954425 \t -156.8066019097497\n",
            "67     \t [-4.27049113 -1.21087166  1.939069   -3.76357723 -5.12       -4.39866566\n",
            " -2.65477471 -2.44744663]. \t  -433.5238536971619 \t -156.8066019097497\n",
            "68     \t [-4.31120081 -3.48565453  4.81111697  4.39240957  4.64762173 -4.17640837\n",
            " -5.10889015 -5.03509758]. \t  -787.6788454712179 \t -156.8066019097497\n",
            "69     \t [ 0.43800157  4.30840128 -3.58244185 -1.58323388  3.45252817  4.19930558\n",
            " -3.36792261  4.92042548]. \t  -524.3344480420718 \t -156.8066019097497\n",
            "70     \t [ 4.7406347  -4.94073952 -4.97769492 -1.227366    4.92522413 -4.73939477\n",
            "  1.88806247 -4.82528898]. \t  -618.9345901186159 \t -156.8066019097497\n",
            "71     \t [ 0.36827569 -5.12       -5.12       -0.7294947  -5.07555503 -5.12\n",
            " -1.16119491 -2.22453233]. \t  -468.4559394892432 \t -156.8066019097497\n",
            "72     \t [ 3.31154611  4.91078165 -2.25045129 -4.15549656 -4.45978752  5.08781276\n",
            " -2.38019905 -2.56991092]. \t  -490.72061585048397 \t -156.8066019097497\n",
            "73     \t [-4.68282726 -1.29259918  3.66621666 -3.60760487 -3.77784607  4.83427581\n",
            " -1.0231259   5.10538726]. \t  -545.0824604322567 \t -156.8066019097497\n",
            "74     \t [-5.07883318  1.83951699 -2.77788822 -3.22528062  4.41746685 -2.82831034\n",
            "  0.8278771   3.16367177]. \t  -327.75624028122536 \t -156.8066019097497\n",
            "75     \t [-4.77420929  3.74037609  2.8511903  -0.28202959 -3.2704286   4.22960311\n",
            " -1.22728009 -2.07681254]. \t  -281.3444110344335 \t -156.8066019097497\n",
            "76     \t [-2.78310225  1.56956308  2.95021309  3.96197501 -2.00831896 -5.00854206\n",
            "  1.60312366  4.85367324]. \t  -478.7078463101761 \t -156.8066019097497\n",
            "77     \t [ 4.05734676  3.36639869  4.69039279  4.95449571 -4.11467526 -4.3741028\n",
            " -4.66153594 -3.32685176]. \t  -643.4171839206099 \t -156.8066019097497\n",
            "78     \t [-3.64288651  2.86532304  0.59494027  4.97251567  3.79592075 -3.02523476\n",
            "  2.60527676 -2.42981478]. \t  -351.357896492636 \t -156.8066019097497\n",
            "79     \t [-1.39944958 -4.57111086 -2.85769668 -4.80214142 -4.43410974  4.36345104\n",
            "  5.04011352  1.85433985]. \t  -578.3628047256431 \t -156.8066019097497\n",
            "80     \t [-4.23655806 -3.77295404  2.65779993  4.9706204  -4.75462082 -3.89693366\n",
            "  5.08220057 -2.25712082]. \t  -592.1455000710192 \t -156.8066019097497\n",
            "81     \t [ 3.91331994 -1.70528395 -2.7501124   3.92755617  2.63457054  3.06134163\n",
            " -2.93436764  2.88550943]. \t  -323.340800794046 \t -156.8066019097497\n",
            "82     \t [ 3.30646965 -5.02627818  0.14842361  4.85251825 -4.95131932 -0.16359081\n",
            "  4.33541336  1.31883648]. \t  -423.9371951886513 \t -156.8066019097497\n",
            "83     \t [ 4.41513579 -4.65017503  5.01186831 -4.77910365 -4.64795289 -2.24396366\n",
            "  4.1561525  -2.54906907]. \t  -540.5842961065252 \t -156.8066019097497\n",
            "84     \t [-4.74064599 -4.64053424 -0.17329318  5.03521545 -3.22631304  2.92968065\n",
            "  4.81193412  3.43691164]. \t  -527.1720254950577 \t -156.8066019097497\n",
            "85     \t [-4.71679307 -4.78655347 -0.39613236  4.67803275 -3.95699707 -4.65887398\n",
            " -2.59444467  0.29533981]. \t  -412.412625447318 \t -156.8066019097497\n",
            "86     \t [ 4.38441813  4.66433428  4.36577041  3.76990138  5.00052777 -4.81842973\n",
            " -0.23452378 -2.23454335]. \t  -481.42409197172003 \t -156.8066019097497\n",
            "87     \t [ 4.74052362 -4.90020741  3.68886502  0.75126241  4.97188607 -0.51037276\n",
            "  3.87328151  4.36089863]. \t  -495.89418572383585 \t -156.8066019097497\n",
            "88     \t [ 3.75127274  4.87856292  0.52604642 -5.11802604  4.89870845 -4.04161314\n",
            "  4.15279364  4.47844416]. \t  -666.4458415787577 \t -156.8066019097497\n",
            "89     \t [-1.06075232  3.57064984 -4.57317015  3.56232704  4.62262133 -3.38849267\n",
            "  4.77002714  3.40096023]. \t  -567.6654191663055 \t -156.8066019097497\n",
            "90     \t [ 3.86696864 -4.44896075  5.07363234  4.152372   -2.83968277  3.50059329\n",
            " -4.73081938 -2.6385061 ]. \t  -526.9361493583731 \t -156.8066019097497\n",
            "91     \t [ 5.06778894 -4.63937613  0.50160176 -4.7015424  -3.78591906  4.57577504\n",
            "  3.88580641 -2.17499258]. \t  -498.73632377493385 \t -156.8066019097497\n",
            "92     \t [ 4.0449472  -3.86912304 -4.74521388 -4.31080674  0.41533456  4.93114062\n",
            "  3.16956359  3.9284262 ]. \t  -528.7278011504524 \t -156.8066019097497\n",
            "93     \t [-3.0832531  -4.79975059  0.16118056 -4.55243499 -0.39256642  2.75448107\n",
            " -3.99642047 -3.04425369]. \t  -370.7912740148163 \t -156.8066019097497\n",
            "94     \t [-0.73074114 -5.12       -5.12       -5.12        0.07042234 -5.12\n",
            " -5.12        0.00749089]. \t  -577.276028055549 \t -156.8066019097497\n",
            "95     \t [ 2.14503281 -1.10545975  4.10182492 -4.90252613  2.22436723 -1.63971245\n",
            "  2.82918696  2.2879954 ]. \t  -292.43966596296974 \t -156.8066019097497\n",
            "96     \t [ 0.40666819  4.62069211  3.05896749  4.40493463 -3.84277455  5.07967679\n",
            "  1.41055262  2.34161851]. \t  -434.9989204655395 \t -156.8066019097497\n",
            "97     \t [-0.40849909 -0.36837898  4.94197703 -1.42042469  3.42165913  3.76147471\n",
            " -3.60124114 -4.25756144]. \t  -461.00622115379997 \t -156.8066019097497\n",
            "98     \t [-5.12       -0.9872672  -5.12       -3.80792862 -1.36346807 -2.48965557\n",
            "  0.16788522 -5.12      ]. \t  -421.2063077287768 \t -156.8066019097497\n",
            "99     \t [-4.64578004  4.4108803  -4.84186472 -1.89028612  0.40988279  2.19124074\n",
            "  5.09304644  4.33215512]. \t  -506.48232419678163 \t -156.8066019097497\n",
            "100    \t [-1.89038501 -0.11112047  5.02357901  4.77948769  1.90872023  0.50725108\n",
            " -2.09580579 -2.40036336]. \t  -267.28195372454275 \t -156.8066019097497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqjDLo0otd9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee1e225-a0e2-4cab-9d75-910daac9e9dc"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 17\n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_loser_17 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_17 = dGPGO(surrogate_loser_17, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.55467805  2.36052095 -3.13991821  0.20149492  1.80616465  3.1175155\n",
            "  0.34317173  4.17827   ]. \t  -258.41326242861834 \t -235.79782281711795\n",
            "init   \t [-0.57875324 -2.49884457 -2.26647022 -4.67638414 -0.31769608  4.52212527\n",
            "  1.02815985  3.77559691]. \t  -360.3515407216042 \t -235.79782281711795\n",
            "init   \t [-1.56342663  0.20561354 -4.2801447   1.05706761 -4.41947127 -0.8235598\n",
            "  0.12249555 -4.00962754]. \t  -292.4074163867352 \t -235.79782281711795\n",
            "init   \t [ 4.87253618  0.77758176  1.94038044  4.01713279  4.85251496 -0.60490047\n",
            " -0.9483114   1.04745517]. \t  -235.79782281711795 \t -235.79782281711795\n",
            "init   \t [-1.91993985 -0.06178726  4.23457571  3.73427573  1.95047484 -4.92945438\n",
            "  2.09212815 -3.62478353]. \t  -413.83828931150714 \t -235.79782281711795\n",
            "1      \t [4.51401957 4.23400766 4.83433318 3.1296932  0.24588569 1.21802929\n",
            " 4.61282793 1.4098879 ]. \t  -339.57567715308704 \t -235.79782281711795\n",
            "2      \t [ 0.44209635  3.94428873 -2.87035824 -2.26924831  3.90993901 -4.45930514\n",
            "  2.82734457 -3.75319363]. \t  -441.0244672495591 \t -235.79782281711795\n",
            "3      \t [ 4.42595181  0.54614973  2.56689034 -3.13851565  1.0307697   2.47296272\n",
            " -4.33428986  0.81887648]. \t  -258.2261564362497 \t -235.79782281711795\n",
            "4      \t [-4.20941955 -4.31584018  2.06026664 -5.09485394  2.09607399 -2.80668053\n",
            "  1.0900119  -2.6554595 ]. \t  -305.49737571712524 \t -235.79782281711795\n",
            "5      \t [ 2.67117625  0.41299568  4.43883274  0.14211974 -1.31876413 -4.67433041\n",
            " -3.51524601 -1.16802904]. \t  -303.8717125415504 \t -235.79782281711795\n",
            "6      \t [-3.54981102  1.64712868  4.75022021 -2.68762755 -1.76612738  1.29808464\n",
            " -3.65160611  1.34769435]. \t  -248.19037042791027 \t -235.79782281711795\n",
            "7      \t [-4.43446054  5.08197854  0.75076171  2.56198624  1.63763772  2.63852708\n",
            " -0.19299006 -0.12646221]. \t  \u001b[92m-154.83237029755054\u001b[0m \t -154.83237029755054\n",
            "8      \t [-1.30613858 -4.33854085 -3.37026713  1.0355193   2.91986214  3.43611244\n",
            "  0.95342411 -1.86829135]. \t  -225.4735839852827 \t -154.83237029755054\n",
            "9      \t [ 1.09944193 -4.64316009 -3.32041737  2.08789452 -0.15464131 -4.29343284\n",
            "  1.9320331  -0.92008962]. \t  -238.46211790406912 \t -154.83237029755054\n",
            "10     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -154.83237029755054\n",
            "11     \t [ 2.95580948 -3.80049642 -4.96869453 -4.6953779  -4.79816573 -1.50424847\n",
            "  4.43468588 -0.72526383]. \t  -470.43611167134793 \t -154.83237029755054\n",
            "12     \t [-2.54364523  2.33883604  1.42069182 -4.05636986  3.70664301 -4.68960538\n",
            " -2.58664462  3.81251026]. \t  -453.04947291990277 \t -154.83237029755054\n",
            "13     \t [ 1.52304157 -2.35739009  0.7121777  -2.0496404  -3.69428374  4.58362589\n",
            " -2.43696327 -4.6762387 ]. \t  -442.5655423406065 \t -154.83237029755054\n",
            "14     \t [-4.22613976 -4.34074043 -4.81022554 -2.1370736   3.949608   -2.39092025\n",
            " -4.69858406  2.82883722]. \t  -474.0788755252838 \t -154.83237029755054\n",
            "15     \t [-4.80561505  3.37060646 -4.87158689 -0.42857934 -4.1316635   3.99450207\n",
            " -4.83850869  1.29478781]. \t  -476.12717467218414 \t -154.83237029755054\n",
            "16     \t [-0.15670324 -5.04547588  1.8267038   4.65806376 -3.75485528  3.37965816\n",
            "  3.71343154  1.82109122]. \t  -409.82421093482986 \t -154.83237029755054\n",
            "17     \t [ 4.78287702  3.12011018 -4.47839917 -2.24195684  4.59736692  3.8551014\n",
            "  0.51524812 -4.45400124]. \t  -478.0328814172733 \t -154.83237029755054\n",
            "18     \t [ 2.65953549 -3.70240546  2.94277433 -2.82448482  3.21976706  4.78076477\n",
            "  2.56065292 -1.06721442]. \t  -336.35830842717144 \t -154.83237029755054\n",
            "19     \t [ 0.56271723  3.93400983 -2.96044792 -5.01647803 -3.18069993 -1.38919401\n",
            "  4.82780518  2.71372461]. \t  -442.4542307084757 \t -154.83237029755054\n",
            "20     \t [-4.29450336  1.34782329 -4.44199496  4.43142777  0.47836868 -3.59255955\n",
            " -4.43738931  3.13143828]. \t  -454.68348084492396 \t -154.83237029755054\n",
            "21     \t [ 4.37155703 -1.02106606 -3.20646551 -0.47853375 -2.12385517 -3.63953652\n",
            " -3.59765806  3.75988674]. \t  -358.6830554758044 \t -154.83237029755054\n",
            "22     \t [ 1.08628319 -3.48748274  2.64021664  4.74032863  2.12378142  4.07071807\n",
            " -5.06192383 -1.46736377]. \t  -454.8636497255348 \t -154.83237029755054\n",
            "23     \t [-0.91364106 -4.0439668   2.63080503  2.87769095 -2.09830823 -2.05772773\n",
            " -2.7151601   4.27505243]. \t  -332.6630954149689 \t -154.83237029755054\n",
            "24     \t [ 5.01294029  4.43078465  0.66675486 -4.80069846 -4.78779884 -1.54983127\n",
            "  0.93312558 -3.0990618 ]. \t  -369.8692706852889 \t -154.83237029755054\n",
            "25     \t [-3.63476077  1.47298641  1.12651813  2.31550021 -3.34031307 -2.52281659\n",
            "  4.87011629  2.77773774]. \t  -364.5330806939506 \t -154.83237029755054\n",
            "26     \t [ 4.63517341  4.18357754  3.80711143  4.96063791 -3.68901948  4.11015782\n",
            " -5.02450531  1.92593404]. \t  -574.2015388377874 \t -154.83237029755054\n",
            "27     \t [ 3.59824761  5.07966004 -3.87096221  3.3794435  -0.92898592 -4.09273405\n",
            "  3.3233557   3.81448938]. \t  -453.7222685895868 \t -154.83237029755054\n",
            "28     \t [ 0.52899705  1.95534651 -0.86623995  3.03036951  5.00130821  4.61625821\n",
            "  4.99187172 -4.62651533]. \t  -645.5033638990153 \t -154.83237029755054\n",
            "29     \t [-0.19455442 -1.03866557 -1.89682342 -3.60794238  2.73980629 -4.49568544\n",
            " -4.97663562 -4.42579398]. \t  -553.9276647917729 \t -154.83237029755054\n",
            "30     \t [ 3.27623503 -1.21231288  2.88164635 -4.69764225 -4.88611499 -4.79671156\n",
            "  3.09869778  4.59984694]. \t  -620.7596285002005 \t -154.83237029755054\n",
            "31     \t [ 3.00421713 -2.40527194  3.83172606 -2.64846671 -4.16644571  3.721191\n",
            "  4.51825089  4.91896586]. \t  -599.0517271851368 \t -154.83237029755054\n",
            "32     \t [-5.00425446 -4.22243866  4.15918476  1.89921928  0.80078413  1.20751011\n",
            " -0.82049246 -3.9734022 ]. \t  -269.99574389958815 \t -154.83237029755054\n",
            "33     \t [-3.90590302 -2.07382626 -4.57162499  4.42836715 -0.22347088  4.33624174\n",
            "  1.13577027  5.00255495]. \t  -487.30051426579985 \t -154.83237029755054\n",
            "34     \t [-1.29698167  3.13657913  4.32072857 -2.66170263  0.17057728  3.10344997\n",
            "  5.05826999 -2.79002998]. \t  -405.01384764425046 \t -154.83237029755054\n",
            "35     \t [-3.14787765 -1.45190597  3.6662123  -0.54774788  3.69039092  2.12511912\n",
            "  0.60060294  4.0857959 ]. \t  -286.9152498939917 \t -154.83237029755054\n",
            "36     \t [ 4.76254396  3.08572617 -0.44898445  4.81856549 -4.5420816   3.05134397\n",
            " -1.68595412 -4.92107743]. \t  -507.8541319313182 \t -154.83237029755054\n",
            "37     \t [ 5.07407477 -3.95013039  4.69458446  3.59297264 -0.4760639   0.32835764\n",
            "  3.27628034 -3.91013279]. \t  -373.9397687130545 \t -154.83237029755054\n",
            "38     \t [-1.33371172 -4.61921658  4.80039486 -3.24979323  4.39390463 -4.99143563\n",
            "  2.16457989  4.05106469]. \t  -565.9345187071315 \t -154.83237029755054\n",
            "39     \t [ 0.82714986  4.76492341  3.66390202  0.38832699  4.90198693  3.56132511\n",
            " -3.80111585 -4.38153418]. \t  -537.936597015819 \t -154.83237029755054\n",
            "40     \t [-5.09682525e+00 -1.39062357e-03 -3.45047477e+00  4.52736287e+00\n",
            "  2.25862338e+00 -3.62551639e+00 -4.17984506e-01 -4.41246012e+00]. \t  -405.03754257808725 \t -154.83237029755054\n",
            "41     \t [-3.83303779 -3.38258738 -4.81728294 -3.91897274  2.31613609 -4.67852081\n",
            "  3.56855568  4.17550306]. \t  -555.402515201198 \t -154.83237029755054\n",
            "42     \t [-5.12       -1.58964118  0.62080657 -5.12       -5.12        0.37538802\n",
            "  1.12563746 -5.12      ]. \t  -487.7842353009871 \t -154.83237029755054\n",
            "43     \t [-5.00035202 -3.13798873 -3.19852679 -4.36507239 -4.89514704  1.23907022\n",
            " -4.84791862  4.95910579]. \t  -641.8867554950007 \t -154.83237029755054\n",
            "44     \t [ 2.83240812  4.51253025 -4.78662916  1.10368454 -4.32716596  4.74705451\n",
            "  4.03574054 -0.75838062]. \t  -469.7968549620438 \t -154.83237029755054\n",
            "45     \t [-4.85011297  3.96130963 -4.4323521  -4.51971434  2.6623591   3.76688158\n",
            "  3.25794934  1.23879682]. \t  -402.70978857672696 \t -154.83237029755054\n",
            "46     \t [ 4.73183114  5.01306721 -2.07444362 -0.90489156  0.55860006 -3.60022575\n",
            " -4.25405703 -5.00854793]. \t  -495.5305260230982 \t -154.83237029755054\n",
            "47     \t [ 3.56126847  3.78008096 -3.05309722 -1.39776146 -5.11222633  4.13422026\n",
            " -4.65302213  0.11191747]. \t  -461.9192751858122 \t -154.83237029755054\n",
            "48     \t [-0.52014047  3.82591952 -4.79993923  2.94805474  4.97403426  2.54462266\n",
            " -5.0055689  -0.68484738]. \t  -475.1261016855098 \t -154.83237029755054\n",
            "49     \t [-4.11950665  5.10956046  4.82557948  0.27090618  0.95587543  5.09315761\n",
            "  4.2359921   4.91695626]. \t  -618.5648542196219 \t -154.83237029755054\n",
            "50     \t [-4.94657431  3.17471554 -3.15416689  1.79033827  3.4591273  -2.88623643\n",
            "  3.75004879  4.77271212]. \t  -477.7740679697948 \t -154.83237029755054\n",
            "51     \t [-3.21350292  3.32374175 -0.07493218  4.50393421 -5.07158729  5.09937734\n",
            "  3.87928789 -4.0504296 ]. \t  -634.7965025762282 \t -154.83237029755054\n",
            "52     \t [ 2.82976832 -2.4217753  -5.05722168  4.83204092 -1.25670599  3.78646333\n",
            " -4.9077536   5.10597075]. \t  -660.9487243823793 \t -154.83237029755054\n",
            "53     \t [-2.33054222  4.55087069  1.98279194  2.03287362 -2.95502891 -0.12780927\n",
            " -4.85470863 -4.93378833]. \t  -478.6514671861531 \t -154.83237029755054\n",
            "54     \t [-4.07487897  5.06606509 -4.87904866 -3.60511861 -1.27791206 -2.04958025\n",
            " -4.67755653 -3.4529159 ]. \t  -473.24528094062015 \t -154.83237029755054\n",
            "55     \t [ 2.31899075  4.7576258   3.63603653 -3.79024871 -3.28421349 -0.34428599\n",
            " -0.60708451  4.71854292]. \t  -383.11247869567876 \t -154.83237029755054\n",
            "56     \t [ 5.01663022 -3.4226084   0.57647927  3.68497958  3.26428984  3.69778525\n",
            "  5.04748773  2.86163367]. \t  -483.07949851808405 \t -154.83237029755054\n",
            "57     \t [-4.59570578  4.68522069  2.27076985 -4.69100236  0.41317154 -3.7889447\n",
            "  0.76328375 -3.0366967 ]. \t  -333.35489196769987 \t -154.83237029755054\n",
            "58     \t [ 2.75777563 -4.73614797 -5.01852492 -0.97609475  4.8160879   2.20085829\n",
            " -3.97883083  5.11416783]. \t  -596.9268833989476 \t -154.83237029755054\n",
            "59     \t [ 2.85429341 -3.5996131  -0.73716145 -3.24371033  4.26931085  4.51365198\n",
            " -4.53847632 -4.97559398]. \t  -633.3883227081569 \t -154.83237029755054\n",
            "60     \t [-3.99025624 -3.55923974  4.66929271 -4.30571933 -3.42540505 -3.98652215\n",
            " -4.52968668 -3.3436235 ]. \t  -567.9084059667042 \t -154.83237029755054\n",
            "61     \t [-4.52898952  3.37788903  4.53343828 -5.03032655 -4.84499859  4.30050995\n",
            "  4.64966595  3.35415419]. \t  -675.8798714269002 \t -154.83237029755054\n",
            "62     \t [ 1.80424288  0.5384617   4.12328527  0.35337235 -4.44760677 -3.98788886\n",
            "  5.0590758  -4.955521  ]. \t  -625.2819254591919 \t -154.83237029755054\n",
            "63     \t [ 3.77569901  4.62693581  0.39152703  2.790895   -4.9183072  -4.70680128\n",
            " -3.79245823  2.58521031]. \t  -496.7075058336996 \t -154.83237029755054\n",
            "64     \t [ 4.63258521 -4.8859887   1.68873066  3.35631205  3.52755925 -5.10180205\n",
            " -0.41790751  4.89379735]. \t  -534.0265959163103 \t -154.83237029755054\n",
            "65     \t [ 3.39667359  3.05872272 -0.68970424  4.55599602  2.05115651 -4.84070612\n",
            "  3.86172903 -4.99082515]. \t  -579.9926085189783 \t -154.83237029755054\n",
            "66     \t [ 4.5395903  -4.75596365  1.20136778 -3.72442614  0.3948449  -4.20847612\n",
            "  1.70378651 -1.86551391]. \t  -280.8700108062407 \t -154.83237029755054\n",
            "67     \t [-4.95438336 -0.77895465  5.11133924  4.39758958  1.00931633  4.33707641\n",
            "  4.80854218  0.26578887]. \t  -461.86668054639557 \t -154.83237029755054\n",
            "68     \t [ 2.98727384  1.5858213  -4.55512747 -4.9026551   4.63313179 -3.73558921\n",
            " -0.11006864  4.38894839]. \t  -517.5901916765552 \t -154.83237029755054\n",
            "69     \t [-2.18858743  2.88621404 -0.75378283 -4.96866475  1.41923851  4.79033088\n",
            " -5.05383517 -2.08566885]. \t  -483.2491363161326 \t -154.83237029755054\n",
            "70     \t [ 4.97553073 -4.73010372 -4.88708073  3.17369742 -4.62586496  1.28193946\n",
            "  3.40596497 -1.56659931]. \t  -399.1351585740257 \t -154.83237029755054\n",
            "71     \t [ 3.3923223  -0.57101074  3.475672    4.26622959 -4.65864496 -2.00656875\n",
            "  3.55910424  5.09219643]. \t  -549.9907539085957 \t -154.83237029755054\n",
            "72     \t [ 4.86897793 -4.42927849  3.59502936  0.2299465  -2.97113226  4.26058214\n",
            " -3.64688046  4.57258805]. \t  -515.3483192448512 \t -154.83237029755054\n",
            "73     \t [-2.39730592  5.02535959  2.30238477  4.58693365 -3.35240958 -1.22327265\n",
            " -2.08480608  5.01860682]. \t  -453.40617717022474 \t -154.83237029755054\n",
            "74     \t [-4.7773965   1.6388035   2.99664197  2.42803223  3.28385928 -5.0577227\n",
            " -4.51225545  0.71425385]. \t  -432.7222474967092 \t -154.83237029755054\n",
            "75     \t [ 2.97917011  0.83769598  4.90911078 -3.85024382  2.65531598 -3.00477745\n",
            "  5.06600858 -4.7684909 ]. \t  -592.8593239027853 \t -154.83237029755054\n",
            "76     \t [-4.35100233 -2.13302938  0.63040436  2.77416749 -4.12888302  4.82343107\n",
            " -4.19138565  4.05861072]. \t  -539.5909624812895 \t -154.83237029755054\n",
            "77     \t [ 3.9370151  -3.91418331  0.22322576  5.0566556  -0.01537934 -4.6313636\n",
            " -3.12163946 -3.83752897]. \t  -463.2941168918678 \t -154.83237029755054\n",
            "78     \t [-4.09828841 -3.13278195 -2.11163655  3.69490178  4.11380192 -3.23552803\n",
            "  4.83693718  0.63435067]. \t  -418.83045347156434 \t -154.83237029755054\n",
            "79     \t [-2.40207364  3.12557418 -4.88078672 -2.72394215 -2.95564201 -3.6340501\n",
            " -1.58798733  5.03345133]. \t  -469.7080699748152 \t -154.83237029755054\n",
            "80     \t [ 3.75165227  0.22047447  4.7260001  -4.18738255  4.36443052 -0.05872053\n",
            "  5.04482862  2.41639216]. \t  -471.439670833272 \t -154.83237029755054\n",
            "81     \t [ 4.93310931  2.68752722 -5.03342398  4.10077471  0.94751776  1.04943439\n",
            " -2.0994416  -2.74582538]. \t  -284.3195226642413 \t -154.83237029755054\n",
            "82     \t [-1.2293496  -4.87924341  4.07737438 -2.25992952 -3.2682472  -1.21936716\n",
            "  3.87049437  0.6202788 ]. \t  -289.70079341779035 \t -154.83237029755054\n",
            "83     \t [ 2.43135514 -3.73967763 -4.85546599 -3.08391515 -5.10546728 -0.40487743\n",
            " -5.10832204 -3.03861315]. \t  -530.4932184946532 \t -154.83237029755054\n",
            "84     \t [ 3.70459704 -3.83389453  1.52146762 -1.78125913 -5.09134432  4.54156504\n",
            "  5.11364121 -4.6529923 ]. \t  -672.3694575038446 \t -154.83237029755054\n",
            "85     \t [ 2.33040163  3.63640521  4.03551548 -4.71026884 -4.21985888  4.74189044\n",
            " -5.11453316 -2.45648591]. \t  -624.8132686372315 \t -154.83237029755054\n",
            "86     \t [ 5.04632239 -4.54374358  2.41661669  4.56771    -5.01572358  4.42288152\n",
            " -2.29749721 -4.00251086]. \t  -576.001488495334 \t -154.83237029755054\n",
            "87     \t [-5.01823006 -4.15202752 -2.95783056  0.82621673 -4.44979771 -2.01053529\n",
            " -0.43790762  2.52921606]. \t  -264.41294270607847 \t -154.83237029755054\n",
            "88     \t [ 2.34524329 -3.45310237  5.11815947 -3.3780792   3.07314094 -4.35134941\n",
            " -5.10833632  4.56870313]. \t  -664.0568557777133 \t -154.83237029755054\n",
            "89     \t [ 4.61161233 -5.05189994 -3.64634601  1.35480473 -1.38254408  0.70722752\n",
            "  1.11536605  4.73754458]. \t  -320.3609399368072 \t -154.83237029755054\n",
            "90     \t [ 1.1559311  -3.43748914 -4.93555757  4.79010891  3.35578481 -4.74473106\n",
            " -4.44163072  1.50141031]. \t  -537.3403422114853 \t -154.83237029755054\n",
            "91     \t [ 2.73048326 -4.65267942  0.33065316 -3.7524744  -4.56661885 -0.57340618\n",
            " -4.87675271  2.71485694]. \t  -439.08805207078063 \t -154.83237029755054\n",
            "92     \t [-4.62109779  0.25233199 -4.75043983 -2.34870285 -4.30927618  4.94976137\n",
            "  2.62961684 -0.34791021]. \t  -400.4702005763574 \t -154.83237029755054\n",
            "93     \t [-1.61580475 -4.44123896 -0.98882492  3.83579623 -4.56295729 -2.38943137\n",
            " -4.26045074 -2.31727087]. \t  -412.22391464490204 \t -154.83237029755054\n",
            "94     \t [ 0.49266351  4.71690655 -3.23386498  4.52234177 -4.57172173  5.11055321\n",
            " -1.91099837  3.12593826]. \t  -522.8661266468455 \t -154.83237029755054\n",
            "95     \t [-3.26939703 -4.50819772 -4.70386133 -4.58666328 -0.59065935  0.53103189\n",
            "  4.18564013 -2.59104689]. \t  -381.6471411433107 \t -154.83237029755054\n",
            "96     \t [-5.10135218 -3.70916626 -0.62555835  4.49575315 -4.69152086  4.26692711\n",
            " -3.03128936 -4.07899698]. \t  -552.2793573201636 \t -154.83237029755054\n",
            "97     \t [-4.25053793  5.09481718 -4.02898053  4.48813351 -2.15225532 -4.06170606\n",
            "  5.01883804 -1.95481279]. \t  -528.2900620557837 \t -154.83237029755054\n",
            "98     \t [-3.84360278 -4.75053128  2.09089633 -4.33680627  0.76651909  4.03714317\n",
            "  4.29324534 -2.22375223]. \t  -417.56866238051435 \t -154.83237029755054\n",
            "99     \t [ 2.01121253 -3.92906408 -0.40105954  4.47276101  4.68258359 -0.73264798\n",
            "  3.947886   -4.8902254 ]. \t  -528.6936212540974 \t -154.83237029755054\n",
            "100    \t [ 1.61687133  4.88987403 -2.25003942  2.77565628  3.84821883 -2.33911025\n",
            " -4.46991052  3.71278916]. \t  -453.4528005753383 \t -154.83237029755054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOqNmgSIteAw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2cf8cee-12e4-47bd-d4e9-6bda1f3ee649"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 18\n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_loser_18 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_18 = dGPGO(surrogate_loser_18, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.82391708  4.79785639  3.78055209  0.31596228 -2.73686192 -5.00327624\n",
            " -0.7119993  -0.99992207]. \t  -303.134303896496 \t -81.06401370190679\n",
            "init   \t [ 0.23218863 -0.22126801  0.56685029  0.44427282  2.67157069  2.17471564\n",
            "  1.22554466 -0.75682027]. \t  -81.06401370190679 \t -81.06401370190679\n",
            "init   \t [-2.15987171  4.85227767 -1.70215377 -2.87947714 -4.44612211  4.9445944\n",
            " -3.8107575  -1.82138068]. \t  -467.3384008943868 \t -81.06401370190679\n",
            "init   \t [-4.39354527 -2.81835582 -1.08917847  4.05652485 -1.58247309  4.96383424\n",
            " -4.82578382 -1.5187483 ]. \t  -446.39910875588674 \t -81.06401370190679\n",
            "init   \t [-1.21898097  2.70499975  4.49335207 -1.84637648 -0.69144645 -2.35370761\n",
            "  3.08281228  1.41556537]. \t  -208.5138761485756 \t -81.06401370190679\n",
            "1      \t [-4.72153807 -0.54862943 -3.19311344  1.30104982 -2.91514573 -3.5740661\n",
            "  0.3701177  -4.09203923]. \t  -314.305007357293 \t -81.06401370190679\n",
            "2      \t [ 2.67208712 -3.99037457 -2.148488    2.12737496 -3.90449112  2.55198214\n",
            "  0.12951135 -1.26301138]. \t  -199.1170525956219 \t -81.06401370190679\n",
            "3      \t [ 0.15531131  0.46668818 -4.01191051 -5.07342816  0.13730905 -0.46181146\n",
            " -0.5783223   5.06091098]. \t  -360.32233275140186 \t -81.06401370190679\n",
            "4      \t [ 4.11717363  3.03178758  2.01395375  1.63361829  4.47315693 -4.65011712\n",
            "  2.84599778 -3.76540159]. \t  -458.0885710056757 \t -81.06401370190679\n",
            "5      \t [-2.87613589 -2.36204857  3.86377212  4.81924511 -2.69254788 -0.09132169\n",
            "  3.3245157  -2.45169484]. \t  -318.8698045732099 \t -81.06401370190679\n",
            "6      \t [-3.49604359  1.45404494 -3.00825081 -3.19957983  4.90675057 -3.87056056\n",
            "  3.96577407 -2.81992642]. \t  -468.52464537528124 \t -81.06401370190679\n",
            "7      \t [ 4.63943718  2.6418305   1.38018945  4.29681613  2.63944848 -1.33298341\n",
            " -5.01709517  3.81276913]. \t  -453.0390834067 \t -81.06401370190679\n",
            "8      \t [ 5.08894648 -1.67538878  5.09575663 -3.06496959 -2.55374005  2.8402276\n",
            " -3.67330473  0.5368607 ]. \t  -324.7548195578733 \t -81.06401370190679\n",
            "9      \t [ 3.42223172 -2.12609735  4.8724154   2.39456946  4.42401398 -2.15469862\n",
            " -4.63598713 -5.02420695]. \t  -593.0131323017791 \t -81.06401370190679\n",
            "10     \t [-1.3478826  -3.9832212   4.72092649 -1.05778748 -3.56621932 -3.20173497\n",
            " -2.46251187  3.52569953]. \t  -371.87444035839957 \t -81.06401370190679\n",
            "11     \t [ 0.5305035  -2.40387146 -3.76947124  3.21663621  2.98389133 -2.09566893\n",
            " -3.69003782 -4.68456234]. \t  -437.5970195478538 \t -81.06401370190679\n",
            "12     \t [ 0.66447811 -3.83879279  0.73747644 -5.1199266   1.03763825 -0.97638321\n",
            " -3.15968102 -3.99483008]. \t  -345.0582379153705 \t -81.06401370190679\n",
            "13     \t [-1.12836081  4.69959827 -2.01832734 -3.58443072 -4.38360641  0.45474381\n",
            "  4.09898035 -1.18589722]. \t  -335.2422306188787 \t -81.06401370190679\n",
            "14     \t [-5.01459895e+00  2.73714762e+00  3.96484086e+00 -4.15403894e+00\n",
            "  1.53519887e+00  4.30126008e+00 -2.26250200e+00 -4.69660105e-03]. \t  -314.93599540925555 \t -81.06401370190679\n",
            "15     \t [-4.53980895  4.82572514 -1.17884387  2.7072872   4.94556367  0.2644122\n",
            " -0.64466555  3.46705064]. \t  -322.4569060693718 \t -81.06401370190679\n",
            "16     \t [ 3.650717    4.32278292  3.413414   -2.97229375  0.39380264  4.88043189\n",
            "  3.73331733 -4.52521879]. \t  -526.0644887363746 \t -81.06401370190679\n",
            "17     \t [-0.847513    5.11237294 -2.43290045  3.325202    4.95436671  3.91088864\n",
            " -3.90974155 -3.0770196 ]. \t  -512.2218770901723 \t -81.06401370190679\n",
            "18     \t [ 1.02429915  3.07391046 -4.27444879 -4.44802406  0.89057239 -3.76330187\n",
            " -4.62863464 -4.05718832]. \t  -524.4957172824636 \t -81.06401370190679\n",
            "19     \t [ 2.37105638  4.49385045  3.73577117 -2.45426     2.33699621  1.88631846\n",
            " -4.77091917 -3.24998846]. \t  -404.4608480089342 \t -81.06401370190679\n",
            "20     \t [ 3.0662871   4.52716193 -4.61899346  2.61714159 -1.89096243 -2.45598965\n",
            " -2.52688729  0.07445995]. \t  -240.60600470307475 \t -81.06401370190679\n",
            "21     \t [-5.02060074 -4.66199256  2.43260221  4.19272539  4.94157957 -0.74329845\n",
            "  1.49622764  3.12999905]. \t  -376.2002579357294 \t -81.06401370190679\n",
            "22     \t [-5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12 -5.12]. \t  -943.7184000000001 \t -81.06401370190679\n",
            "23     \t [-3.42429116  0.24764067  3.17264151  4.75594036 -1.04160166  4.83153257\n",
            " -0.18130256  4.18608081]. \t  -418.42444608567325 \t -81.06401370190679\n",
            "24     \t [ 4.12778788 -4.94437223  1.42746574 -2.6446469   4.86156679  4.40666947\n",
            "  1.43714134  4.63015759]. \t  -520.6729449927628 \t -81.06401370190679\n",
            "25     \t [ 0.57290816 -0.15844274 -4.9320027   1.98058886  3.67925319 -4.34383597\n",
            "  2.93595194  2.23302508]. \t  -370.17120312325403 \t -81.06401370190679\n",
            "26     \t [ 2.11078302 -0.89504084  1.04167835 -3.03920418  4.95407011 -3.65470507\n",
            " -4.46335377  4.7342002 ]. \t  -567.8670996420659 \t -81.06401370190679\n",
            "27     \t [-1.75504787  4.52754909 -3.5814871   3.08556618 -4.68362728  4.21263606\n",
            "  1.24132782  4.43260486]. \t  -504.7714065066599 \t -81.06401370190679\n",
            "28     \t [-4.87806763  4.48605381  2.94410498  3.30247658 -4.68447048 -1.37863478\n",
            " -1.65864145 -2.51119692]. \t  -324.50521155595555 \t -81.06401370190679\n",
            "29     \t [-3.80949757 -4.29118363  1.45501763 -4.88432899 -5.02520892  4.10990179\n",
            " -3.85908957 -2.61973449]. \t  -539.8821492362991 \t -81.06401370190679\n",
            "30     \t [ 3.51893015  1.5632766   2.05302109  4.65625712 -4.66947404 -1.37186865\n",
            " -4.99761918 -4.77148418]. \t  -593.9200978678381 \t -81.06401370190679\n",
            "31     \t [-4.80319134  4.82349685 -2.61094054 -4.32603162  3.04891621  4.10222657\n",
            "  4.46295224  1.64857245]. \t  -473.5290754833484 \t -81.06401370190679\n",
            "32     \t [ 4.37381109  1.9692417  -2.12061416  4.15539633  4.38891059  2.8970259\n",
            "  4.62265389  5.04198358]. \t  -609.0708627652768 \t -81.06401370190679\n",
            "33     \t [4.80257085 3.3881167  4.82441901 1.56933306 0.09115682 4.81202437\n",
            " 0.49899836 4.46915796]. \t  -426.20463582167616 \t -81.06401370190679\n",
            "34     \t [-4.22679515 -2.20242172  3.51481421 -3.05619596 -2.01808741  4.65022789\n",
            "  3.81152896 -3.01331973]. \t  -426.4363494668309 \t -81.06401370190679\n",
            "35     \t [-4.90094479 -1.25937628 -2.18359839 -4.39430052  2.10192787  4.96611256\n",
            " -2.4891906  -4.93131316]. \t  -526.7145629269148 \t -81.06401370190679\n",
            "36     \t [ 3.84462474 -0.26043669 -4.12939642 -2.44233297 -0.03038449 -1.19449002\n",
            "  3.52581427 -4.44459258]. \t  -343.5527433201901 \t -81.06401370190679\n",
            "37     \t [-3.43237087 -3.65362625  1.39470203 -5.08261437  2.42450644  0.42547184\n",
            "  4.65690425  2.16451436]. \t  -367.41219049414616 \t -81.06401370190679\n",
            "38     \t [-1.72268625 -4.11138794 -0.08739609 -2.26712036  0.08097763  4.01866251\n",
            " -4.63189897  4.83984618]. \t  -491.8619048967753 \t -81.06401370190679\n",
            "39     \t [ 4.43888143 -2.78339492  4.05543031 -4.32293168 -1.24157182  1.25665427\n",
            "  4.82578695  2.45355803]. \t  -387.6484374031801 \t -81.06401370190679\n",
            "40     \t [ 4.67536047 -1.47920092 -4.18971724  1.28295545  2.27119307  4.48005573\n",
            " -2.74732063  2.6565191 ]. \t  -340.98828714459034 \t -81.06401370190679\n",
            "41     \t [-0.61789822 -4.27189654 -1.90347045  4.14951574 -2.11625531 -4.42703951\n",
            " -3.85813625  2.19453638]. \t  -399.3327032582384 \t -81.06401370190679\n",
            "42     \t [-2.97432337 -4.86200604 -4.20916148  4.00595386  4.65516358  1.50937996\n",
            "  3.29425569 -4.00375273]. \t  -499.6938297867464 \t -81.06401370190679\n",
            "43     \t [-4.92923813  1.32923868  4.19253175 -2.70786328  3.22582551 -4.72574665\n",
            " -4.46991686 -3.91502298]. \t  -558.3993779436602 \t -81.06401370190679\n",
            "44     \t [ 2.74882756 -0.25735665 -1.8126823   3.35568652 -3.5978553  -3.41470411\n",
            "  5.09987801 -0.092176  ]. \t  -379.40179713053874 \t -81.06401370190679\n",
            "45     \t [ 3.69961881  3.95740371  0.34178595 -4.48001207 -4.80015737  1.51716264\n",
            " -1.8688376   3.30120247]. \t  -366.2913813160801 \t -81.06401370190679\n",
            "46     \t [ 4.2422771  -4.26864282 -3.52469581 -4.75705647 -4.49505886 -3.26811424\n",
            " -4.79455868  2.16464956]. \t  -545.7397318721949 \t -81.06401370190679\n",
            "47     \t [ 3.64998573  4.71685771  0.63376275  4.95295964 -3.62858143  4.97494412\n",
            "  3.07234789 -1.35003812]. \t  -452.1415956958892 \t -81.06401370190679\n",
            "48     \t [ 4.65199705 -5.03112104  1.01548589  2.67097476  2.89476898 -0.27443223\n",
            "  2.99940908 -4.35950097]. \t  -361.26298265766206 \t -81.06401370190679\n",
            "49     \t [-4.66933842  5.09946967 -3.8569484  -0.79740898 -2.15723816 -3.61892254\n",
            " -3.70480341  4.48109893]. \t  -479.5524437745522 \t -81.06401370190679\n",
            "50     \t [-3.19362187  3.47555277  5.09982632  4.51530281  2.78422078 -3.7576635\n",
            " -3.37001293  4.75159914]. \t  -577.5347803892658 \t -81.06401370190679\n",
            "51     \t [-2.56003158 -5.08413757 -2.00243446  3.14461631 -3.68798783 -0.3583179\n",
            "  3.00379109  4.92309516]. \t  -435.6652251661167 \t -81.06401370190679\n",
            "52     \t [ 2.07753565 -0.99431764  4.81844935 -4.59895258 -4.82583661 -3.21043299\n",
            "  1.56991894 -3.5541143 ]. \t  -457.1384324423485 \t -81.06401370190679\n",
            "53     \t [-4.09561412 -1.54882173 -4.30551496  4.52111329  4.18008338  4.98204178\n",
            "  2.15901087  3.57166919]. \t  -529.9197804724695 \t -81.06401370190679\n",
            "54     \t [-4.13658161  4.24080477 -0.52011527 -5.09708181  3.41441651 -4.10498919\n",
            " -2.21837314  1.42883964]. \t  -367.9904249629685 \t -81.06401370190679\n",
            "55     \t [-2.08809177 -4.78145714 -5.02268914 -3.82134293  4.99135677  4.34877215\n",
            "  5.07258687  4.35974464]. \t  -754.3937338732549 \t -81.06401370190679\n",
            "56     \t [ 4.4530929   4.7556078  -0.59029459 -3.42459216  0.84813755 -4.79480935\n",
            "  3.51016006  4.96693506]. \t  -538.1682999732352 \t -81.06401370190679\n",
            "57     \t [-2.81717305 -2.49316045 -2.72198451 -4.33570366 -4.98835556 -4.09583164\n",
            "  0.22166128  1.71817947]. \t  -366.8236044531502 \t -81.06401370190679\n",
            "58     \t [ 0.10532251 -3.41414994  4.56537402 -3.20769552  4.13254896 -2.96361225\n",
            "  4.06561169 -3.31152421]. \t  -468.53081413932773 \t -81.06401370190679\n",
            "59     \t [-4.93855538  0.70416532 -4.70906454 -4.88575046  4.75675842  3.60209686\n",
            " -3.52813752  3.86502132]. \t  -585.0148866421165 \t -81.06401370190679\n",
            "60     \t [-1.83554942 -4.96511213 -3.69238571 -2.92817328 -3.79541954  0.8828646\n",
            "  4.28992489 -3.26271529]. \t  -418.5612749576631 \t -81.06401370190679\n",
            "61     \t [ 3.37518887 -4.9480749  -0.91419815  3.684003   -4.22174777 -4.85893252\n",
            " -1.5001111  -4.53320827]. \t  -528.076851307955 \t -81.06401370190679\n",
            "62     \t [-4.41700465  4.39690048  4.53775385 -1.4034771  -3.17608941 -4.01691623\n",
            " -4.86588535  3.35184602]. \t  -530.6962909951184 \t -81.06401370190679\n",
            "63     \t [ 2.59918633 -3.70957992  4.6452912   3.59536803 -0.90024756 -3.40632961\n",
            "  4.1313736   4.02602093]. \t  -473.5398197656641 \t -81.06401370190679\n",
            "64     \t [ 4.7754924  -4.78056285 -4.6101909  -3.05945151  2.04105936  5.06371042\n",
            " -0.40865538 -4.1550931 ]. \t  -483.67942458531144 \t -81.06401370190679\n",
            "65     \t [-3.54466251  5.10368615 -4.20653216  2.20284509  3.92569518  3.06203074\n",
            "  4.74261041 -4.38002887]. \t  -581.3900057786458 \t -81.06401370190679\n",
            "66     \t [ 4.14794636 -1.25120815  4.74127226  4.83536952 -3.65780528  0.30682377\n",
            " -4.81409953  3.93778552]. \t  -535.0393448797502 \t -81.06401370190679\n",
            "67     \t [-4.99290173 -2.84532053 -3.40952429 -3.4218214   2.61331074 -4.62109177\n",
            " -4.99307544  2.85074062]. \t  -524.6340732241991 \t -81.06401370190679\n",
            "68     \t [-5.08300208 -2.26273098  2.14199083  2.09594129  4.93421871  2.45964025\n",
            " -4.30705273 -3.97436268]. \t  -481.66401129077195 \t -81.06401370190679\n",
            "69     \t [-3.83771653  4.23781584  3.63291775 -2.28084599 -4.32915006  4.19236934\n",
            "  2.69053545  2.58054217]. \t  -414.159457283227 \t -81.06401370190679\n",
            "70     \t [ 1.14772704 -5.05148298  3.52206618  3.86687861  3.94893139 -0.57271472\n",
            " -4.44735608  2.20248046]. \t  -406.57659197395435 \t -81.06401370190679\n",
            "71     \t [-1.32359534  4.20986146  4.85243474  3.85846347  1.21204156 -0.81210832\n",
            "  4.65701009 -4.54982463]. \t  -496.1108793170346 \t -81.06401370190679\n",
            "72     \t [ 4.96669558 -1.81003778 -4.75070341 -1.01643771 -3.228242   -0.02108631\n",
            "  2.74864343  4.20371296]. \t  -349.4259757101438 \t -81.06401370190679\n",
            "73     \t [-1.78285186 -2.36127237 -4.29843809  4.46530661  4.80023686 -1.1559386\n",
            " -4.09505458  4.49820544]. \t  -552.0009926745167 \t -81.06401370190679\n",
            "74     \t [ 5.0705279   0.82321511  4.99822215 -4.89326716 -1.40691599 -4.00152903\n",
            " -0.77776879  5.06305711]. \t  -513.0698658473176 \t -81.06401370190679\n",
            "75     \t [-4.86112616  3.21284393 -5.01029824  4.54597635 -3.86363618 -0.9877199\n",
            "  5.05429293  0.46099055]. \t  -463.26135268977197 \t -81.06401370190679\n",
            "76     \t [ 4.87670999  4.57868411 -4.05395785 -4.54783654  2.85759239  4.11022087\n",
            "  1.42904609 -2.60251451]. \t  -408.41851661504637 \t -81.06401370190679\n",
            "77     \t [ 3.68638509 -0.60451993 -3.87533173  4.36053704  3.28959676  4.17869445\n",
            "  5.05213065 -3.39636101]. \t  -565.2585161389633 \t -81.06401370190679\n",
            "78     \t [ 1.2686452  -4.90217029  1.73320453 -3.03907766  4.44002607 -4.78988071\n",
            "  4.05364486  4.44512191]. \t  -604.9520019944265 \t -81.06401370190679\n",
            "79     \t [-1.70468394  2.18644578 -0.64418711  2.87221455  0.45893027  0.05769509\n",
            " -4.86808514  0.21364972]. \t  -214.03643164915232 \t -81.06401370190679\n",
            "80     \t [ 4.49162139  1.42081199 -1.01209324 -3.31548195 -1.82519629  1.2582092\n",
            " -3.08019295 -3.89362966]. \t  -285.1059419762588 \t -81.06401370190679\n",
            "81     \t [-4.5522897   2.82871051 -4.720571    3.13980912 -4.34110689  2.68349569\n",
            " -2.86910366 -2.23539564]. \t  -378.0427046314546 \t -81.06401370190679\n",
            "82     \t [-3.72695359  3.36168982  2.4070084  -4.20994814 -3.83654929 -4.81001084\n",
            " -1.50788074 -3.27384181]. \t  -438.84085150102646 \t -81.06401370190679\n",
            "83     \t [ 4.36011993  0.09658632 -4.13243627  4.06722744 -0.85865822  2.98870131\n",
            " -3.88480054 -4.76705531]. \t  -481.1504880993595 \t -81.06401370190679\n",
            "84     \t [ 2.1037957  -3.39448834  4.90375773  1.61089232 -5.02141386  3.88724603\n",
            "  3.25455627  1.23903194]. \t  -413.1551069652015 \t -81.06401370190679\n",
            "85     \t [-3.87765198  0.76510688 -2.98482173  5.01386685  4.5052722  -4.1096242\n",
            "  1.9413366  -3.50627945]. \t  -471.0448213745675 \t -81.06401370190679\n",
            "86     \t [ 2.31389077 -1.08896647 -4.51126038 -2.74251671 -4.52256859  4.19320165\n",
            " -2.50685644  2.36183386]. \t  -395.2479405726274 \t -81.06401370190679\n",
            "87     \t [-4.00708205  0.41946636 -2.12777368  0.44481206 -4.3014553   4.64535687\n",
            "  4.86424144  0.38208533]. \t  -419.564762328373 \t -81.06401370190679\n",
            "88     \t [-4.44925838 -4.44646048  2.03600494 -0.98863541  0.03397787 -4.87597513\n",
            " -0.85909028 -4.13335301]. \t  -360.18315249877827 \t -81.06401370190679\n",
            "89     \t [ 5.08195372 -4.22066429  5.09891588 -2.00245789  2.76478317  4.3630508\n",
            " -0.15636123 -4.90296988]. \t  -500.41190230464304 \t -81.06401370190679\n",
            "90     \t [ 2.97329414  4.66691339  2.96415568  5.08394859 -2.09635732  0.91155292\n",
            "  4.97980203  4.67886496]. \t  -557.8277874369735 \t -81.06401370190679\n",
            "91     \t [-3.90126411  5.03764308  2.01814345 -4.00722446  2.24386299  0.84943304\n",
            "  3.97212188 -4.68344573]. \t  -457.8510592132999 \t -81.06401370190679\n",
            "92     \t [-0.51845025  5.02234146 -2.89635919  1.7331369   0.45600363 -4.38836215\n",
            "  4.41788312 -2.70422264]. \t  -399.6107918198576 \t -81.06401370190679\n",
            "93     \t [-3.8662971  -4.46252306 -2.64641052 -4.14469679 -4.45670687  3.9478459\n",
            "  4.97559533  4.85607272]. \t  -699.2724740192923 \t -81.06401370190679\n",
            "94     \t [ 1.57532714 -4.15145369 -4.76064645 -5.10575937  4.50316855  4.72073635\n",
            " -2.86589074  3.29942684]. \t  -588.9049629984789 \t -81.06401370190679\n",
            "95     \t [-4.91272944  4.69819201  0.93826809  1.88535698 -3.19653462 -4.33420459\n",
            "  4.7286967   1.98574898]. \t  -437.01099570512406 \t -81.06401370190679\n",
            "96     \t [-4.36623912 -1.27813718 -0.17604768  0.45706138  1.10630584 -4.4943016\n",
            "  4.91974246  1.9709576 ]. \t  -351.0764080389013 \t -81.06401370190679\n",
            "97     \t [ 3.12265005  5.05986531 -0.94113718  4.59462297  0.19048386 -5.06631907\n",
            "  1.57051989  4.09950151]. \t  -453.95485964632655 \t -81.06401370190679\n",
            "98     \t [-4.87965219  5.10070312 -5.02822246  0.7661753   2.60858923 -3.93275011\n",
            " -2.16988867 -2.67542514]. \t  -371.0874565614132 \t -81.06401370190679\n",
            "99     \t [-0.7501438   3.15409967  5.02067137 -4.16879084 -1.37734623  4.80974791\n",
            " -4.19921823  4.98603395]. \t  -636.2018716523191 \t -81.06401370190679\n",
            "100    \t [ 4.56126487 -3.30158492 -4.58476083 -2.49382816  4.78162375 -4.96340572\n",
            " -1.63767296  0.34702604]. \t  -412.412106818473 \t -81.06401370190679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4HnKuoqteDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7003cb-e2da-4b91-f6f0-c83b3ad1d98f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 19\n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_loser_19 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_19 = dGPGO(surrogate_loser_19, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.60872271  2.67767798 -2.61599688  2.78210017 -1.49020588  3.03818137\n",
            " -1.57695977 -0.57472578]. \t  -152.73804339453181 \t -152.73804339453181\n",
            "init   \t [-2.01417124 -0.59275346  0.74966386 -4.44760047 -4.87332982  3.28317578\n",
            " -1.38099049  2.2742428 ]. \t  -323.7197488227736 \t -152.73804339453181\n",
            "init   \t [-1.01293527  0.56350397 -2.8300206   3.21862419  2.65507157  2.99837476\n",
            "  1.85657419  0.54493065]. \t  -182.81852961404186 \t -152.73804339453181\n",
            "init   \t [ 2.7452723   4.7291508   4.64956866  0.49623227 -2.52475319 -2.84587614\n",
            "  1.92234127  1.96987691]. \t  -255.4837579570394 \t -152.73804339453181\n",
            "init   \t [-4.14230197  2.55639339 -5.00090869 -3.49701125 -2.12620717  3.13206479\n",
            "  2.96251747  5.00628454]. \t  -497.5739847629385 \t -152.73804339453181\n",
            "1      \t [-4.8562831   2.5202371   0.65818482  1.85973564 -3.16121357  4.05790202\n",
            "  3.22145623 -3.32687085]. \t  -361.375551583699 \t -152.73804339453181\n",
            "2      \t [ 2.57100251  0.79792066 -3.07628175 -2.52290659  3.72181543 -2.17142815\n",
            "  0.43296226 -2.98450801]. \t  -231.8548176582704 \t -152.73804339453181\n",
            "3      \t [-3.93618292 -3.46237372  4.64426131  0.6176429   1.44357523  2.37373405\n",
            " -2.91445036 -3.74550726]. \t  -321.6189907894727 \t -152.73804339453181\n",
            "4      \t [ 1.71164252 -2.95911977 -4.03437442  2.02656742 -2.92122741 -4.85463732\n",
            " -0.57796608  4.45551234]. \t  -430.9228367169912 \t -152.73804339453181\n",
            "5      \t [-2.74511363  3.76685972  4.4246735   4.38496769  4.91433138 -4.6635153\n",
            "  2.73141886 -4.00045557]. \t  -603.0563016476349 \t -152.73804339453181\n",
            "6      \t [ 4.50659056 -4.66464622  3.8028831  -3.91576704  3.3573574  -4.86797933\n",
            " -4.62303005 -1.13925638]. \t  -527.078561690918 \t -152.73804339453181\n",
            "7      \t [ 0.74953388 -4.99535814  4.25708702  2.89287469 -1.57494968  2.82565918\n",
            "  3.52640293 -4.34470735]. \t  -436.6811827590352 \t -152.73804339453181\n",
            "8      \t [ 4.9309155  -4.66190939 -1.39842267  3.88626494  0.59667046  4.54090007\n",
            " -4.87810306  1.51474754]. \t  -444.48533101207744 \t -152.73804339453181\n",
            "9      \t [ 3.01635191  1.86005304  1.34166926 -2.51068592  3.41638962  1.81600167\n",
            "  4.53589168  2.03974105]. \t  -302.08268227537843 \t -152.73804339453181\n",
            "10     \t [-1.16939325 -2.28684993 -3.09314025  3.80451342  4.89935167 -4.58750093\n",
            "  2.16351982  3.05576772]. \t  -452.1833650503857 \t -152.73804339453181\n",
            "11     \t [-3.24511568 -0.03305903  4.88870822  0.92764935 -4.78906412 -2.64060126\n",
            " -2.04224143  1.16601697]. \t  -282.25783962950715 \t -152.73804339453181\n",
            "12     \t [ 4.93640568 -2.89768435  1.20317571  3.54544549 -0.26729781  3.02893365\n",
            "  3.73371079  3.06668439]. \t  -324.0093545381129 \t -152.73804339453181\n",
            "13     \t [ 2.14365395  4.475046   -2.75201252 -1.81775304  0.81961399 -4.9226742\n",
            " -3.48771314  3.02356846]. \t  -387.6248423390611 \t -152.73804339453181\n",
            "14     \t [-5.04932398  4.55038173 -3.10694766 -4.25752421  2.16921434  2.41196796\n",
            " -2.63486389 -1.24510704]. \t  -287.80591849658293 \t -152.73804339453181\n",
            "15     \t [ 1.6405952  -4.93154943  2.85629023 -4.11715021 -3.16915087 -4.54186279\n",
            "  3.29548824 -4.82525932]. \t  -579.8862082863274 \t -152.73804339453181\n",
            "16     \t [ 4.73847946  3.19733533  3.59621008 -2.79212097 -2.43502122  2.77966179\n",
            " -4.94097081  3.98422819]. \t  -486.77173471484025 \t -152.73804339453181\n",
            "17     \t [-2.8745998  -4.43294761 -2.7756965  -0.26035087  0.61747234  2.125617\n",
            " -4.33617557  0.41900913]. \t  -232.98730188285626 \t -152.73804339453181\n",
            "18     \t [-2.73967493  4.99555548 -0.82469551  4.75958381 -2.23328553 -3.281701\n",
            " -3.10154036 -3.74777769]. \t  -419.33064738448286 \t -152.73804339453181\n",
            "19     \t [-1.52397821  3.04966104  4.30824494  3.44634834  0.044055    3.23832487\n",
            "  1.71019372  4.79645974]. \t  -391.56730360215226 \t -152.73804339453181\n",
            "20     \t [ 1.48763247 -4.06042201 -4.91731623  0.4058509  -4.17883291  3.77314538\n",
            " -1.53661715  4.94854355]. \t  -493.55195149540185 \t -152.73804339453181\n",
            "21     \t [-4.81925376  4.51866071  4.90666757  1.96687806  3.74473169 -2.85411271\n",
            " -4.8901082   4.85155259]. \t  -626.4458334362118 \t -152.73804339453181\n",
            "22     \t [ 0.72884133 -0.81145476 -3.81890966 -4.69712409 -3.23566528  4.11537028\n",
            "  4.57107203 -3.56690639]. \t  -535.8629893518354 \t -152.73804339453181\n",
            "23     \t [ 5.02441086 -3.71026321  1.49715044 -4.54859603 -1.43081697  3.71368242\n",
            " -1.31951971  0.13773559]. \t  -247.58459542972733 \t -152.73804339453181\n",
            "24     \t [ 1.65627714 -4.4603674   0.33217543  2.75967509 -1.41582852 -1.73059252\n",
            " -2.83494913 -4.29491808]. \t  -305.1489383155981 \t -152.73804339453181\n",
            "25     \t [-5.08179909 -0.71598426 -3.21296628  4.69485866 -2.85708982 -1.58610168\n",
            "  4.17888225  0.82313093]. \t  -329.5570741636583 \t -152.73804339453181\n",
            "26     \t [ 0.75558714 -5.12       -3.72045759 -5.12       -3.97088422 -0.69427104\n",
            " -4.69427822 -5.12      ]. \t  -645.0833431227027 \t -152.73804339453181\n",
            "27     \t [ 4.46089602 -3.22814435 -2.69798742  3.44502345  3.34769414  5.07399664\n",
            "  1.71278211 -4.53904046]. \t  -505.9179755221916 \t -152.73804339453181\n",
            "28     \t [-5.12        0.5978882  -5.12       -5.12       -3.20079294 -3.59715183\n",
            " -5.12       -5.12      ]. \t  -732.5085253192245 \t -152.73804339453181\n",
            "29     \t [-2.02507367 -4.31372728  3.81049558  0.42270714 -3.13549057  3.371996\n",
            "  5.05560659  4.49516551]. \t  -543.5366224627609 \t -152.73804339453181\n",
            "30     \t [ 3.66951971 -1.47236747  3.30332462 -2.05406113  4.31684766  3.69055648\n",
            " -3.30502509 -4.54309323]. \t  -483.8906516033669 \t -152.73804339453181\n",
            "31     \t [ 4.79949273 -3.92018467  3.34062109  2.41600109 -4.97149092 -3.84565559\n",
            "  2.21715066  3.90688118]. \t  -479.43139445795344 \t -152.73804339453181\n",
            "32     \t [-4.97239095 -2.87504964 -0.92183661 -5.11832564  2.0659351  -3.10237591\n",
            "  4.71657872  4.91840566]. \t  -576.9322452090312 \t -152.73804339453181\n",
            "33     \t [ 4.69407217  4.57591402  3.80696205  2.84268071 -3.84278214  3.98693297\n",
            "  4.9604339  -2.20288641]. \t  -519.9861860143415 \t -152.73804339453181\n",
            "34     \t [-5.0260819  -1.21488293  4.01232295 -2.52846501  3.84478158  3.11931665\n",
            "  1.46765049  3.93517081]. \t  -373.3372131297547 \t -152.73804339453181\n",
            "35     \t [-3.39866628  3.00569424  3.16606724 -3.03277692  0.8084546  -4.43189454\n",
            " -1.28655949 -2.98375615]. \t  -300.40939944542583 \t -152.73804339453181\n",
            "36     \t [ 2.79679016 -2.77522545 -2.5914273  -4.51965605 -2.58920673 -1.96756792\n",
            "  3.82070395  2.99765975]. \t  -355.9014981730077 \t -152.73804339453181\n",
            "37     \t [-2.75924015 -5.05550787 -3.73136432  4.80687625  1.64920052 -3.99037409\n",
            "  4.50236875 -4.37974126]. \t  -597.4173647578108 \t -152.73804339453181\n",
            "38     \t [-4.55667568 -2.12164605 -4.30285141  0.82741672  5.11667806 -4.98023914\n",
            " -3.53750233 -4.76261817]. \t  -636.824499278169 \t -152.73804339453181\n",
            "39     \t [ 5.08390804  3.28985327 -1.4609699   3.78075782  4.89403825 -1.33891164\n",
            " -2.87913856  0.92997728]. \t  -306.53129975478726 \t -152.73804339453181\n",
            "40     \t [ 0.08944051 -3.73401507  3.96439982  1.62100229  3.97109872 -2.05235768\n",
            " -1.0680214   4.02217307]. \t  -327.08258338811277 \t -152.73804339453181\n",
            "41     \t [-0.77393755  4.42773897  1.77610697 -3.81516373 -3.73388046  4.88104821\n",
            " -4.92120729 -2.89761644]. \t  -556.8488116971153 \t -152.73804339453181\n",
            "42     \t [ 1.38410175  4.56637169  1.90835178 -0.67332623  5.10272498  3.8302022\n",
            " -3.22627626  2.40012927]. \t  -393.5168089198683 \t -152.73804339453181\n",
            "43     \t [ 4.36009301  4.34841085  3.55996743  0.42007256  1.15841139 -3.44515606\n",
            " -2.81968378 -4.35263215]. \t  -380.69546931323333 \t -152.73804339453181\n",
            "44     \t [-2.35618003 -4.49266608  4.1565802  -5.10126703 -1.72474327  4.09428589\n",
            "  4.0443262  -3.1132364 ]. \t  -509.32956619294794 \t -152.73804339453181\n",
            "45     \t [ 2.44831286 -4.9949258   3.91281193 -3.74764691  3.25921598 -4.70267853\n",
            "  4.62412737  2.47521485]. \t  -542.4974660734474 \t -152.73804339453181\n",
            "46     \t [ 3.72055248 -1.64407553  4.30615828  4.64697806 -3.43347904  0.19164357\n",
            " -4.73337763  2.06216975]. \t  -411.27375167226086 \t -152.73804339453181\n",
            "47     \t [-4.74794588  0.7746091   2.214691   -3.2059102   4.37615119  3.36188279\n",
            "  4.66466502 -3.83368454]. \t  -513.0268650048852 \t -152.73804339453181\n",
            "48     \t [ 4.09568674  5.03955519 -4.88196619  4.78191659 -4.71709108 -3.37299512\n",
            " -0.06682128 -3.03044289]. \t  -483.55381628555966 \t -152.73804339453181\n",
            "49     \t [-4.72760832  5.03898793 -1.831471    0.57048519  2.72523871 -3.09303842\n",
            "  4.59982808 -1.30851647]. \t  -340.84035188333354 \t -152.73804339453181\n",
            "50     \t [ 4.09106501 -2.52386104  1.53623307  3.86109486  4.79227916 -2.42540099\n",
            "  2.76715639 -3.1906763 ]. \t  -381.3573330329529 \t -152.73804339453181\n",
            "51     \t [-0.2859619   4.89377946  2.62696746 -4.31112308 -3.64840521  1.79484265\n",
            "  3.65631987 -4.59190458]. \t  -491.1744224642688 \t -152.73804339453181\n",
            "52     \t [-2.86479366  2.9412352  -1.85002765 -1.712708   -4.98775034 -2.64258665\n",
            "  4.64771992 -1.44216429]. \t  -381.64571182586405 \t -152.73804339453181\n",
            "53     \t [ 4.25948088  1.3149383   4.30923982  2.92075721 -3.25133549  3.00563916\n",
            " -2.60410431 -4.67709426]. \t  -440.96355101238726 \t -152.73804339453181\n",
            "54     \t [ 3.97864237  2.48836787 -4.2509363  -4.94256882 -3.39829392 -0.31528832\n",
            " -2.66842287 -2.17102241]. \t  -326.0293879171836 \t -152.73804339453181\n",
            "55     \t [ 0.64419742  4.01028314  0.39166458 -4.20356346 -0.48253831 -4.69336821\n",
            "  4.76331065  5.01346722]. \t  -596.9528926442035 \t -152.73804339453181\n",
            "56     \t [ 1.02684775 -3.64805945  0.98989122 -4.7236657  -4.80729088 -3.65975473\n",
            " -4.46704994  2.76233086]. \t  -516.5013930358274 \t -152.73804339453181\n",
            "57     \t [ 3.11498496 -1.323034   -3.6597088  -4.22299632  3.55789139  3.70061591\n",
            " -3.67539134  0.05743782]. \t  -364.7653740966541 \t -152.73804339453181\n",
            "58     \t [-4.65805469  2.12865379 -5.03679717  3.70244259 -0.65354896 -3.15921944\n",
            " -4.33926272  3.89205851]. \t  -476.7091070038947 \t -152.73804339453181\n",
            "59     \t [-5.12       -5.12       -1.68609756 -4.25519225 -5.12       -2.17571958\n",
            "  1.00164691 -1.52123855]. \t  -344.6095628496773 \t -152.73804339453181\n",
            "60     \t [ 4.40230857 -2.96737793 -4.98122695 -4.40401203  4.04132616  5.02196378\n",
            "  4.89302131  4.32806942]. \t  -739.4415272242841 \t -152.73804339453181\n",
            "61     \t [ 2.57018932  2.88837136 -3.12909725  4.3492508   0.25259859 -2.72378822\n",
            "  4.57242481  3.99491743]. \t  -447.1864968607787 \t -152.73804339453181\n",
            "62     \t [ 3.70708618 -3.92629043 -4.95950812 -4.38938929  3.64116162 -2.04395204\n",
            " -0.47685464  4.99333539]. \t  -487.8467653390934 \t -152.73804339453181\n",
            "63     \t [-3.48016215 -2.00216995 -1.90278918  4.57182481  4.68365022  3.65072466\n",
            " -2.10272348 -5.00531094]. \t  -535.6219088840761 \t -152.73804339453181\n",
            "64     \t [ 1.99565825 -1.27578402  3.85813003  3.09751049 -4.79988065 -4.18897084\n",
            "  3.30681978 -4.38572509]. \t  -541.172895817521 \t -152.73804339453181\n",
            "65     \t [-4.6605583  -4.70803083 -3.93667182  0.49511831 -0.52270532  3.99356123\n",
            "  4.56005295 -3.63003485]. \t  -461.55773235645336 \t -152.73804339453181\n",
            "66     \t [-5.03430749  1.90371793 -1.00144749  4.0806421   2.7356181   4.95884524\n",
            " -4.86015523  0.75740047]. \t  -457.1037012253525 \t -152.73804339453181\n",
            "67     \t [-1.7201126  -4.74452402  0.86605433 -2.88107587  3.39723011 -2.19152036\n",
            "  0.65025838 -2.39464617]. \t  -218.78927180376547 \t -152.73804339453181\n",
            "68     \t [ 3.9227189  -4.51840625  4.74584607 -4.29274533  3.8537263   2.53005367\n",
            "  4.31761462 -3.44056822]. \t  -535.3552386229392 \t -152.73804339453181\n",
            "69     \t [ 3.39591795 -3.95357246 -3.97710275 -0.3530106  -4.05636161  4.41168914\n",
            " -1.65653665 -4.60867107]. \t  -478.92017617629597 \t -152.73804339453181\n",
            "70     \t [-4.02069164 -4.0330224   4.74817991  3.47442787  1.73638884 -4.25363108\n",
            "  1.76327396 -3.93081012]. \t  -433.62831978694334 \t -152.73804339453181\n",
            "71     \t [-0.01009906  0.62795904  4.15493925  5.11616893  1.81983185 -0.07727703\n",
            " -4.71017338 -2.36570207]. \t  -373.94733931960536 \t -152.73804339453181\n",
            "72     \t [ 5.05141408  1.94030177 -2.65385624  1.21106301 -1.81846509  0.60534404\n",
            "  4.25980735 -1.78906151]. \t  -231.4022431312851 \t -152.73804339453181\n",
            "73     \t [-4.78212961 -4.88402868  1.99794722  3.00307206 -2.96815232 -2.51361267\n",
            " -4.83211224  4.80500924]. \t  -548.7345865618074 \t -152.73804339453181\n",
            "74     \t [ 4.84382616 -4.40235402 -4.28706566 -1.23500576 -1.66244758 -2.64895547\n",
            "  2.17010008 -4.18032821]. \t  -352.14878901261716 \t -152.73804339453181\n",
            "75     \t [-3.40229655  4.34661837  2.35489319  2.79786202  0.96045276 -4.83214292\n",
            "  3.0431217   5.02790085]. \t  -509.0828993755149 \t -152.73804339453181\n",
            "76     \t [ 4.47773363  4.86273271  5.06517294 -1.69852563  1.48623376 -2.51946612\n",
            "  4.96581053 -4.09158894]. \t  -511.5247557803191 \t -152.73804339453181\n",
            "77     \t [-4.53434803  4.94480073  4.24932604 -4.45308312 -2.18479244 -3.48578938\n",
            " -0.29623264  3.63521014]. \t  -406.0557873483332 \t -152.73804339453181\n",
            "78     \t [-3.08047585 -3.62128123 -0.52975333 -4.45931296  4.17266537 -4.35343845\n",
            " -4.80595573  3.51016269]. \t  -577.1211408759783 \t -152.73804339453181\n",
            "79     \t [ 0.5120268   1.58094301  0.54645986 -3.49684265 -5.12       -5.12\n",
            " -4.023183   -5.12      ]. \t  -666.4440323933189 \t -152.73804339453181\n",
            "80     \t [-2.90959117 -2.3799853   1.29808395  3.6576453  -5.09719066  4.71790777\n",
            " -2.61068699  0.20482469]. \t  -389.867040320837 \t -152.73804339453181\n",
            "81     \t [-4.28957845 -4.94752942 -4.26157602  4.42705011 -2.74628309  0.92318833\n",
            " -5.07010875 -4.64102975]. \t  -595.314049201819 \t -152.73804339453181\n",
            "82     \t [-3.18056267 -3.14187577  4.12117945 -3.85385741 -4.95678483 -3.43704388\n",
            "  4.5077793   2.46005312]. \t  -524.6035863489437 \t -152.73804339453181\n",
            "83     \t [ 2.19783536  2.01704106  4.76269488 -4.00314198 -4.1813349   4.33630109\n",
            "  3.03670451  2.51114915]. \t  -460.3545908992264 \t -152.73804339453181\n",
            "84     \t [-3.03783141 -0.43236108  4.53816085 -3.86034045 -4.40313222  0.40534257\n",
            " -2.8118081  -4.22478666]. \t  -427.0540315044459 \t -152.73804339453181\n",
            "85     \t [ 0.24215307 -5.01637748  4.32474443 -3.94514715 -1.12327741  4.58841958\n",
            " -5.11919073  4.65660787]. \t  -658.2988090726801 \t -152.73804339453181\n",
            "86     \t [-2.28912484 -1.40653702  5.01779324  2.58201368  1.79845957  5.00058731\n",
            " -4.40922023  4.76988194]. \t  -595.7089867672369 \t -152.73804339453181\n",
            "87     \t [-5.09371687  5.10101616 -4.87953466  4.43445528 -4.59603403  4.19917681\n",
            " -4.38973889  2.11431278]. \t  -610.1411934691321 \t -152.73804339453181\n",
            "88     \t [-4.95887736  4.96546955 -4.2381063   2.56974395  5.06130059 -1.77911594\n",
            " -5.11720646 -3.31429997]. \t  -572.453839056646 \t -152.73804339453181\n",
            "89     \t [-3.64706155 -1.55708584  2.98106612  4.96920244  1.9416634  -1.47119345\n",
            "  4.38905353  2.17647871]. \t  -348.1620050387696 \t -152.73804339453181\n",
            "90     \t [-4.9483906  -0.25640036 -3.03668656 -5.01937591  1.48675985  4.7035563\n",
            " -4.59648713  4.54714356]. \t  -610.1578851069596 \t -152.73804339453181\n",
            "91     \t [-4.51166199 -0.28840035  1.90613665 -4.32368744  4.88633468  1.42008308\n",
            " -4.41188402 -0.09306951]. \t  -374.00209473131656 \t -152.73804339453181\n",
            "92     \t [ 1.74322594  1.86874441 -4.5989925   4.83911549  3.15260692 -4.30525788\n",
            "  0.21249619 -3.64878211]. \t  -434.87469285871947 \t -152.73804339453181\n",
            "93     \t [ 0.77293137  1.97111171 -4.28736873  2.45648938 -4.99609229  4.22940049\n",
            "  4.77551527  2.03510548]. \t  -512.5536565344634 \t -152.73804339453181\n",
            "94     \t [-0.44761124  0.34820107  5.02789919  2.75080785  3.5325564   4.98564275\n",
            "  4.05757694 -4.03861394]. \t  -563.8152404193071 \t -152.73804339453181\n",
            "95     \t [ 4.27242188  0.53614581 -2.39354292 -4.79587547 -1.92233426  4.89215605\n",
            "  1.31721785  4.34092597]. \t  -452.987858713763 \t -152.73804339453181\n",
            "96     \t [-3.71002455  2.60647693 -3.18597458 -5.07401353 -3.44467282 -1.42484352\n",
            " -2.96740893  4.11094787]. \t  -429.13315937665857 \t -152.73804339453181\n",
            "97     \t [ 4.61327717  4.90070114 -4.03236253 -4.97457071 -0.28742076  2.13915509\n",
            " -4.34205837  3.87206267]. \t  -496.8675385591207 \t -152.73804339453181\n",
            "98     \t [-3.4457865   3.97455798 -1.85166224  0.27857295  5.01751537 -2.51186244\n",
            " -1.34283234  4.87125469]. \t  -420.253426581802 \t -152.73804339453181\n",
            "99     \t [ 0.97148563 -4.81306652 -3.17957365  4.49669754  4.61820948 -4.67574705\n",
            " -4.94201458  1.33345181]. \t  -581.4894870090851 \t -152.73804339453181\n",
            "100    \t [-1.21756842  4.91911202  3.08703768  5.05157816 -2.77783997 -3.54898675\n",
            "  4.14632609 -2.88782925]. \t  -481.75539012323145 \t -152.73804339453181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfiDmH_bteGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e197198b-6215-4724-8c93-4c36f32eceaa"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 20\n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_loser_20 = dGaussianProcess(d_cov_func)\n",
        "\n",
        "loser_20 = dGPGO(surrogate_loser_20, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\n",
        "loser_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.722097    0.66077445 -0.11835563 -1.6744678  -1.27110986  0.3280473\n",
            " -4.42259161  0.86557758]. \t  -164.28536719065698 \t -132.28213531381235\n",
            "init   \t [-2.6839269  -3.47385261 -3.56229991 -3.8188112  -1.76700246  1.98813566\n",
            " -1.44418335  4.00758432]. \t  -310.1550894686203 \t -132.28213531381235\n",
            "init   \t [-3.05275003 -3.98743036  0.28218124  3.76479057 -2.43840637 -0.00619396\n",
            " -0.73150053  0.30723982]. \t  -132.28213531381235 \t -132.28213531381235\n",
            "init   \t [ 0.75721546 -1.10739814 -4.30577546  3.76095755 -3.43548334  3.1076518\n",
            " -2.17161474 -2.36983115]. \t  -310.1222484793693 \t -132.28213531381235\n",
            "init   \t [ 2.22697488  3.90559391  5.0393091  -0.42649562  2.91972373  2.4442259\n",
            " -0.2705103  -0.15529262]. \t  -191.55277957356324 \t -132.28213531381235\n",
            "1      \t [ 4.30728864  2.61813474 -2.20410079  4.60389393  3.48040036  3.22508805\n",
            "  2.4952604   4.24826238]. \t  -442.5587609971722 \t -132.28213531381235\n",
            "2      \t [ 1.64417887 -4.25346266 -0.53384123 -3.88827288 -3.49237376 -3.32866682\n",
            "  4.97929121  4.42131042]. \t  -557.6176193329263 \t -132.28213531381235\n",
            "3      \t [-0.51012006 -0.74868806 -0.30505697  3.86744867  1.7594746   4.11963334\n",
            "  4.47966981 -2.33505232]. \t  -362.88797991469033 \t -132.28213531381235\n",
            "4      \t [ 4.44955614 -2.13360821  4.10720185  2.39925212  2.88050458 -0.27507236\n",
            "  2.51470917  4.28698122]. \t  -335.76860348287215 \t -132.28213531381235\n",
            "5      \t [-3.91293411  2.88532018  1.65072288  2.76545681  4.60039161 -4.26943569\n",
            "  1.23156863 -3.93232258]. \t  -420.23597912178127 \t -132.28213531381235\n",
            "6      \t [-1.26257825 -3.6572517   1.92916383 -1.20022741  1.84333074 -4.53359964\n",
            " -4.51902056 -4.5981504 ]. \t  -497.67750685336034 \t -132.28213531381235\n",
            "7      \t [-1.36114306  4.12459045  0.45523257 -4.7981147   4.46392568 -1.90118512\n",
            " -4.61594301 -3.62407127]. \t  -504.1263731038 \t -132.28213531381235\n",
            "8      \t [ 3.18549963  1.39147754 -3.29705633 -4.21724791 -3.38666378  0.79298607\n",
            "  1.7390529  -4.1889532 ]. \t  -340.44147425079825 \t -132.28213531381235\n",
            "9      \t [-5.12       -4.95937989 -3.9831332  -3.50368761 -3.89699554 -5.12\n",
            " -5.12       -5.12      ]. \t  -798.5399266588842 \t -132.28213531381235\n",
            "10     \t [ 4.12876868  4.80520776  4.77941632 -4.90271379 -0.05901974 -3.58815148\n",
            "  0.25554618 -4.18406528]. \t  -445.6763934769549 \t -132.28213531381235\n",
            "11     \t [-4.73358359  0.35401167  1.08036012 -5.09279157  0.85489432  3.80346997\n",
            "  4.43695619 -4.22235364]. \t  -500.7898477309751 \t -132.28213531381235\n",
            "12     \t [ 1.34048309  0.69597845 -4.83646794  3.69068387 -1.37750937 -1.84499674\n",
            " -0.50560173  5.09314637]. \t  -366.6468123795353 \t -132.28213531381235\n",
            "13     \t [ 2.22015245  4.99900615  4.38913471  4.62874018 -3.79354301 -2.24991212\n",
            " -2.50196261 -0.99147537]. \t  -352.4140311601115 \t -132.28213531381235\n",
            "14     \t [ 4.79087088 -0.94799833  4.91024952  3.88005337 -0.62997974  3.33557191\n",
            "  0.41603295 -4.71723837]. \t  -405.27165212742636 \t -132.28213531381235\n",
            "15     \t [ 4.92677125  1.53912033 -3.04542069 -0.59011188  4.72885737  4.76827568\n",
            " -3.90562594 -0.6927353 ]. \t  -417.0731802779107 \t -132.28213531381235\n",
            "16     \t [ 3.65868812  2.56579156 -1.38016142  4.72992989  2.19125752 -3.445696\n",
            "  0.20866163 -1.80736153]. \t  -243.43825185342058 \t -132.28213531381235\n",
            "17     \t [-1.04356817  1.67474864 -0.50494701 -3.90815974 -1.27826809  5.06554936\n",
            "  4.72015522  3.13206553]. \t  -465.1246865017904 \t -132.28213531381235\n",
            "18     \t [-4.43873326 -2.71773728  3.72734547 -0.94996697 -0.79508233 -4.79736714\n",
            "  3.73814091 -1.31561486]. \t  -332.6753968826721 \t -132.28213531381235\n",
            "19     \t [ 1.78866288 -5.1028478   3.33605197 -4.86754739  4.39084072  1.08225382\n",
            " -2.67082228 -0.73853794]. \t  -341.1588233956468 \t -132.28213531381235\n",
            "20     \t [-3.01773588 -0.60336082  3.01730218 -0.53133665  3.29747499 -4.34078569\n",
            " -3.03556623  4.46207479]. \t  -429.48118690199294 \t -132.28213531381235\n",
            "21     \t [ 0.08296276 -4.24504454 -1.29299679 -3.17528341  2.6114569  -3.91025846\n",
            "  4.33192539 -4.43272585]. \t  -495.7836837649471 \t -132.28213531381235\n",
            "22     \t [-4.50459226  4.92854671 -3.81002921  0.85977529  3.83952549  3.58843789\n",
            " -2.44917507 -3.21284186]. \t  -390.9174498397427 \t -132.28213531381235\n",
            "23     \t [-3.00405964 -3.04606103 -0.52231307  1.13360097  3.57919601  4.06574232\n",
            " -4.30839356 -4.8674063 ]. \t  -516.2437096199313 \t -132.28213531381235\n",
            "24     \t [-3.70176067 -1.38641892 -2.24133892  4.54881945  4.54699679  2.42051045\n",
            " -1.24746711  3.62082879]. \t  -369.6907333577205 \t -132.28213531381235\n",
            "25     \t [ 4.37837236e+00 -4.68151088e+00  3.79781015e+00  2.98847088e-03\n",
            " -3.82600785e+00 -3.05298886e+00 -4.58088088e+00  4.28281806e+00]. \t  -529.0210121069344 \t -132.28213531381235\n",
            "26     \t [-4.36901913  3.708553   -1.00233903 -3.55839758 -2.02817687 -3.42920121\n",
            " -0.13593644  4.34234501]. \t  -342.3589481435898 \t -132.28213531381235\n",
            "27     \t [ 1.59219624 -4.37740095  4.46903271 -1.83935635 -2.87181407  5.01996796\n",
            "  0.25366106 -0.56185339]. \t  -309.7209458184118 \t -132.28213531381235\n",
            "28     \t [ 3.33020962  3.79062089  3.2210877  -4.05988623 -5.02963221 -2.48540496\n",
            " -1.8871732   5.07192358]. \t  -531.1594891465263 \t -132.28213531381235\n",
            "29     \t [ 1.32723519  4.59736317 -2.29790054 -4.06327296  5.06642424 -1.70805853\n",
            "  3.28241285 -1.56997654]. \t  -366.90114498298686 \t -132.28213531381235\n",
            "30     \t [-4.78398604 -0.9080889  -4.7166842  -1.52484158  4.75148093 -5.02104635\n",
            "  0.52416447 -1.51469392]. \t  -385.0035845538857 \t -132.28213531381235\n",
            "31     \t [ 3.6256787  -4.72024494 -4.07563999  0.16337912  3.63918736 -1.20402648\n",
            "  0.90963829  1.75701572]. \t  -213.0516937384514 \t -132.28213531381235\n",
            "32     \t [ 4.49249774  2.59055522  3.57987514 -4.8154984   1.00238482 -2.02326784\n",
            "  4.69288692  4.9670409 ]. \t  -545.9269346287647 \t -132.28213531381235\n",
            "33     \t [ 0.65647757  2.62589303  4.67957595  4.14152706 -4.34638345  4.12219231\n",
            "  4.72639017  4.47502934]. \t  -661.5143805288717 \t -132.28213531381235\n",
            "34     \t [-3.86651974  4.91482368 -2.27514161  4.95295096 -4.97365079 -0.00894866\n",
            "  4.46267411 -3.70198725]. \t  -549.6490495098249 \t -132.28213531381235\n",
            "35     \t [ 4.11723247 -3.97201285 -0.26975294  2.93739875 -3.57328272 -2.44494961\n",
            " -4.53491658 -4.93413107]. \t  -521.6688138772249 \t -132.28213531381235\n",
            "36     \t [-4.30818271 -0.15085506 -1.89619714  3.01191803 -4.55097171  5.00032155\n",
            " -4.08384759  4.79519561]. \t  -619.9511412268035 \t -132.28213531381235\n",
            "37     \t [-1.10511012  1.79249863  3.15103425  2.58137412 -3.52668105 -4.17466683\n",
            "  4.43390634  4.55756524]. \t  -534.6307309041911 \t -132.28213531381235\n",
            "38     \t [ 1.11146657 -4.5313971   3.53521779 -4.6500569  -4.03571194 -2.13207306\n",
            "  1.29236717 -5.06723902]. \t  -492.10393622152446 \t -132.28213531381235\n",
            "39     \t [-3.95491318 -4.96561533 -3.03360534  3.38479251 -4.18462808  4.49476065\n",
            "  3.31255324 -4.830339  ]. \t  -610.6328375651256 \t -132.28213531381235\n",
            "40     \t [-4.17214038  1.79042877  4.92079921 -4.24070095 -2.90632998  0.02091369\n",
            " -4.85329778 -2.92277773]. \t  -443.8539254875753 \t -132.28213531381235\n",
            "41     \t [ 2.37665316 -2.44026576 -2.58813515  4.96487971 -4.2036418  -3.27176684\n",
            "  4.92592072 -4.09680622]. \t  -592.9569325640667 \t -132.28213531381235\n",
            "42     \t [-2.94337814 -0.30132935 -4.30749995  2.3505918  -1.91626416 -4.76114462\n",
            " -0.44155297 -5.08021252]. \t  -448.81445556596617 \t -132.28213531381235\n",
            "43     \t [ 3.81901256 -2.30069736 -4.26806047 -4.83744545  2.98230921  5.05308766\n",
            "  1.63868137  4.07367883]. \t  -522.6526282848426 \t -132.28213531381235\n",
            "44     \t [-4.58284526  1.99798186  2.14690668 -5.10213173  4.80708675  4.42989787\n",
            " -1.22951364  1.92713381]. \t  -420.5180216704457 \t -132.28213531381235\n",
            "45     \t [-3.85068863 -4.2227434   4.90648877 -3.02424539 -2.27919975  1.78592313\n",
            "  2.54887448  4.98902187]. \t  -449.0069907969167 \t -132.28213531381235\n",
            "46     \t [-4.02511708  2.95054394 -4.36753055  4.01959544  4.27007882 -4.83190891\n",
            " -1.21468252  3.16045229]. \t  -476.9553185897689 \t -132.28213531381235\n",
            "47     \t [ 5.03724485 -4.10422338  3.87090172  3.20281017  4.67863374 -2.69327794\n",
            " -0.11648928 -3.23435103]. \t  -381.8004932063827 \t -132.28213531381235\n",
            "48     \t [-2.42459096  3.5172467   3.54722133  2.77649431 -3.85607446  4.2594164\n",
            " -0.52688781 -4.18092872]. \t  -424.19162495394573 \t -132.28213531381235\n",
            "49     \t [ 4.7797872   3.96134955 -0.41919145  4.79503951 -1.734741    3.73479707\n",
            " -4.73355259  2.28913382]. \t  -444.2333226990391 \t -132.28213531381235\n",
            "50     \t [ 1.86579487  4.99854161  1.0033673   2.12205727 -3.22946323 -4.83685886\n",
            "  4.7122199  -3.68407377]. \t  -531.017469530529 \t -132.28213531381235\n",
            "51     \t [ 4.74863442  0.69407034 -4.80359229 -4.78139621 -4.32177364 -0.10034368\n",
            " -0.77265772  3.89383313]. \t  -403.10703276346345 \t -132.28213531381235\n",
            "52     \t [-1.6429885   0.0494173   4.57696325  3.57099391  4.86568577 -4.55846234\n",
            "  5.02279833  4.71362454]. \t  -713.9555985061122 \t -132.28213531381235\n",
            "53     \t [-2.99278985  4.09402315 -2.25427974 -4.15812396 -4.98598826 -3.23930795\n",
            "  5.04723872 -2.00337815]. \t  -524.5737664233332 \t -132.28213531381235\n",
            "54     \t [-2.10707126 -1.79078364  4.10321695  3.01751542  4.65665302  0.8910786\n",
            " -0.50658875 -0.75646939]. \t  -217.34493240298133 \t -132.28213531381235\n",
            "55     \t [ 0.43443398 -4.82568451 -3.89063841 -2.9323994  -4.06573673 -4.87121313\n",
            " -4.21561552  2.49684776]. \t  -525.867530815453 \t -132.28213531381235\n",
            "56     \t [ 1.17415488  3.88300702 -4.78572348  3.21666921 -4.7994311   4.54940094\n",
            "  3.23879536  5.00873182]. \t  -655.1141288830049 \t -132.28213531381235\n",
            "57     \t [ 4.9409656   3.29563116  3.85194897 -2.86103607  4.08979341 -3.27685511\n",
            " -4.26568893  3.5782632 ]. \t  -501.2533344384266 \t -132.28213531381235\n",
            "58     \t [ 1.77125645 -5.11497996  4.29102027  1.70332684  3.00657374  2.73235778\n",
            " -3.98865859  4.96093613]. \t  -520.5522262091306 \t -132.28213531381235\n",
            "59     \t [ 4.80989237 -0.34598638  0.63856064  0.88473553 -4.64851945  0.51189312\n",
            "  3.36774237  1.91713721]. \t  -246.13979876624404 \t -132.28213531381235\n",
            "60     \t [ 3.84084832 -4.15648781 -1.48444165 -2.65297354  2.73128322  4.03348968\n",
            "  3.79335143 -4.7734201 ]. \t  -501.9933683839742 \t -132.28213531381235\n",
            "61     \t [-4.68403777  4.78343056  2.50373307  4.39015881 -2.62076406 -1.16547745\n",
            " -4.51918591  4.37148411]. \t  -501.93496391706594 \t -132.28213531381235\n",
            "62     \t [ 4.8125266  -4.14883374 -4.60223094 -4.86505344  2.72308395 -3.99785857\n",
            " -2.68065196 -2.64873994]. \t  -455.2036441497522 \t -132.28213531381235\n",
            "63     \t [-4.06453579 -4.94789968 -4.83707994  3.92992882  0.49036452 -4.56900797\n",
            " -3.43307238  3.99979727]. \t  -534.3994801796765 \t -132.28213531381235\n",
            "64     \t [ 4.29907783 -4.18804713  4.60294067 -3.97045656  0.91648359 -0.63462298\n",
            "  5.06292815  0.26048321]. \t  -366.7725282490275 \t -132.28213531381235\n",
            "65     \t [-4.85028361 -1.33118419 -1.43604211 -4.8217969   0.50586317 -2.21495035\n",
            " -1.00921088 -4.50873369]. \t  -326.729405805846 \t -132.28213531381235\n",
            "66     \t [-1.47334145 -3.43478903 -1.56153651  4.97947713 -3.53338243  1.06150654\n",
            "  4.49620671  5.11942722]. \t  -552.6263828445142 \t -132.28213531381235\n",
            "67     \t [-4.60318334  3.29832292 -4.81575769 -0.50638108 -4.60151559  4.0727718\n",
            "  0.25095789 -2.47405063]. \t  -368.3502397126819 \t -132.28213531381235\n",
            "68     \t [-3.73051006  3.79231747 -4.75050712  2.22188097 -4.57988567 -4.68025656\n",
            " -4.45552724  3.91756282]. \t  -628.1750436926087 \t -132.28213531381235\n",
            "69     \t [ 4.01514129  4.03857753 -2.55995633 -1.07135519 -2.63228332 -4.77262821\n",
            " -0.61107319  0.33551708]. \t  -247.81981796933985 \t -132.28213531381235\n",
            "70     \t [-3.09263311 -2.85811429 -4.78909245 -0.87625343  2.55810264  3.77770925\n",
            "  3.69459828  1.25643633]. \t  -324.3049352590146 \t -132.28213531381235\n",
            "71     \t [ 4.06223082  4.50470765  0.71686673  4.2989692  -4.80995356  2.80221033\n",
            "  3.24715262 -3.29405271]. \t  -455.9595695386739 \t -132.28213531381235\n",
            "72     \t [-3.5535053   5.01196027 -3.87530704  2.32054893  1.88121856  1.8006963\n",
            "  4.91322996  0.72004935]. \t  -339.73722267661253 \t -132.28213531381235\n",
            "73     \t [-3.53909797 -4.05483232 -4.63821738  4.79159766  3.03026949 -1.58957218\n",
            "  4.29332012 -1.82634038]. \t  -418.5708000113503 \t -132.28213531381235\n",
            "74     \t [ 2.54065264  4.59062236  4.10638927 -2.58355376 -5.03052008  0.85672041\n",
            " -2.76366799 -4.85647798]. \t  -498.9713745967064 \t -132.28213531381235\n",
            "75     \t [-2.6998693   4.64433272  4.94518275 -1.40683959 -3.0874715   4.14720868\n",
            " -1.18811207  3.49193238]. \t  -389.99868098937736 \t -132.28213531381235\n",
            "76     \t [-4.96184156 -4.81695404  2.27494179 -4.23250692  5.05349888  3.05741584\n",
            "  0.36287897 -3.85801598]. \t  -461.98057478529313 \t -132.28213531381235\n",
            "77     \t [ 4.90167377 -3.76831883 -0.81232246  3.97091052  1.12041741  4.61301593\n",
            " -1.65925273  0.13059752]. \t  -270.8434388812133 \t -132.28213531381235\n",
            "78     \t [-1.41713113  4.49869529  5.09930383  4.8101848   3.19594992  0.79341284\n",
            "  4.47526635  1.13512367]. \t  -418.39660021726945 \t -132.28213531381235\n",
            "79     \t [-5.04028501 -4.6393292   5.08557532  1.43869276  4.32776343  2.30545821\n",
            "  4.47327375  4.31482437]. \t  -568.8712280891283 \t -132.28213531381235\n",
            "80     \t [ 0.54721314  1.83971479  2.94164187 -4.15861803  4.22537584  5.08482966\n",
            " -3.93764879 -4.15069289]. \t  -592.9682488183498 \t -132.28213531381235\n",
            "81     \t [-5.12        0.85549038  0.74317575  0.17206623 -5.12       -5.12\n",
            " -5.12       -1.2349897 ]. \t  -513.5142818713937 \t -132.28213531381235\n",
            "82     \t [ 0.57117002 -0.80279648 -5.04436395 -5.05500057  4.97848119 -4.40341781\n",
            "  4.19247316  4.15043525]. \t  -681.2777718168121 \t -132.28213531381235\n",
            "83     \t [ 5.03435565 -4.9242681  -3.11087812  4.48563227  0.34606962 -4.57324953\n",
            " -3.59794403  3.36330223]. \t  -490.55515741414206 \t -132.28213531381235\n",
            "84     \t [-4.79200081  4.81826665  3.93458252 -2.77176357  3.43443086 -3.13868286\n",
            "  3.57345208  3.57181969]. \t  -456.1028133934816 \t -132.28213531381235\n",
            "85     \t [ 0.91806988 -0.21686847 -4.93716773 -2.40491543 -5.0405948  -2.74189214\n",
            " -4.69905039 -5.01441652]. \t  -625.0665854430682 \t -132.28213531381235\n",
            "86     \t [ 3.9821822  -4.66561367 -2.11627911 -3.876779   -0.64911566  4.40474836\n",
            " -4.4532276  -0.57223559]. \t  -392.90313609917536 \t -132.28213531381235\n",
            "87     \t [-2.89566722 -2.67370469  4.35852809  0.38436728 -2.32519611  5.07442282\n",
            " -3.86454526  3.85107792]. \t  -484.98420252802623 \t -132.28213531381235\n",
            "88     \t [ 4.33362589  4.86454229 -3.86350599 -4.74979548 -0.13163849  1.40083722\n",
            " -5.00390614 -3.00824671]. \t  -460.66075666625494 \t -132.28213531381235\n",
            "89     \t [ 5.08367889  3.61984313 -4.6643294   0.68693191  2.3989084   2.40521966\n",
            "  4.55929977 -3.01029078]. \t  -400.695330415366 \t -132.28213531381235\n",
            "90     \t [-2.50380428  1.85368733 -4.80431782 -4.83320476 -0.28729918  5.03445595\n",
            " -5.03450479 -1.89627826]. \t  -534.5030551811024 \t -132.28213531381235\n",
            "91     \t [ 4.3074709  -2.09211978 -2.95273532  2.33947159  4.71319625 -2.95834664\n",
            "  4.52527469 -3.74529607]. \t  -494.50338467440054 \t -132.28213531381235\n",
            "92     \t [ 4.37369686  1.64404179  4.64844497 -2.7917668  -3.06694447  4.29029129\n",
            " -4.73046282  3.6604643 ]. \t  -541.8382190229837 \t -132.28213531381235\n",
            "93     \t [ 0.44985771 -5.04018311 -2.67352371 -1.98745115 -4.13204736  4.40905542\n",
            "  4.44234105 -1.50988587]. \t  -446.6387949917347 \t -132.28213531381235\n",
            "94     \t [ 4.45160046  0.85827729  4.31029756 -3.50117674  4.61732147  1.27672196\n",
            "  3.97381346 -4.0892082 ]. \t  -486.7487209708847 \t -132.28213531381235\n",
            "95     \t [ 2.29183362 -4.25880269 -1.60290865 -3.84858402  4.8914368  -2.46004838\n",
            " -4.75621962  4.61687575]. \t  -593.299153821644 \t -132.28213531381235\n",
            "96     \t [ 3.20266808  0.7090719  -4.52728769  4.21093389  4.97003275 -1.27198075\n",
            " -4.8400682  -4.63203128]. \t  -612.5227764965464 \t -132.28213531381235\n",
            "97     \t [-0.66551097  4.51914064  3.38283834 -4.396338   -5.10659132 -0.80795747\n",
            "  4.45304114  2.37845833]. \t  -471.29679190919546 \t -132.28213531381235\n",
            "98     \t [ 4.15523548  4.89760637 -4.52582521  2.60039168  4.35751514 -0.56381114\n",
            " -3.51413984  4.65119041]. \t  -510.096326025636 \t -132.28213531381235\n",
            "99     \t [ 0.78204696  0.83270194  2.60888247 -4.33041426 -4.79979036  4.58985252\n",
            "  3.79167165 -4.66580997]. \t  -613.813229638116 \t -132.28213531381235\n",
            "100    \t [-2.78453089 -1.47255593  0.3676772  -3.15026286 -3.97190591  4.56368814\n",
            " -2.4883475  -3.67832185]. \t  -407.6198428979011 \t -132.28213531381235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kM4bcwSteJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6b6d39e-3864-438a-b074-f4d0decb77dd"
      },
      "source": [
        "end_lose = time.time()\n",
        "end_lose\n",
        "\n",
        "time_lose = end_lose - start_lose\n",
        "time_lose\n",
        "\n",
        "start_win = time.time()\n",
        "start_win"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1616585401.6237192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NMzLM7nteQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d46364-9aeb-4d86-e198-4a596f48beb1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 1 \n",
        "\n",
        "np.random.seed(run_num_1)\n",
        "surrogate_winner_1 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_1 = dGPGO_stp(surrogate_winner_1, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.1486226  -3.38872572 -0.65475564  2.75724772 -2.09586888 -3.59257132\n",
            " -4.88982196 -0.8169012 ]. \t  -328.0959084909929 \t -201.54672633894333\n",
            "init   \t [-2.67589487 -1.6624006   5.02489564 -2.68568111 -4.28858717  1.73670644\n",
            "  1.24152749 -2.31164385]. \t  -280.8839324859534 \t -201.54672633894333\n",
            "init   \t [-0.34589276 -3.90791423 -4.36267454  4.10392759  3.01017662  3.4874332\n",
            "  3.22772436  5.02737768]. \t  -548.5335043326104 \t -201.54672633894333\n",
            "init   \t [ 0.79128402  3.21297323 -0.80570494 -4.83893289 -0.46964077 -4.04146089\n",
            "  3.24833343  2.024732  ]. \t  -322.64234862459267 \t -201.54672633894333\n",
            "init   \t [ 0.66852251 -2.31191249  5.10437114 -3.70644938  1.18185664 -0.15322828\n",
            " -0.97252315  2.33317475]. \t  -201.54672633894333 \t -201.54672633894333\n",
            "1      \t [-1.8143854  -1.01841357 -1.85378403  4.57955153  4.28757363  3.21376643\n",
            " -4.77105058  4.54013818]. \t  -577.6945507490634 \t -201.54672633894333\n",
            "2      \t [-0.85685749  4.37545244  1.02757506 -1.367164    2.72142012  1.32454858\n",
            " -4.17664952 -4.70221304]. \t  -396.22213339906483 \t -201.54672633894333\n",
            "3      \t [ 4.66308842  0.84598875 -4.15122453  1.11050319 -3.49839947  4.87163532\n",
            " -2.05963361 -0.01488499]. \t  -313.09403696321726 \t -201.54672633894333\n",
            "4      \t [ 4.50211867  3.52020401  0.59833872  4.66546641 -0.06524297 -0.97792544\n",
            "  0.60780846  2.84541126]. \t  -206.30933206172915 \t -201.54672633894333\n",
            "5      \t [-1.03156768 -4.09716338 -2.65023964  0.34176635  0.30694719  3.16298674\n",
            "  4.18980601 -3.18576573]. \t  -320.74829573525165 \t -201.54672633894333\n",
            "6      \t [-5.00073662  1.52813283 -4.81227914 -4.1373695  -1.5276949   2.70157047\n",
            " -4.98038175  3.67939215]. \t  -505.0161297967612 \t -201.54672633894333\n",
            "7      \t [-3.93220317 -3.69843659 -2.81018095  1.23484693  4.50101399 -3.36676303\n",
            " -2.10707555  1.44062107]. \t  -289.5975053416226 \t -201.54672633894333\n",
            "8      \t [-4.12558236 -4.0606954   2.63942955 -3.62357305  4.86767692  1.54210721\n",
            "  3.35016639 -1.3149525 ]. \t  -348.5578810169892 \t -201.54672633894333\n",
            "9      \t [-4.75817249 -0.99322514 -1.50822354  0.20869353 -3.33009375 -2.63325281\n",
            "  4.71182959  1.79887385]. \t  -309.96031249828116 \t -201.54672633894333\n",
            "10     \t [-3.64943616  4.76787457 -3.77407107  1.51899132  3.04907989  3.14110259\n",
            "  2.35817095 -3.44937339]. \t  -350.5396156120918 \t -201.54672633894333\n",
            "11     \t [ 4.03221345  3.58698611  1.24648967 -5.02074478 -3.71518292  1.82387278\n",
            " -0.50911699 -1.88878525]. \t  -266.81087668898175 \t -201.54672633894333\n",
            "12     \t [ 4.63674551 -4.6281269  -0.42155692 -3.88885714  1.81238622  4.32806214\n",
            " -1.61546108  3.49219493]. \t  -370.0123514248279 \t -201.54672633894333\n",
            "13     \t [-0.12596247  4.35779699  2.65609637  1.19983946 -4.88336546 -2.84094986\n",
            " -4.16830866  3.44941961]. \t  -449.39347109826764 \t -201.54672633894333\n",
            "14     \t [ 3.76467274 -1.81782839  2.25008069  0.72537853  3.84366629 -4.87742973\n",
            "  3.15140597  1.78559961]. \t  -349.70626856742626 \t -201.54672633894333\n",
            "15     \t [-1.22258763  0.90856751  3.13104671  3.85690408 -3.10141916  4.87282644\n",
            "  4.36504616  4.41712003]. \t  -572.08252685319 \t -201.54672633894333\n",
            "16     \t [ 4.02048756  0.91381162 -1.55145409 -0.16421347  4.95252691  3.37402237\n",
            "  2.43986153 -4.04480546]. \t  -388.65917263088727 \t -201.54672633894333\n",
            "17     \t [-4.61491168  0.22560982 -4.4900489  -4.05259464  4.86459139  0.25186857\n",
            " -2.70035443 -3.92739636]. \t  -440.7157295852119 \t -201.54672633894333\n",
            "18     \t [4.61873336 0.83964776 4.47081406 4.50065107 2.49815134 4.71072113\n",
            " 3.50702545 0.40377992]. \t  -415.47875034411805 \t -201.54672633894333\n",
            "19     \t [-1.80776106  4.43168218  4.57378626 -1.99083558  1.35824893  4.00503073\n",
            "  2.80695487  2.1273609 ]. \t  -317.9839940993175 \t -201.54672633894333\n",
            "20     \t [ 4.77995323 -3.53596255  3.94977777  3.33687398 -1.4959541   2.01786005\n",
            " -1.9408511  -2.62136459]. \t  -256.1558481987143 \t -201.54672633894333\n",
            "21     \t [-2.17149059 -3.59638969  4.80494534 -0.21803099 -4.46695367 -3.25794579\n",
            " -3.89312838  4.85422792]. \t  -558.093067666367 \t -201.54672633894333\n",
            "22     \t [-1.0946097   0.22297995 -0.74049532 -5.07588386 -4.4171997  -3.17543654\n",
            " -4.94057362 -1.59597405]. \t  -455.3015869153963 \t -201.54672633894333\n",
            "23     \t [ 2.59874194 -3.33129644 -3.87254822 -1.58202482 -4.10283151 -4.91029881\n",
            "  4.4859348  -4.94632265]. \t  -649.3761087377535 \t -201.54672633894333\n",
            "24     \t [-4.41474078 -0.38692462  5.04064682  5.05941718  2.73198484 -2.80213693\n",
            " -2.1028147  -4.03858575]. \t  -444.26926872239676 \t -201.54672633894333\n",
            "25     \t [-2.1603285  -4.17003418  5.02724918  4.84552232  5.07542979 -0.63960571\n",
            "  0.12879688  3.7796963 ]. \t  -454.84090273570314 \t -201.54672633894333\n",
            "26     \t [ 0.60778789  3.95576477 -3.0188754   1.46224944  3.46143486 -4.82745475\n",
            "  3.30169697 -3.87687526]. \t  -463.84236294623736 \t -201.54672633894333\n",
            "27     \t [-4.99188222  2.32475228 -3.11862758  3.99233087 -0.30231847 -3.17982672\n",
            " -1.51948531 -1.15496916]. \t  -216.61842069249553 \t -201.54672633894333\n",
            "28     \t [-5.04748709  3.0494448   4.66398666 -5.0759968   3.05160404 -4.73117186\n",
            "  0.11900895 -4.78361965]. \t  -576.4252786438269 \t -201.54672633894333\n",
            "29     \t [ 3.36444364 -1.63999011  4.04012686 -1.09531888 -4.32849003  0.08810346\n",
            "  4.97565104  3.79138663]. \t  -452.4877118821266 \t -201.54672633894333\n",
            "30     \t [ 4.65403043  2.46591919 -2.36586501  0.60685337 -3.76523203  0.7614489\n",
            "  4.97096417 -1.54968462]. \t  -318.63581057054273 \t -201.54672633894333\n",
            "31     \t [ 4.49855503  3.09289469 -1.28472905 -0.49341256 -1.26308729 -4.63363614\n",
            " -3.07314868 -4.08017492]. \t  -381.38717216457644 \t -201.54672633894333\n",
            "32     \t [ 5.00253654  3.239052    2.07737943 -4.62612043  4.00971261  3.29127815\n",
            " -2.66743976  3.0448558 ]. \t  -413.91863077350513 \t -201.54672633894333\n",
            "33     \t [-3.63047934  4.71263026 -3.81408637 -4.98248057 -2.97049411  2.88123525\n",
            "  3.91350438  0.13819394]. \t  -401.8300352431608 \t -201.54672633894333\n",
            "34     \t [ 3.94506145  4.6219637  -4.05883276 -3.62467217  4.56192664 -4.92182544\n",
            " -4.30806291  3.44376204]. \t  -634.4578556365511 \t -201.54672633894333\n",
            "35     \t [-4.08995962 -1.45983655  5.09227953 -4.9458337  -3.49473395  4.80298781\n",
            " -4.75884507  3.08324068]. \t  -630.6842395836534 \t -201.54672633894333\n",
            "36     \t [ 1.87672265 -2.51768762 -2.65499639  0.56149328  4.0045964   1.83641484\n",
            " -4.85547309 -2.76696176]. \t  -365.3041360248913 \t -201.54672633894333\n",
            "37     \t [-1.68852435  1.27484007  5.03394079  4.36178687  3.91980182  2.19374904\n",
            "  4.33403257 -5.08919112]. \t  -602.6092059002998 \t -201.54672633894333\n",
            "38     \t [-4.51260628 -0.94366779 -0.45814386  4.50369554 -4.919382    1.26842236\n",
            "  3.90741448 -4.48597884]. \t  -502.42964726450975 \t -201.54672633894333\n",
            "39     \t [ 0.78457056 -4.62843608 -3.18149112  4.57391595 -4.67127302 -0.53927668\n",
            "  3.34454207  2.52538923]. \t  -397.6802095479603 \t -201.54672633894333\n",
            "40     \t [ 2.08344421  3.4485939  -2.03516244 -2.02977018  4.70479387  3.37055144\n",
            "  5.06277645  4.57187747]. \t  -582.509441140899 \t -201.54672633894333\n",
            "41     \t [-0.11041322 -3.74738688 -0.92671969 -3.8306141   2.25999311 -4.9730623\n",
            " -2.6387679  -4.07307686]. \t  -444.75610227503375 \t -201.54672633894333\n",
            "42     \t [ 3.38225706  0.81101684  4.75370528  2.92931596  2.67393075  4.66937398\n",
            " -5.00639378  1.9355584 ]. \t  -486.8586594332529 \t -201.54672633894333\n",
            "43     \t [-4.22120316  5.01571144  3.00350741  3.11875493 -3.61609638  3.44983769\n",
            " -4.29645721 -2.78040351]. \t  -461.9539849548813 \t -201.54672633894333\n",
            "44     \t [-3.75196389e-01  1.73576047e+00  1.79600857e+00  3.42676622e+00\n",
            "  3.46886943e+00 -4.72052518e-03  5.10638162e+00  3.83611337e+00]. \t  -423.23181673152885 \t -201.54672633894333\n",
            "45     \t [-2.50358196 -0.41728937  4.13729633 -5.02402201 -5.05658796 -4.33062379\n",
            "  2.86409028  3.84744806]. \t  -575.1462033186323 \t -201.54672633894333\n",
            "46     \t [ 4.54276945 -0.85023378 -4.48265994  3.40057316 -1.76737483 -4.31457671\n",
            " -2.21093249  4.71079823]. \t  -467.6828798692925 \t -201.54672633894333\n",
            "47     \t [ 1.11051161  5.05314514 -2.54852681  0.93527866 -0.36196333  4.18052386\n",
            " -4.80129549  4.89244233]. \t  -533.6565090559733 \t -201.54672633894333\n",
            "48     \t [-3.78094599 -3.18064913 -2.24166601 -2.3537154  -3.34459301  4.93705664\n",
            "  0.21491806  2.16443804]. \t  -311.74406099867895 \t -201.54672633894333\n",
            "49     \t [ 1.42529376 -3.57045519 -4.21976659 -4.19541722  1.69575876  1.04977954\n",
            "  3.96345158  3.09681743]. \t  -359.0282316303535 \t -201.54672633894333\n",
            "50     \t [ 1.12195583 -4.51683244 -1.05506503 -0.61958291 -3.17430458  4.2380258\n",
            " -4.9979383  -2.85373993]. \t  -445.0899406986292 \t -201.54672633894333\n",
            "51     \t [-2.05334836  3.91156405  0.44043171 -1.92884299  3.14752265 -2.02867305\n",
            " -4.9550074   4.34326629]. \t  -447.28455230624115 \t -201.54672633894333\n",
            "52     \t [-1.84509173  4.2231208  -1.2744469  -0.03916864 -5.0891493  -0.17283747\n",
            " -0.5163163  -4.55102269]. \t  -341.18962156443877 \t -201.54672633894333\n",
            "53     \t [ 4.17234548 -3.74905414 -3.28714663 -4.64943455  3.46893149 -0.91697168\n",
            "  3.294976   -4.08604531]. \t  -439.18089529704207 \t -201.54672633894333\n",
            "54     \t [-0.22981553 -4.88433679 -1.86750539  3.05642706 -4.51768031  4.1337743\n",
            " -3.74878553  4.41780061]. \t  -554.6811864644135 \t -201.54672633894333\n",
            "55     \t [-3.66473515  3.96498083  4.78883     5.11040933  2.04173208 -1.97420377\n",
            " -2.09724764  4.96084585]. \t  -490.0335412853425 \t -201.54672633894333\n",
            "56     \t [ 3.14349815  4.83222621  5.10291592  2.36986671 -3.60173808 -1.09538429\n",
            "  4.88439415 -3.00314864]. \t  -468.3808707706148 \t -201.54672633894333\n",
            "57     \t [ 1.63889926 -5.09519984 -2.26775329  4.54201968  3.37905796 -3.41977384\n",
            "  3.42337946 -3.81798893]. \t  -478.4682861062739 \t -201.54672633894333\n",
            "58     \t [-4.96972516 -1.6273064  -4.54108934  0.80199298 -4.72840973  1.50771214\n",
            " -5.11575729 -1.0082738 ]. \t  -411.1898737292093 \t -201.54672633894333\n",
            "59     \t [-4.71050862 -2.78060845 -1.04016182  3.58118617  4.99600492  4.91475171\n",
            " -0.6381454  -1.8752615 ]. \t  -392.9103299814835 \t -201.54672633894333\n",
            "60     \t [-4.8406052  -3.56177698  4.67550287 -0.23061687 -0.96683197  2.50043333\n",
            "  3.71415788  4.60815181]. \t  -423.2297941154369 \t -201.54672633894333\n",
            "61     \t [ 5.09762027 -4.11752181  4.79551488 -1.2743292  -4.94845215  3.43860937\n",
            " -4.89257636  2.94542147]. \t  -565.7255369425181 \t -201.54672633894333\n",
            "62     \t [ 1.54347122  2.78945109 -4.59900383  4.67928518 -3.54500945 -4.9755038\n",
            "  4.90698434  3.93123634]. \t  -672.5354345486169 \t -201.54672633894333\n",
            "63     \t [-0.06702641 -3.60031952  3.03502531  3.48018484 -2.11961712 -2.1899569\n",
            "  4.07469199 -2.57693433]. \t  -322.59585474914707 \t -201.54672633894333\n",
            "64     \t [ 3.35007418  5.00284853  4.58005418 -1.99488166  2.57489137 -0.46254789\n",
            "  1.24491103 -2.87126753]. \t  -251.36495734327855 \t -201.54672633894333\n",
            "65     \t [ 3.60991938  5.04976858 -3.7073178   4.63682243  2.03555794  3.73807391\n",
            "  4.04360244  2.5089196 ]. \t  -460.63407379595697 \t -201.54672633894333\n",
            "66     \t [-5.10412658 -3.10712386 -3.17940034 -4.78488113 -1.36979352 -4.96823704\n",
            " -2.66680955  4.19141947]. \t  -515.0756911594598 \t -201.54672633894333\n",
            "67     \t [ 3.47330315  4.72191459  3.54277161  4.43181283  2.37302937 -4.97213651\n",
            "  0.25842993 -4.65485297]. \t  -523.1722837068255 \t -201.54672633894333\n",
            "68     \t [-4.12997292  1.56303328 -4.43985584 -1.65886211  3.07342182 -1.84200725\n",
            "  4.10954663  0.90168877]. \t  -284.3975842175573 \t -201.54672633894333\n",
            "69     \t [-3.9177791  -3.01187815 -0.9195855  -1.32802401 -3.41887683 -3.50890879\n",
            "  0.43199022 -4.76120148]. \t  -358.06018117224755 \t -201.54672633894333\n",
            "70     \t [ 4.75786285  1.4050329   4.96586987 -0.17608764 -4.21408654 -3.93526128\n",
            " -1.80341495 -1.19802756]. \t  -316.6477252111942 \t -201.54672633894333\n",
            "71     \t [-4.07599477 -1.56268903  1.56544864  2.80331601  4.85590761 -4.92961175\n",
            "  3.206448    0.18149223]. \t  -396.2222408574762 \t -201.54672633894333\n",
            "72     \t [-5.01281965  4.02193832 -2.11280359 -0.57703439  1.95972921  4.95218285\n",
            "  2.05700269  4.95135481]. \t  -464.297547210802 \t -201.54672633894333\n",
            "73     \t [ 4.7432243  -4.44136182  1.51638096 -5.01668874 -2.52173591 -2.98061438\n",
            "  2.30172974 -1.11800907]. \t  -301.70186927832293 \t -201.54672633894333\n",
            "74     \t [-3.55860061 -4.90613746  3.92708133  0.39119221  5.08240253  1.44764579\n",
            " -2.71130073 -5.0346024 ]. \t  -503.6460156422692 \t -201.54672633894333\n",
            "75     \t [-0.11031178  2.26444911  3.2855467   4.58630993 -3.95079574 -3.04183648\n",
            "  4.47867085  4.44005218]. \t  -558.4715399632651 \t -201.54672633894333\n",
            "76     \t [-4.91335295 -1.84876415  3.96255349  1.02127073 -1.68604074  3.32312077\n",
            " -4.30219838 -3.59295179]. \t  -395.56361500096756 \t -201.54672633894333\n",
            "77     \t [-2.68862644 -1.31627671 -0.60553155 -5.04498003  5.06822595  1.61315466\n",
            " -1.0978015   4.24104316]. \t  -409.9771133819818 \t -201.54672633894333\n",
            "78     \t [ 3.80602352 -1.09359229  1.69303258 -5.01768308  2.34434506  3.40735638\n",
            " -5.11319593 -5.03912922]. \t  -609.4815838280847 \t -201.54672633894333\n",
            "79     \t [-4.67326765  2.91068022  3.97651232  3.98570976 -3.95134052 -3.1369543\n",
            " -1.70732303 -3.67760179]. \t  -415.47608502020506 \t -201.54672633894333\n",
            "80     \t [ 4.93094917 -3.25880174  4.64981765 -3.22807196  3.91576939 -4.44503044\n",
            " -3.27154294 -2.2037308 ]. \t  -461.08645558252124 \t -201.54672633894333\n",
            "81     \t [ 2.45501843 -3.6142415  -1.51737422 -1.62533443 -4.64421571  0.69608787\n",
            "  0.19502089  4.76634098]. \t  -342.38793067070674 \t -201.54672633894333\n",
            "82     \t [ 2.88706191  4.39384619 -0.93365415  4.64846357 -0.43420665  1.55403441\n",
            " -1.28899128 -4.16142861]. \t  -301.5980887567159 \t -201.54672633894333\n",
            "83     \t [ 3.73729925 -5.01394756  4.81545103  2.87949265  2.38026782 -3.99409161\n",
            "  0.60144108 -3.20375769]. \t  -375.66797089029853 \t -201.54672633894333\n",
            "84     \t [ 4.93471067  3.81145391  4.11498117  2.54737149  4.49255463  3.53668241\n",
            " -2.72234347 -5.07849016]. \t  -564.3318945477258 \t -201.54672633894333\n",
            "85     \t [ 4.67348873 -1.79470299  4.55768084 -1.51460123  1.12628985  0.35162474\n",
            "  2.96782211 -4.05486019]. \t  -300.0522361792631 \t -201.54672633894333\n",
            "86     \t [-4.57768913  1.04749214 -3.08872908  5.01675286 -2.5406343   4.18318346\n",
            " -3.7925496   4.33423928]. \t  -540.6790216920224 \t -201.54672633894333\n",
            "87     \t [ 3.95112324  4.98218195 -3.70349697 -4.10490258  0.3110347   0.89193422\n",
            "  4.55960167 -5.01222012]. \t  -525.5697880375109 \t -201.54672633894333\n",
            "88     \t [ 4.49356215 -0.91705531 -4.86808467  4.23986516 -4.11544056 -3.7227642\n",
            "  1.09719161 -3.10132557]. \t  -418.0853164325455 \t -201.54672633894333\n",
            "89     \t [ 0.77713654  1.83219312 -4.53235311 -4.17957928  1.06522931  4.01771619\n",
            " -2.85027743 -0.25563479]. \t  -298.73720088742493 \t -201.54672633894333\n",
            "90     \t [ 4.16270216 -2.16384928 -4.60059942  5.10366387  4.67039894 -4.21638711\n",
            " -1.95446585 -2.10887198]. \t  -472.42759945405845 \t -201.54672633894333\n",
            "91     \t [-4.78506546 -4.72144287  4.31553863  0.70669777  2.29170612 -4.1767954\n",
            " -4.18658474  1.62012518]. \t  -399.97439534600795 \t -201.54672633894333\n",
            "92     \t [-1.85761716  4.02603288  0.81107569  3.83948424 -4.32173667 -3.94457283\n",
            "  5.10872754 -2.72837652]. \t  -525.799666359124 \t -201.54672633894333\n",
            "93     \t [-4.97403819  3.55671713  1.15333805 -2.59149682 -3.15619449  3.02756536\n",
            " -0.67606558  2.39447811]. \t  -234.7679048876058 \t -201.54672633894333\n",
            "94     \t [ 4.37616217  4.36254395 -3.9674514   2.44022007  5.01248056 -1.85198282\n",
            " -4.82658792 -1.02221906]. \t  -445.89004267205496 \t -201.54672633894333\n",
            "95     \t [ 2.97277883  3.10727836  4.18104904 -1.31676196 -4.74675081  4.45962305\n",
            " -1.21726453  3.0200052 ]. \t  -402.8499573218509 \t -201.54672633894333\n",
            "96     \t [-0.17775748 -1.70089516  3.54405948  4.43131322 -2.59416758  4.96872788\n",
            "  3.86706731 -3.07063505]. \t  -483.93283828231074 \t -201.54672633894333\n",
            "97     \t [-2.09966925  5.07532683  4.85709949 -0.46770975  1.28131702 -5.09199706\n",
            " -3.08834341 -0.60670556]. \t  -361.0650112379403 \t -201.54672633894333\n",
            "98     \t [ 2.22467126  5.08929858  2.62920785 -0.78629763 -3.18368131  4.58562924\n",
            "  4.60702727 -4.73003231]. \t  -584.3679935975167 \t -201.54672633894333\n",
            "99     \t [ 3.98262889 -2.68647407 -3.49740097 -1.26913318  5.09574036 -3.18530047\n",
            " -2.81723696  2.79954095]. \t  -382.40074397126915 \t -201.54672633894333\n",
            "100    \t [-0.78512089  2.23252641 -4.85095208  3.06287456  4.53224679  0.71719444\n",
            "  0.30830352  1.61224239]. \t  -245.95724763381975 \t -201.54672633894333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBLcW6tlteS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065fd395-9d33-4308-f72d-80ea88a31557"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 2 \n",
        "\n",
        "np.random.seed(run_num_2)\n",
        "surrogate_winner_2 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_2 = dGPGO_stp(surrogate_winner_2, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.60433145 -4.36322715  4.04410125 -0.65030607 -3.81258     0.77678463\n",
            "  3.48642222 -0.66436556]. \t  -266.73879363027606 \t -205.20381448253355\n",
            "init   \t [ 2.00612414  1.89069411  2.05463926  2.86406925  1.46175353  4.72090796\n",
            " -4.00931957  3.03212891]. \t  -387.12857956211883 \t -205.20381448253355\n",
            "init   \t [ 3.40562005 -2.39607436  3.44765838  0.32897952  0.17313346 -4.11046182\n",
            "  4.2892185   1.70658296]. \t  -312.7789728136913 \t -205.20381448253355\n",
            "init   \t [-3.33025814 -2.89083891 -0.32895713 -0.65647368  3.98698988 -2.84058346\n",
            "  0.91155831 -2.28145592]. \t  -205.20381448253355 \t -205.20381448253355\n",
            "init   \t [ 0.26339516 -2.46418319  0.29643398 -1.92367877  0.45222142 -2.6413414\n",
            " -4.15500263 -3.17986428]. \t  -271.9028038542476 \t -205.20381448253355\n",
            "1      \t [-3.58107824  4.03913561 -2.04029852 -2.32586783 -5.05364741  1.00365777\n",
            "  3.01415303  1.00987973]. \t  -285.07587324909576 \t -205.20381448253355\n",
            "2      \t [ 4.18021262 -1.11976423 -2.36632484 -1.94732869 -4.97029632  1.99215769\n",
            " -1.27677137  3.8314449 ]. \t  -328.1309142393032 \t -205.20381448253355\n",
            "3      \t [-2.33939103  3.42595734  2.45061491 -3.17801789  4.72775184 -4.60559431\n",
            " -4.96352682  3.94635514]. \t  -623.4359705286043 \t -205.20381448253355\n",
            "4      \t [-3.48637274 -3.89123995 -1.38904965 -5.09060776 -5.02164417  4.52607733\n",
            " -1.28724552 -3.83352781]. \t  -530.0471157456185 \t -205.20381448253355\n",
            "5      \t [-2.21749132  3.31612471 -1.8780737  -3.95441088  2.82677089  1.75664842\n",
            " -1.24224273  0.01314203]. \t  \u001b[92m-169.31317882574902\u001b[0m \t -169.31317882574902\n",
            "6      \t [-2.10140792  2.67807242  1.68628494  4.56034289 -1.8500807  -3.14762825\n",
            " -4.13600895 -2.97135732]. \t  -377.41471871614783 \t -169.31317882574902\n",
            "7      \t [-1.50746301  3.70830327 -1.20220183 -0.11369006 -2.21473359  3.55914987\n",
            " -5.11033216 -4.99695832]. \t  -517.2587546011025 \t -169.31317882574902\n",
            "8      \t [ 1.92461002 -4.86898679 -3.35639454  5.02882577  1.59222489  3.60954208\n",
            "  0.32370062 -0.91059447]. \t  -284.28629363971817 \t -169.31317882574902\n",
            "9      \t [ 4.65755556  4.56925642  3.15028751  2.39346138  1.7131338   3.76319177\n",
            " -4.21394718 -4.96668611]. \t  -537.4256306312348 \t -169.31317882574902\n",
            "10     \t [-4.29305357  3.1084574   3.38374609  1.94268041 -4.16652041 -4.91875808\n",
            "  2.9327471  -0.23981948]. \t  -379.83225856683373 \t -169.31317882574902\n",
            "11     \t [ 3.31386882  4.20874624  2.80639656  4.70516753  0.77583565 -1.58822836\n",
            "  2.17294614 -1.95275945]. \t  -240.29324869898412 \t -169.31317882574902\n",
            "12     \t [ 3.12063365  3.06485531 -1.15489206 -4.11579771 -0.39116557 -1.55059134\n",
            "  5.03513459  3.94726293]. \t  -417.5917136581396 \t -169.31317882574902\n",
            "13     \t [-2.76086403 -4.57795664 -4.83509079 -0.96938259  2.40971448 -2.71791874\n",
            " -0.89998849  4.59320673]. \t  -371.23721574598903 \t -169.31317882574902\n",
            "14     \t [-4.24641002 -1.98367933  0.97079043  4.83409668 -2.75449056  3.70806754\n",
            " -2.9250261  -1.21257134]. \t  -314.29098852150787 \t -169.31317882574902\n",
            "15     \t [-0.88643923  4.80610418 -4.95779804  3.32053101 -0.14313835 -0.6041757\n",
            " -2.36866112  3.53279031]. \t  -306.23739860772207 \t -169.31317882574902\n",
            "16     \t [ 0.66304699 -4.11634551 -4.71385582  1.83050897 -5.06760425  1.48635757\n",
            "  4.12745891 -1.21654435]. \t  -387.1424722930613 \t -169.31317882574902\n",
            "17     \t [-2.7530542  -4.51049845  4.05867285  2.34421782 -4.77124791 -3.28013617\n",
            "  1.30665985  3.79903639]. \t  -425.46113752925817 \t -169.31317882574902\n",
            "18     \t [-4.61968796  0.78786726  3.95100547  4.81505391  3.86779689 -3.68881212\n",
            "  3.98945164  0.06503618]. \t  -430.04047725424493 \t -169.31317882574902\n",
            "19     \t [-4.76750173  1.30939219 -0.93440447 -1.66206922 -4.28771943 -2.76698945\n",
            " -4.82578735  4.31430513]. \t  -489.6107880434111 \t -169.31317882574902\n",
            "20     \t [ 2.52097868  5.04761329  2.1078495   2.47022686 -4.72403086 -0.98245121\n",
            "  4.68123328  3.99443427]. \t  -493.4645612819357 \t -169.31317882574902\n",
            "21     \t [-4.78489803 -2.41979538  2.99986707 -2.46299596  0.43117938  3.19292183\n",
            "  1.59679611  1.40874144]. \t  -181.69187359749793 \t -169.31317882574902\n",
            "22     \t [ 2.35778315 -4.4845486   3.23209445 -1.43320869  1.08258847 -3.29813697\n",
            " -3.91334207  4.68573548]. \t  -439.3120381810914 \t -169.31317882574902\n",
            "23     \t [ 4.92127717 -5.03850139 -4.96727471 -2.99379577  2.99593661 -1.44102364\n",
            "  3.57821778 -3.96104207]. \t  -457.3464752548669 \t -169.31317882574902\n",
            "24     \t [-3.33305933  3.21853738 -4.0173242   4.38738553  4.51018032  3.29766901\n",
            "  0.51461302 -3.10219053]. \t  -403.039370978181 \t -169.31317882574902\n",
            "25     \t [ 3.83979553  1.48184107 -1.7439722   3.15633214  4.43126687 -4.71169675\n",
            " -3.66443456  1.26185135]. \t  -406.22564628128055 \t -169.31317882574902\n",
            "26     \t [-4.03913391  3.87819358  3.15300343 -5.03522468  3.42413908 -1.25884211\n",
            "  3.18612405 -4.38935752]. \t  -470.9567394475918 \t -169.31317882574902\n",
            "27     \t [-4.78281992 -3.1733766   5.0575263  -3.89255314 -3.86036586 -0.74472548\n",
            " -3.71797816 -2.30888003]. \t  -397.61036720624094 \t -169.31317882574902\n",
            "28     \t [ 3.55326666  3.93875976  5.00820111 -3.60007997 -5.10336264 -1.28933452\n",
            "  2.04806101 -1.68270993]. \t  -362.9517301300212 \t -169.31317882574902\n",
            "29     \t [-4.19988392 -4.61444641 -1.94535925  5.1129109  -0.68644786 -0.66710116\n",
            "  4.03827284  2.85988481]. \t  -360.75721440245036 \t -169.31317882574902\n",
            "30     \t [ 4.24528381 -4.98885233 -3.96115371 -4.37022184 -4.90764816 -3.97270478\n",
            "  1.74344984 -0.89542513]. \t  -434.07826444939803 \t -169.31317882574902\n",
            "31     \t [-0.63771352 -4.64082075 -5.00143266  4.20706563  2.81158345 -3.51632093\n",
            " -4.94617292 -3.73069925]. \t  -585.6311096780846 \t -169.31317882574902\n",
            "32     \t [ 4.1985992  -4.82250548 -2.44379099  4.12514011 -3.78843665 -5.07858253\n",
            " -4.13395575 -1.42645779]. \t  -512.5434708096061 \t -169.31317882574902\n",
            "33     \t [-5.07493032  4.84578945  3.77902323  0.10244051 -3.61994104  3.82051334\n",
            "  2.85649489 -3.75983363]. \t  -438.90882559771836 \t -169.31317882574902\n",
            "34     \t [ 4.53995872 -3.29522859 -4.30937043  2.60308384  3.97467177 -3.63082952\n",
            "  4.7340503   3.18147539]. \t  -521.0850183497041 \t -169.31317882574902\n",
            "35     \t [ 1.29758886  2.37265318  1.94715773  3.48995734  5.06761857  4.84508127\n",
            "  5.09736115 -2.21023269]. \t  -563.2515097745854 \t -169.31317882574902\n",
            "36     \t [ 1.91236942  3.41539283 -4.62689197  2.53189963 -1.68107188  0.68118123\n",
            "  4.47598433 -4.12851247]. \t  -410.3654564959471 \t -169.31317882574902\n",
            "37     \t [-3.35686775 -2.75780207  1.16619598  4.30772719  4.39254268 -0.06371758\n",
            " -4.05898016  4.88631857]. \t  -507.6182277557201 \t -169.31317882574902\n",
            "38     \t [ 4.78371816 -2.26275887 -4.14004267  1.4218486   4.77697342  3.42103164\n",
            " -3.24732027  4.01985715]. \t  -480.03834322314015 \t -169.31317882574902\n",
            "39     \t [ 2.68355553  4.48457184  1.23478328  4.56053051 -4.06493999 -2.50483732\n",
            " -4.79992279  3.85203266]. \t  -535.4360650629866 \t -169.31317882574902\n",
            "40     \t [ 2.83805721  4.81882546  4.65802003 -4.32832814  3.86072907  3.50057239\n",
            " -2.80894808  4.07267609]. \t  -530.5009124160661 \t -169.31317882574902\n",
            "41     \t [-0.20118737 -4.88264784  1.75877754 -4.84054904  3.91713356  3.38563518\n",
            "  3.48337766 -4.58801692]. \t  -549.555995356515 \t -169.31317882574902\n",
            "42     \t [-0.05421855 -2.42174328 -3.56435409 -3.73137802  4.90951471  2.51546336\n",
            "  4.46724739  3.10352196]. \t  -480.77010085277516 \t -169.31317882574902\n",
            "43     \t [ 5.11908958 -3.65978574  3.53449184  2.83137419  3.27034835 -0.4266979\n",
            " -2.67528706 -0.18223685]. \t  -227.4718845797353 \t -169.31317882574902\n",
            "44     \t [-4.09392026 -0.31499592  3.62888001 -2.34084664  3.72063975  3.64534652\n",
            " -4.47302285 -2.73439824]. \t  -427.2013024057689 \t -169.31317882574902\n",
            "45     \t [-3.97755508 -4.78953048 -4.23355458 -3.48722095 -3.82161664  4.83960173\n",
            " -2.80370621  4.97634451]. \t  -630.8035964870385 \t -169.31317882574902\n",
            "46     \t [ 0.64056064  4.41150712  3.48622047 -1.75601874 -3.61224431 -4.30173207\n",
            " -0.99707082  4.98128858]. \t  -469.86459182614584 \t -169.31317882574902\n",
            "47     \t [ 4.89404358  2.97490825 -4.47613672 -1.9569842  -2.11852924 -4.69943423\n",
            " -0.53322196 -4.694026  ]. \t  -450.288612903963 \t -169.31317882574902\n",
            "48     \t [-3.92788925 -3.42312441  5.1099417   4.01791104  2.97212014  3.63840378\n",
            "  4.11857388  4.83510693]. \t  -611.1328356325879 \t -169.31317882574902\n",
            "49     \t [-2.50138661  5.04301938 -2.41924973  1.72666945  2.02571643 -4.1482169\n",
            "  1.08588608 -3.10047105]. \t  -295.52614315095747 \t -169.31317882574902\n",
            "50     \t [-4.37015948  2.14174352 -1.80806673  5.07649173  2.72441839  4.13618351\n",
            "  4.74992451  4.36413962]. \t  -591.2213721992784 \t -169.31317882574902\n",
            "51     \t [ 4.20440393 -3.13475091  3.35145393 -4.0896613  -2.37675859  4.05684575\n",
            " -2.76710741 -3.84686121]. \t  -436.9061918432802 \t -169.31317882574902\n",
            "52     \t [-4.27805516 -1.74413738  1.73616366 -4.42301829 -2.1280766  -4.85084958\n",
            "  3.9317017   4.82458017]. \t  -569.9294811295076 \t -169.31317882574902\n",
            "53     \t [ 2.88109137  0.29733634  4.00968546 -3.43153659  5.0646981  -2.94614086\n",
            " -0.86567058  1.10662132]. \t  -299.1889058375874 \t -169.31317882574902\n",
            "54     \t [ 1.55588352  1.59635582 -0.15551959  4.75437643 -4.86880442  4.38104995\n",
            "  2.9280033  -0.40113727]. \t  -392.99400357934616 \t -169.31317882574902\n",
            "55     \t [-4.99748813 -1.04902355 -4.89487031  4.30345899 -1.02216079 -3.5922673\n",
            " -1.73858645 -0.62851626]. \t  -280.1035023941334 \t -169.31317882574902\n",
            "56     \t [-3.82491021 -4.85103543 -1.70439733 -2.62804859 -4.88451689 -3.75704349\n",
            "  5.09689346 -4.62612039]. \t  -655.0774562150963 \t -169.31317882574902\n",
            "57     \t [-1.36276994  4.96921625  4.31980047 -2.2906993  -3.92574252 -5.01088598\n",
            " -1.34306646 -4.82948987]. \t  -555.144316535798 \t -169.31317882574902\n",
            "58     \t [ 0.89057948 -4.5158084   0.81981427  5.01262181  2.99882743 -1.98641802\n",
            "  4.99780586 -3.8245282 ]. \t  -504.6025195898005 \t -169.31317882574902\n",
            "59     \t [ 3.44543637 -4.03255736  2.74420326  2.62133572 -0.67345506 -5.10670594\n",
            " -0.32894132 -4.61503411]. \t  -424.355745097988 \t -169.31317882574902\n",
            "60     \t [-3.99638879  4.46893428  4.36358431  4.36702722  2.00018232  4.55093103\n",
            " -1.58257111 -2.8785852 ]. \t  -417.41140876755577 \t -169.31317882574902\n",
            "61     \t [-2.01194625 -0.5588173  -4.78873769 -5.07914211 -1.64738738  3.98430702\n",
            "  4.51172729 -3.21410387]. \t  -510.6103772714973 \t -169.31317882574902\n",
            "62     \t [ 3.82338427 -2.52652198 -1.775587   -1.28270076  4.12578094  3.29541822\n",
            " -1.65449454 -5.09389191]. \t  -420.4366794104877 \t -169.31317882574902\n",
            "63     \t [-2.63972242 -1.84287396 -4.98768816 -4.26718471 -2.96112975 -1.37448241\n",
            "  0.63036339  0.26111893]. \t  -219.73069337826902 \t -169.31317882574902\n",
            "64     \t [-0.48746942  1.89480639 -1.71426464  3.16701543 -0.46986366 -3.613258\n",
            "  4.1089392   2.18271145]. \t  -292.0894287524082 \t -169.31317882574902\n",
            "65     \t [-0.01236862  4.23437251  4.93152019 -3.65709363 -4.89933499  3.80215429\n",
            " -4.22834287 -2.73458113]. \t  -554.0483196027777 \t -169.31317882574902\n",
            "66     \t [-3.86412406  1.64711561 -4.10289184  3.33601159  4.85204708 -3.72202382\n",
            " -0.76569266  3.19901971]. \t  -402.18087783940115 \t -169.31317882574902\n",
            "67     \t [-4.3490476   1.34980181  4.73142845  5.07622284  2.87658307 -5.06310699\n",
            " -4.66299543  1.74090326]. \t  -564.4241472443039 \t -169.31317882574902\n",
            "68     \t [ 3.45615753  1.5438658  -1.08325461 -2.78201306 -4.47779892 -3.37971658\n",
            " -4.23955873  0.24042539]. \t  -346.2585396743417 \t -169.31317882574902\n",
            "69     \t [-2.99988145  2.43165445  4.76582146  2.95426438 -3.43512453  2.97954159\n",
            " -0.03539677  4.15921155]. \t  -374.5425576133624 \t -169.31317882574902\n",
            "70     \t [ 3.70889231  4.4282614  -4.49468819 -1.18129402  3.73752867  1.30956932\n",
            "  0.76204464  4.92733112]. \t  -397.5925217246695 \t -169.31317882574902\n",
            "71     \t [ 4.04248532 -5.08464922 -3.8374726  -4.65240495 -0.82427189  4.48554749\n",
            "  1.55417327  0.00973083]. \t  -339.83395593917817 \t -169.31317882574902\n",
            "72     \t [ 3.32112439 -4.17630984 -0.43690323  3.72530451 -3.29009368  0.76808711\n",
            "  3.67853145  4.53108092]. \t  -418.62726163631646 \t -169.31317882574902\n",
            "73     \t [ 4.2501116   3.38060686 -4.33456282  4.30102551 -2.18717438 -0.39248151\n",
            " -3.97819818 -3.08121805]. \t  -382.8576127408727 \t -169.31317882574902\n",
            "74     \t [-1.57081479  4.43855086  3.68952826  1.2182152   2.68556543  0.92573721\n",
            "  4.86870385  2.92673996]. \t  -364.30261493128825 \t -169.31317882574902\n",
            "75     \t [ 3.18433547  4.83450381 -1.38083566 -2.23011552  4.72714928 -0.15277564\n",
            "  4.74950605 -3.49344535]. \t  -449.9063100221066 \t -169.31317882574902\n",
            "76     \t [-0.26001988  2.20078004  3.24603256  2.85552704  4.82310377 -3.68255266\n",
            " -1.76158351 -4.24102495]. \t  -437.27218710839657 \t -169.31317882574902\n",
            "77     \t [ 4.81255193  4.91942323  2.0088577   0.2412158  -4.8834965   3.23592217\n",
            " -1.36885487  3.57445575]. \t  -381.3014350996227 \t -169.31317882574902\n",
            "78     \t [ 4.21514401 -4.10944416  4.70645829  4.36656143 -4.68434537  2.66094675\n",
            " -4.57929101 -4.11415411]. \t  -628.6609242109971 \t -169.31317882574902\n",
            "79     \t [ 0.43739468  4.29930305  4.91908652 -4.4480546   1.66898474  4.19330993\n",
            "  1.76827606 -2.96529075]. \t  -400.5541575724196 \t -169.31317882574902\n",
            "80     \t [-1.70500705 -3.4893655   4.55885905  4.08338867  2.42295442 -0.15249149\n",
            " -4.95502809 -3.55215604]. \t  -458.60591833313646 \t -169.31317882574902\n",
            "81     \t [ 4.28730236  2.81692335 -0.008738   -4.01728082 -4.81887728  5.11038251\n",
            "  2.43183134 -1.28542552]. \t  -426.2246092619868 \t -169.31317882574902\n",
            "82     \t [ 4.72366536 -2.94056594  4.22860845  2.60444857  2.9338194   4.16906668\n",
            "  2.4748911   3.44832409]. \t  -405.70916550786154 \t -169.31317882574902\n",
            "83     \t [-1.50414731  1.45380616 -5.02561229 -4.95765824  3.00291662 -4.94472644\n",
            " -4.6450796  -2.70052055]. \t  -581.7427015545682 \t -169.31317882574902\n",
            "84     \t [ 4.63060597  4.19444816  1.67355508 -2.26266873  1.34814922 -2.07929457\n",
            " -3.04580272 -4.37381606]. \t  -338.51920350262475 \t -169.31317882574902\n",
            "85     \t [ 2.75381884  4.57772154 -4.70881339 -2.58018552  0.70766869  4.87294101\n",
            "  1.83047774 -1.09444939]. \t  -320.6571836210239 \t -169.31317882574902\n",
            "86     \t [ 4.89837241 -2.650246   -4.5272028   1.95191323 -2.14890127  4.06357484\n",
            " -4.25504775 -3.34724497]. \t  -453.3033533960939 \t -169.31317882574902\n",
            "87     \t [ 2.53943132 -3.83740806  1.51661723 -4.26648864  4.62170068  2.94669603\n",
            " -4.93671664  0.03712789]. \t  -445.1201149248139 \t -169.31317882574902\n",
            "88     \t [ 4.62422282 -0.03855247  2.3491581  -4.87939117  3.91813852  4.99804878\n",
            "  4.92996574  1.65107464]. \t  -551.7581850562086 \t -169.31317882574902\n",
            "89     \t [-4.63834478 -4.53691753  1.12261235  3.48142955  1.40103469  4.57768315\n",
            "  3.54838267 -3.82028446]. \t  -455.38297930409016 \t -169.31317882574902\n",
            "90     \t [-0.95999353 -2.52767749  3.99550491 -2.8371644  -4.78090578  4.36886101\n",
            " -1.37130108  3.67676788]. \t  -443.90930355236975 \t -169.31317882574902\n",
            "91     \t [ 3.35131392 -4.24637154  4.54076334 -3.85610393 -5.08330631 -5.11903546\n",
            " -3.76120462 -2.9510482 ]. \t  -623.7516574648881 \t -169.31317882574902\n",
            "92     \t [ 1.32436111 -3.83581439  2.0222463  -5.07812867 -5.05726671 -4.79863763\n",
            " -3.61488761  4.99122982]. \t  -703.4110394814636 \t -169.31317882574902\n",
            "93     \t [ 3.35692111 -2.24789535  2.24607359 -1.42433607  4.86511112 -4.74310342\n",
            "  2.76934921 -3.80003398]. \t  -467.16030114556634 \t -169.31317882574902\n",
            "94     \t [ 4.30006621 -4.9869798  -1.84804953  4.61640924 -2.82680985  3.17631288\n",
            " -4.12501885  4.50995074]. \t  -546.0370619508554 \t -169.31317882574902\n",
            "95     \t [-0.81157888  2.48192211 -0.92759888 -2.21557387 -3.50311467 -4.84659514\n",
            "  4.95615074 -2.58270807]. \t  -462.7979516516625 \t -169.31317882574902\n",
            "96     \t [ 1.14417293  1.32547701 -4.22301544 -1.846765   -4.97752279  2.30173157\n",
            " -1.84788015 -1.81492966]. \t  -277.88751194440636 \t -169.31317882574902\n",
            "97     \t [ 0.50992683 -1.65488218  4.68515234  2.4826824  -4.42224509 -3.11351429\n",
            " -5.03456639  1.68085363]. \t  -452.21934836869156 \t -169.31317882574902\n",
            "98     \t [-4.32394902  0.7279633   4.92055256 -4.55672802 -2.22214211 -5.08008459\n",
            " -3.93803182  3.57311513]. \t  -565.6740000708211 \t -169.31317882574902\n",
            "99     \t [-3.50160141 -3.69042342 -3.04169519 -0.92351754  1.85071893  4.78507864\n",
            "  0.41253414 -1.22951781]. \t  -238.45960169625536 \t -169.31317882574902\n",
            "100    \t [-3.70841322 -0.10455078 -0.82285598  5.01244867 -3.74101617 -1.42108548\n",
            "  3.6626428  -4.41146134]. \t  -447.9895416202546 \t -169.31317882574902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emgjXwfeuvRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f654238-3614-449e-8365-3f5db2593782"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 3 \n",
        "\n",
        "np.random.seed(run_num_3)\n",
        "surrogate_winner_3 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_3 = dGPGO_stp(surrogate_winner_3, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 2.57613422e+00 -4.00126694e+00 -1.42118102e-01 -1.72873986e-03\n",
            "  1.60880639e+00 -2.70454056e+00  1.15501968e+00 -3.89475939e+00]. \t  -226.23757295607857 \t -200.83819991364615\n",
            "init   \t [ 2.17295152 -1.30498005  0.25362711 -2.42394027  1.24550372 -0.52121845\n",
            " -2.87678861  3.56542093]. \t  -200.83819991364615 \t -200.83819991364615\n",
            "init   \t [ 4.51432417  5.05385819 -3.54862621  1.12022459 -2.14496207 -2.14068561\n",
            "  3.26002484  1.12353371]. \t  -249.2524227715819 \t -200.83819991364615\n",
            "init   \t [ 1.1383917   3.70078893 -1.31804167 -3.13683123 -0.37390212 -2.85955193\n",
            " -3.88879197  1.70639   ]. \t  -252.1724482635516 \t -200.83819991364615\n",
            "init   \t [ 2.32018826 -0.4223289  -1.35717313 -2.05342954 -2.49788598  2.26036994\n",
            " -4.91879441  2.94613072]. \t  -328.7841092566316 \t -200.83819991364615\n",
            "1      \t [-3.55865421  4.31406842 -3.85626065 -3.59130616  2.02875186  3.68832922\n",
            " -3.19072393 -3.1190355 ]. \t  -397.3824499112952 \t -200.83819991364615\n",
            "2      \t [ 4.20312907  5.02301841  2.37347995 -2.42404182  3.1767739   1.10381544\n",
            "  2.76259721 -1.23640066]. \t  -231.9548674593155 \t -200.83819991364615\n",
            "3      \t [-3.24386001 -4.31707621  4.57836799 -0.11427234 -2.45910312 -2.57297709\n",
            "  3.87464245  4.62742456]. \t  -457.08516557325333 \t -200.83819991364615\n",
            "4      \t [-4.12874772  4.77086715  4.43158116  2.92424375 -4.19713104 -3.38348989\n",
            " -2.35816039  0.9252171 ]. \t  -358.2326693147111 \t -200.83819991364615\n",
            "5      \t [-2.37079491 -1.21173666  3.5833956   4.95644465 -3.88089579  2.67162054\n",
            "  4.96609713 -4.59080633]. \t  -604.7157912633598 \t -200.83819991364615\n",
            "6      \t [-3.5553363  -2.51308271 -2.98117052 -0.24939697 -2.0899883   0.42425475\n",
            " -2.2295405  -2.63903951]. \t  \u001b[92m-165.6149144600416\u001b[0m \t -165.6149144600416\n",
            "7      \t [-0.57937858  4.81269618 -0.67848759  3.26339372  2.25619687  4.3915296\n",
            "  4.65449192  2.9502183 ]. \t  -453.0854436147101 \t -165.6149144600416\n",
            "8      \t [-1.73947672 -0.19702211  0.59362284  3.6497256   2.97110418 -2.03813863\n",
            " -4.83812673 -1.29285357]. \t  -303.72797613563966 \t -165.6149144600416\n",
            "9      \t [-2.19887099 -0.3989578  -3.77540966  4.68038287  0.38087753 -3.38391162\n",
            "  3.1741463   1.9242806 ]. \t  -305.1182231593023 \t -165.6149144600416\n",
            "10     \t [ 1.99060721 -4.14574025  2.89764932  4.66662845 -1.8217684  -1.65925127\n",
            " -3.73866684  4.49320648]. \t  -443.10317369827254 \t -165.6149144600416\n",
            "11     \t [-4.99583186 -0.17514218 -1.89337007  0.86461806  0.6602039   2.79787651\n",
            "  4.87752486 -3.50544022]. \t  -352.7491483820859 \t -165.6149144600416\n",
            "12     \t [-5.06460164  3.92642251  4.19954258 -4.14915557  4.86321254  0.86589201\n",
            "  1.74112993  5.02310081]. \t  -524.0800813236228 \t -165.6149144600416\n",
            "13     \t [ 4.81471734 -2.7955622   3.51195023  3.64688019 -0.91107709  2.65353054\n",
            "  4.43562097  0.48392899]. \t  -315.00644791267257 \t -165.6149144600416\n",
            "14     \t [-3.36493228 -0.86290433  5.08679604 -1.99105011  2.56859135 -0.83018129\n",
            "  0.80958797 -5.10062385]. \t  -356.13803242369573 \t -165.6149144600416\n",
            "15     \t [-1.00345942 -3.4396889  -4.4558846  -5.00858705 -4.17212317  3.22710585\n",
            "  4.51358303  5.01445725]. \t  -677.8619568544066 \t -165.6149144600416\n",
            "16     \t [-4.31249479  4.2494038  -1.83080617 -4.81173919 -2.87996608 -4.61749645\n",
            "  2.42049726 -1.52994239]. \t  -386.5154688209628 \t -165.6149144600416\n",
            "17     \t [ 3.74717368  4.93332353  4.42912001  1.74866334 -1.4015247   0.73584451\n",
            " -3.16082965 -0.5819831 ]. \t  -219.51498239443552 \t -165.6149144600416\n",
            "18     \t [ 0.06596798  4.37306267  2.26218499 -1.31445173 -5.11994787 -0.06351359\n",
            "  2.72556341  0.22888885]. \t  -244.028808945172 \t -165.6149144600416\n",
            "19     \t [-4.09347869  3.99684471  2.8612852   4.34320193  5.0239991  -3.24204109\n",
            "  1.69648658  0.97074674]. \t  -365.67365235104444 \t -165.6149144600416\n",
            "20     \t [ 3.96977623 -3.02470376  3.79635332 -3.17603498  4.32759672  4.51445138\n",
            " -0.07002238  0.09689538]. \t  -333.67400355363225 \t -165.6149144600416\n",
            "21     \t [ 3.48363279 -4.77781707 -2.57716541 -4.63400729 -3.56865426  3.70754444\n",
            "  1.88975794 -2.34405226]. \t  -378.7189324711516 \t -165.6149144600416\n",
            "22     \t [-4.65138428  4.56209364 -4.93508667  3.12314362 -4.34639927 -4.28088875\n",
            "  2.86999865 -3.92402244]. \t  -560.5959649212805 \t -165.6149144600416\n",
            "23     \t [ 3.58074273  2.29522854 -2.65608111  3.58119719 -3.33503151  4.83277335\n",
            " -1.54687915 -1.21331372]. \t  -320.09531304053155 \t -165.6149144600416\n",
            "24     \t [-4.26369086 -3.00816968 -4.33078242 -0.02131847  3.99035438 -2.7527389\n",
            " -2.10683888  4.89070021]. \t  -440.04912355624475 \t -165.6149144600416\n",
            "25     \t [ 5.08148746 -5.04980795 -0.19201359 -4.2167737   2.94405086  1.24799901\n",
            "  4.307832    5.11285608]. \t  -539.7724456525267 \t -165.6149144600416\n",
            "26     \t [-1.6666722   2.72811996 -4.73225061 -3.17806606  2.24831237 -0.07657253\n",
            "  2.39428893  3.41117614]. \t  -283.7731165688903 \t -165.6149144600416\n",
            "27     \t [-3.98291681 -3.03866581  4.06498607 -0.8985933   3.06647287  3.03404652\n",
            " -2.93853906  3.43807604]. \t  -344.3897472595925 \t -165.6149144600416\n",
            "28     \t [ 4.59491946  3.92737703  4.79961546  4.44533506 -2.75581378 -4.22381201\n",
            "  4.46494993 -2.0739799 ]. \t  -519.0924680106698 \t -165.6149144600416\n",
            "29     \t [-1.7833297  -4.79328605  1.23163806  3.6240855   4.44854011  3.71463101\n",
            "  4.10120817  3.70176764]. \t  -515.3207020171175 \t -165.6149144600416\n",
            "30     \t [ 2.36764724 -4.12912246 -5.11278159 -4.88272169 -0.1369534  -1.27990615\n",
            " -5.06732677 -1.29721183]. \t  -416.61996155896736 \t -165.6149144600416\n",
            "31     \t [ 4.88519892 -4.71049226 -4.8376928   1.39784473  2.92269987  2.05469847\n",
            "  4.80052993  0.57828301]. \t  -378.30082863707486 \t -165.6149144600416\n",
            "32     \t [-0.37627667 -0.24909713 -3.73113316  3.63674711  4.97033588  4.5730304\n",
            " -3.97313031  3.36844445]. \t  -545.2019965785341 \t -165.6149144600416\n",
            "33     \t [-4.09595317  3.17069886 -2.31328907  3.57403912 -2.97182541  1.78338754\n",
            " -3.20470106  4.13359925]. \t  -375.85789899114604 \t -165.6149144600416\n",
            "34     \t [ 1.99766343 -3.65831152  1.65104481  2.16678227 -4.93680486 -0.84354728\n",
            " -3.04637046 -4.57742605]. \t  -416.42966184337934 \t -165.6149144600416\n",
            "35     \t [ 4.13979078 -2.84892591 -2.05926123 -2.10957573 -4.05040257 -5.09091622\n",
            "  3.77630759  4.8588576 ]. \t  -590.118378187466 \t -165.6149144600416\n",
            "36     \t [-2.39065083  1.59063752  4.60984039 -3.7339372  -4.78267941 -4.02413548\n",
            " -1.46076106 -3.96926864]. \t  -482.80611836344264 \t -165.6149144600416\n",
            "37     \t [-0.1183154  -1.16918232  3.77998077  1.53430319 -3.67094998  4.5391997\n",
            "  0.63786436  5.09762052]. \t  -456.76843034171054 \t -165.6149144600416\n",
            "38     \t [ 0.81818408  0.01760265  3.57777518 -4.0543445   1.51727603 -5.04219042\n",
            "  2.90395795  0.38719889]. \t  -329.1052322488243 \t -165.6149144600416\n",
            "39     \t [ 4.00235756  3.94789283 -4.90283147 -3.00597374  1.91501186 -2.36003704\n",
            "  0.48759914 -4.91038808]. \t  -401.76192377375673 \t -165.6149144600416\n",
            "40     \t [-4.11122265 -0.65313182 -4.37765342 -1.87528492  4.41361012 -5.11473376\n",
            " -2.8412116  -4.04742236]. \t  -531.2368215351628 \t -165.6149144600416\n",
            "41     \t [-5.05649752 -4.51367403 -1.33521642 -0.55800422 -3.65964909 -3.26809208\n",
            "  4.96885255 -1.05608722]. \t  -385.70530097033554 \t -165.6149144600416\n",
            "42     \t [ 1.9468205  -4.72076693  1.23038522  3.60692043  1.29884289  4.99910652\n",
            " -0.7890109  -4.63449453]. \t  -439.50987874360806 \t -165.6149144600416\n",
            "43     \t [ 2.08461474  3.20256047 -2.2175171   3.08132495  4.90313257 -2.43949919\n",
            "  3.64223655 -2.3849389 ]. \t  -371.8639660503517 \t -165.6149144600416\n",
            "44     \t [-4.4349194   0.62264184  3.95438734 -5.1131375  -4.29111568  4.39093638\n",
            "  1.45220718 -4.56758949]. \t  -561.3477472539048 \t -165.6149144600416\n",
            "45     \t [-3.58156066 -3.63793078 -3.68252181  4.55087128 -3.49879613  4.15495844\n",
            "  5.0984582   2.86020042]. \t  -575.0171298978515 \t -165.6149144600416\n",
            "46     \t [-1.19618108 -4.57038798 -4.13124085 -4.11579657  3.92049199  2.77371457\n",
            "  1.73536566 -1.45794641]. \t  -323.26588196201754 \t -165.6149144600416\n",
            "47     \t [ 4.60853833  2.50907368  0.82978267  4.95561098  4.12426475  4.76330971\n",
            " -3.33618009 -2.28174822]. \t  -474.87166348393663 \t -165.6149144600416\n",
            "48     \t [ 1.10244126  3.93927975 -4.83700628  3.75176432 -1.37318066 -5.0639404\n",
            " -2.9545803   4.27330054]. \t  -529.2287315326463 \t -165.6149144600416\n",
            "49     \t [-3.02865804  4.16075214  5.11703678  3.71405905  3.6277037   3.88347341\n",
            " -3.61416751  0.6985856 ]. \t  -429.15460866155087 \t -165.6149144600416\n",
            "50     \t [ 4.52323051 -0.364056   -3.97499568  4.4447561  -4.79645301 -1.68665752\n",
            "  0.90168413  4.54375192]. \t  -450.10526788701134 \t -165.6149144600416\n",
            "51     \t [ 4.15603519  2.48334728  1.15472271 -4.0195727   2.80163422 -1.94969446\n",
            " -3.99720406 -3.79003967]. \t  -387.0469785505217 \t -165.6149144600416\n",
            "52     \t [ 3.90705573 -0.65389494 -2.40592793 -3.91142183 -4.47974445 -4.13684487\n",
            "  0.97584079 -2.53223914]. \t  -355.6677936367802 \t -165.6149144600416\n",
            "53     \t [ 4.44943312  0.12158497  2.01939044  2.81397114  4.70641533 -4.26157394\n",
            " -1.59374089  1.12022133]. \t  -311.2716061613177 \t -165.6149144600416\n",
            "54     \t [-4.8826681  -2.41994925  0.17059691 -3.8523049  -0.5946109   1.04228636\n",
            "  2.14396969  2.47021761]. \t  -184.27909694315812 \t -165.6149144600416\n",
            "55     \t [-4.83719711 -1.47180833  0.59006296 -3.95163267 -1.08271781 -3.95802354\n",
            " -4.78486403  1.12246614]. \t  -361.43804096978437 \t -165.6149144600416\n",
            "56     \t [-1.99997631 -4.95320468 -4.81149873 -2.43109156  4.98601524 -0.54322265\n",
            "  4.69230141  4.83535365]. \t  -613.4020548979688 \t -165.6149144600416\n",
            "57     \t [ 4.13392994 -2.75180843 -4.34500325 -3.32909893  5.11303387  4.52309813\n",
            " -3.13634195 -2.12092299]. \t  -491.5121118581919 \t -165.6149144600416\n",
            "58     \t [-0.9436469   4.42993142 -4.30233252  4.19931458  3.58442411  1.9735575\n",
            " -3.31570468 -4.12153603]. \t  -466.6700337630325 \t -165.6149144600416\n",
            "59     \t [ 3.51134944 -2.7817619  -4.04836574  4.53657662 -3.43607516  4.1419191\n",
            "  5.07570862 -2.83640314]. \t  -565.9630928007358 \t -165.6149144600416\n",
            "60     \t [-4.65917322  2.11510492  4.30635671 -0.62383879 -2.8893578   3.23842257\n",
            " -4.24926685 -0.9461814 ]. \t  -326.0682388008232 \t -165.6149144600416\n",
            "61     \t [ 3.14948666  2.56698501  3.11243386  4.36758631  4.43605767  1.28845414\n",
            " -4.31363559  4.90350181]. \t  -559.4235908290552 \t -165.6149144600416\n",
            "62     \t [-3.08310612 -4.49848062 -3.9886485   1.51363717 -2.99692476 -4.0841644\n",
            " -5.03284612  5.00487742]. \t  -629.5578873875214 \t -165.6149144600416\n",
            "63     \t [ 3.75920732 -3.13829369 -4.85227113  4.19498514 -1.08763861 -1.48312444\n",
            " -4.29602284 -4.68596827]. \t  -498.8244327716992 \t -165.6149144600416\n",
            "64     \t [-0.15749175  3.40044101 -4.76547284 -0.82566731 -5.07011487 -1.50734758\n",
            " -4.76969204 -3.93294209]. \t  -519.163809727644 \t -165.6149144600416\n",
            "65     \t [ 1.3485576  -2.87165768  3.68662353  1.73300059 -4.72618328 -5.01575396\n",
            "  2.75058919 -0.8919975 ]. \t  -393.05441826225746 \t -165.6149144600416\n",
            "66     \t [ 3.55018506  3.46066288 -0.36734678  4.98791821 -4.71947281 -4.40571604\n",
            " -1.88160032 -5.06419982]. \t  -594.2593497807134 \t -165.6149144600416\n",
            "67     \t [ 1.03907416 -1.20828904  5.09430556 -4.76523747  1.3189944   1.82704036\n",
            "  4.6556721   3.90905411]. \t  -475.38520107549346 \t -165.6149144600416\n",
            "68     \t [-0.81103278 -3.09881846  4.70364827 -1.60734826  5.03163127 -3.73425545\n",
            " -3.04040922  0.75340167]. \t  -376.0743994993374 \t -165.6149144600416\n",
            "69     \t [ 2.94326765  4.63952446 -3.33162983 -3.67015192 -0.86684208  4.91115601\n",
            "  3.88107012 -2.98571591]. \t  -464.12126025883293 \t -165.6149144600416\n",
            "70     \t [-4.68100927 -4.83364798 -0.5671837   4.04508856  2.39339921 -3.74876659\n",
            "  4.03480504 -4.35320092]. \t  -513.577944261707 \t -165.6149144600416\n",
            "71     \t [ 1.66460906  1.61183406  4.57021927  3.84399121 -0.83043895 -2.56106015\n",
            "  4.81593476  5.03679832]. \t  -537.8423380581762 \t -165.6149144600416\n",
            "72     \t [ 0.07315316 -3.51898302 -5.01607313  5.02558043  4.97717796  2.02930963\n",
            " -0.82332499 -3.15812968]. \t  -434.3860385843546 \t -165.6149144600416\n",
            "73     \t [ 0.10287845 -4.92331077  3.31616422 -4.97948734 -2.2359061   3.95872136\n",
            " -2.0937237   1.68678555]. \t  -353.1335196047208 \t -165.6149144600416\n",
            "74     \t [-3.69769847 -4.87812716  4.13528045  0.68430122 -1.49441671  4.51499389\n",
            " -1.75550005 -3.3747954 ]. \t  -360.60376978942213 \t -165.6149144600416\n",
            "75     \t [-3.92099652 -2.31303045  2.1780635   4.78071981  0.77151028 -2.08551138\n",
            " -0.32105931  5.091489  ]. \t  -368.90736482122463 \t -165.6149144600416\n",
            "76     \t [-3.42491766  4.04111917  4.70902194 -4.94905253 -3.3649588  -1.58526332\n",
            " -1.75272781  4.85287025]. \t  -490.4887740094316 \t -165.6149144600416\n",
            "77     \t [-1.42207645  4.60861515  0.32887124 -4.48957141 -0.18745656  4.77880713\n",
            "  0.89686823  5.04601158]. \t  -471.97660003062936 \t -165.6149144600416\n",
            "78     \t [ 3.31787527 -4.66750492 -5.09189265  3.04241179  2.7638064  -4.06638785\n",
            "  0.6835523   3.29009128]. \t  -396.66119203126243 \t -165.6149144600416\n",
            "79     \t [ 4.31814955 -4.20822131  4.728219   -4.23371303 -2.2727284  -2.57089294\n",
            "  5.08165006 -4.58151658]. \t  -606.9980777131369 \t -165.6149144600416\n",
            "80     \t [-3.71693032  3.27184081 -1.02934527  4.03588811 -4.7710224   1.89474517\n",
            " -2.25688631 -4.54297654]. \t  -439.6751484088795 \t -165.6149144600416\n",
            "81     \t [-4.20706853  5.06523426  1.28807946  3.80626446 -1.7945366  -0.6718442\n",
            "  3.36498874  2.33814926]. \t  -273.7483009425343 \t -165.6149144600416\n",
            "82     \t [ 2.71884896 -4.98047054 -3.62925576  4.49556144 -3.83118267 -4.37380054\n",
            "  4.17486173 -0.34172591]. \t  -488.46819262230065 \t -165.6149144600416\n",
            "83     \t [-0.99523326  4.57301701  1.64025597  3.13242291  4.97756553  4.81504752\n",
            "  3.4615533  -3.69545857]. \t  -546.2517303604358 \t -165.6149144600416\n",
            "84     \t [-4.06645626  4.39013458  0.79026094 -4.89529051  3.17915555 -4.91871013\n",
            " -3.03660534  4.65118291]. \t  -586.123873072239 \t -165.6149144600416\n",
            "85     \t [-1.91955588  4.65664662  2.90753862  0.57680715  1.90456619 -0.55121874\n",
            " -3.11929093 -4.45100936]. \t  -320.3071985317357 \t -165.6149144600416\n",
            "86     \t [ 4.31793122  2.15684981  2.72196441 -1.98687719 -3.86143404  4.83462885\n",
            " -1.46137015 -4.19764675]. \t  -436.6728331050999 \t -165.6149144600416\n",
            "87     \t [ 2.54870954  4.70311118 -4.61605779  1.53685197  4.04407676 -4.01542705\n",
            "  2.92245623  4.94958934]. \t  -558.3934950219625 \t -165.6149144600416\n",
            "88     \t [-3.04669778 -0.84590611 -0.64993312 -0.04035054  4.97029845 -1.98405905\n",
            "  4.61083273  0.81857933]. \t  -313.30453489931335 \t -165.6149144600416\n",
            "89     \t [5.12       5.12       5.12       3.19645611 5.12       5.12\n",
            " 5.12       4.62722001]. \t  -841.3042466518264 \t -165.6149144600416\n",
            "90     \t [-3.44559024 -3.59478614 -0.17953188 -2.16681237  4.88319012  4.53628538\n",
            " -4.38444877 -4.63165258]. \t  -605.4704864826051 \t -165.6149144600416\n",
            "91     \t [-5.0954253  -4.98001643 -5.05040628 -5.03237937 -5.02349365 -4.18500797\n",
            " -3.75549485 -5.11784032]. \t  -792.9113648580637 \t -165.6149144600416\n",
            "92     \t [-5.08861897  4.44140024  0.32582628  4.62631685  0.92623141 -4.55019251\n",
            "  4.17869159 -4.99135459]. \t  -601.3300775793577 \t -165.6149144600416\n",
            "93     \t [ 5.08491067  4.39172863  2.80465771  2.7778989  -3.77508433  3.89499732\n",
            "  3.52518741  3.81620275]. \t  -484.67426538618196 \t -165.6149144600416\n",
            "94     \t [ 4.00397714 -4.99896615 -0.26934774 -4.37865943  4.69988487 -4.78098999\n",
            "  4.48910644  2.12091725]. \t  -567.562073363626 \t -165.6149144600416\n",
            "95     \t [ 0.64905027  3.47820959  3.77316897 -4.42261006  4.02935013  4.86638313\n",
            " -4.88591264  4.43638685]. \t  -693.3911252177093 \t -165.6149144600416\n",
            "96     \t [-4.01706801 -4.66388903  1.9569449   0.01633189  5.02269914  2.84065614\n",
            "  2.79383245 -2.52338364]. \t  -351.26223962206853 \t -165.6149144600416\n",
            "97     \t [-3.58780127 -4.31485358  4.51925311  1.62146642 -4.94102178 -4.66885364\n",
            " -1.36798883 -4.55153451]. \t  -553.5849326353689 \t -165.6149144600416\n",
            "98     \t [ 1.91377938 -0.57840012 -1.58941999 -5.04747169  4.37893112  4.39241294\n",
            "  0.50410784  4.69189821]. \t  -503.3433754037393 \t -165.6149144600416\n",
            "99     \t [-2.93096527 -0.45383843 -3.44898834  4.79087274 -0.38202111 -3.81221321\n",
            " -0.52794575 -4.32410982]. \t  -375.96091562667254 \t -165.6149144600416\n",
            "100    \t [-1.51400503 -4.22768085 -4.42752985  1.86057034 -5.02189573  4.89923871\n",
            " -3.52056019  3.49721832]. \t  -565.4118511113008 \t -165.6149144600416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8riJpBBKuvT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3587a03a-d213-4673-e22d-a7b0bae09762"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 4 \n",
        "\n",
        "np.random.seed(run_num_4)\n",
        "surrogate_winner_4 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_4 = dGPGO_stp(surrogate_winner_4, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.47505713  3.29006044  1.45620137  1.71235961 -4.71920737 -4.44751474\n",
            " -2.28863345 -1.88046844]. \t  -346.80639555492485 \t -165.62625697677552\n",
            "init   \t [-3.1376137  -3.10176889  3.57585195  3.50574682 -1.56298519  2.45496116\n",
            " -0.06749038 -0.27635987]. \t  -165.62625697677552 \t -165.62625697677552\n",
            "init   \t [-3.7790926  -1.54671161  4.27823555  2.60935971 -4.15202172  0.36061924\n",
            "  2.14992129  0.60475125]. \t  -223.4687278056974 \t -165.62625697677552\n",
            "init   \t [-0.25707746  4.70597666  2.91673192  2.51031751  4.76862861  1.58260827\n",
            "  2.63690453 -2.92386101]. \t  -340.87882459564884 \t -165.62625697677552\n",
            "init   \t [-4.10230933 -4.5220156  -2.28380738  4.65096756 -4.15019246  2.30585903\n",
            " -2.53997873  4.26674294]. \t  -468.7231264209916 \t -165.62625697677552\n",
            "1      \t [-5.01918393  0.79364164 -1.36560668  2.11685063 -4.95451332 -1.5583133\n",
            " -2.89797694 -3.01695924]. \t  -318.88110310996603 \t -165.62625697677552\n",
            "2      \t [ 3.38576809 -4.3130908  -3.53830876  2.15054785  0.27847194  0.50551805\n",
            "  3.97000942  1.13685114]. \t  -227.31453273392674 \t -165.62625697677552\n",
            "3      \t [-0.6886086  -1.43145706 -0.31580828 -4.46654462  3.35049964  0.27980904\n",
            " -4.56051967  0.68552565]. \t  -290.618546996452 \t -165.62625697677552\n",
            "4      \t [-3.86756311  4.38856448  0.42274798 -0.81644185 -0.58896168  1.5495776\n",
            " -2.04661219  2.34948859]. \t  \u001b[92m-146.3021445183416\u001b[0m \t -146.3021445183416\n",
            "5      \t [ 2.24935468  3.62297272 -3.38191621  1.32525079  2.91295512  4.26665495\n",
            " -4.95797077  3.27809936]. \t  -482.33909643382617 \t -146.3021445183416\n",
            "6      \t [ 2.52401141  4.89527516 -1.78631296 -3.99611412 -4.3332438   1.4262729\n",
            "  1.71205768  3.43900057]. \t  -348.9688511662107 \t -146.3021445183416\n",
            "7      \t [ 4.07399877 -1.40885832 -0.72048101  3.264926   -3.7566101   1.93859512\n",
            "  0.27400098 -4.43890597]. \t  -316.02960401738403 \t -146.3021445183416\n",
            "8      \t [ 3.62918725 -3.18431037  3.76376293  4.84862432  1.68522388  2.75533686\n",
            " -4.14313579  1.65749666]. \t  -371.87359578066287 \t -146.3021445183416\n",
            "9      \t [-0.9793471  -2.83335481  2.40612664 -4.10630253 -5.02154806 -3.3394002\n",
            "  3.27840214 -4.68800354]. \t  -545.8738864378656 \t -146.3021445183416\n",
            "10     \t [-5.11266324  1.25806116 -4.17519619 -3.86194815 -3.5132387  -1.10015022\n",
            "  2.58566227 -0.96547333]. \t  -264.49299414811026 \t -146.3021445183416\n",
            "11     \t [-4.85042959 -4.17453657 -4.14955465 -4.31946754  0.65295806 -4.50511015\n",
            "  2.30970752  2.97336511]. \t  -416.6461074491099 \t -146.3021445183416\n",
            "12     \t [ 3.22412015 -0.25475316  1.09877381 -3.31291554  0.33986372  4.57355098\n",
            "  0.88638865 -4.67465616]. \t  -364.4491217475104 \t -146.3021445183416\n",
            "13     \t [-1.34564202  4.29465533 -0.95347472  2.2507207  -3.51666944 -5.08806327\n",
            " -4.14307493  4.7832665 ]. \t  -582.0469408812384 \t -146.3021445183416\n",
            "14     \t [-3.1781556   1.67527919  4.87474953 -3.63637223 -4.35565761  3.64346706\n",
            "  1.17231251 -4.87148812]. \t  -513.8754223932103 \t -146.3021445183416\n",
            "15     \t [ 1.44851679 -3.55804525 -1.58856358  2.13357113  4.25760422 -1.73388059\n",
            " -3.21925444 -3.17177188]. \t  -314.8969876230169 \t -146.3021445183416\n",
            "16     \t [ 4.90639024 -4.65145326 -4.92323079 -4.65329435 -2.87173756 -3.60286696\n",
            "  0.54841078  3.52548931]. \t  -447.32806221993656 \t -146.3021445183416\n",
            "17     \t [ 3.11907928  3.55766047  3.74507826 -4.64451655  1.88793109 -0.6525064\n",
            " -1.12516468  5.02367169]. \t  -394.54171492348394 \t -146.3021445183416\n",
            "18     \t [-4.70872364  4.67334767  2.96104014  0.53547164  2.74327504 -4.69908531\n",
            " -4.83594073 -2.5073105 ]. \t  -477.4159443841699 \t -146.3021445183416\n",
            "19     \t [ 3.81382517 -0.03011874 -4.93782375  4.10588391 -3.43688686 -1.38985165\n",
            " -1.62820446  3.9223462 ]. \t  -367.41334545675204 \t -146.3021445183416\n",
            "20     \t [-4.42395956  4.79079632  4.42810491 -3.56541236  3.74768255 -2.91520747\n",
            "  3.75162855  0.22720203]. \t  -395.3000911033991 \t -146.3021445183416\n",
            "21     \t [ 4.45069647  4.53504662  2.79680087  3.92630254  4.90176722  0.24002011\n",
            " -0.25085012  3.93223496]. \t  -390.6942086427498 \t -146.3021445183416\n",
            "22     \t [-4.96329736  4.96365676 -3.81166527 -3.25499944  2.00977268  3.78180898\n",
            " -4.34280101 -4.12609666]. \t  -534.1017988023593 \t -146.3021445183416\n",
            "23     \t [-0.8620689   1.62527512 -4.56364471  0.4171429   5.0945421  -4.74439019\n",
            "  2.85122814 -0.16349883]. \t  -391.15038675649475 \t -146.3021445183416\n",
            "24     \t [ 3.54430591 -4.85602521  3.30258877  1.81881179  4.58910745 -3.45464464\n",
            "  1.01854513  4.95756182]. \t  -486.46599608409974 \t -146.3021445183416\n",
            "25     \t [-2.85670624 -3.26159207 -0.90954827 -3.82092816  3.47537588  4.59253368\n",
            "  4.62039325  2.36716649]. \t  -471.5199738092435 \t -146.3021445183416\n",
            "26     \t [-1.82136929 -4.39559442  3.15777516 -4.92286178 -0.96617045 -4.75232217\n",
            " -0.82155468  4.13993984]. \t  -450.8250929831165 \t -146.3021445183416\n",
            "27     \t [-4.66300472 -4.9671362  -1.21119701  0.36675827  0.64784103 -4.65828461\n",
            " -3.81224682 -0.15382984]. \t  -310.2456106476028 \t -146.3021445183416\n",
            "28     \t [-2.88296299 -2.65529807 -2.21393424  0.65857442  4.26757371  1.84380565\n",
            "  2.78416051 -4.84129946]. \t  -392.0770215664036 \t -146.3021445183416\n",
            "29     \t [-3.32073888  4.5038439  -4.92300128 -1.06896595  2.63035393 -3.8634696\n",
            " -4.93131781  1.33493114]. \t  -437.5088939727755 \t -146.3021445183416\n",
            "30     \t [-4.99097224 -3.53792402 -4.36233826 -4.87589301  1.46536873  4.39575127\n",
            " -2.44009417 -4.49726126]. \t  -532.2845227664976 \t -146.3021445183416\n",
            "31     \t [ 3.10447953  1.00066852  2.41912603  2.940337   -4.26232521  4.16905766\n",
            " -0.31823372  3.01589207]. \t  -332.37638741970403 \t -146.3021445183416\n",
            "32     \t [ 0.38105067  4.59804319 -2.21353496  3.23159899 -3.96889433 -5.02481741\n",
            "  4.86280467 -0.75756728]. \t  -499.2740427841084 \t -146.3021445183416\n",
            "33     \t [ 2.856321   -4.82143515 -4.35850867 -2.45302618 -4.62187878 -4.36812625\n",
            "  0.2563302  -4.4203084 ]. \t  -513.7751126384626 \t -146.3021445183416\n",
            "34     \t [-0.51500219  3.67479012 -3.46646987  3.82066971 -1.89614925  4.01022654\n",
            "  4.66316783 -2.17752073]. \t  -426.3298226484756 \t -146.3021445183416\n",
            "35     \t [ 4.92384118  3.10406487 -0.75927944 -0.49127901  0.06947341 -1.28563058\n",
            "  3.75800082 -2.61435737]. \t  -209.6877012287717 \t -146.3021445183416\n",
            "36     \t [ 0.21917246 -0.64178228 -2.31355852 -4.2037116  -4.35503807  5.07096244\n",
            " -4.812319    0.01986208]. \t  -498.84602830015024 \t -146.3021445183416\n",
            "37     \t [-4.67478169  4.5440977   4.11508047  4.34396144  3.61563244 -1.31116917\n",
            " -3.96611129  5.04606571]. \t  -578.9243791065808 \t -146.3021445183416\n",
            "38     \t [-1.53958635  0.57949686 -4.33460426 -3.95384665  0.46941326 -3.20170867\n",
            " -2.71308719 -4.75148148]. \t  -416.68583448326353 \t -146.3021445183416\n",
            "39     \t [-4.75844253 -1.97284549 -1.14118176  3.23917271  0.72636368 -3.28818279\n",
            "  4.56834246  0.75537894]. \t  -294.4668061909565 \t -146.3021445183416\n",
            "40     \t [-1.70039583  0.16258292  4.43800746 -2.09349984  3.550636    4.66962646\n",
            " -1.87036761  3.84335864]. \t  -416.08962681184323 \t -146.3021445183416\n",
            "41     \t [-4.29623107 -1.8851069   4.85586807 -2.07759538  3.56275243  2.7581478\n",
            " -3.7301555  -4.84609987]. \t  -507.95502361178035 \t -146.3021445183416\n",
            "42     \t [-0.10502943 -0.36888156  3.39992398 -2.78749202 -4.57439456  2.43242488\n",
            "  5.06072442  4.85081864]. \t  -573.6877007840466 \t -146.3021445183416\n",
            "43     \t [ 3.85237875  5.03962585 -3.94373056  4.74864989  4.67748959 -3.88169945\n",
            " -4.56777749  3.57297277]. \t  -650.4755166586444 \t -146.3021445183416\n",
            "44     \t [ 1.59065985 -4.81706692  1.98800809  1.5703927  -4.79010762 -2.44263765\n",
            " -4.20969459  1.65422925]. \t  -367.12654928286713 \t -146.3021445183416\n",
            "45     \t [ 5.04274676  2.96728202  2.85650568  4.30807236  3.60634648  5.11895369\n",
            " -3.10667484 -4.21663395]. \t  -573.806454343144 \t -146.3021445183416\n",
            "46     \t [-1.26290079  3.68276917  4.88368723  2.37110314 -3.81426669 -4.76895947\n",
            "  3.20016727  4.47817513]. \t  -564.0811319562519 \t -146.3021445183416\n",
            "47     \t [ 4.61119035  1.79969176 -4.54010556 -4.21474278 -2.56568887 -0.52963547\n",
            " -3.25386897 -1.20390458]. \t  -280.9403720937468 \t -146.3021445183416\n",
            "48     \t [-1.97906067e+00 -5.06587474e+00 -4.92721831e+00 -3.69186650e-03\n",
            " -3.53543769e+00  4.11910868e+00  3.01042163e+00 -3.63919135e+00]. \t  -461.76246445397476 \t -146.3021445183416\n",
            "49     \t [-4.47611082  4.96493127 -3.5643393   4.36518183 -4.36631004  5.10835213\n",
            " -1.28138672  1.35649328]. \t  -461.7785882529002 \t -146.3021445183416\n",
            "50     \t [-1.56496003 -2.37095158  5.08372749  4.85648544  4.98358808 -1.74533345\n",
            "  2.65193589 -3.73338659]. \t  -488.7592168339534 \t -146.3021445183416\n",
            "51     \t [ 2.10193727  3.82903593 -2.83875961  3.04040823 -0.41018574  0.01155386\n",
            " -4.39876588 -3.26341213]. \t  -316.3780910916196 \t -146.3021445183416\n",
            "52     \t [ 3.75622318 -1.63065096 -2.98126195 -3.66894187 -3.53208842  4.96511426\n",
            "  3.56964205  4.45558531]. \t  -558.242298841939 \t -146.3021445183416\n",
            "53     \t [-5.09402896 -2.97373832  3.38397241 -4.77989481 -1.72475521 -4.77255631\n",
            " -4.50231355 -4.95710029]. \t  -659.3949584394024 \t -146.3021445183416\n",
            "54     \t [ 4.97925593  0.91897659 -5.04889568 -2.48202406  4.31815513  3.45777607\n",
            "  3.96023936 -0.87949818]. \t  -408.5400596872646 \t -146.3021445183416\n",
            "55     \t [-5.05443213  4.90828413  2.13894856  4.73399032  4.07572176  3.95483795\n",
            " -3.77788279 -2.00356413]. \t  -486.0206920151199 \t -146.3021445183416\n",
            "56     \t [ 1.64891882  1.3935868   2.27921084 -4.89750961  4.75372458 -4.88154146\n",
            " -1.26563264 -1.97697654]. \t  -416.5763504993622 \t -146.3021445183416\n",
            "57     \t [ 2.83373686 -2.56843768  4.37821452  4.27278888 -2.40150186 -1.58508239\n",
            "  5.05763663 -3.06273331]. \t  -449.7684689519893 \t -146.3021445183416\n",
            "58     \t [ 4.13062329 -2.07782679  2.65203033 -1.62416075 -2.92571376 -4.43578735\n",
            "  1.57164586  4.0902555 ]. \t  -369.33644087170126 \t -146.3021445183416\n",
            "59     \t [-5.04577372  4.72178612  3.69781976  3.92299537 -0.54570355 -4.06425739\n",
            "  3.54646094 -2.49195317]. \t  -410.94997552521266 \t -146.3021445183416\n",
            "60     \t [-4.04614918  5.09674198 -1.30001055 -2.65490082 -3.57105574  4.96423521\n",
            "  4.30498746  4.52258581]. \t  -606.573617876973 \t -146.3021445183416\n",
            "61     \t [ 3.01881351 -4.85592317 -3.44276048 -2.98487297  4.73342452  3.99467003\n",
            " -3.79897189  3.26468994]. \t  -521.530666100087 \t -146.3021445183416\n",
            "62     \t [ 4.21606518  1.70849031  3.94564507  4.72793131  2.30842104 -3.37044612\n",
            " -4.8513881  -1.86547713]. \t  -447.126052148545 \t -146.3021445183416\n",
            "63     \t [ 4.1462711  -2.39404586 -4.84410943  4.77345282  3.73488148 -5.05958757\n",
            " -0.96986848  3.49428331]. \t  -517.8019687128765 \t -146.3021445183416\n",
            "64     \t [-0.10408468 -2.98949241  4.70561186  0.36413513  0.98483348 -3.94179786\n",
            " -1.6469646  -3.13867179]. \t  -280.71732836531163 \t -146.3021445183416\n",
            "65     \t [ 4.46310513 -3.15760608  1.32484892 -0.00881942  4.85415598 -3.93756725\n",
            "  4.65403125 -2.99600117]. \t  -479.3952437314698 \t -146.3021445183416\n",
            "66     \t [-1.37175944 -1.57498417 -0.98810533  4.05449904  4.42709039  4.62425255\n",
            "  0.51071846  3.1121375 ]. \t  -381.1347289777317 \t -146.3021445183416\n",
            "67     \t [ 0.81805007 -4.60452661 -0.14117157 -3.36131753 -2.99062559  2.13804925\n",
            " -1.97070128  4.99623069]. \t  -387.35709529872213 \t -146.3021445183416\n",
            "68     \t [ 4.4578621  -3.80741175  4.52034218 -4.04270956  1.7332398   4.42415363\n",
            " -4.27037261  0.7761196 ]. \t  -440.470667145212 \t -146.3021445183416\n",
            "69     \t [ 4.97697474  1.69309632 -0.19417545 -3.8473819  -2.95367004 -2.85542181\n",
            " -5.10760912  4.43225706]. \t  -522.140283959709 \t -146.3021445183416\n",
            "70     \t [ 1.01701785  4.24810926 -4.42860544  4.32488465  4.11220173  3.70584182\n",
            "  4.9262465   3.59686688]. \t  -611.1088765622912 \t -146.3021445183416\n",
            "71     \t [ 1.08864835  3.47241036  4.53949122  2.94787777 -3.90444286  4.55438279\n",
            " -5.10183095 -4.37252254]. \t  -657.7114640943697 \t -146.3021445183416\n",
            "72     \t [ 4.95426969 -3.63062797  5.10477816 -1.51585688  4.52773554  2.26203606\n",
            "  1.81951644 -4.55472903]. \t  -460.61699663617037 \t -146.3021445183416\n",
            "73     \t [ 4.43926055 -3.40463956  4.20615967 -3.58790848  0.48350573  4.27903413\n",
            "  3.36428915  3.63582255]. \t  -443.470284547139 \t -146.3021445183416\n",
            "74     \t [-2.56108697 -2.84491247 -5.11790176  2.41259437  1.64627233  4.6111901\n",
            " -4.12797677 -4.06380959]. \t  -517.1346624761586 \t -146.3021445183416\n",
            "75     \t [ 4.49091194 -1.55521139 -4.69958041 -2.48363195  4.12249291 -2.34338361\n",
            "  3.47112123  4.62008872]. \t  -488.9634896236278 \t -146.3021445183416\n",
            "76     \t [-0.80474909  3.57585766 -1.09288764  4.455313    2.61290519 -4.21123278\n",
            "  2.98637868  4.96340613]. \t  -509.25926706803006 \t -146.3021445183416\n",
            "77     \t [-3.16802288  4.31919809  3.56034036 -3.61517657  5.06233873 -4.72966007\n",
            " -3.1525915   4.80313155]. \t  -654.140278058291 \t -146.3021445183416\n",
            "78     \t [4.76973772 0.40806644 1.52014574 1.06581554 3.33584376 4.91037757\n",
            " 4.16013862 0.30255348]. \t  -356.74951206578504 \t -146.3021445183416\n",
            "79     \t [ 3.19035317  5.03553275 -4.12787019 -4.61891095  4.91131835  0.64225441\n",
            " -4.15924549  2.53130369]. \t  -492.7822559627822 \t -146.3021445183416\n",
            "80     \t [-4.99908419 -3.07914248 -4.65747972 -2.58994133 -4.74673793 -4.59250345\n",
            " -2.65054124  1.08234076]. \t  -433.6140227597693 \t -146.3021445183416\n",
            "81     \t [-4.51563128  4.94574174 -0.36139375 -0.10889307  4.53012148  3.27667087\n",
            "  4.48412279  3.09805225]. \t  -454.31525284421355 \t -146.3021445183416\n",
            "82     \t [-4.81480928 -4.83624407  1.77894681 -4.98741328  1.74934374 -3.00317917\n",
            "  5.00036473 -3.28789153]. \t  -509.8749274953702 \t -146.3021445183416\n",
            "83     \t [ 2.94202439  4.54760053 -4.95884168 -4.46988397 -4.87061159 -4.25803077\n",
            "  2.23482687 -3.82986888]. \t  -583.4101977210817 \t -146.3021445183416\n",
            "84     \t [ 4.60297627 -2.14817767  4.90022975 -3.49926089 -4.93592746  0.18006191\n",
            " -3.49704481 -4.756247  ]. \t  -540.0245615861933 \t -146.3021445183416\n",
            "85     \t [-1.08822019 -2.15103416 -2.31028409  3.95352541 -2.53083886 -1.21286008\n",
            "  4.70562184 -4.65025822]. \t  -457.8230638168915 \t -146.3021445183416\n",
            "86     \t [-1.4583203  -4.52062327 -0.35578582  3.78774907 -4.83167549  2.77721786\n",
            " -4.19572238 -4.62092946]. \t  -557.8222819054766 \t -146.3021445183416\n",
            "87     \t [ 4.83357214  4.47966423  0.96624731 -4.9712099  -4.58922018  3.1662362\n",
            " -1.4016299  -1.87473069]. \t  -372.4747210054916 \t -146.3021445183416\n",
            "88     \t [-4.4693135   4.24575924  4.34788956 -2.89311773 -3.41521267 -4.62574296\n",
            " -4.51234823 -0.19691766]. \t  -475.7632517638615 \t -146.3021445183416\n",
            "89     \t [ 4.58297708 -0.33024493  0.87036016  3.86104877  0.41235547 -4.06208499\n",
            "  4.0923735   2.49435361]. \t  -349.98561088063565 \t -146.3021445183416\n",
            "90     \t [-5.01192461  2.71141464  4.76021238 -4.04106606 -4.51948809 -4.20123001\n",
            "  3.84317541  2.47760808]. \t  -533.6518318246698 \t -146.3021445183416\n",
            "91     \t [5.12 5.12 5.12 5.12 5.12 5.12 5.12 5.12]. \t  -943.7184000000001 \t -146.3021445183416\n",
            "92     \t [-4.92674559  4.93386021 -3.98498277 -4.64250824  4.58067405 -2.76483619\n",
            "  2.35758658 -4.60591946]. \t  -566.2128115633946 \t -146.3021445183416\n",
            "93     \t [-4.82732937  0.7617054  -4.69019731 -4.09179901  0.374498    3.17738803\n",
            " -1.91676209  3.309134  ]. \t  -332.0254208969397 \t -146.3021445183416\n",
            "94     \t [ 4.87221629  4.48590581  2.52736247 -4.6639981  -0.5028183  -3.88744463\n",
            " -4.43901736 -4.56724153]. \t  -566.9085628641039 \t -146.3021445183416\n",
            "95     \t [ 2.3525354   3.56787547  5.09744911 -4.62217288  1.09311383  4.89002792\n",
            "  4.32114545  1.57336306]. \t  -494.36236869168636 \t -146.3021445183416\n",
            "96     \t [ 1.22822887  5.08718835  3.96745254  3.62865393 -2.1640604   1.85233425\n",
            "  1.44950005 -4.50983838]. \t  -374.57720417188955 \t -146.3021445183416\n",
            "97     \t [ 4.65778387 -3.45480021 -4.40070821 -4.44722165  1.32980112 -0.65345021\n",
            "  1.25986394 -2.68910341]. \t  -263.14091520854504 \t -146.3021445183416\n",
            "98     \t [ 1.09555834  4.56678291 -3.60577636 -1.69207799  0.01850856 -4.42105484\n",
            "  0.67031636  4.75708304]. \t  -394.8286901932942 \t -146.3021445183416\n",
            "99     \t [ 4.64585523 -1.77626878 -4.88394405  2.781867   -1.17127624 -4.98361868\n",
            " -0.21664396 -2.64659339]. \t  -342.6504625054537 \t -146.3021445183416\n",
            "100    \t [ 4.03145684 -4.37754658 -1.8788636   4.57951683 -3.65268822  5.04061936\n",
            " -3.98283762  2.07466894]. \t  -513.6894508075991 \t -146.3021445183416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrvkDXP0uvWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30083ff-a26b-4071-9fdd-886530a1757f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 5 \n",
        "\n",
        "np.random.seed(run_num_5)\n",
        "surrogate_winner_5 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_5 = dGPGO_stp(surrogate_winner_5, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.58729753  0.42762882  0.61873954 -1.20782752 -3.90047561  3.54303094\n",
            "  2.45495411  4.42734146]. \t  -358.07993275421416 \t -191.0582179343833\n",
            "init   \t [ 3.67951879  2.13099137  1.85311997 -0.93591243  2.81174646  4.9610363\n",
            "  4.76656492  2.68257959]. \t  -440.2387279623039 \t -191.0582179343833\n",
            "init   \t [ 2.28457508 -3.1898747  -0.24613755 -2.16324482  3.55437597  3.73325571\n",
            " -1.2826718  -0.39471791]. \t  -204.02442667207546 \t -191.0582179343833\n",
            "init   \t [3.75520732 3.06877821 2.55257243 0.39811528 0.98991542 2.6976486\n",
            " 2.32004232 2.54212732]. \t  -191.0582179343833 \t -191.0582179343833\n",
            "init   \t [ 0.5992029   3.04558915 -1.51609106  4.46525397  4.55980658  3.872474\n",
            " -1.66783187  4.83819235]. \t  -506.2318322394824 \t -191.0582179343833\n",
            "1      \t [ 2.93499453 -4.66586726 -4.44927383  4.16377803  3.1780443  -4.4736638\n",
            " -0.65762836  1.31319723]. \t  -368.2961856386949 \t -191.0582179343833\n",
            "2      \t [-3.36202716  0.9751399  -0.98615644  2.90532312  3.91477757 -3.638786\n",
            "  0.82668116 -1.83217109]. \t  -237.59676331051745 \t -191.0582179343833\n",
            "3      \t [ 3.38049033 -2.620933   -0.0712623  -2.25177506  3.20656637 -3.17286342\n",
            " -3.47233925  4.88112165]. \t  -432.27897372171685 \t -191.0582179343833\n",
            "4      \t [ 4.31478619  0.2406012   3.00114119 -0.15841025 -1.37667132  4.80551301\n",
            " -4.72333487 -2.89660886]. \t  -417.1799190590581 \t -191.0582179343833\n",
            "5      \t [-5.00945286 -3.09210297 -0.39880369 -4.45719124  4.55915523 -2.45794355\n",
            " -4.27979665 -3.13774118]. \t  -471.3185418432943 \t -191.0582179343833\n",
            "6      \t [ 4.64840177 -0.61625871  3.59712734 -4.80886683  2.47104864 -4.99398842\n",
            "  2.42302143 -1.22482299]. \t  -386.954654290192 \t -191.0582179343833\n",
            "7      \t [-4.31450528  4.80511433  4.53287247 -1.30767464  3.86760946 -0.7561011\n",
            " -4.02542796  4.08643456]. \t  -458.5162729872259 \t -191.0582179343833\n",
            "8      \t [-4.42904907  2.22889591  0.29905893 -3.03981043  2.11032903  0.55963354\n",
            "  5.06528481 -3.7134262 ]. \t  -380.84515405154747 \t -191.0582179343833\n",
            "9      \t [ 4.51874036 -1.20032029 -2.55935692  4.46325734 -2.10504339 -1.2292994\n",
            "  3.58439135 -0.45803182]. \t  -245.47061481984463 \t -191.0582179343833\n",
            "10     \t [-3.95212917 -4.77814163  2.74774225 -3.2003693   3.80603318 -1.90102196\n",
            "  4.90229505  0.07146516]. \t  -387.281402022425 \t -191.0582179343833\n",
            "11     \t [-3.51743397 -2.13491744 -2.35319421  1.09513801 -2.62758766  4.20055727\n",
            "  0.67067344 -4.31519396]. \t  -335.40294918309814 \t -191.0582179343833\n",
            "12     \t [ 4.88760444  2.33937221 -3.46748812 -2.92500418 -2.59910277 -0.61435801\n",
            " -0.99715673 -3.29993915]. \t  -235.24534960711748 \t -191.0582179343833\n",
            "13     \t [-5.09092902  3.86986842  3.40126425 -3.82940864 -4.48195454 -3.48156404\n",
            "  3.30442461  1.80472427]. \t  -424.8907020979349 \t -191.0582179343833\n",
            "14     \t [-1.42167188  0.66893234  4.10233943  4.92162383 -0.83987545  4.31183454\n",
            " -3.8031181   1.02491464]. \t  -375.0211901380205 \t -191.0582179343833\n",
            "15     \t [-2.05554035  2.58848965 -5.10206947  1.62960514 -2.79426225 -1.14314063\n",
            " -1.56979159  0.28115097]. \t  \u001b[92m-171.1038107992223\u001b[0m \t -171.1038107992223\n",
            "16     \t [ 4.41755051  3.90610729  0.29503076  0.29310325 -4.82697947 -3.9369468\n",
            " -3.94871446  2.75711028]. \t  -430.0905014561491 \t -171.1038107992223\n",
            "17     \t [-0.89493939  4.49043898  4.8030371   1.94829746  3.00725091 -3.93593112\n",
            "  4.69831634  0.48230166]. \t  -420.0672158519592 \t -171.1038107992223\n",
            "18     \t [ 2.96857913 -1.09773997  0.71883078  4.95316222  3.34517327  4.44495376\n",
            "  5.11813956 -2.89035231]. \t  -535.6051095049726 \t -171.1038107992223\n",
            "19     \t [ 2.13785506 -4.92876248 -1.18676013  0.34223428 -2.75364588 -3.71032466\n",
            " -4.45310904 -2.49051197]. \t  -366.79386234012316 \t -171.1038107992223\n",
            "20     \t [-1.7675214   4.5836736  -4.42445671  4.02842386  3.66065406  1.02005054\n",
            " -4.93651318 -4.68831996]. \t  -588.4563533959985 \t -171.1038107992223\n",
            "21     \t [-4.43514584  1.63284787  3.20130493 -4.29445809  0.36932758  3.1096296\n",
            " -3.18039699 -4.01024866]. \t  -387.67946478997555 \t -171.1038107992223\n",
            "22     \t [-0.79597755 -0.80843374  4.28121956  2.68620448 -4.35824641 -3.89371555\n",
            "  0.88312607 -0.97456993]. \t  -284.7853685880371 \t -171.1038107992223\n",
            "23     \t [-3.04013002 -4.00316872  0.65037229 -3.5750429  -2.93170851 -4.15283859\n",
            "  2.46744116  5.03076723]. \t  -485.2235863858027 \t -171.1038107992223\n",
            "24     \t [-1.38059471 -4.97623873 -4.87081936  2.98398663  2.72811571 -1.78678746\n",
            "  5.06852167 -2.59166398]. \t  -448.15518829962633 \t -171.1038107992223\n",
            "25     \t [-4.76868157 -2.26602424  1.62175182 -1.4736976  -3.15595109 -1.85461989\n",
            " -4.79875981  2.61309482]. \t  -335.84804351784555 \t -171.1038107992223\n",
            "26     \t [ 2.7403562   4.63519863 -4.4788889  -3.71235705  3.59932653  3.611072\n",
            " -3.94018774 -4.37233719]. \t  -570.4164210918681 \t -171.1038107992223\n",
            "27     \t [ 4.02805464 -2.12953482 -5.05405653  3.19283472 -2.89862006  0.57992261\n",
            " -2.97850247  3.78737403]. \t  -363.58410581326467 \t -171.1038107992223\n",
            "28     \t [-4.91142248  3.12888573 -4.1420714  -3.77687286  3.03967821 -2.6594036\n",
            "  0.3027712   3.48507494]. \t  -338.6717182468555 \t -171.1038107992223\n",
            "29     \t [-5.01372694 -4.51139878 -4.61209674 -3.89421434  0.08216564  4.29238463\n",
            "  1.35875589  1.56903035]. \t  -333.51634988185606 \t -171.1038107992223\n",
            "30     \t [-4.56657785 -3.38460686 -2.98992734  4.33166162  1.03149011  4.30690015\n",
            " -1.75286747  3.78739885]. \t  -398.5160499569953 \t -171.1038107992223\n",
            "31     \t [-4.7953962   5.04834762 -2.41830366  0.0813202  -0.38907527  4.44844916\n",
            "  2.93731756  1.81234654]. \t  -297.6992202270984 \t -171.1038107992223\n",
            "32     \t [ 3.32050624  4.16006075  1.17026024  5.07772642  4.49316389 -3.4435035\n",
            " -1.78629534  0.09915345]. \t  -347.38323764444436 \t -171.1038107992223\n",
            "33     \t [ 3.69192678 -4.7725542   3.99673559  3.42455649  2.77133177 -3.10713066\n",
            "  4.70220693 -0.7695754 ]. \t  -409.85709028785095 \t -171.1038107992223\n",
            "34     \t [-2.28710484  4.68650541 -3.04233671 -3.4650116  -3.31428906 -3.1927557\n",
            "  2.48020042 -4.18242643]. \t  -424.0361535124885 \t -171.1038107992223\n",
            "35     \t [ 1.97173503 -5.00243972  4.8491832  -1.90659979  5.03062241  0.13637446\n",
            " -4.0967816  -4.959454  ]. \t  -579.9229747719382 \t -171.1038107992223\n",
            "36     \t [ 3.44104692  4.61849829  1.37333796 -3.59675879  4.61502952 -3.75997712\n",
            " -3.44595077 -4.22401925]. \t  -529.0845246090865 \t -171.1038107992223\n",
            "37     \t [ 3.64129663  3.82296726 -4.81691619  2.5031928  -3.96250797  4.16670013\n",
            " -4.24116458 -5.03871014]. \t  -648.8579648074565 \t -171.1038107992223\n",
            "38     \t [-0.48631721 -4.38426527 -1.81695425 -4.07550229 -4.59877335 -1.73902322\n",
            "  1.66860658 -4.99688483]. \t  -458.15230364811896 \t -171.1038107992223\n",
            "39     \t [ 0.74544648  2.21461591 -3.88998109  0.74539072  1.45517611 -4.40288372\n",
            "  3.98287686  4.52262837]. \t  -459.55951926168694 \t -171.1038107992223\n",
            "40     \t [-1.56107189  4.73608916  3.38338209  4.93434255  4.39420974  4.68085035\n",
            "  5.00333212  4.13617084]. \t  -719.1349512404149 \t -171.1038107992223\n",
            "41     \t [-3.87231553 -4.799808   -1.96860609  4.41651569 -0.01015478 -0.53996243\n",
            " -3.83066613 -3.73109761]. \t  -366.55642246527304 \t -171.1038107992223\n",
            "42     \t [ 2.85544726  4.16715003  0.13043283 -3.85918215 -4.609136   -4.55477545\n",
            "  4.46153439  3.12261027]. \t  -550.547176240655 \t -171.1038107992223\n",
            "43     \t [ 0.26898132  3.86187684 -3.64834766  5.00848554 -4.54577211  4.59866579\n",
            " -2.94022559  2.79629331]. \t  -523.4466866393359 \t -171.1038107992223\n",
            "44     \t [-5.11084492 -3.52862861  4.99019095  3.02408392  4.21734717 -1.45491753\n",
            "  3.84644829  4.19540256]. \t  -508.3176945801322 \t -171.1038107992223\n",
            "45     \t [ 1.04952083  3.61178705  3.96855697  2.58493395 -4.27447015 -4.7486416\n",
            " -4.98988933 -5.04016504]. \t  -705.3395082223959 \t -171.1038107992223\n",
            "46     \t [-3.01060497  4.89420001  4.64292075 -3.77913554  2.10172841  4.0599024\n",
            "  4.075529    3.03854931]. \t  -489.88269930917977 \t -171.1038107992223\n",
            "47     \t [ 0.2156222  -4.65149712 -0.98065869  2.48256701  2.01066803  1.48249625\n",
            "  4.11481812  4.70007113]. \t  -399.5051206696618 \t -171.1038107992223\n",
            "48     \t [-2.06259333 -5.04055292  4.43757784  4.66044258 -3.70824735  3.01007575\n",
            " -0.39618779 -3.77230395]. \t  -439.08362826882444 \t -171.1038107992223\n",
            "49     \t [-4.7009373   4.60693306  4.83910421  4.34932019 -4.18279874 -1.81466112\n",
            " -3.94387137 -0.60087265]. \t  -429.4678383392464 \t -171.1038107992223\n",
            "50     \t [ 4.65107985  4.37278146  4.27209609  3.56626917  3.60171656  4.20695616\n",
            "  0.47572527 -4.92295163]. \t  -532.0210128513343 \t -171.1038107992223\n",
            "51     \t [-4.19983565  4.71930325  4.54749126 -0.83410318  4.24903822 -3.56082032\n",
            " -4.91631089 -5.03852043]. \t  -665.6367801027253 \t -171.1038107992223\n",
            "52     \t [ 4.75034156 -4.75188239  4.85928359 -4.35618657  0.50247337  0.88769811\n",
            "  3.00683797  2.89841363]. \t  -350.9542532880726 \t -171.1038107992223\n",
            "53     \t [ 2.08574602  4.14418027 -4.06907071  0.14746379  5.08084963 -3.64403721\n",
            " -3.77991835  3.27886581]. \t  -483.22916291036074 \t -171.1038107992223\n",
            "54     \t [ 3.02426647 -4.86416699 -4.74542769 -2.9376882  -2.82516742  0.08431178\n",
            "  2.2269944   3.8922653 ]. \t  -354.4085960819865 \t -171.1038107992223\n",
            "55     \t [-2.37573626  2.84814693 -0.76057292  4.55762351 -4.96642722 -5.04797485\n",
            "  4.9086145   2.60722108]. \t  -605.95273110172 \t -171.1038107992223\n",
            "56     \t [ 2.57006655  4.22389117  5.09630286 -4.75003937 -3.7321332   4.09914708\n",
            " -1.5117662   0.14318253]. \t  -397.080360553092 \t -171.1038107992223\n",
            "57     \t [ 1.35414327  3.03068195 -4.67803043  3.83248227 -2.20540161  4.70989135\n",
            "  3.87234278  0.49377182]. \t  -408.94055350853915 \t -171.1038107992223\n",
            "58     \t [-3.27999221 -2.8319131   5.02312937  3.17258154  5.06432256  3.58001188\n",
            " -0.18085682 -3.99312874]. \t  -475.6796997782727 \t -171.1038107992223\n",
            "59     \t [-4.64016685 -3.03714156  5.04650917 -0.13723133 -1.29968958  4.52180278\n",
            "  4.14576962 -0.44283005]. \t  -369.463495414863 \t -171.1038107992223\n",
            "60     \t [-3.06767709 -0.87591257  1.65706995 -3.38853514  2.22153687  4.52665844\n",
            " -2.30088899  4.14792752]. \t  -387.4324153745929 \t -171.1038107992223\n",
            "61     \t [ 4.34089772 -3.26556073 -4.21474917 -1.83406636 -3.89084258  4.34840819\n",
            " -2.97781936 -2.60787621]. \t  -412.54390212181795 \t -171.1038107992223\n",
            "62     \t [-3.4575239   3.47386126 -2.05023656 -4.62564744 -4.56381348  2.54992033\n",
            " -2.91210034  4.79384185]. \t  -520.6509480337529 \t -171.1038107992223\n",
            "63     \t [ 1.38072658  3.32586288 -5.03134756  2.82699153  3.22886891 -3.43844959\n",
            "  4.22825821 -4.76626433]. \t  -561.8909964139343 \t -171.1038107992223\n",
            "64     \t [-1.17713274 -3.98598426 -4.09661494 -4.33109714  2.75338265 -4.94969378\n",
            "  3.17099328 -4.04115217]. \t  -544.478221229926 \t -171.1038107992223\n",
            "65     \t [ 4.18916099  3.85473733  3.29768532 -4.74723431  2.89372626  1.17163776\n",
            " -3.65628814  4.20414167]. \t  -455.11841652362136 \t -171.1038107992223\n",
            "66     \t [ 4.97444514  1.09641338 -4.04663537 -5.0342975   4.8418141  -3.87068655\n",
            "  2.806562   -3.84436198]. \t  -558.1313172795503 \t -171.1038107992223\n",
            "67     \t [ 4.43554579 -4.11897588 -1.13166387 -4.83955075 -2.63230628  2.41572432\n",
            " -4.95464977  3.80890294]. \t  -508.69432460703194 \t -171.1038107992223\n",
            "68     \t [ 3.82749321 -2.58233817  2.35510404  0.43509414 -2.0700242   4.80591682\n",
            "  2.43681875 -4.72331067]. \t  -425.43334690134503 \t -171.1038107992223\n",
            "69     \t [-0.27170494  4.96350848  0.25433415  0.07667086  3.94398366  4.64592397\n",
            " -0.84206849 -2.13616317]. \t  -298.3160204709141 \t -171.1038107992223\n",
            "70     \t [-2.95547929 -3.92104374  3.2675095   2.08658694  4.83834493 -3.14942936\n",
            " -4.9937881   4.84208549]. \t  -627.6223731890891 \t -171.1038107992223\n",
            "71     \t [ 4.10515396 -1.70574103  1.45275684  4.8141808   5.06092392  3.77578907\n",
            " -3.99647187 -4.73960328]. \t  -626.8257272440835 \t -171.1038107992223\n",
            "72     \t [ 0.9154374   0.35190172 -5.05690016 -3.49399292  0.42147517  2.29009102\n",
            " -1.83286672  3.56174793]. \t  -283.9938563240328 \t -171.1038107992223\n",
            "73     \t [-2.48386589  3.48837574 -4.69328472 -3.74447235 -4.85078951 -5.02636173\n",
            "  1.23298995  4.21538192]. \t  -574.7062532157381 \t -171.1038107992223\n",
            "74     \t [-4.5215853  -1.94806222 -4.95639997  4.51897407  3.05854156 -4.06901752\n",
            " -4.37766784  2.7954216 ]. \t  -526.1945239676865 \t -171.1038107992223\n",
            "75     \t [-2.96335304  4.38216064 -1.2151778   4.83240616 -4.55148725  2.15514219\n",
            " -4.44024291 -3.82202263]. \t  -531.347857390051 \t -171.1038107992223\n",
            "76     \t [-2.72073761  1.06722305 -5.07216029 -4.33849566 -2.95515524  3.5122675\n",
            " -3.53906893 -3.269616  ]. \t  -453.02997417772747 \t -171.1038107992223\n",
            "77     \t [-0.91871576  4.70781541 -2.95801634  5.01913016 -1.17332275 -5.02443511\n",
            " -3.93939747  4.01524678]. \t  -568.1500832213835 \t -171.1038107992223\n",
            "78     \t [ 3.48654824 -4.76512883  3.63797453  3.35417487 -4.42737016  3.56025287\n",
            "  4.34224055  3.38269799]. \t  -539.862429500032 \t -171.1038107992223\n",
            "79     \t [ 1.3834368  -4.75501138 -4.93039771 -0.93746134  3.25889876 -1.34192963\n",
            " -4.31723116 -3.64082879]. \t  -423.99718838442016 \t -171.1038107992223\n",
            "80     \t [ 2.37217032 -4.52055376  2.04985303  3.57879937 -2.46014399 -2.66303859\n",
            " -0.23034572  4.59049573]. \t  -352.0997286402288 \t -171.1038107992223\n",
            "81     \t [ 3.54175712  4.87045322  1.17511638 -0.66674897 -3.79273669  2.73825404\n",
            "  2.58357371 -4.70821514]. \t  -406.8823442277866 \t -171.1038107992223\n",
            "82     \t [ 4.92799215 -2.8318837  -2.1539358   0.38727749  3.30235394 -2.99873668\n",
            "  1.13132428 -4.59009524]. \t  -340.83578556991654 \t -171.1038107992223\n",
            "83     \t [ 4.98244788  0.4420112  -3.56175541  0.81528364  1.66982129  4.36844919\n",
            "  0.83377756 -4.67234488]. \t  -373.8869430122669 \t -171.1038107992223\n",
            "84     \t [-3.36048252  2.15021571  1.22264423  4.48505701 -0.41074613  1.59089818\n",
            "  1.84903939 -1.38373403]. \t  \u001b[92m-160.76691012969428\u001b[0m \t -160.76691012969428\n",
            "85     \t [-1.38789846  3.7883653   1.67260938 -4.53035889 -2.47570826 -4.65249673\n",
            " -4.89391337  4.26840988]. \t  -595.0464703734411 \t -160.76691012969428\n",
            "86     \t [-3.50707612 -1.25306695  3.20812401  2.98145652  2.27337669 -5.10651648\n",
            " -4.87715804 -3.65829705]. \t  -537.7445112181385 \t -160.76691012969428\n",
            "87     \t [ 1.44488206  2.98913971 -3.44834709  1.61325431 -4.02617569 -4.83612071\n",
            " -4.36708273 -4.25505102]. \t  -565.7636363830178 \t -160.76691012969428\n",
            "88     \t [-3.88907623 -0.95819418  2.20794082  4.64960019 -2.29496074  4.70212619\n",
            "  3.37891588  5.06262807]. \t  -562.0166212882028 \t -160.76691012969428\n",
            "89     \t [ 0.40004203 -2.5798365  -1.2176588  -4.31185441  4.62756431 -4.47037449\n",
            "  4.24671108  2.76185151]. \t  -506.529299361683 \t -160.76691012969428\n",
            "90     \t [ 4.92101195  4.06602299 -4.58347651  3.41323696  0.46198733  0.59325597\n",
            " -4.33144188  1.41742561]. \t  -317.4883231370131 \t -160.76691012969428\n",
            "91     \t [-3.86099865 -3.90234553 -4.03904552 -4.03518499  4.80707784  4.62389757\n",
            " -3.78553391 -4.30793823]. \t  -652.0375313973866 \t -160.76691012969428\n",
            "92     \t [ 4.61439089 -4.85096101  2.28757243 -3.72894843 -3.91660791 -3.91850937\n",
            " -1.95547954  4.64919681]. \t  -508.1903682662893 \t -160.76691012969428\n",
            "93     \t [-4.91934502 -5.04744719 -4.93954297 -5.02437561 -5.08331919 -4.9125215\n",
            " -5.08995496 -5.11191272]. \t  -913.73263640711 \t -160.76691012969428\n",
            "94     \t [-3.69879471  2.28215894 -0.8695921  -4.84900632 -4.49073241  2.93169012\n",
            "  2.41560404 -0.77052916]. \t  -318.4155529859649 \t -160.76691012969428\n",
            "95     \t [ 1.11397232  4.41075317  3.65876215 -2.27380859 -3.02053733 -4.39774617\n",
            "  0.77891554 -2.24900765]. \t  -307.3613708784583 \t -160.76691012969428\n",
            "96     \t [-4.96378899 -4.07426261 -3.26250224  3.56622616 -4.20863254 -2.3344898\n",
            "  4.82432285 -4.58058076]. \t  -592.6764640992994 \t -160.76691012969428\n",
            "97     \t [-0.50473241  0.28518221 -4.81740718 -0.56750927  4.69091671  4.88886743\n",
            "  3.41663512  1.27823589]. \t  -419.542426171951 \t -160.76691012969428\n",
            "98     \t [ 5.00302092  2.08785145 -4.26863965 -3.78744873 -1.25797672  4.71213884\n",
            "  4.82525201 -1.34399916]. \t  -464.3615013507835 \t -160.76691012969428\n",
            "99     \t [-2.00898784 -0.34205434  0.17701356  3.85496505  1.46382857 -1.85904061\n",
            " -0.08408264  4.58269248]. \t  -263.3152722077779 \t -160.76691012969428\n",
            "100    \t [ 4.28525498  4.85048307  0.58543901  3.11323144 -1.2829482  -5.02098198\n",
            "  3.81592177  0.45276419]. \t  -368.27495542590617 \t -160.76691012969428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO3I_9cbuvY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516b13ae-6fc2-4e24-a883-fd2b010d5ce1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 6 \n",
        "\n",
        "np.random.seed(run_num_6)\n",
        "surrogate_winner_6 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_6 = dGPGO_stp(surrogate_winner_6, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.02288795 -1.72052679  3.28938622 -4.69302655 -4.0175956   0.97333314\n",
            "  0.30532979 -0.83141193]. \t  -235.23441702954543 \t -201.94095626044867\n",
            "init   \t [-1.68542362  1.25459899 -0.6334318   2.41543277  0.18469286  0.80751207\n",
            "  1.48843618  5.01989654]. \t  -251.71565703551553 \t -201.94095626044867\n",
            "init   \t [ 3.27534794 -0.88882243  3.85298079  3.31529659 -4.56218104  2.2388453\n",
            "  3.09422656  2.42080403]. \t  -348.8531157616155 \t -201.94095626044867\n",
            "init   \t [ 2.14150913  0.41919339 -3.84180045  4.68630831 -0.9906555  -2.89842012\n",
            "  2.22490467  5.06068417]. \t  -431.90936813726233 \t -201.94095626044867\n",
            "init   \t [-2.50251207  1.75420858  1.01382055  2.22548117  4.47845923 -1.51746797\n",
            " -2.52278684 -0.99868151]. \t  -201.94095626044867 \t -201.94095626044867\n",
            "1      \t [ 2.52426974  2.29448261 -0.96145617  5.01124965 -0.50688737 -1.29220163\n",
            "  2.14659693 -4.27562441]. \t  -309.93117061486333 \t -201.94095626044867\n",
            "2      \t [-3.94122701 -1.28480828 -0.06578283  1.82165145 -4.4292268  -3.47715752\n",
            " -1.23572881 -0.31463601]. \t  -214.23651607250392 \t -201.94095626044867\n",
            "3      \t [ 0.68495272 -1.12020105 -3.91648579 -4.1522513   0.27697028 -5.06255741\n",
            " -5.11410257  2.94682699]. \t  -524.6693250717898 \t -201.94095626044867\n",
            "4      \t [-0.90292441 -3.62134384  4.06919975 -3.14648372  3.40643678 -2.96215879\n",
            "  1.00052604  4.46507807]. \t  -393.48824400615496 \t -201.94095626044867\n",
            "5      \t [ 5.09872913 -2.35067757 -0.29347515 -4.52301675  4.73557543  2.06098602\n",
            " -0.24839256 -3.81236264]. \t  -373.4566300664054 \t -201.94095626044867\n",
            "6      \t [ 0.45041751  3.04462334 -4.19217931  4.07489457 -5.03627391  4.82675639\n",
            " -0.2109413  -1.32181192]. \t  -418.7792092236846 \t -201.94095626044867\n",
            "7      \t [-2.11122647  4.196848   -4.11257499 -2.91251049  3.32078439  3.28306277\n",
            " -4.12634234 -4.06027961]. \t  -495.23795573777846 \t -201.94095626044867\n",
            "8      \t [-4.02575353 -4.96908952 -0.40750639 -2.03711785 -1.54320181  1.65082713\n",
            " -2.76294025 -4.25624588]. \t  -309.3086180204047 \t -201.94095626044867\n",
            "9      \t [-2.76024815  2.22944214 -2.80877977 -3.58085902 -4.94024164  2.91833315\n",
            "  0.927044   -3.72853864]. \t  -382.87955544631467 \t -201.94095626044867\n",
            "10     \t [-1.49356718  4.76503151  4.17420652 -4.1252743  -3.09701969 -4.01123252\n",
            "  0.55453569 -0.66853668]. \t  -318.21101818035913 \t -201.94095626044867\n",
            "11     \t [ 3.99531502 -3.58048569  1.96690361  1.16346462 -1.10982483 -4.267787\n",
            " -2.30004731 -1.32578776]. \t  -225.15884706627827 \t -201.94095626044867\n",
            "12     \t [-3.95614005 -1.82630411  3.2894209   2.29458665  3.66795106  4.40217692\n",
            "  4.1171064  -0.32397013]. \t  -378.8811018683255 \t -201.94095626044867\n",
            "13     \t [-3.1345121   0.2108516   2.07787827  2.94367407 -4.57786845  4.80300532\n",
            " -3.8471932  -1.32359046]. \t  -418.34664535781764 \t -201.94095626044867\n",
            "14     \t [-2.76675299 -3.93643419  4.01358587  1.54257244  4.26124832 -3.99666206\n",
            "  5.01236591 -1.33903159]. \t  -473.3324447138828 \t -201.94095626044867\n",
            "15     \t [ 3.71115089  4.88449954  4.86593922 -0.34742123  3.78051598 -2.92503548\n",
            " -0.40306706  0.63080169]. \t  -260.12124002026013 \t -201.94095626044867\n",
            "16     \t [ 4.17230617  4.56538953  3.52021908  1.42713737  1.79238904  4.17390386\n",
            " -2.22027985  4.10130806]. \t  -394.0818666384531 \t -201.94095626044867\n",
            "17     \t [-4.56387674 -3.20198508 -4.55585105 -2.69468356 -3.85926296 -4.56771792\n",
            "  4.81769501  0.62638462]. \t  -497.91099533054893 \t -201.94095626044867\n",
            "18     \t [-3.74818327 -1.16235616 -5.11467101  0.77008414  4.80529879  1.05232015\n",
            "  3.40901987 -3.36319866]. \t  -391.5402244013708 \t -201.94095626044867\n",
            "19     \t [ 0.54575391 -3.23351063 -3.92657205 -0.5773002  -4.78939184  3.40671317\n",
            "  3.95685153  3.91689223]. \t  -485.45465051868956 \t -201.94095626044867\n",
            "20     \t [ 4.54341168  3.2463194  -2.56102657 -1.89365475 -1.85318887 -0.76638414\n",
            " -0.30285133  1.06403606]. \t  \u001b[92m-106.13508085915566\u001b[0m \t -106.13508085915566\n",
            "21     \t [ 0.42690359 -4.39558378 -3.06281021  4.44222487  3.11538524 -4.90288126\n",
            "  0.20498133 -3.99188306]. \t  -466.433185110738 \t -106.13508085915566\n",
            "22     \t [-0.0947966  -0.02266045  1.48503726 -3.4200694   0.96578367  5.01066175\n",
            " -1.59151372  0.94200849]. \t  -233.54704811001648 \t -106.13508085915566\n",
            "23     \t [-3.45418976 -1.84883821  3.84221069 -3.08699013 -2.53019677  0.01376025\n",
            "  3.87860752 -3.56776052]. \t  -340.3207230274565 \t -106.13508085915566\n",
            "24     \t [-4.04294051  5.09852426 -4.69011397  0.33393687 -3.43734899 -1.04864285\n",
            " -4.38645187 -0.99548747]. \t  -343.0622637346648 \t -106.13508085915566\n",
            "25     \t [ 3.62577069 -3.37518238  3.16509726  3.62191887  2.63810145  2.95134537\n",
            " -3.5042903  -1.27761982]. \t  -304.5360188964003 \t -106.13508085915566\n",
            "26     \t [ 4.46485484 -3.64946539 -4.16643175 -3.25392469 -1.51748286 -4.33043533\n",
            "  2.69473106 -3.12334749]. \t  -393.90490477883407 \t -106.13508085915566\n",
            "27     \t [ 3.58908026 -2.51472709 -4.62060133 -3.14800331  1.50230493 -2.88003557\n",
            "  4.89700853  4.47857129]. \t  -518.5966552354527 \t -106.13508085915566\n",
            "28     \t [ 2.02100411 -5.01594556 -1.3855721   0.62551375  2.62736825  3.94402312\n",
            "  2.80181189 -0.11408451]. \t  -244.63077846579424 \t -106.13508085915566\n",
            "29     \t [ 2.65579224 -3.79455128 -1.78059187 -2.98287746 -4.08668447  4.79673836\n",
            "  4.66548265 -4.54962878]. \t  -620.4694434095638 \t -106.13508085915566\n",
            "30     \t [ 3.80549638 -4.22299587 -2.69089808 -2.29708295 -5.06128381 -0.70057014\n",
            " -3.10742611  4.58548119]. \t  -459.81188997840184 \t -106.13508085915566\n",
            "31     \t [ 4.75023726  4.27067431 -3.3620698   2.19325949  2.43952425  4.77026491\n",
            " -2.9627453  -1.70517315]. \t  -363.18905967046635 \t -106.13508085915566\n",
            "32     \t [-5.01927955  1.1663558  -4.7011278  -1.16335361 -3.63535837  4.79523325\n",
            " -1.55904175  4.64245203]. \t  -493.107201789186 \t -106.13508085915566\n",
            "33     \t [ 2.0377716   4.76513209  3.37300772 -3.59672561 -2.07884593  2.66463433\n",
            "  4.0278761  -4.28659452]. \t  -460.2180649083683 \t -106.13508085915566\n",
            "34     \t [-0.68903817 -2.09917966 -4.49665447  2.36225714  1.52296817  4.27623354\n",
            " -3.92228882 -1.28224827]. \t  -334.4265552229343 \t -106.13508085915566\n",
            "35     \t [ 0.18482649  0.93086031 -4.95372807  2.75689867 -4.87862792 -0.49565\n",
            " -4.44860518  4.55289487]. \t  -530.6278842189843 \t -106.13508085915566\n",
            "36     \t [ 0.69598124  2.35116678  4.59945961 -1.03104698  4.93035907  4.75792977\n",
            " -0.40864942 -4.93658695]. \t  -532.755341580188 \t -106.13508085915566\n",
            "37     \t [ 3.31155489  2.45867005  3.27810844  1.1735702  -2.4029312   0.54376176\n",
            " -4.68726686 -3.56618524]. \t  -346.9827299373274 \t -106.13508085915566\n",
            "38     \t [ 4.47670277  4.23110465 -3.83553635  4.23276522  3.07953241  2.89127288\n",
            "  3.77021165  3.28722849]. \t  -455.16737635586446 \t -106.13508085915566\n",
            "39     \t [-2.47521342  4.9223336  -0.15387365 -2.05770095  3.76132609  4.12386583\n",
            "  4.78240876  1.85681033]. \t  -432.0504592472265 \t -106.13508085915566\n",
            "40     \t [ 4.85023392 -2.14550357  2.12580605  1.77227441  4.0600194  -0.30169956\n",
            "  4.44083503  5.00108753]. \t  -479.95116602193184 \t -106.13508085915566\n",
            "41     \t [-2.77237399  5.11944894  3.11934993  4.3553662  -4.53948843 -1.66517746\n",
            "  4.67115669 -2.18124201]. \t  -475.6436026966678 \t -106.13508085915566\n",
            "42     \t [-3.54673255  2.81125853  5.01772592 -4.88789731  4.56226192 -0.39551573\n",
            " -0.20484863 -0.8885397 ]. \t  -311.1040701964837 \t -106.13508085915566\n",
            "43     \t [-3.46626255 -5.05036206 -4.56818742 -3.93815336  4.12077587 -0.47862406\n",
            " -3.28979071  0.73275424]. \t  -354.00145184898275 \t -106.13508085915566\n",
            "44     \t [ 3.64093417 -4.00244767  3.59053716 -3.84326899  3.18960734 -4.85520603\n",
            "  4.41323268 -1.91886626]. \t  -501.1531835371191 \t -106.13508085915566\n",
            "45     \t [-5.10874879  4.21598999  4.10583423 -4.49370891 -4.94953316  4.64702151\n",
            "  2.00294546  0.08914188]. \t  -473.2001103204254 \t -106.13508085915566\n",
            "46     \t [-3.91654277 -4.58633028  0.98705919  3.98683305  4.08601039  0.25161144\n",
            " -3.42203294  4.99298654]. \t  -489.1791038123092 \t -106.13508085915566\n",
            "47     \t [-0.56309754 -2.60151385  4.70827237  3.67697901 -2.11526416  0.65935223\n",
            " -3.14072719  4.08341944]. \t  -361.8608820207138 \t -106.13508085915566\n",
            "48     \t [-4.87561327 -1.81883564 -4.04192564  4.78991474 -1.82158104 -3.47673813\n",
            "  4.75478923  2.73922843]. \t  -478.57271166274074 \t -106.13508085915566\n",
            "49     \t [ 0.11526199  4.13583993 -0.37303008 -4.87378406 -4.46179566 -1.38413665\n",
            " -4.29517805  4.19913703]. \t  -510.8911717394892 \t -106.13508085915566\n",
            "50     \t [-3.8642733   2.54661749  2.16248097  3.55173607  4.54480002 -3.8693846\n",
            "  5.10789814  4.62608506]. \t  -639.3399442584694 \t -106.13508085915566\n",
            "51     \t [-0.67238592  4.28367109 -2.17091375 -3.24446164  2.45761711 -3.17379151\n",
            "  4.01259496 -4.10974256]. \t  -431.8599279297032 \t -106.13508085915566\n",
            "52     \t [-4.96527359 -3.60423778  1.48675861 -0.69044524 -3.46355355 -0.19678388\n",
            "  4.35471869  3.79482756]. \t  -367.33732637951977 \t -106.13508085915566\n",
            "53     \t [-4.65039156  4.85936791  4.9540581   1.06281505  4.88232538  2.51241567\n",
            " -4.78722589  4.233646  ]. \t  -607.8711236334872 \t -106.13508085915566\n",
            "54     \t [-4.95668398 -4.85330363 -0.22587324 -3.30718235  2.78076883  4.1531545\n",
            " -0.94203961  4.97719891]. \t  -462.12837710509757 \t -106.13508085915566\n",
            "55     \t [-3.01256307 -4.52488852 -1.58710086  5.01259611 -1.31792367  1.82574468\n",
            "  3.87530419 -3.10230069]. \t  -368.89062511613827 \t -106.13508085915566\n",
            "56     \t [-3.8492514  -4.18835154  3.88923564  1.99254383 -0.52256147 -4.71312547\n",
            " -4.99013036 -2.87789626]. \t  -486.37546336795276 \t -106.13508085915566\n",
            "57     \t [-3.88117735  1.54590988 -5.01148809  2.4739459   2.39014116 -4.93234102\n",
            "  0.01428807 -3.93342592]. \t  -417.9778304356534 \t -106.13508085915566\n",
            "58     \t [ 3.20332175 -4.66802727 -5.02378842  3.54051142  2.38033248 -4.34803865\n",
            " -3.16828924  3.86409112]. \t  -511.1770147373011 \t -106.13508085915566\n",
            "59     \t [ 3.02547331 -3.10679321  3.5987173  -0.85303238 -4.28866145 -4.48412984\n",
            "  3.455954    4.39433806]. \t  -520.9153619486746 \t -106.13508085915566\n",
            "60     \t [-3.71556508  4.73214987 -4.58327115 -2.14292087  2.7036367  -2.32018549\n",
            " -2.03367284  3.00138026]. \t  -309.8443365840298 \t -106.13508085915566\n",
            "61     \t [ 4.45967325  3.70343116 -4.01164335 -4.16705531 -5.10015563 -0.3631626\n",
            " -4.59692018 -4.03761277]. \t  -574.2462580236294 \t -106.13508085915566\n",
            "62     \t [-4.49147715 -3.68123613 -4.84615514 -4.56130614 -4.83543849 -4.13213253\n",
            " -3.95725696 -4.83609839]. \t  -717.0304817326657 \t -106.13508085915566\n",
            "63     \t [-4.93098526  2.09819077  0.74957117 -4.6308532  -1.70493948 -0.87776751\n",
            " -4.51763809 -2.03579514]. \t  -315.7602208549928 \t -106.13508085915566\n",
            "64     \t [ 4.8489422   4.32101468  0.43921162 -3.80374026  4.31964144 -4.67899558\n",
            "  4.64168637  4.70615616]. \t  -671.9615784218171 \t -106.13508085915566\n",
            "65     \t [ 2.91474854  2.09341135  3.0936606  -4.4903181  -3.7833668   1.88863194\n",
            "  4.92782527  4.84931281]. \t  -577.706351874046 \t -106.13508085915566\n",
            "66     \t [-2.35153181  4.92304191 -2.70603984  3.88806167  0.25382464  4.45325428\n",
            " -4.1707243   3.97869145]. \t  -504.15388414129694 \t -106.13508085915566\n",
            "67     \t [ 3.72363644  2.27037293 -0.46639431 -3.56087446  4.95872435 -0.71633977\n",
            " -3.72774039  4.42965077]. \t  -455.8169116791738 \t -106.13508085915566\n",
            "68     \t [-4.78802505  4.41254096  2.2653911   4.33132906 -4.7083569  -0.58945099\n",
            " -2.98597944  0.96110887]. \t  -335.0340479659676 \t -106.13508085915566\n",
            "69     \t [-0.78071247 -3.86179554  3.2761237  -5.07747122  3.07955139 -4.70170687\n",
            " -4.96745624 -1.00682876]. \t  -526.6517091123824 \t -106.13508085915566\n",
            "70     \t [ 2.17923392  3.65673359 -1.89303715  3.64916608  3.99017707 -1.1847071\n",
            " -3.59938188  4.57611489]. \t  -441.75310326078466 \t -106.13508085915566\n",
            "71     \t [ 5.06770835  4.15249142 -5.00509727  3.51957821  2.62435252 -4.06921344\n",
            " -3.75172144 -1.82611416]. \t  -443.86331618840336 \t -106.13508085915566\n",
            "72     \t [-4.36564853 -0.98117698  4.72752293 -1.56407871  3.44563989 -5.0499109\n",
            " -0.80963659 -4.9210999 ]. \t  -508.5162369436109 \t -106.13508085915566\n",
            "73     \t [ 0.64152152  4.49358696 -0.35843428  0.74100658 -4.47526133 -4.60202766\n",
            "  3.75538081  2.57317277]. \t  -422.27969707017087 \t -106.13508085915566\n",
            "74     \t [ 2.35979099 -3.35818804 -4.25997558  2.13234368 -3.02375127 -0.47058354\n",
            " -2.21015335 -2.73014513]. \t  -241.62023772825623 \t -106.13508085915566\n",
            "75     \t [ 4.95553103  0.18727981  3.44896198 -0.11230817  4.07363426  0.51530073\n",
            "  4.9201608  -3.82049833]. \t  -431.15512938990406 \t -106.13508085915566\n",
            "76     \t [-4.76620556 -3.87429368 -4.17728446 -1.91327879  4.30415298 -5.01838851\n",
            "  1.94581135 -2.38849419]. \t  -435.6051904483724 \t -106.13508085915566\n",
            "77     \t [ 0.66257973 -0.12265418  4.83875086  4.64730637  3.98380109 -4.00420977\n",
            " -2.11200177  4.05721356]. \t  -495.5667024125798 \t -106.13508085915566\n",
            "78     \t [ 4.74872091  3.89450277 -5.10147584 -1.63574877 -3.4150799   4.50279753\n",
            "  3.22209012 -3.63293191]. \t  -499.8860918084773 \t -106.13508085915566\n",
            "79     \t [-4.49021001  3.2292904  -4.84933812 -1.0785456  -1.21876261 -3.01947076\n",
            "  5.07393626  4.39154697]. \t  -512.8493180705632 \t -106.13508085915566\n",
            "80     \t [-3.85446418 -4.43488512 -4.91953805  4.70462497 -4.4971218  -1.97038022\n",
            " -4.93829975  0.06810263]. \t  -510.49250096232976 \t -106.13508085915566\n",
            "81     \t [-1.92933129  2.10372574 -2.07554656  4.82109058 -4.66617902 -4.8859438\n",
            " -4.00368908 -4.89746633]. \t  -674.6578901865314 \t -106.13508085915566\n",
            "82     \t [ 4.09158574  4.84111428 -5.01849578 -4.73894002  2.13465286  0.4692077\n",
            "  4.58192125  1.16287119]. \t  -410.8807799144782 \t -106.13508085915566\n",
            "83     \t [ 5.03854397 -0.73403259 -4.73133804  1.07231504  2.22039009  3.44342566\n",
            " -3.23386358  4.31413043]. \t  -416.1132791996703 \t -106.13508085915566\n",
            "84     \t [-5.00885529 -4.00689414 -4.1600842   3.87708479 -4.85121108  4.70286695\n",
            "  0.18981725  0.95580506]. \t  -427.17879104648586 \t -106.13508085915566\n",
            "85     \t [ 4.49043686 -4.03409248  1.182445    1.09188696 -4.78052156  4.54879785\n",
            " -2.98120999 -4.44072191]. \t  -520.0649073363679 \t -106.13508085915566\n",
            "86     \t [-2.46337653 -4.06594345  5.08632182 -4.74084977 -2.31065868  2.97188394\n",
            " -1.03386052  3.67981277]. \t  -402.1451829119885 \t -106.13508085915566\n",
            "87     \t [ 5.03132786 -4.22763464 -3.69974133 -4.41162051 -2.10458713  1.7728991\n",
            " -2.48378837 -3.11765761]. \t  -341.92209593549535 \t -106.13508085915566\n",
            "88     \t [ 0.52258621 -2.86879325  5.0327939  -3.8674148  -3.83865924 -4.79017676\n",
            " -3.29847246 -4.98262094]. \t  -638.6704982940568 \t -106.13508085915566\n",
            "89     \t [-3.1719485  -5.04643881  4.92403634  4.84540539 -4.26553904 -1.74911095\n",
            "  3.63394211  0.07794002]. \t  -429.4623569921495 \t -106.13508085915566\n",
            "90     \t [ 4.49976466  3.40314084 -4.31064859 -2.20401255 -3.22973832 -3.40029917\n",
            "  3.83797909 -5.05022952]. \t  -547.2637613514726 \t -106.13508085915566\n",
            "91     \t [-3.60294652 -4.21057808 -5.08106797  4.76656476  3.97338184  0.34933666\n",
            "  1.44050567  2.86395029]. \t  -376.5855914479687 \t -106.13508085915566\n",
            "92     \t [-1.08034275  2.78531003  3.91519391  4.16436346  4.26434286 -3.4155565\n",
            "  3.52118754 -4.23123229]. \t  -522.9741694457754 \t -106.13508085915566\n",
            "93     \t [ 2.57702993 -0.30714814 -4.03899135 -4.15111115  1.38948455  5.01383455\n",
            "  4.92445936  0.99564699]. \t  -462.86417296472825 \t -106.13508085915566\n",
            "94     \t [ 4.80515929  4.03136352  3.81243599 -4.9926733  -4.50243181 -2.84677294\n",
            " -3.46882836 -3.41231665]. \t  -526.2692796720997 \t -106.13508085915566\n",
            "95     \t [ 0.89858141  1.09282394  1.90170698  3.85507028 -4.89719779  4.20226978\n",
            "  4.33220039 -3.97141822]. \t  -556.9118944099887 \t -106.13508085915566\n",
            "96     \t [ 4.3783636  -5.0151658   0.50957871 -0.41398252  4.95578408 -3.45687883\n",
            " -4.73607349 -4.41757335]. \t  -578.569807483756 \t -106.13508085915566\n",
            "97     \t [ 2.02253427 -3.23243172  4.15389486 -4.54169929  4.46062296  3.99584481\n",
            "  3.50476556  2.44945204]. \t  -488.52916575226624 \t -106.13508085915566\n",
            "98     \t [-3.52538342 -4.81126227 -1.07253251 -4.27914201  4.42062391  1.76222542\n",
            "  2.71397027 -0.54502054]. \t  -305.6980516740729 \t -106.13508085915566\n",
            "99     \t [-4.29441526  2.1037432   5.03562287 -4.45766467  1.2957369  -0.24230724\n",
            "  2.83063455  5.08734073]. \t  -454.7317409261424 \t -106.13508085915566\n",
            "100    \t [-4.99097019 -0.70901932  1.41385028 -1.57186098  4.26642161  4.7759874\n",
            " -1.38392458 -3.00662472]. \t  -355.39227468341886 \t -106.13508085915566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rQbLZD8uvbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a9e9803-9642-4461-ca38-da0df8ca1567"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 7 \n",
        "\n",
        "np.random.seed(run_num_7)\n",
        "surrogate_winner_7 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_7 = dGPGO_stp(surrogate_winner_7, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.55672335 -2.02386832 -4.48474711 -0.4110301   3.43299466  4.37244977\n",
            "  2.3243672   2.74940131]. \t  -353.7866241526368 \t -217.44194749723354\n",
            "init   \t [-2.36334012  1.47485995 -4.16385785 -4.30401653  0.91764484 -1.60419289\n",
            "  5.00609176  1.29508563]. \t  -344.5427966394509 \t -217.44194749723354\n",
            "init   \t [ 1.86141982  0.53510977 -2.36687301 -1.29782388 -2.83721627 -3.21082777\n",
            " -1.11976352 -3.14201697]. \t  -217.44194749723354 \t -217.44194749723354\n",
            "init   \t [ 1.13572794  3.9199585   1.25274956 -2.52806201 -3.27751366  3.23998177\n",
            " -2.8121946   0.17261711]. \t  -234.58737464459995 \t -217.44194749723354\n",
            "init   \t [ 0.18939719  1.02783934  0.33403374 -4.98370509  0.24675597  4.05385947\n",
            "  2.76378925 -3.86199863]. \t  -373.52986721661773 \t -217.44194749723354\n",
            "1      \t [-2.09026361  1.14712145  2.31565437 -0.3737859   2.75569016 -3.15769824\n",
            "  0.59255523  0.51996833]. \t  \u001b[92m-126.06288515837247\u001b[0m \t -126.06288515837247\n",
            "2      \t [-1.51468308  4.71146742  1.43003054  2.16034289 -4.99833339 -2.51553245\n",
            "  0.52972606  3.07306252]. \t  -311.89148085588613 \t -126.06288515837247\n",
            "3      \t [-2.04716979  0.31652053 -3.72902456  3.97315929 -2.23037105  2.56657632\n",
            " -1.88076485 -4.88687095]. \t  -389.461781652991 \t -126.06288515837247\n",
            "4      \t [ 4.73629479 -1.34734679  2.20127751  3.52547737 -0.84747307  4.29069522\n",
            " -4.71170392  4.35685033]. \t  -511.6256870588915 \t -126.06288515837247\n",
            "5      \t [ 4.70555877  0.09158045 -3.80239688 -3.84226126 -4.1888473   2.12306748\n",
            "  3.79858017  1.96157841]. \t  -371.14910893749106 \t -126.06288515837247\n",
            "6      \t [ 1.37771885  0.82081389  4.85490971 -4.5851756  -3.85333427 -2.70311804\n",
            " -4.33441952  3.3807073 ]. \t  -499.0771768328371 \t -126.06288515837247\n",
            "7      \t [ 4.2191701  -1.22543815 -1.43787317  3.87431541  0.42985254  4.87494941\n",
            "  2.89026166 -1.37831396]. \t  -304.2364498186564 \t -126.06288515837247\n",
            "8      \t [-1.13542945 -3.29790074  4.25210209 -2.68027179  2.71207286  0.18556258\n",
            " -3.61630697 -4.61294952]. \t  -404.77949845291243 \t -126.06288515837247\n",
            "9      \t [-1.86553537  2.66611528  5.03500594  3.91408686  2.6018486   4.63137625\n",
            " -3.94379584  4.80278023]. \t  -610.9849412618994 \t -126.06288515837247\n",
            "10     \t [ 4.60306575 -0.86214225 -2.57311838  3.23890485 -1.01386668 -2.82458863\n",
            " -5.09984632  2.247192  ]. \t  -359.967062494124 \t -126.06288515837247\n",
            "11     \t [ 3.80241898 -4.76561259  3.75477373 -2.31697124  1.95612299 -4.8590656\n",
            "  3.87732368 -4.51857722]. \t  -553.0199071382995 \t -126.06288515837247\n",
            "12     \t [-4.93082189 -1.08547738  3.13985151  4.61447679 -1.12473443  1.83139203\n",
            "  3.52783216 -3.01896669]. \t  -327.9007090938635 \t -126.06288515837247\n",
            "13     \t [-4.28544622 -2.99510281 -1.59378884  3.59331017 -0.97728126 -1.35562958\n",
            " -2.03418121  3.35328811]. \t  -230.29769605871667 \t -126.06288515837247\n",
            "14     \t [-4.02966971  1.77374782  2.02018761 -0.67095285 -4.61254618  4.78410608\n",
            "  4.76591033  3.90358091]. \t  -561.179582860869 \t -126.06288515837247\n",
            "15     \t [ 3.95149817 -4.99450645 -4.51563062  0.26401164  2.01242039  1.53796201\n",
            " -0.35519101  4.30213569]. \t  -310.3473339324236 \t -126.06288515837247\n",
            "16     \t [ 4.14940467  1.36567646 -3.1957341   3.25372311 -1.23230608 -1.9790755\n",
            "  3.6659892   2.67370714]. \t  -276.29205645412515 \t -126.06288515837247\n",
            "17     \t [-2.27249058  4.20525525 -3.02863272  3.81122184  3.08064796 -1.54627104\n",
            " -3.62805533  1.41504326]. \t  -296.10801462263225 \t -126.06288515837247\n",
            "18     \t [-1.21951511 -2.03118811  4.33393671  3.06502757 -4.39819052 -4.34326947\n",
            " -1.95456176 -1.94162451]. \t  -370.4710305353688 \t -126.06288515837247\n",
            "19     \t [-4.43486764  0.66658031 -4.80754618 -3.4003684   3.75222782 -4.3816852\n",
            " -1.63572945 -4.98804401]. \t  -539.5092306809628 \t -126.06288515837247\n",
            "20     \t [-3.16138531  1.84161343 -2.32963366 -4.6937687  -3.23007463 -4.62488528\n",
            " -2.34824634  4.59170695]. \t  -508.95917656188817 \t -126.06288515837247\n",
            "21     \t [-3.08427564  1.23472968 -3.1005727   4.56550044 -3.64561646 -4.04221536\n",
            "  4.79912902 -3.2053463 ]. \t  -532.6827628024603 \t -126.06288515837247\n",
            "22     \t [ 4.25779129 -1.72621711  4.53974865 -3.02334512  5.04457279  3.06400636\n",
            " -1.9793179   1.66978335]. \t  -355.7755436866107 \t -126.06288515837247\n",
            "23     \t [1.05039904 4.66273077 2.03364616 4.75044165 3.63891332 0.4328576\n",
            " 4.28238984 1.22631228]. \t  -354.99480686323244 \t -126.06288515837247\n",
            "24     \t [-0.18242758 -4.37562517 -2.68283982  3.51170104  4.61903856 -4.63396726\n",
            "  0.79788305 -4.63478577]. \t  -521.0722727207896 \t -126.06288515837247\n",
            "25     \t [ 0.74578014 -4.74256809  2.97615692  2.80810404 -0.04522388 -0.96730771\n",
            "  4.64630612  4.75957031]. \t  -441.6239471753703 \t -126.06288515837247\n",
            "26     \t [ 4.89596661 -1.33007875  4.45885482 -2.32985531 -2.3387499   3.73847449\n",
            "  3.21680713  4.75064811]. \t  -473.0558712877664 \t -126.06288515837247\n",
            "27     \t [ 1.87064481  2.42930953 -4.25997183 -4.91930109  3.25242741  0.17750408\n",
            " -3.59930004 -2.44735996]. \t  -358.22433282920497 \t -126.06288515837247\n",
            "28     \t [ 5.06038003  4.88820424  2.29473495  2.33135213 -0.3584241  -1.80582821\n",
            " -0.48450905 -4.94079206]. \t  -328.0778486593332 \t -126.06288515837247\n",
            "29     \t [ 2.76022523  3.19957201 -1.18154826  1.70668765  4.99700325  4.90051723\n",
            " -2.53105423  3.98780098]. \t  -484.93738931099335 \t -126.06288515837247\n",
            "30     \t [-4.64236112 -2.78620974 -3.05213582 -3.83987755  3.68876152  3.63189677\n",
            " -0.96814899 -4.61015673]. \t  -447.77108432770297 \t -126.06288515837247\n",
            "31     \t [ 0.41822299 -3.5989025   1.26313989 -3.05174671 -4.43250861 -4.97663478\n",
            "  1.79611246  1.78689615]. \t  -363.0814555767522 \t -126.06288515837247\n",
            "32     \t [-4.27836871  2.29804118  3.688304   -4.9606354   4.40335324  2.27000493\n",
            "  4.3871339   4.62689507]. \t  -601.9678024196846 \t -126.06288515837247\n",
            "33     \t [ 0.0514396  -0.40989119  4.78774391  4.46426208  4.39339107  5.09632421\n",
            " -3.18701334 -4.03513517]. \t  -602.5271401890568 \t -126.06288515837247\n",
            "34     \t [-4.96834109 -4.38271173  3.53285414 -2.33109276  3.79547402 -4.77674926\n",
            "  4.91327904  4.07253773]. \t  -632.8786874652055 \t -126.06288515837247\n",
            "35     \t [ 4.5643842   4.45895676 -2.34073508  4.44726022 -4.93999175  2.95208387\n",
            " -3.17935933  0.80221201]. \t  -406.36083064806195 \t -126.06288515837247\n",
            "36     \t [-1.83003609  3.83239604  4.78749515 -2.79244221 -5.08260614 -1.18674102\n",
            " -3.25124143 -5.10049421]. \t  -552.4036911625924 \t -126.06288515837247\n",
            "37     \t [-3.21848904  2.40477509 -4.98385284  3.26748195  1.75994418  4.40119472\n",
            "  4.9624183  -2.78332492]. \t  -505.2111343927684 \t -126.06288515837247\n",
            "38     \t [ 4.11877048 -4.45061137  4.15827131 -2.78389491  4.65159982 -4.86511458\n",
            " -0.84195562  4.98909544]. \t  -593.7478529229361 \t -126.06288515837247\n",
            "39     \t [-5.04667268 -4.94917215  4.11016193  2.36420834  2.01098783  2.59182362\n",
            " -4.88683234  1.93108435]. \t  -405.0219974895101 \t -126.06288515837247\n",
            "40     \t [ 1.92421178  4.74518747 -0.92018962 -1.48166455  4.89835247 -2.59321123\n",
            "  4.65948536 -3.39279253]. \t  -464.43947291247133 \t -126.06288515837247\n",
            "41     \t [ 3.71783018 -3.62494958 -3.89301902 -4.96338463  3.5554692  -4.73447431\n",
            "  3.14442446  4.81580369]. \t  -636.5561656707883 \t -126.06288515837247\n",
            "42     \t [ 0.98736104 -4.79100785 -0.19376361 -4.29879054 -1.46628453  2.20634764\n",
            " -2.32998647  0.69067816]. \t  -202.6893476537861 \t -126.06288515837247\n",
            "43     \t [ 4.97129733 -1.68083118 -4.87817699 -4.86671673 -0.5994676  -3.81803964\n",
            " -5.10673473  3.38359304]. \t  -559.8959023006187 \t -126.06288515837247\n",
            "44     \t [ 4.16808471  1.2778299   1.23652869  4.91545255 -5.04738958  5.09223219\n",
            "  2.3434763   3.74043524]. \t  -555.2080279537713 \t -126.06288515837247\n",
            "45     \t [-4.77256561  2.41467605 -1.13798927 -2.11920939 -3.26211852  3.40752618\n",
            " -3.55511358  4.82943011]. \t  -454.2214389750327 \t -126.06288515837247\n",
            "46     \t [-4.16641793 -5.10884189 -2.55278582  2.44522073 -4.94198432 -2.57543199\n",
            " -2.74848245 -4.19066892]. \t  -468.3120168281308 \t -126.06288515837247\n",
            "47     \t [ 4.59868702 -4.06351461  3.62809396  2.11164905 -2.69001242 -4.44366744\n",
            " -1.16524722  5.10767241]. \t  -484.36673170300537 \t -126.06288515837247\n",
            "48     \t [-4.74564094  2.58073326  3.96868301 -0.14740857  4.77652724  3.2886208\n",
            "  4.98237726 -2.92854975]. \t  -504.5257623800317 \t -126.06288515837247\n",
            "49     \t [-5.08943205 -1.98438267  3.92418583 -4.63075288  0.67808371 -3.42433661\n",
            "  4.97407719 -4.65131354]. \t  -584.6743834389501 \t -126.06288515837247\n",
            "50     \t [ 3.60330402 -4.56395011 -0.12815549  3.26161117 -4.70226816  1.98215782\n",
            " -4.76511543 -2.86022831]. \t  -455.76663208313505 \t -126.06288515837247\n",
            "51     \t [-2.17339662 -4.09099619  3.26230892  5.11514306  4.91920704  4.18799046\n",
            "  2.65190339  0.45815705]. \t  -451.9188631967146 \t -126.06288515837247\n",
            "52     \t [-1.56981928 -1.76021983 -3.90391609  4.7958652  -3.37199942  4.65109866\n",
            "  1.75876496  4.84877887]. \t  -542.7702999823342 \t -126.06288515837247\n",
            "53     \t [ 2.12103433  2.71628641  4.55417272  1.29771506 -2.56582687  4.34204542\n",
            "  2.70112208 -4.33063105]. \t  -435.35776914467215 \t -126.06288515837247\n",
            "54     \t [ 4.18553753  0.3560553   1.85750414  3.01054101  3.66933258 -5.03527626\n",
            "  0.51805222  3.52405766]. \t  -385.0512249098672 \t -126.06288515837247\n",
            "55     \t [ 4.45692006  4.77107879 -0.75681542 -3.53334663  5.06842461  3.82125335\n",
            "  4.70147327  5.11098795]. \t  -696.8080269212567 \t -126.06288515837247\n",
            "56     \t [-2.94603597  4.52838373  2.85133733  4.28961967 -4.89742324  2.85120091\n",
            " -2.00766628 -3.259035  ]. \t  -429.57075954906884 \t -126.06288515837247\n",
            "57     \t [-5.0083248   5.11026403 -1.18492991 -0.17718899 -0.57235897 -3.27087235\n",
            " -5.05734659 -5.07103573]. \t  -532.2407928857123 \t -126.06288515837247\n",
            "58     \t [ 4.78836073  3.79247422  5.05453042 -2.10443279 -2.73276821 -2.02348411\n",
            "  4.41652593 -0.07759148]. \t  -344.54861334419996 \t -126.06288515837247\n",
            "59     \t [ 1.03026763 -4.5711518  -3.21554021 -0.66432757 -3.94967897  4.82222503\n",
            "  4.13275306 -4.32685568]. \t  -562.4906509885475 \t -126.06288515837247\n",
            "60     \t [-5.10819161 -4.05627337 -3.46243958 -4.92472376 -1.55153485 -4.00046855\n",
            " -3.48271739 -0.94839304]. \t  -392.13704019783205 \t -126.06288515837247\n",
            "61     \t [-3.75640757 -0.35662482 -2.52119034  4.58741618 -4.76809673 -4.60715911\n",
            "  3.39571525  4.81313781]. \t  -624.6874732329553 \t -126.06288515837247\n",
            "62     \t [-4.78367167  4.14154228 -0.66206603  0.10642798 -2.88873759  1.04720257\n",
            "  3.34384843 -4.85890298]. \t  -373.993146864827 \t -126.06288515837247\n",
            "63     \t [ 3.90341241  0.7271449  -3.17033464  4.04988313  4.3810933  -1.73961296\n",
            " -4.21500868 -5.09057248]. \t  -557.8563109962846 \t -126.06288515837247\n",
            "64     \t [-1.4475125  -4.34201896  4.85771972 -1.69396662  3.17627425  4.31667248\n",
            "  1.43096795  4.80325247]. \t  -483.2210811513405 \t -126.06288515837247\n",
            "65     \t [ 5.07012284  3.2925214   1.7924797  -4.14379389  2.26515226 -4.86743609\n",
            " -5.10734572  0.88524491]. \t  -482.3809106329983 \t -126.06288515837247\n",
            "66     \t [-4.91554525  2.89709073 -4.92224896 -1.57136991  0.23902827  4.44092204\n",
            " -4.78237799 -2.25757831]. \t  -442.9989299504249 \t -126.06288515837247\n",
            "67     \t [ 1.41460149  4.60555716  4.83363382 -1.16002436  4.62465953 -1.58201115\n",
            "  2.99414855  4.12020927]. \t  -440.4154931796994 \t -126.06288515837247\n",
            "68     \t [-3.29513168  4.69703011  4.31837646 -3.82056116  3.60718111  5.05741155\n",
            " -1.5779542  -0.14830569]. \t  -405.44273268819427 \t -126.06288515837247\n",
            "69     \t [ 4.96780163 -4.81269844  2.69303631 -4.15229241  0.32736337  4.84633609\n",
            "  4.26916063 -2.69726244]. \t  -488.96624791701055 \t -126.06288515837247\n",
            "70     \t [ 4.35060813 -3.51173579  2.71548523 -3.27307704 -4.49088034 -0.25380375\n",
            " -3.36246315 -4.0047921 ]. \t  -417.242597006925 \t -126.06288515837247\n",
            "71     \t [-2.7684024  -4.07046535  0.42269151 -2.54916832 -1.70455879  2.46638763\n",
            "  4.44445639  4.70659919]. \t  -433.8454360635856 \t -126.06288515837247\n",
            "72     \t [-4.45566592  2.91953845  4.51273269 -3.72364167 -3.67595816 -3.35553114\n",
            "  4.21277873  2.37190231]. \t  -457.8174411087285 \t -126.06288515837247\n",
            "73     \t [ 5.11574287 -3.94641232  0.57743523  0.3797981  -3.77851313 -0.24347718\n",
            "  4.66869826 -0.31347036]. \t  -284.00125388753884 \t -126.06288515837247\n",
            "74     \t [-4.53383559 -3.25727348  4.49248153  4.12056034  5.10550144 -5.0523998\n",
            " -3.47339804 -3.1886414 ]. \t  -619.5206839116902 \t -126.06288515837247\n",
            "75     \t [-2.7809732  -4.70223428  2.09823975 -1.41226033 -4.17598147 -2.18303309\n",
            " -5.11333508  3.31745112]. \t  -459.99670604909386 \t -126.06288515837247\n",
            "76     \t [ 3.07375851  4.72973896 -1.1202067   1.39261569  3.94036867  4.30418106\n",
            "  0.60322853 -3.43563089]. \t  -351.47499903370965 \t -126.06288515837247\n",
            "77     \t [ 4.57955326 -0.92803845 -4.95763029  2.03006401  0.82997734 -1.5522242\n",
            "  4.72067532 -4.51997331]. \t  -450.24916249284456 \t -126.06288515837247\n",
            "78     \t [-3.93950123  0.29809163 -3.93104113 -2.69367102  4.41074442 -2.783079\n",
            " -4.47258678  3.67176586]. \t  -482.70974209062933 \t -126.06288515837247\n",
            "79     \t [-4.64015587 -4.49621655  0.67652099 -3.33270916 -4.93350316 -1.32246406\n",
            "  2.00973947 -2.94966904]. \t  -337.83229896147117 \t -126.06288515837247\n",
            "80     \t [-4.6333684   3.96468851  4.50521121  4.91482817 -4.46962491 -5.03923329\n",
            " -4.29872131  0.32600801]. \t  -592.8727913226526 \t -126.06288515837247\n",
            "81     \t [ 4.63242419 -2.60474489  3.93465664  0.70012493  3.74226594 -4.99623212\n",
            " -3.63647532 -2.97825111]. \t  -466.7583050628426 \t -126.06288515837247\n",
            "82     \t [-0.3467273  -3.68527946 -2.91703194 -3.35700387  4.87774891 -1.91295388\n",
            "  3.9196103  -2.2308955 ]. \t  -386.1650147457948 \t -126.06288515837247\n",
            "83     \t [-1.69213891 -1.03896808 -4.79324514 -1.99321746 -4.92141787 -0.64548894\n",
            "  1.31802159  2.14991621]. \t  -262.5785930526664 \t -126.06288515837247\n",
            "84     \t [-4.65891214 -1.8539564   5.08351102 -4.96897638  2.98653259 -4.29999065\n",
            " -4.40106778  2.62358603]. \t  -551.0567434148775 \t -126.06288515837247\n",
            "85     \t [-4.01208706 -5.01784455  3.81245008 -1.4487396  -3.20429523  4.68594121\n",
            " -1.5758705  -3.3518294 ]. \t  -408.8015498884233 \t -126.06288515837247\n",
            "86     \t [ 1.95451571  4.36284974 -5.10419484 -1.61602583 -2.43919275  5.03461818\n",
            "  1.6217405  -2.13914608]. \t  -367.34407079968463 \t -126.06288515837247\n",
            "87     \t [-1.48931253 -4.7682876  -2.72133167  3.88708211  4.92667111  5.09506253\n",
            " -4.6902831  -2.23040876]. \t  -601.2532420165638 \t -126.06288515837247\n",
            "88     \t [-3.16579097  1.16457568  5.0466967   4.25375159  1.72253713 -2.93140422\n",
            " -3.98755077  3.44062764]. \t  -433.9214901411437 \t -126.06288515837247\n",
            "89     \t [-3.08185897  0.29527744 -3.14916545 -3.27739878  3.29631686  4.57099795\n",
            " -4.67572104  4.92893055]. \t  -609.4734115758253 \t -126.06288515837247\n",
            "90     \t [-1.56907655  5.10778164  1.71859534  1.64432888  5.03324701 -5.06748945\n",
            " -3.36504479 -4.6113956 ]. \t  -604.4458612710002 \t -126.06288515837247\n",
            "91     \t [ 4.32620399 -3.63086328 -1.93931556  4.9443213  -3.29805233 -4.89871883\n",
            " -0.76392229 -3.6684274 ]. \t  -464.2648049149675 \t -126.06288515837247\n",
            "92     \t [ 2.047526    1.70281313  2.3927379   0.33016402  1.26575371 -0.65166592\n",
            " -4.45336702  4.74099642]. \t  -356.8055185531831 \t -126.06288515837247\n",
            "93     \t [-4.27019977 -1.75817112  2.72854221  4.88072815 -5.098481   -3.27604232\n",
            "  5.03547098 -4.87471531]. \t  -703.9996278205869 \t -126.06288515837247\n",
            "94     \t [-0.03430723 -3.08835292  4.86965696 -0.28950539 -5.00835447  1.71133878\n",
            "  0.44354846  2.25133024]. \t  -275.4681593529996 \t -126.06288515837247\n",
            "95     \t [ 0.48593532 -5.09643193  4.62398774  5.1158141  -1.85799238  3.85565002\n",
            "  0.67773994 -5.10147814]. \t  -538.8862274988127 \t -126.06288515837247\n",
            "96     \t [-2.88237755 -2.46127004 -0.78802228  4.22170457  4.57418874 -5.00298658\n",
            "  1.45550213  3.23238101]. \t  -446.78885862678726 \t -126.06288515837247\n",
            "97     \t [ 1.20624255 -1.40983937  4.00790281  1.8873918   4.84619211 -0.31889029\n",
            "  2.35659385 -4.41948848]. \t  -381.0369665992607 \t -126.06288515837247\n",
            "98     \t [ 3.02154951 -5.00095118 -2.76672328 -4.16395755 -4.10616315 -3.59311794\n",
            "  3.52193193 -4.4948962 ]. \t  -561.6938541462497 \t -126.06288515837247\n",
            "99     \t [-1.92804257  3.18763758 -2.8191181   0.92585961  1.82086742 -4.43848087\n",
            "  2.582314    5.07014659]. \t  -438.41853572855973 \t -126.06288515837247\n",
            "100    \t [-4.14741394  3.76804542 -4.870802    1.9124336  -4.71433047  4.86110818\n",
            "  3.970222    3.33827089]. \t  -583.7989751144055 \t -126.06288515837247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YRio_skuvd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d004b4-f197-4838-9eaf-134110f21615"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 8 \n",
        "\n",
        "np.random.seed(run_num_8)\n",
        "surrogate_winner_8 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_8 = dGPGO_stp(surrogate_winner_8, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.99872128 -4.68771825  1.02085207 -2.04932398  3.03730465 -1.37015168\n",
            "  3.89742944 -2.07010168]. \t  -277.86676122742784 \t -180.51916289603517\n",
            "init   \t [-1.74998258  0.70366122  2.49781681 -4.56854645  1.04524157 -0.72377777\n",
            " -3.01595019  0.49815264]. \t  -180.51916289603517 \t -180.51916289603517\n",
            "init   \t [-1.18004907 -0.43124987 -2.23607519  0.87291919  1.19692315  0.82388062\n",
            "  4.34999751 -2.6686217 ]. \t  -220.47800037058124 \t -180.51916289603517\n",
            "init   \t [ 3.35954485  4.67643031  4.19598825  2.82329052 -0.36849066 -1.29661262\n",
            "  4.62746655  4.05379841]. \t  -431.85390329456686 \t -180.51916289603517\n",
            "init   \t [-0.2416498   4.43676172  4.77427222  3.16353515  1.62974284 -3.16385107\n",
            "  1.99781252 -1.93490553]. \t  -279.0706376092465 \t -180.51916289603517\n",
            "1      \t [-0.80689796  0.12979216 -3.32388196  5.07613741 -3.43250948 -2.05510194\n",
            " -3.97044354  3.43910665]. \t  -426.1198945095334 \t -180.51916289603517\n",
            "2      \t [ 4.07058243  1.87505943  3.823545   -0.7045548   4.15212304  3.79618737\n",
            "  3.36854962 -1.74745794]. \t  -345.97103603679506 \t -180.51916289603517\n",
            "3      \t [ 1.60816369 -3.63276347  2.89894505  4.30924253  2.24531665 -4.14943213\n",
            " -1.74543052  0.34956413]. \t  -279.28727434266773 \t -180.51916289603517\n",
            "4      \t [-3.38323741 -0.81655844  1.40105076  4.58830172 -2.54333418  1.80646949\n",
            "  4.90933886  4.55754025]. \t  -489.68208836931797 \t -180.51916289603517\n",
            "5      \t [ 3.06019179 -2.43870083 -2.47955666  5.02439222  1.06725782  2.83803554\n",
            " -2.28129529 -1.28756674]. \t  -244.39662275572095 \t -180.51916289603517\n",
            "6      \t [-0.50148047  1.93005816 -1.12481853 -4.97971357 -4.24871876 -1.46973755\n",
            "  3.82520467  2.9982716 ]. \t  -388.2487927521442 \t -180.51916289603517\n",
            "7      \t [ 4.44986416  2.59160065 -2.13776153  2.53965108  3.82229504 -5.02413012\n",
            " -1.59196109 -1.31218712]. \t  -328.7595208766232 \t -180.51916289603517\n",
            "8      \t [-2.63009491  2.97300268 -1.09355664  1.409759    2.32608454  3.66061559\n",
            " -5.11285049  0.36342263]. \t  -327.63144338629075 \t -180.51916289603517\n",
            "9      \t [-2.53291184 -1.84741376 -4.45052851 -4.7843232   0.63505707  4.79454939\n",
            " -3.75931101 -1.16895793]. \t  -414.02346987701105 \t -180.51916289603517\n",
            "10     \t [-4.47481624  3.11688336  2.54393998 -3.31704088  3.60130476  4.77393335\n",
            "  0.71525816 -4.37852437]. \t  -461.4224190707449 \t -180.51916289603517\n",
            "11     \t [ 3.38777639 -1.50760259  3.77036565  1.01796157 -4.86928761 -1.64703553\n",
            "  0.18621712  3.23948886]. \t  -281.83792201450086 \t -180.51916289603517\n",
            "12     \t [-2.84404368 -3.41145951 -4.82923641  2.02781195  4.41855085 -5.031258\n",
            " -4.91790685  2.55135054]. \t  -588.6524262167944 \t -180.51916289603517\n",
            "13     \t [ 0.12075833  3.53187191 -1.13812866 -4.18492602  4.75846939  4.37401389\n",
            "  4.91290648  2.56838572]. \t  -548.6397863682118 \t -180.51916289603517\n",
            "14     \t [ 3.83260518 -3.59614177  4.94103107  3.02187054 -2.89650737  2.38820085\n",
            "  4.53826575 -4.92297598]. \t  -564.5478312162915 \t -180.51916289603517\n",
            "15     \t [ 0.63940217 -4.53533341  4.8143005  -4.39581915  1.48714894  4.07740076\n",
            "  2.545188   -3.81744206]. \t  -461.110731573049 \t -180.51916289603517\n",
            "16     \t [-3.60718928 -1.4152173   0.54359524 -4.77844283 -4.47608368  4.48713264\n",
            "  0.96362504  0.19062556]. \t  -337.01154391561914 \t -180.51916289603517\n",
            "17     \t [ 5.03657361  2.14121545 -5.0614108   0.9557451  -2.87767627  2.75542412\n",
            " -4.53535155  2.72962719]. \t  -405.59620242543093 \t -180.51916289603517\n",
            "18     \t [ 2.88594046 -2.10783246  3.24830708 -3.35904163  2.67335704 -4.31631745\n",
            "  0.10541753  4.93611068]. \t  -436.5187741793278 \t -180.51916289603517\n",
            "19     \t [-4.60418858  4.67669774  1.08408569  0.18942655  3.69823627 -3.31481009\n",
            " -2.50513253  4.09057771]. \t  -380.71579539428444 \t -180.51916289603517\n",
            "20     \t [ 2.89004832  2.29273214  0.02662787 -4.96553505 -3.07042196  4.14880503\n",
            "  0.28885754 -3.89733982]. \t  -390.0049871815359 \t -180.51916289603517\n",
            "21     \t [-4.34829873  4.8056149   2.63278856  2.70249436 -3.33886902  3.32420497\n",
            " -1.98131952 -3.03250746]. \t  -338.1946658605332 \t -180.51916289603517\n",
            "22     \t [ 3.96711026 -4.66703301 -3.38814135 -2.60897667  4.53013364  0.81045759\n",
            "  2.79927726  4.79759783]. \t  -466.5047351743416 \t -180.51916289603517\n",
            "23     \t [ 2.77240754  2.5565598  -4.69097634  3.83705084 -0.20889492 -1.5246837\n",
            "  4.36955398  4.62223751]. \t  -464.40365175389996 \t -180.51916289603517\n",
            "24     \t [ 4.34756974  0.28432146 -3.99051557 -4.1519451   4.66598637 -3.99885193\n",
            "  4.69377078 -2.29238674]. \t  -536.8530055710505 \t -180.51916289603517\n",
            "25     \t [-2.40802768 -4.89934205 -3.92211253  2.87573277 -1.83341418 -1.37337664\n",
            " -2.45354227 -3.7298118 ]. \t  -314.58903267753135 \t -180.51916289603517\n",
            "26     \t [ 5.03561283 -1.94774771  4.84033306  0.65898714 -5.05929832 -3.27758434\n",
            " -4.16862726 -5.0033758 ]. \t  -619.3185473500058 \t -180.51916289603517\n",
            "27     \t [ 4.98741914 -4.88116804  2.38148864 -1.94074891  3.76053791 -0.75507706\n",
            " -1.8225068  -5.07721439]. \t  -408.21108253473403 \t -180.51916289603517\n",
            "28     \t [ 2.19481864 -4.12875518 -2.50783499 -3.58099359 -4.62923168 -0.92061762\n",
            " -4.08935361  0.27512394]. \t  -338.97162361612516 \t -180.51916289603517\n",
            "29     \t [ 3.95559354 -4.94153651  4.06993348  4.94169925  3.65520971  3.87409279\n",
            " -0.11987066  5.05050476]. \t  -572.8746573913305 \t -180.51916289603517\n",
            "30     \t [ 4.88622164  4.20294744  1.52432748 -2.01267827 -0.03877796 -0.03765484\n",
            " -2.47547849  4.78886469]. \t  -308.7566971038034 \t -180.51916289603517\n",
            "31     \t [ 2.10484717  3.67633788 -0.94550013  4.41772355 -4.47698873  0.69187552\n",
            "  1.67327399 -4.9287631 ]. \t  -429.23819680513293 \t -180.51916289603517\n",
            "32     \t [-3.56264823  4.79477148 -3.3156554  -0.37949176  4.3976868  -4.77850975\n",
            " -0.67465059 -3.91327402]. \t  -451.62785856729056 \t -180.51916289603517\n",
            "33     \t [ 4.3746049  -3.45794581  3.14337867 -4.82984216  4.57264257  3.18742561\n",
            " -2.74753886  4.78134957]. \t  -567.2405467940839 \t -180.51916289603517\n",
            "34     \t [-4.26263721 -3.06243842  3.6672734   3.67019167 -2.87048066 -2.78499413\n",
            " -4.48129316 -1.5193328 ]. \t  -377.9313902287684 \t -180.51916289603517\n",
            "35     \t [-4.84033142  0.64683101 -4.77800586  2.15451209 -4.84721005  4.64872933\n",
            " -4.54964791  4.77402493]. \t  -685.6882163667333 \t -180.51916289603517\n",
            "36     \t [-4.99478657 -2.9415192   4.34640252  1.08312843  3.52136984  4.55818598\n",
            " -0.57134204  0.70996919]. \t  -296.59933292980014 \t -180.51916289603517\n",
            "37     \t [-4.49149967 -3.96688424 -2.92032019 -3.89883361  4.98121429  1.54937171\n",
            "  2.23761564  4.85189021]. \t  -499.8753054061116 \t -180.51916289603517\n",
            "38     \t [-3.36525447 -1.54448367  0.12300683  3.56352321 -4.58313269 -4.93239854\n",
            "  4.89524317 -4.38312174]. \t  -639.3707274540823 \t -180.51916289603517\n",
            "39     \t [ 1.50533204 -3.77219987 -4.91581673 -0.91213341 -5.07288479 -1.23308137\n",
            "  4.2545633  -3.9001535 ]. \t  -492.74119980167814 \t -180.51916289603517\n",
            "40     \t [-3.77854353  3.17936999 -4.24604221  2.36963403 -3.50945646  5.10280427\n",
            "  3.1441825   1.99806299]. \t  -429.99378541928 \t -180.51916289603517\n",
            "41     \t [ 1.27002286  3.11549515  5.0761917  -0.67981569 -4.96796072  4.91721756\n",
            "  2.40479006  1.20213575]. \t  -420.6968318820452 \t -180.51916289603517\n",
            "42     \t [-2.43921096 -4.84802837 -3.77932237 -4.11067927  2.43463713 -3.64419562\n",
            " -2.91494692 -2.92936715]. \t  -400.8432814051702 \t -180.51916289603517\n",
            "43     \t [ 3.5964777  -0.6804963  -4.41600893 -1.16786362 -2.38444909  5.01054494\n",
            "  3.51850897  3.27146697]. \t  -429.1604865261535 \t -180.51916289603517\n",
            "44     \t [-0.06761511 -4.30965696 -4.82083185 -2.41192342 -2.60586807 -5.04028198\n",
            "  3.27073244  4.1333081 ]. \t  -528.0787336856462 \t -180.51916289603517\n",
            "45     \t [ 3.50503851  4.96098179 -1.77107594  3.26338186  4.43104384  1.82068367\n",
            " -5.09034827  4.07971727]. \t  -546.1110940325218 \t -180.51916289603517\n",
            "46     \t [ 3.97405564 -4.75710002 -2.01610248  5.07982104  3.97698667 -2.99383872\n",
            "  4.55425869  4.69086357]. \t  -630.5485044279746 \t -180.51916289603517\n",
            "47     \t [ 2.57155298  3.4084711  -1.70871252 -5.03894525  3.99660009 -3.4129706\n",
            "  3.9249342   5.02817986]. \t  -600.0219798119202 \t -180.51916289603517\n",
            "48     \t [-3.18882275 -2.56444877 -0.71584988  3.36244557  4.82715942 -1.45670243\n",
            "  2.48358987  4.08630645]. \t  -376.08283550853577 \t -180.51916289603517\n",
            "49     \t [-0.50760166  4.39934331  4.91586869  2.69970455  0.39716769  2.96123225\n",
            " -2.33184496  5.03567605]. \t  -434.9458784136016 \t -180.51916289603517\n",
            "50     \t [-1.78996274  4.77720088  4.59860514 -4.03648124 -3.94034674 -4.33638585\n",
            " -4.14819873  4.29775634]. \t  -636.1371547050605 \t -180.51916289603517\n",
            "51     \t [ 5.01960078  4.66343278  2.47908295 -0.1380686   2.4412476   0.91037699\n",
            " -4.27646892 -4.63889164]. \t  -422.1484084919773 \t -180.51916289603517\n",
            "52     \t [ 4.1238205   4.45841046 -4.36439719  2.53410932  1.82655466  4.84593007\n",
            " -2.63657092 -4.58239807]. \t  -513.8187312212864 \t -180.51916289603517\n",
            "53     \t [-3.83359827 -3.01522124 -3.7875479   3.90733566  1.60675722  4.41781314\n",
            "  0.31463524  1.0547853 ]. \t  -276.58956433068636 \t -180.51916289603517\n",
            "54     \t [-2.69552383  3.741289   -0.70344203 -4.59602035 -4.15665532 -3.80921854\n",
            " -1.6067944  -3.68854063]. \t  -421.6034055653096 \t -180.51916289603517\n",
            "55     \t [ 1.98664074  1.76485065 -3.60578134  2.79705221  3.94454191  4.79852633\n",
            "  2.01598348  2.04566978]. \t  -358.35474661653774 \t -180.51916289603517\n",
            "56     \t [-5.07574257  0.9567305   2.26465    -4.88807507  3.91342817 -4.93868051\n",
            "  4.90344371  2.79780682]. \t  -592.3989559199782 \t -180.51916289603517\n",
            "57     \t [ 4.80012579 -0.89581978 -3.23378812 -3.88285619  4.16408667  4.83044301\n",
            " -2.40201335 -1.67065029]. \t  -405.7380623113728 \t -180.51916289603517\n",
            "58     \t [ 3.13903097  4.15131655  2.18342166 -4.30940714  2.66825456 -4.84201899\n",
            " -1.08896277 -2.62730781]. \t  -372.697973174463 \t -180.51916289603517\n",
            "59     \t [ 1.41773499  4.05249716  4.63254487  0.55379983 -2.44363061  0.94868112\n",
            "  4.71743379 -4.92883902]. \t  -485.8471633373821 \t -180.51916289603517\n",
            "60     \t [-2.65893363 -4.02358501  2.18739427 -3.51967483 -4.47898169 -3.53177444\n",
            "  4.33510834 -0.30582069]. \t  -410.8022555111339 \t -180.51916289603517\n",
            "61     \t [-0.38581044  4.66183745 -4.94019583 -5.11893072 -0.56556666 -2.01091883\n",
            " -3.37674108  3.70470884]. \t  -437.12241617662204 \t -180.51916289603517\n",
            "62     \t [-1.50385763 -2.82163626  1.91460617  0.87816512  2.4301678   1.01736253\n",
            " -4.75075709  4.9673666 ]. \t  -423.39113119996387 \t -180.51916289603517\n",
            "63     \t [-4.69795367 -0.52700265 -3.23152009 -4.97281493 -4.95960836 -1.47316114\n",
            " -3.49313255  3.35839495]. \t  -464.52410784473864 \t -180.51916289603517\n",
            "64     \t [-0.29428861 -0.78853173  4.29742184  0.86710332 -0.66478091  0.69406844\n",
            " -1.28852935 -4.34349309]. \t  -227.39081375306705 \t -180.51916289603517\n",
            "65     \t [-3.56358405 -4.93006088  2.4194607   4.72620838 -4.86416627  3.67797867\n",
            " -0.69679818  1.69074593]. \t  -393.9530831563613 \t -180.51916289603517\n",
            "66     \t [-1.91647273  4.63728945 -3.4853342  -4.0478746   0.33452304  3.41628748\n",
            "  3.64796615 -4.30693188]. \t  -460.8021394306826 \t -180.51916289603517\n",
            "67     \t [ 4.04331205  2.94331322 -3.87019312 -1.6112972  -3.13922825 -3.1782376\n",
            " -1.87656017 -3.77804134]. \t  -337.7149097801716 \t -180.51916289603517\n",
            "68     \t [-1.97357908  4.47846413  1.07380433 -5.0038314   4.81557785  4.94993909\n",
            " -3.38895691  4.11984897]. \t  -626.7615575651567 \t -180.51916289603517\n",
            "69     \t [-4.66907786  4.06529344 -2.81502672  2.13806286  3.33464297  4.72978126\n",
            "  1.89659275 -2.88664154]. \t  -378.5771341595189 \t -180.51916289603517\n",
            "70     \t [ 1.69428745 -5.08713966 -5.06739538 -3.1022465   5.05147468  2.54965972\n",
            "  4.36569506 -4.21070954]. \t  -612.0070338262956 \t -180.51916289603517\n",
            "71     \t [ 4.43534036 -2.53833732 -2.58898923  4.1737641  -3.85334919 -4.03052634\n",
            " -4.61889907 -3.25070405]. \t  -527.9369494440782 \t -180.51916289603517\n",
            "72     \t [ 1.72104166 -4.073186    3.22837667 -3.64091869 -2.9838938   3.04424112\n",
            "  4.00159172  3.92839893]. \t  -456.10631035844983 \t -180.51916289603517\n",
            "73     \t [ 4.75665963 -5.02713752 -0.31277421  1.39064692 -0.64635884 -2.06329955\n",
            " -4.10535339  4.30678261]. \t  -375.19573846853996 \t -180.51916289603517\n",
            "74     \t [-1.8908175   3.88350561 -4.68352978  3.82393485 -0.7396749  -4.20426989\n",
            " -3.34291874 -2.48761549]. \t  -394.55718019498534 \t -180.51916289603517\n",
            "75     \t [ 4.05207489  0.86706438 -5.03334349 -5.04638044  3.80727246 -2.94375154\n",
            " -3.09386029 -1.63501019]. \t  -408.6508985788998 \t -180.51916289603517\n",
            "76     \t [-0.86601187  2.81435558  0.23356561 -2.95797086 -3.39187438  4.38741594\n",
            " -3.91311416  4.5337975 ]. \t  -496.40356263036733 \t -180.51916289603517\n",
            "77     \t [-3.24213356  2.96993132  4.05912226  1.8025518   2.85166669  4.45015867\n",
            "  4.73667284  0.58562796]. \t  -409.85826286341154 \t -180.51916289603517\n",
            "78     \t [-4.08569762  3.7928806  -4.81135734  3.52094086  0.20969951 -5.05716912\n",
            "  4.49623901  4.42567564]. \t  -616.3760103347921 \t -180.51916289603517\n",
            "79     \t [-5.00358128 -4.87305407 -4.82585006  1.12286164 -3.41238885  3.47881779\n",
            "  4.37244595 -3.12334512]. \t  -490.1441876836949 \t -180.51916289603517\n",
            "80     \t [ 2.7884492  -0.77670121  4.54035095  0.0128683   4.4468915  -4.10725526\n",
            "  4.89807278 -4.43386255]. \t  -596.1294115098096 \t -180.51916289603517\n",
            "81     \t [ 1.86220954  4.66937795 -1.85514483 -4.52556887 -1.80034777 -5.00855032\n",
            "  4.69352581 -4.03885245]. \t  -590.7444292452253 \t -180.51916289603517\n",
            "82     \t [ 0.18413055 -3.98510189  4.98386229 -0.1095038  -3.7624921   3.06030421\n",
            " -4.32444789  1.8757326 ]. \t  -392.38802718400063 \t -180.51916289603517\n",
            "83     \t [ 3.87933749 -4.39074483 -3.16245725  4.57620678 -4.67494227 -1.50468136\n",
            "  4.94505046  2.72110953]. \t  -520.6466086445382 \t -180.51916289603517\n",
            "84     \t [ 2.39066453  4.82421174  4.69635349  1.74362973 -3.28690803  0.29426038\n",
            " -2.60181483 -0.66339004]. \t  -236.034632422002 \t -180.51916289603517\n",
            "85     \t [ 3.87243046 -0.96845733 -2.70013377  1.14240261 -4.34087669  4.85074589\n",
            "  1.45005726 -4.86952224]. \t  -483.7751424578108 \t -180.51916289603517\n",
            "86     \t [ 4.54582083  2.74449752  2.9112695  -4.78280925 -0.52501157 -0.22497002\n",
            "  4.03230345  2.62782708]. \t  -323.398501250347 \t -180.51916289603517\n",
            "87     \t [ 5.0200218  -4.94692444  3.66352839 -4.68783188 -2.35491673  1.81323575\n",
            " -1.40300075 -0.23094412]. \t  -263.9728001032732 \t -180.51916289603517\n",
            "88     \t [-4.9104834   5.04888376  2.83437918 -3.45449293 -1.13839777  2.74868834\n",
            "  0.53161558  1.28537784]. \t  -213.93785155563603 \t -180.51916289603517\n",
            "89     \t [ 2.46360552  3.8099589  -5.08742201  4.00899244 -0.5141476  -4.78317037\n",
            "  4.75779754 -4.54222188]. \t  -639.1393458294378 \t -180.51916289603517\n",
            "90     \t [-4.90928011 -0.42528737  3.81385921 -3.68421699 -1.78023529  5.00990296\n",
            " -4.25535131 -4.06043019]. \t  -547.4869595286636 \t -180.51916289603517\n",
            "91     \t [-2.46961973 -3.75198488  4.4255501   1.91889948  0.04054293 -5.1085242\n",
            "  4.68158437  2.43110756]. \t  -465.0322172840936 \t -180.51916289603517\n",
            "92     \t [ 4.16736441 -4.42581008 -4.68956185  0.58828089  4.98580271  0.64103211\n",
            " -4.05182583 -0.7026913 ]. \t  -369.53070878591683 \t -180.51916289603517\n",
            "93     \t [ 4.66694696  2.45855157  2.96601538  5.00605306  0.80563715 -4.44376114\n",
            " -2.92386761  2.70608567]. \t  -400.65690039600645 \t -180.51916289603517\n",
            "94     \t [-0.36234209  3.25101085 -0.22343969  3.11407433 -3.8902223  -4.28621975\n",
            "  3.61317809  1.40083769]. \t  -353.1924336833699 \t -180.51916289603517\n",
            "95     \t [ 0.04857774  2.05917898  4.62489532  2.63764314  4.52949538 -1.77013824\n",
            " -4.56384798 -0.98017584]. \t  -375.34930613201783 \t -180.51916289603517\n",
            "96     \t [-2.40283341  0.2707662   4.71337035 -0.18686914 -4.99859647 -4.77847373\n",
            " -1.17128571 -2.79990638]. \t  -406.95937549594754 \t -180.51916289603517\n",
            "97     \t [-2.207926   -0.59321657  2.20911159  4.58233505  4.92116949  4.96664555\n",
            " -3.00149343 -4.78394563]. \t  -619.4572288420076 \t -180.51916289603517\n",
            "98     \t [ 2.01677979  0.29203301  2.48464151  5.11864712 -1.63078273  4.54297114\n",
            "  1.24909107  1.98386857]. \t  -307.09674875900896 \t -180.51916289603517\n",
            "99     \t [-4.60689612 -4.67913347 -4.1643026   4.07327962  1.7787684  -4.51540887\n",
            "  3.13013119 -3.30726029]. \t  -477.6441506149468 \t -180.51916289603517\n",
            "100    \t [ 3.40755067  2.66842357  0.29189128  4.74004121  5.00277298 -0.8122025\n",
            "  5.11413452 -4.55364435]. \t  -594.0426775875231 \t -180.51916289603517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejw6v-Ihuvf_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8c6e937-4165-4e96-db7b-9bb24659ad40"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 9 \n",
        "\n",
        "np.random.seed(run_num_9)\n",
        "surrogate_winner_9 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_9 = dGPGO_stp(surrogate_winner_9, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.76413244 -0.12207719  3.33307058 -4.79798899  3.15443162  0.67192238\n",
            " -2.07234561 -4.64183582]. \t  -383.4493461208245 \t -276.8057458851627\n",
            "init   \t [ 5.02402457 -5.05010449  2.76268061  2.52689511 -1.25502529 -0.05993009\n",
            "  4.39243154 -1.07055059]. \t  -276.8057458851627 \t -276.8057458851627\n",
            "init   \t [ 4.85331248  0.25000669 -4.16140192  3.20827815 -2.95232732  0.55650083\n",
            " -2.12716425  3.23729777]. \t  -277.7575521997104 \t -276.8057458851627\n",
            "init   \t [ 3.35915588 -2.85104771  1.48310734 -4.14534019 -0.90456843 -4.12809972\n",
            " -3.64532737 -2.94711116]. \t  -371.7161372605202 \t -276.8057458851627\n",
            "init   \t [-0.23904098 -4.32523431 -2.71315168 -5.05289725  4.08211648  0.53488053\n",
            " -3.40432253  4.3917126 ]. \t  -482.1410604064339 \t -276.8057458851627\n",
            "1      \t [-0.3457215  -2.41570642  0.505635   -1.25610202 -3.03382172  4.25433599\n",
            "  4.49717681  3.45593439]. \t  -410.6056418678222 \t -276.8057458851627\n",
            "2      \t [ 0.38378555  2.50300083 -4.65143953  4.44032741  0.59211964 -4.61742586\n",
            "  5.04755889 -4.78967291]. \t  -648.000461900787 \t -276.8057458851627\n",
            "3      \t [ 4.1967864  -3.62383051 -4.07857858  4.26642924  0.97175294  1.12842288\n",
            " -0.90654271 -5.02684512]. \t  -386.8590556303891 \t -276.8057458851627\n",
            "4      \t [-4.8710492  -2.05323762  4.64732929 -2.32223252 -1.77534112 -0.74841883\n",
            " -0.60840948  5.09474963]. \t  -347.8856442527038 \t -276.8057458851627\n",
            "5      \t [-1.35739698  3.13372387 -1.81874951 -2.36077576  1.18828857  3.48605034\n",
            "  1.6175686  -4.00636277]. \t  -280.39824376989225 \t -276.8057458851627\n",
            "6      \t [ 0.81711508  0.33401963  5.0650915   3.97129991  1.53230457  1.60569378\n",
            " -0.18323784  2.41800804]. \t  \u001b[92m-215.1596001270892\u001b[0m \t -215.1596001270892\n",
            "7      \t [ 2.91243546 -2.47622884 -5.00852066 -0.17779531 -2.66430053 -4.43563613\n",
            "  0.849529   -2.18361589]. \t  -292.86699854088897 \t -215.1596001270892\n",
            "8      \t [ 2.02795906  4.8457081  -1.26954319 -2.39812669  4.53484958 -4.93015644\n",
            " -3.50972469  4.53471091]. \t  -578.3126130057084 \t -215.1596001270892\n",
            "9      \t [-3.31854584  2.04247219  3.30956382 -0.17415201  4.35201916 -4.82258864\n",
            "  4.88947837 -1.68824217]. \t  -476.7318910842152 \t -215.1596001270892\n",
            "10     \t [-4.0521322   3.52300708 -0.59871754  0.80404697 -4.83467926  0.17354503\n",
            "  2.28877277  1.05551119]. \t  \u001b[92m-207.53780922794502\u001b[0m \t -207.53780922794502\n",
            "11     \t [ 3.46828345  4.55535565  4.63137549  2.63101813  3.60010336  4.09461313\n",
            " -5.05210632 -2.08715034]. \t  -524.4843437936995 \t -207.53780922794502\n",
            "12     \t [-4.75191925 -1.71899666 -4.77380114  1.90907046  3.53598641  1.45997595\n",
            " -1.23534464 -3.85690587]. \t  -316.4298634894203 \t -207.53780922794502\n",
            "13     \t [-3.24292855 -3.70502394  0.22072781  3.13725504  2.14602858 -0.14408744\n",
            "  3.51686745  0.04791113]. \t  \u001b[92m-187.23525034036663\u001b[0m \t -187.23525034036663\n",
            "14     \t [-4.55681471 -3.64516523 -0.43118294 -3.13902794 -4.49607725 -0.39004375\n",
            "  4.12953407 -3.20193732]. \t  -390.68770111685075 \t -187.23525034036663\n",
            "15     \t [-1.11527917 -0.38988152  0.30494605  1.03183788 -0.08438276 -3.39428654\n",
            " -4.35086719  2.42438017]. \t  -254.77955672516424 \t -187.23525034036663\n",
            "16     \t [ 0.82027222 -2.39290507  4.88168313 -3.35931629 -3.72873072  4.68634669\n",
            " -4.2275348   4.51410294]. \t  -618.1669414144055 \t -187.23525034036663\n",
            "17     \t [ 3.25207762  3.02054951  3.39221164  4.58774245 -3.4985204   4.87014996\n",
            "  3.58259696 -4.24885414]. \t  -585.3097575683016 \t -187.23525034036663\n",
            "18     \t [ 3.11653097  2.24095074  4.00852509  2.91342265  1.61454667 -4.97950825\n",
            " -1.76667359 -2.96347232]. \t  -355.8255458820284 \t -187.23525034036663\n",
            "19     \t [ 2.29797466 -0.29101371 -3.13496836  2.12987244  3.61923957  4.14227711\n",
            "  5.06047468  0.18508455]. \t  -401.0576828167208 \t -187.23525034036663\n",
            "20     \t [ 3.43898286 -5.04617334  0.40415517 -1.18642334 -3.48086599  4.48375334\n",
            " -4.94502121 -3.23935859]. \t  -505.20135947526063 \t -187.23525034036663\n",
            "21     \t [-3.36061148 -0.4619389  -4.44996125 -1.91215998  1.46988261 -3.81573099\n",
            "  4.96880668  3.47355871]. \t  -453.2621249789785 \t -187.23525034036663\n",
            "22     \t [-2.64620858 -1.3461983  -3.95621385 -3.83538708 -1.93358743  4.20130156\n",
            " -5.11501688 -4.96597285]. \t  -621.4528646278093 \t -187.23525034036663\n",
            "23     \t [ 4.11264029  3.06771073 -0.54346694 -4.52535565 -4.14568668 -2.1151068\n",
            "  3.24170941  1.97363495]. \t  -336.03524197333775 \t -187.23525034036663\n",
            "24     \t [ 3.87716895 -4.71456532 -4.25678468 -4.71066885  3.49788576 -4.09949121\n",
            "  4.94629864 -3.12660821]. \t  -614.0864582516155 \t -187.23525034036663\n",
            "25     \t [ 0.01097714 -4.75973474  4.05304715 -4.06808623  4.73612901 -0.65507116\n",
            "  2.36084583  4.12081067]. \t  -450.3822410817873 \t -187.23525034036663\n",
            "26     \t [-4.1247737   0.8707743   4.7449998   1.18969329  2.69082186  2.7042515\n",
            " -0.92306698 -4.75987941]. \t  -359.0332561652974 \t -187.23525034036663\n",
            "27     \t [ 3.7539052   2.65649462 -3.99373821 -3.86268233  4.70531678  4.23435609\n",
            "  1.12336358  3.3591262 ]. \t  -453.1189348561493 \t -187.23525034036663\n",
            "28     \t [-3.6161308   5.06638324  3.50777465 -4.87385503  2.49950513 -4.83224303\n",
            " -0.33140099  3.95529778]. \t  -493.6090767410049 \t -187.23525034036663\n",
            "29     \t [ 4.57027047  3.84585713  3.65535915 -2.31224556 -3.27848482  3.76604098\n",
            " -1.22781687  0.75418682]. \t  -265.8832994681585 \t -187.23525034036663\n",
            "30     \t [-4.18881836 -4.61468202  4.2253199  -1.97338327 -0.50322153 -3.58558906\n",
            " -1.92769879 -3.85181162]. \t  -352.3823638522697 \t -187.23525034036663\n",
            "31     \t [-4.01741287  4.69215646 -4.87405369  3.88468691 -0.32433668  3.75379162\n",
            " -2.5003732  -0.34545711]. \t  -321.59410669786985 \t -187.23525034036663\n",
            "32     \t [-3.16332904  4.11619186 -0.3555176   2.4537201   4.37874543  2.86893477\n",
            "  2.34076895  3.5732207 ]. \t  -354.1042917541045 \t -187.23525034036663\n",
            "33     \t [-4.90443258  4.97179387  3.78192178  1.4538279  -4.83638223 -3.32021314\n",
            " -4.3013889   0.84857022]. \t  -443.2242401547216 \t -187.23525034036663\n",
            "34     \t [-2.77541148  3.70795244 -0.77717835 -5.09223024  3.86029519  4.13234918\n",
            " -4.71143931  0.65326727]. \t  -476.5009262923606 \t -187.23525034036663\n",
            "35     \t [-3.48916507 -2.27814623 -3.99409699  1.64916104 -3.76015106 -5.03427003\n",
            " -4.90097277 -3.78570014]. \t  -586.8374057305169 \t -187.23525034036663\n",
            "36     \t [-1.41386298 -4.25277637 -4.18783644  4.44629405 -3.71755365  4.43791678\n",
            "  5.00301446 -2.52170938]. \t  -583.2181461552595 \t -187.23525034036663\n",
            "37     \t [-0.77851653  4.94725738 -5.02215078  0.69211491 -3.33309984 -2.96234461\n",
            " -3.45958444  4.39882841]. \t  -473.9181756897471 \t -187.23525034036663\n",
            "38     \t [-1.38555721  0.52353134 -2.36747467  1.03352727  5.10847252 -5.03946372\n",
            " -3.72713157 -3.52729945]. \t  -503.19038665693085 \t -187.23525034036663\n",
            "39     \t [ 4.66733818  3.74085938 -3.08209838 -2.82545447 -2.64799853  2.32930377\n",
            " -3.40203596 -4.15491728]. \t  -396.9399254968581 \t -187.23525034036663\n",
            "40     \t [-0.52145149 -4.40275239  4.77573155  2.49927339 -4.9948001  -4.54528177\n",
            "  4.5899858   1.60579239]. \t  -549.250674064088 \t -187.23525034036663\n",
            "41     \t [ 4.66084663  2.47225038  3.62601153  2.56617877 -3.71837296 -1.11552592\n",
            "  4.58499855  3.78658874]. \t  -438.1919000394597 \t -187.23525034036663\n",
            "42     \t [ 3.74380809 -3.07399699 -3.96447944 -4.10593442 -4.62852992  2.66115671\n",
            "  2.99733184 -3.51799388]. \t  -459.00630673775674 \t -187.23525034036663\n",
            "43     \t [ 4.73253209  3.14635463 -2.06549496  0.15993567  4.2355687  -4.21421608\n",
            "  2.35650123  0.07312213]. \t  -290.26945573733667 \t -187.23525034036663\n",
            "44     \t [-1.90317743  3.07715363  4.98167235 -4.17663357  0.6773467   3.17171657\n",
            "  3.53416841  4.16550174]. \t  -455.6844544850478 \t -187.23525034036663\n",
            "45     \t [ 1.08258363 -3.22278099  2.94659559 -4.7601769  -2.93585789 -5.00419359\n",
            "  4.79998237 -1.1578716 ]. \t  -503.9812123300705 \t -187.23525034036663\n",
            "46     \t [-2.51745832 -4.67354095  0.93708225  2.85954563 -3.92379679  2.29791724\n",
            " -4.40678272  0.56705241]. \t  -332.5379138777783 \t -187.23525034036663\n",
            "47     \t [ 4.89176125 -4.30891543  4.59994148  4.3767263  -0.45529558 -5.1158782\n",
            " -0.32862714  4.31979303]. \t  -509.2747436716945 \t -187.23525034036663\n",
            "48     \t [-4.45889511 -2.08961047  4.55929707 -3.76182895  1.77278515  3.86086326\n",
            "  4.43174314 -1.52675365]. \t  -408.86335769837314 \t -187.23525034036663\n",
            "49     \t [-4.8850703   3.49853245 -3.79580025 -4.48798485 -2.37982529 -3.54572031\n",
            "  0.88674548 -1.06489973]. \t  -290.46265230779704 \t -187.23525034036663\n",
            "50     \t [ 2.33931931  0.22413231 -2.64136972  5.00188797  4.61215452  0.25544379\n",
            " -4.44238276  0.80621875]. \t  -376.6735375649972 \t -187.23525034036663\n",
            "51     \t [ 2.73114969  4.49098442 -4.81523543  3.37227685 -4.98366876 -4.65896413\n",
            "  4.45659475  3.99017282]. \t  -683.666484824371 \t -187.23525034036663\n",
            "52     \t [-3.28818115 -4.4765901  -2.47166253  4.43790773 -2.19559974 -4.82471792\n",
            "  1.49352203  4.9815725 ]. \t  -525.912782498279 \t -187.23525034036663\n",
            "53     \t [ 3.68970864 -4.8786108   3.96324917  1.67930145  4.13311442 -2.84105122\n",
            " -4.06002598 -1.11268626]. \t  -378.7517309392079 \t -187.23525034036663\n",
            "54     \t [-4.95027651  0.12823157 -4.48385891  2.33269826  4.79110472  1.66291743\n",
            " -4.78151791  4.94462997]. \t  -593.6195281450272 \t -187.23525034036663\n",
            "55     \t [ 4.49317363  2.6254389  -1.19208454  3.48906952 -4.27850277 -4.22072036\n",
            " -4.57153933 -1.11189816]. \t  -441.5302444587993 \t -187.23525034036663\n",
            "56     \t [-0.25151338 -4.49276921 -0.31718072  1.67096803  4.08080833  4.40293315\n",
            " -4.24478188 -2.82426546]. \t  -441.42247700357353 \t -187.23525034036663\n",
            "57     \t [-2.82374231  1.42163343 -0.10108016  4.84307404 -4.00304622  1.2494471\n",
            " -2.03291656 -4.79443267]. \t  -408.17824874322116 \t -187.23525034036663\n",
            "58     \t [-1.9135842   3.08322379  2.18244792 -4.01559639 -3.47232149  2.20872892\n",
            " -5.01216762 -1.39569033]. \t  -382.4560022294222 \t -187.23525034036663\n",
            "59     \t [-3.59775319 -2.18091117 -3.34727857 -4.97272615  5.05062858 -3.28301136\n",
            "  4.47440497 -4.63448424]. \t  -659.1642977191141 \t -187.23525034036663\n",
            "60     \t [ 5.09602582 -4.43763189 -1.67720992 -4.01884882 -3.36823438  0.05451396\n",
            " -0.49402558  4.39380339]. \t  -351.29365522521095 \t -187.23525034036663\n",
            "61     \t [ 0.22707226  4.09748342 -3.3307767   0.38480526 -3.4692206  -4.54757695\n",
            " -0.06715175 -4.72519468]. \t  -430.4163013326306 \t -187.23525034036663\n",
            "62     \t [ 4.38918444  3.80525684 -3.36307691  1.11063825 -3.9182859   1.91362192\n",
            "  3.74634598 -2.14727557]. \t  -320.9584390349112 \t -187.23525034036663\n",
            "63     \t [ 5.09725639 -3.86130772  0.91575257 -1.34436444  2.33711256  3.98028439\n",
            "  0.59045637 -2.92459221]. \t  -258.7793348210269 \t -187.23525034036663\n",
            "64     \t [-2.39677349  3.16430114 -4.8392569  -2.97541218 -0.20095726  4.38099144\n",
            "  4.4620886   4.34522718]. \t  -537.2177302838423 \t -187.23525034036663\n",
            "65     \t [ 2.44476921 -4.39175783 -1.61563881  4.58530334  4.16177573 -3.96628024\n",
            "  1.02681853  4.34567452]. \t  -475.9326132150784 \t -187.23525034036663\n",
            "66     \t [ 4.79756415  3.26432906  3.98190539 -3.7209667   4.36166029 -0.59367355\n",
            "  4.65645006 -2.54035551]. \t  -447.91742602892816 \t -187.23525034036663\n",
            "67     \t [-3.40948556 -2.47969782  4.26700485 -3.48102333  5.04467376  1.14335745\n",
            " -4.1823136   2.57592911]. \t  -437.62725925466356 \t -187.23525034036663\n",
            "68     \t [ 4.68875559 -5.02629955  0.90070243  4.07486964  2.59325816  2.7167735\n",
            "  0.35526451  2.93592585]. \t  -289.1147115398168 \t -187.23525034036663\n",
            "69     \t [ 2.73752363  4.58338282  3.1868934  -3.74488042  4.78761418  2.28149775\n",
            " -2.26666038  3.89010396]. \t  -438.9393729073836 \t -187.23525034036663\n",
            "70     \t [ 4.12960519 -4.84889025  3.41617921 -1.58509999 -4.73881849 -4.30934869\n",
            " -4.963391    3.26315142]. \t  -590.4750507799312 \t -187.23525034036663\n",
            "71     \t [ 3.96760989  4.00212018 -2.00246363  4.26035785  1.2303735   4.73492153\n",
            " -4.08320154 -4.56126922]. \t  -557.6431821423058 \t -187.23525034036663\n",
            "72     \t [ 1.11307592  4.78462454  1.38674048  1.50803599 -0.01342799 -1.20843759\n",
            "  3.20147787 -2.47165699]. \t  -191.27179982852002 \t -187.23525034036663\n",
            "73     \t [ 5.07813151 -2.98902207  1.11986308 -1.96132945  2.12918678 -4.51742405\n",
            "  4.97488702  5.05482696]. \t  -585.5720706920308 \t -187.23525034036663\n",
            "74     \t [-1.90304893  1.61446121 -4.13369406  3.433915    2.88889167 -4.43414874\n",
            " -0.36183031  3.51580316]. \t  -366.7658826726901 \t -187.23525034036663\n",
            "75     \t [5.12 5.12 5.12 5.12 5.12 5.12 5.12 5.12]. \t  -943.7184000000001 \t -187.23525034036663\n",
            "76     \t [-4.8713431  -1.0207988  -0.67467645 -3.44036933  4.63837819  1.81652622\n",
            "  1.73830901  4.47564528]. \t  -383.2987725063089 \t -187.23525034036663\n",
            "77     \t [ 5.10907034  4.85226604  4.17761821 -4.14252304 -3.76251412 -3.6083732\n",
            " -2.07414802 -3.94371675]. \t  -497.6335915905818 \t -187.23525034036663\n",
            "78     \t [ 4.90713701 -3.66603338 -4.82484168 -1.08290572  2.1488922   4.67507251\n",
            " -3.51950639  1.27009031]. \t  -379.3276437098469 \t -187.23525034036663\n",
            "79     \t [ 3.55580302 -0.51670293  4.52443587  2.11983442 -4.90346033 -1.18627321\n",
            " -1.38134881 -4.66661129]. \t  -408.8020905323795 \t -187.23525034036663\n",
            "80     \t [ 4.48524481 -4.99173721 -0.9681445   2.30856784  3.8949211  -4.855028\n",
            "  0.88246976 -4.09221257]. \t  -450.7828875053041 \t -187.23525034036663\n",
            "81     \t [-3.68979873  1.02543484  1.98319056  2.46753993 -1.48406482 -5.03934558\n",
            "  2.97522824  4.67624796]. \t  -452.1563025396927 \t -187.23525034036663\n",
            "82     \t [ 4.31966744 -3.32446542 -1.20949263  2.12162666 -4.87651493  4.65736864\n",
            "  1.45242669 -0.47296175]. \t  -328.76231410862266 \t -187.23525034036663\n",
            "83     \t [-3.73624779 -3.88088774 -4.9131433  -3.6084316  -3.90445108  0.27927677\n",
            " -0.11445539  4.42158281]. \t  -401.7686936849068 \t -187.23525034036663\n",
            "84     \t [-2.05018826 -4.82684833 -4.1970134  -3.77723638  3.40201774  3.74582616\n",
            "  4.32155879 -0.24557687]. \t  -433.9844861677893 \t -187.23525034036663\n",
            "85     \t [ 1.31486153  5.03424188  2.34517174 -0.88682751  0.65361511 -3.81364447\n",
            "  4.5964801   4.38822516]. \t  -463.40632071991996 \t -187.23525034036663\n",
            "86     \t [-3.12806544 -0.82545668  4.54959606  4.26777771 -3.24338519 -5.11351605\n",
            "  1.085212   -3.19176284]. \t  -445.3283415801045 \t -187.23525034036663\n",
            "87     \t [-2.2157834   3.95727899  0.44039891  0.85806776 -4.81722526  4.62609894\n",
            " -2.00880423  4.49528137]. \t  -474.09732708026485 \t -187.23525034036663\n",
            "88     \t [ 2.61449818  1.45641082 -5.04265178 -4.2445349   5.08316869 -0.83108771\n",
            " -1.29553254 -4.7407672 ]. \t  -484.3122641173285 \t -187.23525034036663\n",
            "89     \t [-4.80243532  4.67903749 -1.21485134 -4.70304968 -4.96114385 -4.49561347\n",
            "  5.07014795  4.66268334]. \t  -757.9501786556475 \t -187.23525034036663\n",
            "90     \t [ 4.13360024  4.84339695 -4.37693209  4.86162864  4.82334809  3.90482718\n",
            " -0.63075588  1.29631536]. \t  -440.05589949931385 \t -187.23525034036663\n",
            "91     \t [ 4.98596308  3.84402887 -3.95772239 -3.85159599  0.35306019 -1.16789165\n",
            "  4.95947249 -4.16413255]. \t  -480.4444639519978 \t -187.23525034036663\n",
            "92     \t [ 0.70669701  3.13645452  3.70460341 -5.02980489 -3.32262041 -3.3897654\n",
            " -2.49335937  2.2903268 ]. \t  -372.1668731042978 \t -187.23525034036663\n",
            "93     \t [ 4.21208099 -3.38978708 -4.81972602 -3.86215687 -3.88170487 -4.84927627\n",
            "  5.05503041  3.50977172]. \t  -663.92959162228 \t -187.23525034036663\n",
            "94     \t [ 3.44750882  4.64463117 -4.00963725 -5.0225341  -0.65995828  5.01935906\n",
            " -4.65463021  4.18010926]. \t  -648.9525837936898 \t -187.23525034036663\n",
            "95     \t [-4.35743204 -2.36498177 -4.19071491  3.62661249  2.6205157   5.07633986\n",
            "  3.42418793  1.00232938]. \t  -414.5326642848686 \t -187.23525034036663\n",
            "96     \t [-0.65006782 -0.42580625  2.82700894 -4.9743059  -4.65862553  4.42672047\n",
            "  5.05551952 -3.84965958]. \t  -647.2920836343852 \t -187.23525034036663\n",
            "97     \t [-2.20456053 -1.78122189  1.0679689  -4.31989769 -5.01650525 -4.42940998\n",
            "  1.69705164  4.27883333]. \t  -499.44519516785294 \t -187.23525034036663\n",
            "98     \t [ 3.49055166  0.39374849 -4.56749811 -3.51513034  3.83694385 -3.11816129\n",
            "  1.06420104  4.74925864]. \t  -444.82430607237904 \t -187.23525034036663\n",
            "99     \t [ 4.2867213  -4.87738692  4.34595572 -0.06215489 -4.7692856   4.7715501\n",
            "  4.37592773 -4.74036762]. \t  -686.7776857653938 \t -187.23525034036663\n",
            "100    \t [-4.23003719  2.72164651  3.78870086 -4.39507654  0.78233181 -1.63191228\n",
            " -1.59371806 -3.65675373]. \t  -296.8308726780916 \t -187.23525034036663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4xG5dbuuvig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37bc45b-216b-4ab4-e377-917e2387a554"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 10 \n",
        "\n",
        "np.random.seed(run_num_10)\n",
        "surrogate_winner_10 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_10 = dGPGO_stp(surrogate_winner_10, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.57275736 -3.9423289   4.61089653 -0.18236005  3.81413924 -2.94571335\n",
            " -4.70313344 -1.05272872]. \t  -385.9754059539706 \t -352.16802530271787\n",
            "init   \t [-2.7327263   3.49942502 -2.99947679  2.48288802 -1.10434173 -3.25369324\n",
            "  2.49384361 -4.40747949]. \t  -352.16802530271787 \t -352.16802530271787\n",
            "init   \t [ 3.94585297  4.63507865  4.41490877 -0.86598704 -4.82322781  4.93596144\n",
            " -1.64211012  2.11647687]. \t  -437.2230551014739 \t -352.16802530271787\n",
            "init   \t [-1.41437883 -4.7605156   3.63579651  1.61027592  2.72059386  0.55385332\n",
            "  3.94335167  4.13898358]. \t  -382.1028014270721 \t -352.16802530271787\n",
            "init   \t [-5.01328179 -4.35653902 -2.61499689 -3.75495933  2.02675303 -1.04238199\n",
            "  3.92317124 -3.26648309]. \t  -360.16156644546146 \t -352.16802530271787\n",
            "1      \t [-0.69120848 -4.9342136   1.9603237  -0.31036772 -3.80700478  4.00729141\n",
            "  4.28240511 -4.37124102]. \t  -511.13628956580146 \t -352.16802530271787\n",
            "2      \t [-1.64422687  4.1658285   1.59045739 -3.50127712  2.88252444  2.96609181\n",
            " -3.49909343  0.47668923]. \t  \u001b[92m-275.89055024502613\u001b[0m \t -275.89055024502613\n",
            "3      \t [ 0.16275012 -3.26135029 -2.28264585 -1.25926838 -1.15670706  2.88937188\n",
            "  1.34959924  3.7622242 ]. \t  \u001b[92m-226.03899188137302\u001b[0m \t -226.03899188137302\n",
            "4      \t [ 4.70277011  2.46653232 -4.76892847 -1.52775527  5.00334863  4.41305233\n",
            " -0.64089783  2.14291854]. \t  -393.4775126438687 \t -226.03899188137302\n",
            "5      \t [ 3.63148428  2.87570825  2.90332752  3.41280192 -2.62751689 -3.08336467\n",
            "  2.89804663  3.21828326]. \t  -334.81542212986676 \t -226.03899188137302\n",
            "6      \t [ 5.08639972  0.59547281 -4.35771525 -0.91677037 -3.63032957  1.36330471\n",
            "  0.06774278 -0.91962543]. \t  \u001b[92m-170.7574293822782\u001b[0m \t -170.7574293822782\n",
            "7      \t [-0.31072679  3.09772766  1.68779177 -3.16816607  2.11664836  0.65362716\n",
            "  4.76286163 -4.91624941]. \t  -445.0978075513252 \t -170.7574293822782\n",
            "8      \t [-1.71577834  1.6875709  -0.88048116  5.0214985   4.72345603  2.87308778\n",
            " -2.776206   -4.01007736]. \t  -455.5072033515323 \t -170.7574293822782\n",
            "9      \t [ 2.0636308  -3.67355968  1.87631804  4.24375289  1.51876952 -0.50676943\n",
            " -3.93276236  4.7191558 ]. \t  -413.35210184261996 \t -170.7574293822782\n",
            "10     \t [-3.69151167  4.36076234 -5.07374087  1.97011201  1.04682543 -4.92492262\n",
            " -1.11737054  2.77708195]. \t  -365.85914511787394 \t -170.7574293822782\n",
            "11     \t [ 4.03267796 -4.53272386 -4.91481642 -3.08993267 -0.73657925 -4.16957581\n",
            " -2.62510246 -3.72926348]. \t  -434.53296894118955 \t -170.7574293822782\n",
            "12     \t [ 5.1140465  -1.15981285  4.0197045  -4.08344167 -3.54434877 -0.04264564\n",
            "  2.11257085 -5.0750915 ]. \t  -444.131931751421 \t -170.7574293822782\n",
            "13     \t [ 3.32809349  0.59096378  2.41751274 -5.09927265  0.17717635 -2.32308143\n",
            "  4.23007903  2.83256086]. \t  -355.29750211130613 \t -170.7574293822782\n",
            "14     \t [-4.76673174  0.07679634  4.07731074  0.39937844  3.94061254 -4.22345536\n",
            " -1.45262729 -4.04403553]. \t  -403.5171843165749 \t -170.7574293822782\n",
            "15     \t [ 5.09992516 -1.22744486  4.75595255 -3.13010849 -2.88182035 -3.04431592\n",
            " -4.50015649  3.67385386]. \t  -482.93912447657567 \t -170.7574293822782\n",
            "16     \t [ 4.97082645 -2.72142464  1.68484574  4.84761051 -3.21702564  4.58186601\n",
            "  2.83182553  3.65058639]. \t  -482.49099119217504 \t -170.7574293822782\n",
            "17     \t [-0.29901239  4.3013356  -3.20648732 -4.21871175 -2.12171986  3.67061427\n",
            "  3.64225999  4.18586056]. \t  -475.5099467915456 \t -170.7574293822782\n",
            "18     \t [-1.83436216  0.25370281 -0.34286741  4.7548482  -4.95625373  1.49370754\n",
            " -3.34168833 -5.06296037]. \t  -513.726550486559 \t -170.7574293822782\n",
            "19     \t [ 4.41893481  4.50206243 -1.4616215  -0.4067432  -0.04431091  0.18002621\n",
            " -4.53532647 -4.69956488]. \t  -388.01074691406325 \t -170.7574293822782\n",
            "20     \t [ 3.94791592 -1.30339271 -0.19844673 -3.45452034  4.6718752   0.69107787\n",
            " -1.05721847 -3.23710396]. \t  -270.48902551769 \t -170.7574293822782\n",
            "21     \t [ 5.08772924 -0.37036405 -4.73977154 -0.46378082  2.29744209 -3.71705302\n",
            "  2.08650533  4.29055259]. \t  -381.4513641844289 \t -170.7574293822782\n",
            "22     \t [ 4.9264537  -3.54227703 -3.53842143  0.04454811 -4.10088085  1.11335232\n",
            " -4.69460751  5.02696896]. \t  -534.8967682505141 \t -170.7574293822782\n",
            "23     \t [-2.16956164  1.25239449 -0.93590331  1.80974295 -1.81155177  3.09433274\n",
            " -4.94599767  4.41902533]. \t  -424.8929037770257 \t -170.7574293822782\n",
            "24     \t [-2.43511589  0.57195177 -4.58615873  3.81785183 -4.53360004  0.14153966\n",
            "  3.70917752  2.52588746]. \t  -378.2212651035323 \t -170.7574293822782\n",
            "25     \t [-1.19302407  2.17984984  3.71800403 -0.13047817 -2.82280396  4.29635793\n",
            "  5.06331193  0.841209  ]. \t  -388.179772019607 \t -170.7574293822782\n",
            "26     \t [-5.10025545 -1.58832086  1.44395417 -1.3725172  -3.94116704 -2.8622733\n",
            "  5.04042735  4.57369127]. \t  -516.8585655366013 \t -170.7574293822782\n",
            "27     \t [ 0.12825346  5.06759315  3.74778927 -4.92166471 -2.41127942 -2.82330329\n",
            " -3.57216441 -3.90730137]. \t  -478.76249005008737 \t -170.7574293822782\n",
            "28     \t [-5.01341919 -4.84249874 -5.09899608 -0.78889553 -3.91076157  2.79407134\n",
            " -3.50095337 -3.29302525]. \t  -448.3827997683644 \t -170.7574293822782\n",
            "29     \t [-4.55158001  4.6887436  -4.50291908 -3.65442386 -4.94790859 -2.96754307\n",
            "  3.27907764  0.25057578]. \t  -429.9492343588589 \t -170.7574293822782\n",
            "30     \t [ 2.25858453  0.59745427 -2.52265124  3.17673241  3.78002193  0.01979391\n",
            "  4.78455397 -3.93789638]. \t  -421.0180298610798 \t -170.7574293822782\n",
            "31     \t [-3.55727218 -3.82350309  4.54720712 -1.17338271 -0.88045052  4.2189191\n",
            " -2.08266218  1.33922182]. \t  -264.81325133666877 \t -170.7574293822782\n",
            "32     \t [-3.29000281  1.84610113 -0.81055312 -4.70610818  4.32442352 -2.54674946\n",
            "  0.75459223  4.78633418]. \t  -427.8777192390985 \t -170.7574293822782\n",
            "33     \t [-4.12438165 -3.80490868 -1.83902637  0.58361244 -0.07144562 -4.13459516\n",
            " -3.58742042  3.98743327]. \t  -377.3525267329384 \t -170.7574293822782\n",
            "34     \t [-4.13965097 -3.40456413  4.21996318  3.66038119 -4.16341173 -4.1072635\n",
            " -4.96472263  0.24070023]. \t  -508.22710836420873 \t -170.7574293822782\n",
            "35     \t [ 4.18467826 -5.00531967  3.21883845 -2.39999295  3.06724109  4.38374888\n",
            " -1.39645771  4.04639276]. \t  -428.7209887257355 \t -170.7574293822782\n",
            "36     \t [-4.3925937  -0.60596621  2.83143231 -4.00125027 -4.63581636  4.0032745\n",
            " -3.91884693 -4.38240471]. \t  -572.8768151439509 \t -170.7574293822782\n",
            "37     \t [-0.52468362 -4.25559407 -0.07897538  0.74536526 -1.84664263 -4.29610265\n",
            "  3.99189785 -1.76327133]. \t  -302.9456220335915 \t -170.7574293822782\n",
            "38     \t [ 4.79976015 -4.02251057 -3.6864747  -3.95954782  4.27770811 -4.50276304\n",
            "  4.42263861 -3.97922322]. \t  -635.6162916930908 \t -170.7574293822782\n",
            "39     \t [ 4.42296496  0.37859045  4.58246612  5.09834972  1.09622286  4.51546649\n",
            "  4.34462864 -2.81022164]. \t  -510.47344691577894 \t -170.7574293822782\n",
            "40     \t [-4.80906808  4.31505053 -3.5945553   4.4437708   3.66497019  4.91285989\n",
            "  5.07116853  1.37164291]. \t  -585.1630092845159 \t -170.7574293822782\n",
            "41     \t [-3.20126332  4.91836905  5.00534647  4.87061477 -0.74278104 -5.00342255\n",
            " -3.76983158 -1.88164641]. \t  -509.4510263680845 \t -170.7574293822782\n",
            "42     \t [-0.12383594  4.22346178  1.77125805  2.55255167  5.02340067 -2.13493306\n",
            "  2.67504239  1.72660387]. \t  -298.62539607780803 \t -170.7574293822782\n",
            "43     \t [-4.16148078 -4.34110638 -2.54792248 -4.69626626  1.61716173 -2.39368169\n",
            " -4.90452419 -4.10999259]. \t  -513.6748731507865 \t -170.7574293822782\n",
            "44     \t [-4.34466559 -0.88987713  4.23967231  4.82631768 -3.10048194 -2.46752109\n",
            "  2.85863142 -4.73958092]. \t  -489.06605200084095 \t -170.7574293822782\n",
            "45     \t [-0.00636983 -4.12830272 -4.32571333 -4.51313268 -5.11998042 -4.63453695\n",
            "  4.28642657  2.5426204 ]. \t  -611.9727717895099 \t -170.7574293822782\n",
            "46     \t [-4.99611825 -1.91836383  1.03257532  2.87727385  2.93505146  3.25338842\n",
            "  4.05949443 -3.20511425]. \t  -372.7532686742368 \t -170.7574293822782\n",
            "47     \t [-4.04630995 -0.6064237  -4.95536883 -3.84407358  4.72648013  3.91940729\n",
            "  1.65736624 -0.95456412]. \t  -380.2689454028815 \t -170.7574293822782\n",
            "48     \t [-3.66420884  3.48719249 -5.04741034  0.53593081 -2.77148162  3.81459139\n",
            " -1.87591675 -2.67176594]. \t  -322.77769842284033 \t -170.7574293822782\n",
            "49     \t [-2.37329103  2.77555868  1.73603009 -1.38362965 -2.69377835 -4.73329841\n",
            " -2.75295051  2.89452123]. \t  -328.52316031479836 \t -170.7574293822782\n",
            "50     \t [-4.52348277  4.66712174 -3.76739798  4.89540803 -5.06200108 -4.31252129\n",
            " -3.97356291 -1.97468376]. \t  -583.8916258340821 \t -170.7574293822782\n",
            "51     \t [ 1.89337985 -0.43077575 -1.3701705  -1.50470132  5.04516859 -0.08568708\n",
            " -4.99049958  3.510284  ]. \t  -418.8696654378551 \t -170.7574293822782\n",
            "52     \t [-1.61218554 -2.17949359 -4.88945349  2.99633878  4.42026958  3.97315939\n",
            " -3.80539225  4.07798691]. \t  -546.5487555582936 \t -170.7574293822782\n",
            "53     \t [ 3.47773199  4.44921187  4.27276819  1.95486765 -4.71823186 -1.50107628\n",
            "  1.32114814 -4.7471356 ]. \t  -439.06960355316426 \t -170.7574293822782\n",
            "54     \t [ 2.50297266 -0.60817363 -2.62287333  0.15469309 -5.06859405 -4.640027\n",
            " -1.24531472  4.22613772]. \t  -439.10864852507495 \t -170.7574293822782\n",
            "55     \t [ 4.59379843  3.37005576 -0.79194014 -5.09090232 -1.93067441  2.2457797\n",
            " -3.79111151  2.26123079]. \t  -339.77986917272574 \t -170.7574293822782\n",
            "56     \t [-2.41800539  4.97480402 -4.92623218 -4.29761932  5.07250342 -2.73194599\n",
            " -4.27840403 -2.54318239]. \t  -555.333546563032 \t -170.7574293822782\n",
            "57     \t [ 3.33216098  3.00886069  4.82827709  4.39327746  4.31574791  5.05660517\n",
            " -3.39976956 -0.34137822]. \t  -504.7353874803934 \t -170.7574293822782\n",
            "58     \t [ 2.87267394  4.17296822  2.68871577 -0.23267042  4.91611246 -4.56908825\n",
            " -3.82677268 -1.00157319]. \t  -421.61843118322474 \t -170.7574293822782\n",
            "59     \t [ 3.62737562 -2.35838278 -4.94411066  1.74242259 -0.50378307  3.98772355\n",
            " -5.06216226 -4.02428154]. \t  -515.3763937047045 \t -170.7574293822782\n",
            "60     \t [ 3.80981321 -4.71648678 -0.02156658 -3.74856381 -2.86229719  2.92516133\n",
            " -3.02089059 -2.42992508]. \t  -318.63337518843406 \t -170.7574293822782\n",
            "61     \t [ 5.00767469  1.26439074 -2.47646399  2.98244158  0.46328779 -1.78727423\n",
            " -5.05267102  2.02444362]. \t  -313.9852664481642 \t -170.7574293822782\n",
            "62     \t [-4.05351819 -4.47257843 -0.60089827  4.94867929 -2.30942532  4.65159459\n",
            "  0.5999337   0.87384863]. \t  -320.59942285123435 \t -170.7574293822782\n",
            "63     \t [ 3.21893437  4.75474756 -1.93193904 -0.43793828 -3.13571354 -4.34820496\n",
            "  4.75707614 -1.17252942]. \t  -399.5529432382959 \t -170.7574293822782\n",
            "64     \t [ 4.64373843 -2.48917745  3.59065734  2.1567422  -3.67197951 -4.73247178\n",
            " -2.02895458 -1.98938962]. \t  -353.51379120071203 \t -170.7574293822782\n",
            "65     \t [-0.86413844 -3.45762495  4.33741794  2.59691045 -4.897827   -0.25271828\n",
            "  0.85687536  5.09398738]. \t  -441.1284871350823 \t -170.7574293822782\n",
            "66     \t [ 3.19225917 -5.00474448  3.51592727  3.11211588  4.34287793 -3.89939365\n",
            "  2.653807   -3.6056679 ]. \t  -474.9518860303458 \t -170.7574293822782\n",
            "67     \t [ 5.03332339 -2.57567867  4.99140337 -4.58672231  4.70276183 -3.24872089\n",
            " -3.74842328  4.7341508 ]. \t  -649.0541733922037 \t -170.7574293822782\n",
            "68     \t [ 3.00877153 -4.31565021  3.56532966  4.33087424  0.42269073  3.51088451\n",
            " -2.94669364 -4.20406228]. \t  -436.48833145673893 \t -170.7574293822782\n",
            "69     \t [1.83613999 3.40704826 0.78666575 3.12635591 4.77851401 3.90213559\n",
            " 0.64605969 5.05661643]. \t  -480.5479630388518 \t -170.7574293822782\n",
            "70     \t [-0.1200767   4.95730469 -1.4373816   4.22048502 -0.63470807  4.99209591\n",
            "  3.95577406 -5.03552802]. \t  -590.5421102010754 \t -170.7574293822782\n",
            "71     \t [-2.26837406 -4.1948629  -3.14162913  3.76508469  2.88965072 -0.7885907\n",
            " -4.27256791 -2.13162681]. \t  -336.26839915531906 \t -170.7574293822782\n",
            "72     \t [ 0.6077639   4.74067648 -5.10757295 -1.46011331  3.98085636  1.29800886\n",
            "  5.07044591  1.33419948]. \t  -415.65873866426256 \t -170.7574293822782\n",
            "73     \t [-1.88917073  0.68424021 -3.41435923 -4.5331617  -4.06816185  2.22191765\n",
            "  2.18394228 -3.49405128]. \t  -365.10269651110366 \t -170.7574293822782\n",
            "74     \t [-1.14598142 -4.88226926  2.94928139 -3.23924498  2.3938968  -2.10016731\n",
            "  1.20712879 -4.07074806]. \t  -314.9379576930638 \t -170.7574293822782\n",
            "75     \t [ 0.34577816 -2.06544347  4.86666882  4.77834346 -5.04404045  3.84016426\n",
            " -3.43221215  0.5391485 ]. \t  -471.5142374774717 \t -170.7574293822782\n",
            "76     \t [ 2.49380051  1.93339185  0.64353965 -1.69047929 -1.78075593  4.55710687\n",
            "  0.35432321 -4.30830257]. \t  -316.19773914554276 \t -170.7574293822782\n",
            "77     \t [-0.36359847  4.54152503  4.87435913 -3.80015956  5.00247607 -1.91218267\n",
            " -3.60638983  5.02561903]. \t  -610.5856806381007 \t -170.7574293822782\n",
            "78     \t [-4.2958292   4.77266807  3.06527783  5.09688078 -4.89613647  1.84683409\n",
            "  1.06902542  1.01722389]. \t  -352.7146302422869 \t -170.7574293822782\n",
            "79     \t [-2.88719458 -4.46584124 -4.59019607 -4.20563799 -1.7944584   3.09811505\n",
            " -4.29444848  4.64623069]. \t  -557.668629349713 \t -170.7574293822782\n",
            "80     \t [-3.15248807 -4.72153326 -4.87168039 -0.26013999  3.84677781 -4.98354507\n",
            "  3.58450279  2.42787567]. \t  -486.0945242945622 \t -170.7574293822782\n",
            "81     \t [ 1.83447698  3.77021065  4.49602423  2.36227227  2.14256363  0.26135769\n",
            " -0.65912724 -5.09590397]. \t  -348.90808584516424 \t -170.7574293822782\n",
            "82     \t [-1.54144638 -3.62670895  4.75710771 -4.03565137 -1.19122116 -2.10025535\n",
            " -1.78609476  3.44706906]. \t  -312.66893854453633 \t -170.7574293822782\n",
            "83     \t [-4.2236931   4.0458425   4.79828778 -3.8558337  -4.27157236  4.81384722\n",
            " -4.79478471  2.51666229]. \t  -620.9866151152478 \t -170.7574293822782\n",
            "84     \t [ 4.26936313  0.22844123 -3.98104547 -3.80013782  0.69278695  2.18493454\n",
            "  4.14991754 -4.42163141]. \t  -431.6448971674357 \t -170.7574293822782\n",
            "85     \t [-3.37378349 -2.75865721  0.03137884 -2.21155797  3.95089892  4.0157636\n",
            " -3.72004145 -3.26079607]. \t  -402.90914442589377 \t -170.7574293822782\n",
            "86     \t [-3.95080247  0.95464228  4.71331768  3.54004273  4.21050229  4.5682365\n",
            " -4.88272761  3.04306712]. \t  -589.0288430967779 \t -170.7574293822782\n",
            "87     \t [ 3.9667703  -3.33530011 -3.51683354  4.00240995 -3.34375326  1.71119264\n",
            "  3.34133897 -4.96841183]. \t  -488.2704792432202 \t -170.7574293822782\n",
            "88     \t [ 4.37510304 -3.03891151 -2.79102716  2.97998385 -3.19210115 -1.45032839\n",
            "  4.5091283   2.872599  ]. \t  -368.4107354754633 \t -170.7574293822782\n",
            "89     \t [-1.40729842  0.02337728 -3.99161084 -4.77228274  0.13613794 -4.79071537\n",
            " -3.87094251  1.32483063]. \t  -397.6083550138032 \t -170.7574293822782\n",
            "90     \t [-3.74094501  4.02046276  4.99470944 -3.59505863 -2.82541445 -1.97955629\n",
            "  3.74517336 -0.96831994]. \t  -341.9741693370703 \t -170.7574293822782\n",
            "91     \t [ 4.13648573  2.22712144  1.78039593  3.00493687 -4.98355509 -0.30758651\n",
            " -4.03951082  0.61218841]. \t  -314.6271594678498 \t -170.7574293822782\n",
            "92     \t [-1.67147972 -0.65231243  4.52868571 -2.57329899  4.44731394  3.54164086\n",
            "  3.16658719  0.05804034]. \t  -336.02951760745856 \t -170.7574293822782\n",
            "93     \t [ 4.86022731 -0.54681485  1.37043005  4.98505689 -0.88821191 -4.12209452\n",
            "  4.29252998 -3.85258318]. \t  -482.87168073045046 \t -170.7574293822782\n",
            "94     \t [ 4.3444832   1.09154529 -4.94523561 -4.83446784 -3.66087432 -1.83577962\n",
            "  3.40730385  3.99048623]. \t  -484.0022630689408 \t -170.7574293822782\n",
            "95     \t [-2.36061388 -2.45976729 -4.17219018  3.39693327  2.29619477  1.76672987\n",
            "  4.76095333  1.80610258]. \t  -345.9048904439963 \t -170.7574293822782\n",
            "96     \t [ 4.090553    4.57089298  4.9545553  -4.96766957  0.99276422  4.67496699\n",
            "  2.28351548 -1.29691872]. \t  -416.889455983808 \t -170.7574293822782\n",
            "97     \t [-4.88983463 -3.83107486 -4.74299403  2.38639313 -3.53241585 -1.82568266\n",
            "  3.45574993 -3.44110939]. \t  -404.24605333538784 \t -170.7574293822782\n",
            "98     \t [-1.03006122  2.0100074   3.7495572   4.31389316 -4.53970754 -1.99529491\n",
            " -5.10727802  4.83793816]. \t  -622.5246399389522 \t -170.7574293822782\n",
            "99     \t [-2.07830298  1.38775016 -1.43868003 -4.8396599  -2.19785841 -4.5776199\n",
            "  3.99006048 -4.44980755]. \t  -527.8005848107273 \t -170.7574293822782\n",
            "100    \t [ 5.09345027  4.65313815 -4.62077753  0.60007667 -1.38994809  5.00179588\n",
            "  4.76871598 -0.01903777]. \t  -453.69676274165573 \t -170.7574293822782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSj_CQIAuvk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79a8f134-e235-4931-c771-eac852534e78"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 11 \n",
        "\n",
        "np.random.seed(run_num_11)\n",
        "surrogate_winner_11 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_11 = dGPGO_stp(surrogate_winner_11, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 4.92580518  3.28957798  1.4939506  -0.78143474 -3.04833558 -0.08287467\n",
            " -3.70116269 -0.4861846 ]. \t  -199.328627991057 \t -199.328627991057\n",
            "init   \t [-3.95535741 -5.09005324  0.23988403 -3.17469533 -3.66878933 -1.68072836\n",
            "  0.85700801  4.66360642]. \t  -371.33373135563875 \t -199.328627991057\n",
            "init   \t [ 4.97602467 -3.51277821  1.50799121 -0.08432225  3.26374507  1.8591538\n",
            "  1.97393801 -3.23583363]. \t  -241.32944618066992 \t -199.328627991057\n",
            "init   \t [ 3.9633366   0.66475842  1.73406641 -4.83201623 -0.61553705  4.24424807\n",
            " -3.088857    4.67305641]. \t  -470.469518894517 \t -199.328627991057\n",
            "init   \t [-2.63594969  1.40305335 -1.97175977  1.69687477 -1.50561156  4.86926807\n",
            " -1.76401693  2.83643699]. \t  -273.80464224498314 \t -199.328627991057\n",
            "1      \t [ 2.27211609  2.02425273 -1.2017534   4.16140797 -1.81853031 -4.31745003\n",
            "  2.0394904   3.25603062]. \t  -329.2676500747198 \t -199.328627991057\n",
            "2      \t [-3.69480656 -2.83253806  3.2747732   5.02500578 -5.06179771  3.60408914\n",
            "  3.67571491  0.76998055]. \t  -468.2381428914773 \t -199.328627991057\n",
            "3      \t [-4.13596727 -1.0508567   1.75136576 -3.55868316  0.65420774  1.77056145\n",
            " -5.02292824  4.76010165]. \t  -458.0000388046471 \t -199.328627991057\n",
            "4      \t [-3.61752876  2.99909561  0.1754234  -4.49062742 -1.22212296  1.71872834\n",
            "  4.97691018 -5.01665075]. \t  -511.74472953719817 \t -199.328627991057\n",
            "5      \t [-3.33539955 -1.26268526  1.94599964  4.92721403  2.08546241  3.34953724\n",
            " -4.27127122 -2.52482762]. \t  -390.55064122727174 \t -199.328627991057\n",
            "6      \t [ 3.4506638  -2.28972411 -4.72154565 -2.03612565 -4.39132286 -1.00741573\n",
            "  4.50346009  0.21594287]. \t  -350.70398565509174 \t -199.328627991057\n",
            "7      \t [-4.34539115  4.93596182 -1.04713303 -1.61522295  0.44934128 -1.05379523\n",
            "  1.10450307  4.23364103]. \t  -240.93677037409716 \t -199.328627991057\n",
            "8      \t [ 3.61739562 -0.72572306 -4.39576726  0.25459781  2.74571778 -3.88721073\n",
            " -3.12290975  1.68819358]. \t  -291.791700258221 \t -199.328627991057\n",
            "9      \t [ 1.84822825 -1.58025135  4.2708715  -4.70395687 -0.34828434 -3.15872902\n",
            "  1.01027634  1.66955706]. \t  -241.55610557955714 \t -199.328627991057\n",
            "10     \t [-2.15998023  3.85545002 -0.54053289  5.04117111 -2.63495086  1.56342599\n",
            "  4.20047587 -2.265158  ]. \t  -350.8608004276867 \t -199.328627991057\n",
            "11     \t [-1.47895719 -4.26158453 -3.99179746 -0.3229649   4.83917585  2.70663318\n",
            " -2.77916902  0.2142721 ]. \t  -302.2071427677263 \t -199.328627991057\n",
            "12     \t [ 0.77262228  3.35922916 -2.7130201   2.50729784  0.9153661  -4.69397989\n",
            " -2.46807739 -5.00773931]. \t  -450.04301459145205 \t -199.328627991057\n",
            "13     \t [-2.50634688 -0.777872    1.22243455 -3.46787027  3.06002545  4.5751336\n",
            "  4.8119627   3.96201758]. \t  -520.1549046345149 \t -199.328627991057\n",
            "14     \t [ 3.0504194  -4.39355043 -1.97567319  3.61335842 -4.20123562  4.8947748\n",
            " -3.46490789  1.45702944]. \t  -444.8743300822997 \t -199.328627991057\n",
            "15     \t [-1.33533273 -5.04061147 -1.93792846  3.5377157  -2.5941644  -3.61933378\n",
            " -0.29635047 -0.38459549]. \t  -227.97105286685064 \t -199.328627991057\n",
            "16     \t [ 3.9282266   3.10306817 -5.01303718  0.81124716 -0.51778628  4.43171041\n",
            " -4.51383199 -3.22892021]. \t  -457.92415784144885 \t -199.328627991057\n",
            "17     \t [ 4.8960545   3.3017529  -3.18776844  4.37309421 -3.84111719  3.63244037\n",
            "  0.74989536  3.60283937]. \t  -413.4745672253348 \t -199.328627991057\n",
            "18     \t [ 3.23579495  4.81255367 -3.92346266  4.60479345  3.92222871  5.08407494\n",
            "  3.4718759   4.76100216]. \t  -685.5097707267493 \t -199.328627991057\n",
            "19     \t [ 4.38332568  3.95542661  1.00506254 -4.61028775 -2.97097197  3.96177287\n",
            "  4.665975   -0.36993258]. \t  -430.35510528931144 \t -199.328627991057\n",
            "20     \t [-1.61953557 -0.4025592   3.38102512 -3.32051474  3.42004578  1.05154819\n",
            " -1.30751742 -2.69630105]. \t  -216.5898830708943 \t -199.328627991057\n",
            "21     \t [-2.72335001  1.80846448  4.68225647 -0.71121565 -2.78382979 -3.6860239\n",
            " -3.2612813  -2.13435768]. \t  -312.9163374954662 \t -199.328627991057\n",
            "22     \t [ 5.04512834 -4.87504612 -5.07267826  2.78616273  4.4880482  -1.75812555\n",
            "  4.72918448 -4.23618597]. \t  -600.6098643591031 \t -199.328627991057\n",
            "23     \t [ 3.89048929  3.37721285 -5.10183403  4.2231121   4.76516682  4.46839842\n",
            "  2.5181604  -4.07598316]. \t  -598.0024877904641 \t -199.328627991057\n",
            "24     \t [-1.89502117 -3.50854512 -4.63650053 -4.24721432 -3.52703368 -3.69551581\n",
            " -1.93227808 -3.19173316]. \t  -416.6316428292571 \t -199.328627991057\n",
            "25     \t [ 2.99006083 -4.78933663 -1.37834144 -4.85180391 -4.27207983 -5.08830951\n",
            " -3.48096344  4.81227784]. \t  -671.3580162400641 \t -199.328627991057\n",
            "26     \t [ 2.56310428  2.29616516  0.74244643  4.08857666  4.8035438  -1.20997568\n",
            " -3.23577709  4.79762072]. \t  -467.2172710813889 \t -199.328627991057\n",
            "27     \t [-2.52702852  3.96400466  4.75190887  4.42557445  1.99427102 -2.77589181\n",
            "  3.64274785  4.99538704]. \t  -542.5347433234866 \t -199.328627991057\n",
            "28     \t [-0.49996    -3.18559168 -4.5682586  -0.92706615  4.94602105 -2.27980192\n",
            "  2.86101047  5.04060105]. \t  -500.65025509454904 \t -199.328627991057\n",
            "29     \t [ 4.79503013 -0.51000274 -4.96006049 -4.26903427  4.87365683  2.19777744\n",
            " -4.16644613 -2.03600142]. \t  -472.6390698869045 \t -199.328627991057\n",
            "30     \t [-2.86279218 -3.46116575  3.51499835 -3.75647884  4.79280233 -4.76261495\n",
            "  5.06368628 -2.52767238]. \t  -607.2143193092587 \t -199.328627991057\n",
            "31     \t [ 2.36743685  4.30230317  4.33115074 -2.16958914 -3.5387015  -2.87203698\n",
            "  4.7884971  -3.19753453]. \t  -472.13481857973056 \t -199.328627991057\n",
            "32     \t [ 0.68149802  4.96341088 -4.84936281 -4.62101212  4.48186363 -1.02872019\n",
            "  1.13768069 -1.75242087]. \t  -346.1124580495231 \t -199.328627991057\n",
            "33     \t [-0.48816741 -0.48325636  5.11021944 -3.34964062 -3.95239888  5.02075962\n",
            " -2.42726439 -1.97483753]. \t  -425.72537881470237 \t -199.328627991057\n",
            "34     \t [ 4.85042227 -1.06431264  4.0003933   0.70708243 -4.31749916  3.0197601\n",
            "  3.89467357  4.24796647]. \t  -474.2602508626314 \t -199.328627991057\n",
            "35     \t [-0.29653323 -3.39836145  3.6487833   2.91645431  1.16679823 -0.71750854\n",
            "  4.68395716  0.80404901]. \t  -265.79347756491603 \t -199.328627991057\n",
            "36     \t [ 0.73691287  4.83728344  3.59236137  2.52724612  3.7011516   2.38717938\n",
            "  2.51664583 -2.98347072]. \t  -329.8324273540846 \t -199.328627991057\n",
            "37     \t [-3.17189869  0.80127866  2.98196938  3.68557945  4.26785752 -5.0138008\n",
            "  0.77873965 -2.62919296]. \t  -393.8039667985212 \t -199.328627991057\n",
            "38     \t [ 5.06418635  1.79177623 -2.48558938 -3.95460132  5.10035071  1.41710375\n",
            "  4.58771965  4.26050474]. \t  -547.8192487616767 \t -199.328627991057\n",
            "39     \t [-0.43825254 -4.81542366 -1.31180762  4.03521951  4.8193474  -1.70342495\n",
            " -2.65279496 -4.89975325]. \t  -491.7255684368986 \t -199.328627991057\n",
            "40     \t [-3.92729809 -4.89224793 -3.61513481  4.73399242 -2.25956926  3.22784584\n",
            "  1.57131789 -4.73371375]. \t  -476.73203113939195 \t -199.328627991057\n",
            "41     \t [ 3.86443352 -4.77253769  3.98261844  1.39982127  0.11107938 -1.55397422\n",
            " -4.41705181 -3.25353584]. \t  -351.716924443401 \t -199.328627991057\n",
            "42     \t [-4.31959005 -3.51836371  0.14065676  4.37063433  2.94466182 -1.1244994\n",
            " -0.32503071  3.79919076]. \t  -287.0382332960804 \t -199.328627991057\n",
            "43     \t [ 4.62505946 -2.05668122  3.96426856  3.77966672  2.39310816  4.01693951\n",
            " -0.6986398   3.40257247]. \t  -355.62717778791836 \t -199.328627991057\n",
            "44     \t [-0.7454531   4.62515977  2.1157467  -3.41515104  4.82717221 -3.9360811\n",
            " -4.8566068   4.35685141]. \t  -629.8500904688315 \t -199.328627991057\n",
            "45     \t [ 3.84198627  3.66406173 -2.33104007 -4.32229777 -3.27987545 -3.0156033\n",
            "  2.54127739  3.28267814]. \t  -372.40736688531945 \t -199.328627991057\n",
            "46     \t [-1.06965773 -0.1293583  -4.4448289  -3.9248483  -1.88305428  4.01923832\n",
            "  2.86661212  1.63035233]. \t  -315.50665561507026 \t -199.328627991057\n",
            "47     \t [-3.43259662  4.2398073  -5.00238849 -3.99293435 -4.99911911  2.86728332\n",
            " -1.00310622 -3.1138274 ]. \t  -445.4751863820742 \t -199.328627991057\n",
            "48     \t [-4.71543746  3.38210427 -3.50656828  2.32758775  2.40587724  0.46648486\n",
            " -0.34125355 -3.56162838]. \t  -236.21495845630145 \t -199.328627991057\n",
            "49     \t [-4.58716345  1.480839   -4.6606856   4.0111352  -2.26308728 -2.41792975\n",
            " -2.08265964  1.84159924]. \t  -273.13095619385456 \t -199.328627991057\n",
            "50     \t [-2.28715658 -4.40950515 -3.56469343  4.96403235 -2.98980986  5.11656387\n",
            "  2.33950645  4.34118189]. \t  -571.6562276561119 \t -199.328627991057\n",
            "51     \t [ 1.3180904  -0.77287266  4.18583388  4.86763593 -4.83028962  3.94723377\n",
            " -0.91537028 -3.40829161]. \t  -459.21050885647793 \t -199.328627991057\n",
            "52     \t [-4.23153639  1.69036078 -5.04894766 -4.61158401 -3.50494711 -5.03831766\n",
            "  1.31338237  2.02094039]. \t  -443.6425383565135 \t -199.328627991057\n",
            "53     \t [-0.04792754  4.92155106  3.88300939 -1.57304052  4.33876639  3.65621114\n",
            " -4.94209472  2.7734198 ]. \t  -510.41344704227845 \t -199.328627991057\n",
            "54     \t [-5.0476453   0.73437813  2.98108543  1.15693311 -4.866035   -4.21871444\n",
            "  4.86617725 -1.67874315]. \t  -472.0519219010078 \t -199.328627991057\n",
            "55     \t [ 2.93680345 -4.87788146 -4.7259462  -4.32011069  0.99070085 -3.64628053\n",
            "  3.0781831  -4.96153084]. \t  -545.8097930715213 \t -199.328627991057\n",
            "56     \t [ 5.09778776 -1.25296294 -3.27104077 -1.04889635 -4.34832862  4.80593115\n",
            "  2.82338067 -5.0979991 ]. \t  -562.465891192808 \t -199.328627991057\n",
            "57     \t [ 0.65755    -4.20163231 -0.94781967 -4.90808523  4.0035798  -1.59302415\n",
            " -5.11029209  4.11146209]. \t  -548.2002611310315 \t -199.328627991057\n",
            "58     \t [ 3.68101607 -4.41758342  4.12358501  3.7153635  -3.25493146 -3.58129892\n",
            " -2.66420109  4.53461533]. \t  -502.92229744428164 \t -199.328627991057\n",
            "59     \t [ 3.67856434 -2.61169794  2.7677468   3.37586106 -4.61209593 -4.28005707\n",
            "  4.47990149  0.18511901]. \t  -452.7720353264983 \t -199.328627991057\n",
            "60     \t [-4.1831664  -4.69962739 -2.45345295 -2.60067706 -0.60954928 -0.26051761\n",
            "  4.38864394 -3.721319  ]. \t  -354.65631354716885 \t -199.328627991057\n",
            "61     \t [-4.58857456  2.62420178  0.336973    4.59678162  4.98928288  5.00251734\n",
            "  1.71621507  3.59106685]. \t  -518.0897884832625 \t -199.328627991057\n",
            "62     \t [-4.96061865 -4.58279843  5.06892387  2.33768658 -3.92731122  4.74314861\n",
            " -3.57875972 -4.50251435]. \t  -629.4902533990743 \t -199.328627991057\n",
            "63     \t [-4.9671949  -1.81252512 -4.76982228  0.63942876  3.93852272  5.07177316\n",
            "  5.09689867 -1.92128643]. \t  -544.4090794919023 \t -199.328627991057\n",
            "64     \t [ 1.55795267  4.92895741 -3.74983387 -0.58237224 -3.67656466 -4.29316148\n",
            "  2.88313188 -5.04573559]. \t  -534.5926297876912 \t -199.328627991057\n",
            "65     \t [-4.9093221   3.95686232 -0.02820251 -4.37283839 -3.74960752  4.00553274\n",
            "  5.0191188   3.91430908]. \t  -597.3831484747747 \t -199.328627991057\n",
            "66     \t [-1.97089894 -4.33886542  5.09628503  1.15714317 -2.49134684  2.93505084\n",
            " -2.64524228  5.07896486]. \t  -462.87763842549134 \t -199.328627991057\n",
            "67     \t [-0.07221216  4.59420431 -4.72181182 -3.46046891  0.29245907 -0.53580488\n",
            " -3.99411402  3.24662395]. \t  -355.1498891104459 \t -199.328627991057\n",
            "68     \t [ 4.83927129  4.47524839  2.11407664  4.97124031 -4.83518432 -4.39961353\n",
            "  1.71001828 -2.17683522]. \t  -467.14778633015374 \t -199.328627991057\n",
            "69     \t [ 3.93628738  2.28387314  4.90471306 -2.84404673  3.3793907  -0.35326868\n",
            "  4.73834806 -1.74252327]. \t  -369.75444387138 \t -199.328627991057\n",
            "70     \t [-2.30102071  1.85074606 -4.21381328  4.21368235  3.97531673  0.87158396\n",
            " -5.02870112  2.69875185]. \t  -455.2889651790728 \t -199.328627991057\n",
            "71     \t [ 1.37173497 -0.12859842 -1.91565353 -3.34992544  4.94645509  4.88326471\n",
            "  1.61205126 -3.37216302]. \t  -432.3894865259468 \t -199.328627991057\n",
            "72     \t [ 3.93507888 -4.13919322  0.20248714 -4.15420227 -3.39148121  0.96284197\n",
            " -2.71127849 -0.28277236]. \t  -234.07328669446895 \t -199.328627991057\n",
            "73     \t [-0.29416577  1.69991317 -3.98061158  1.26827103  4.22951755 -2.62738251\n",
            "  4.89378019 -1.27989484]. \t  -371.4473595941797 \t -199.328627991057\n",
            "74     \t [ 3.54548219 -2.76775461  3.45451594 -3.01584414 -2.02368427 -2.14430518\n",
            "  3.65969528 -4.87388141]. \t  -431.92978509543707 \t -199.328627991057\n",
            "75     \t [-4.44422084 -1.34696888  3.25022714  0.50783662  4.61205381  3.01643639\n",
            "  4.92451474 -2.37965567]. \t  -432.1098103052422 \t -199.328627991057\n",
            "76     \t [-4.51752737 -1.82538388 -3.30509334 -2.32413678  4.74103193 -2.38083679\n",
            " -1.40026355 -3.48402773]. \t  -338.67946085086896 \t -199.328627991057\n",
            "77     \t [-5.05417641  4.86793299  4.04041669 -5.04784758  1.18245635 -4.70786991\n",
            "  4.40855269 -2.08724937]. \t  -534.7116908928868 \t -199.328627991057\n",
            "78     \t [-0.88475274 -1.44672724 -1.11981207 -4.74375668 -1.84814893  2.19264845\n",
            " -4.69307746 -4.78869402]. \t  -482.29574468862995 \t -199.328627991057\n",
            "79     \t [-4.07685852 -3.38164245 -4.54187263 -1.07956251 -4.69135864  1.62738601\n",
            " -3.48573144  0.96783136]. \t  -324.5198154933763 \t -199.328627991057\n",
            "80     \t [-5.01818263  3.93864192 -4.57365193  1.37551622 -4.71845458 -2.85730101\n",
            "  5.03911384 -0.58850068]. \t  -467.35443762698117 \t -199.328627991057\n",
            "81     \t [ 4.31694725 -3.24441126 -3.29464292  4.18302629 -3.46756926 -3.22766225\n",
            " -5.03638701  0.89452659]. \t  -448.8280793246695 \t -199.328627991057\n",
            "82     \t [-3.52274043 -3.78960095  4.30369055 -1.37048576  3.76706798 -4.68446457\n",
            " -2.40472713  2.10902481]. \t  -382.8921619591491 \t -199.328627991057\n",
            "83     \t [-4.63394919  4.92403512  3.11228545  4.60814157  3.45181985 -0.08732553\n",
            " -3.71960295  1.57914226]. \t  -360.38326653656276 \t -199.328627991057\n",
            "84     \t [ 4.98802972 -4.0675513  -3.43265459  2.56341585  4.38764734  3.6424538\n",
            "  2.30139891  2.14068584]. \t  -369.201553147284 \t -199.328627991057\n",
            "85     \t [-2.09470079 -0.71657491  1.14006769  5.00490037 -2.65092011 -3.79728072\n",
            " -4.85286442  3.63577344]. \t  -501.76587656070427 \t -199.328627991057\n",
            "86     \t [-4.36908724 -3.71932923 -1.212631    3.22930837  4.14289084 -4.00955603\n",
            "  4.72488964 -3.5149234 ]. \t  -530.2674217677549 \t -199.328627991057\n",
            "87     \t [-0.7876028  -4.46186686  4.60943253 -2.56253154 -3.04458504  4.83855455\n",
            "  4.08584805 -2.78271286]. \t  -496.067864210867 \t -199.328627991057\n",
            "88     \t [ 4.62599086  2.90880094  4.41899054  4.87352886 -2.5742978  -1.47608408\n",
            " -4.62694697 -4.42963565]. \t  -544.951438449151 \t -199.328627991057\n",
            "89     \t [ 0.16177764  5.06797231  3.86208038  4.72287534  0.82009942  4.99913037\n",
            " -4.14888952 -4.10512366]. \t  -593.9840134716571 \t -199.328627991057\n",
            "90     \t [-3.8441509  -1.98164048  4.33894873 -4.72259207  3.58257778 -3.98946437\n",
            "  4.78340529  5.00859464]. \t  -688.8464236653256 \t -199.328627991057\n",
            "91     \t [-4.99341815  4.10658878 -0.34706294  0.88504877 -4.46951777 -4.89403\n",
            " -4.3197357   3.84749959]. \t  -554.7959346504094 \t -199.328627991057\n",
            "92     \t [ 0.46634479  2.33770282  4.7069223   4.79691084 -1.96314626  4.55796177\n",
            "  1.01902094  2.72813558]. \t  -380.38437857274397 \t -199.328627991057\n",
            "93     \t [ 3.30195461  0.55881671  3.47545839  4.35880897  5.03838936 -1.92634469\n",
            " -4.06726759 -2.91623242]. \t  -456.786364048751 \t -199.328627991057\n",
            "94     \t [-5.03511421  3.73471705 -2.48985186 -4.75631493  3.49637016  1.63705748\n",
            " -2.53459389 -0.66049884]. \t  -287.99880915444777 \t -199.328627991057\n",
            "95     \t [ 4.92402351  3.19870291  3.85278409 -4.71096053  3.91646076  4.91870375\n",
            " -3.42445189 -2.59368856]. \t  -535.7749020633737 \t -199.328627991057\n",
            "96     \t [ 4.00002825 -3.74362233 -3.5140134  -1.22110918 -2.197142    4.65806607\n",
            "  1.9616144   4.63369525]. \t  -440.06615647712147 \t -199.328627991057\n",
            "97     \t [-1.22302412  0.96560133  4.88977098 -0.67601958 -4.99908438  1.67564525\n",
            "  4.80328834  0.58525985]. \t  -382.96038047414737 \t -199.328627991057\n",
            "98     \t [ 0.35838685  3.92682533 -0.17203346  2.81383548 -3.72717933  2.29428368\n",
            "  4.98275137  4.36957513]. \t  -490.30974973224085 \t -199.328627991057\n",
            "99     \t [-0.28640763 -0.93481241 -2.15367088  2.61440666 -4.90974167 -1.86021791\n",
            "  3.68390729 -4.7923636 ]. \t  -463.10764304883935 \t -199.328627991057\n",
            "100    \t [ 4.84814656 -4.03917657 -0.31536803  4.74894902 -1.73659944 -0.74991812\n",
            "  0.73548452 -2.15267157]. \t  -205.95453041913333 \t -199.328627991057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l98Nt7Tguvna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d196b4f1-b20c-431a-b625-dcf2c079def7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 12\n",
        "\n",
        "np.random.seed(run_num_12)\n",
        "surrogate_winner_12 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_12 = dGPGO_stp(surrogate_winner_12, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [-3.15884083  1.25039382 -0.63766795  2.9220719   2.86695228 -2.32865172\n",
            " -2.28900603  3.0911711 ]. \t  -235.23146270653385 \t -119.61569010596395\n",
            "init   \t [ 4.69134698  3.84955018 -1.45595116  0.01019009  1.87866046  2.17806876\n",
            " -1.32863227  0.62664895]. \t  -119.61569010596395 \t -119.61569010596395\n",
            "init   \t [ 0.03157161 -4.97901108  2.79374461  3.91824579 -1.38356752  1.18165687\n",
            " -4.34809609 -1.34324218]. \t  -299.1328730459762 \t -119.61569010596395\n",
            "init   \t [ 4.43535464  1.55011219 -1.0526456   2.95659666 -1.87559811  0.6973302\n",
            "  3.77986447 -0.65358414]. \t  -186.70407348837227 \t -119.61569010596395\n",
            "init   \t [ 3.09399185 -3.64782772  2.09163234  2.0949126  -2.87956884  4.35064452\n",
            " -0.59247866  4.19139542]. \t  -364.893303476081 \t -119.61569010596395\n",
            "1      \t [-1.20506929 -4.56833346 -0.4951203   4.93572855 -3.85082675 -3.89753961\n",
            "  2.44247609  0.89398921]. \t  -354.81541396698753 \t -119.61569010596395\n",
            "2      \t [-1.19817157  1.61883881  3.90363347  0.74416726 -0.73686572 -2.47420996\n",
            "  3.740359   -3.3456302 ]. \t  -281.53017033038316 \t -119.61569010596395\n",
            "3      \t [ 3.98687432  4.28177271 -3.55957822 -3.90159355 -5.01705068 -2.25444364\n",
            " -3.86127758 -0.4338066 ]. \t  -413.68468359333997 \t -119.61569010596395\n",
            "4      \t [-3.45596926  0.84828548  0.72109252 -3.53263982 -2.57142474 -3.09193817\n",
            " -2.18327808  0.79584861]. \t  -193.71653768066736 \t -119.61569010596395\n",
            "5      \t [-5.0392713   1.28642045  0.78649942 -2.71140686  1.90152795  4.89785969\n",
            "  1.88625656 -3.78633376]. \t  -361.57621590745845 \t -119.61569010596395\n",
            "6      \t [ 3.75494823 -1.68635637  4.60295502 -3.67510687 -2.35349499 -0.3069475\n",
            " -2.23949311  0.06908573]. \t  -200.7799410908595 \t -119.61569010596395\n",
            "7      \t [-4.48115473  4.69856248 -2.58544488  0.7519363  -3.12662811 -0.47930587\n",
            " -3.5600688  -4.48065658]. \t  -386.1352526901647 \t -119.61569010596395\n",
            "8      \t [ 3.95142065 -4.2020785   4.3605733   3.29550753  3.11075961 -4.71147969\n",
            "  5.0613613   4.20250379]. \t  -653.5962551692268 \t -119.61569010596395\n",
            "9      \t [-2.63884853 -4.74823966 -4.72667146  0.53968904  2.55330202 -0.94153795\n",
            " -3.71978724 -4.39722242]. \t  -409.70236539299896 \t -119.61569010596395\n",
            "10     \t [ 0.11049625 -4.12457898 -4.75350988 -2.64771547  2.36530464  1.49068986\n",
            "  1.76019576  4.37052337]. \t  -345.6717578822854 \t -119.61569010596395\n",
            "11     \t [-4.99777619  3.54079835 -4.03410463 -2.99367945  5.08636374  3.52706711\n",
            " -4.2657072  -5.00335179]. \t  -666.361473147168 \t -119.61569010596395\n",
            "12     \t [ 2.57344092  2.83832724  3.28730555 -1.70570834 -4.5453893   5.02259256\n",
            "  1.2803518   0.43941179]. \t  -334.47290106270987 \t -119.61569010596395\n",
            "13     \t [ 4.70411276 -0.75159137 -2.94105951 -3.29936842  2.97210015 -0.85414404\n",
            " -4.09206189 -4.83236498]. \t  -445.3243496177385 \t -119.61569010596395\n",
            "14     \t [-0.97422921 -4.34173854 -3.47203652 -3.40092589 -3.9888922   1.66929\n",
            " -4.99905804  0.02447271]. \t  -392.29515003700726 \t -119.61569010596395\n",
            "15     \t [ 2.97386747  4.43169212  1.62960814 -4.86649615  1.54198998  2.16946987\n",
            "  4.58313404  2.62475744]. \t  -393.1005840537307 \t -119.61569010596395\n",
            "16     \t [ 2.41797118 -4.07927895  5.00574416 -4.24357528  4.15780498 -0.50754755\n",
            "  4.66423605  3.35380286]. \t  -516.5837390836538 \t -119.61569010596395\n",
            "17     \t [-2.70571653  0.18187063 -3.41277004 -3.69883974 -4.49865405  2.46788799\n",
            "  3.03978136  2.53694823]. \t  -350.9567298008808 \t -119.61569010596395\n",
            "18     \t [-5.05511133  0.29818975 -4.7771362   2.10253213  1.84100063 -5.03393887\n",
            "  2.23816984 -3.10161592]. \t  -392.89330087974093 \t -119.61569010596395\n",
            "19     \t [ 1.95059339  1.26951562  4.99764993  2.0940138  -3.60492296 -4.38919314\n",
            " -2.58198387  3.93715957]. \t  -450.74097861711755 \t -119.61569010596395\n",
            "20     \t [ 3.82984112 -3.89324659 -0.05577154 -2.10118563  3.43989218  1.3903408\n",
            "  3.41553454 -4.35662397]. \t  -366.9167652418358 \t -119.61569010596395\n",
            "21     \t [-3.3457227   2.99220584  4.07970672  5.04320906  3.9459153   2.27190385\n",
            " -1.71752197 -2.65150847]. \t  -366.481973301136 \t -119.61569010596395\n",
            "22     \t [ 4.61016658  3.11002809  4.34915504 -4.40976207 -4.65282099 -3.9028902\n",
            "  3.75225906  3.78424266]. \t  -587.8867439908552 \t -119.61569010596395\n",
            "23     \t [-2.82228706  3.65754107 -1.97827262  4.75386533 -4.49766022 -2.69018542\n",
            "  3.51535733 -0.52640632]. \t  -370.14645911604305 \t -119.61569010596395\n",
            "24     \t [-2.35044614 -2.84174276  2.8733477  -2.34996109  4.05936535 -3.20836466\n",
            " -1.87230457 -5.03493579]. \t  -440.030406369399 \t -119.61569010596395\n",
            "25     \t [ 1.92964896 -1.48309132  4.24977763  4.08644197  4.29365995  1.33551495\n",
            " -3.05364694  4.52591321]. \t  -461.124146558007 \t -119.61569010596395\n",
            "26     \t [ 1.72630286 -4.6153764  -1.03035037 -3.23871896 -4.36614688 -4.87675375\n",
            " -0.26063009 -2.94506482]. \t  -398.600894566865 \t -119.61569010596395\n",
            "27     \t [-4.06957082  3.07781431 -5.04564028 -4.63868102  4.5238576   0.09073362\n",
            " -3.8670247   3.63065877]. \t  -510.45865064750575 \t -119.61569010596395\n",
            "28     \t [ 3.83137915  2.46955649 -4.13832376  4.76995056 -4.05417157  3.24549292\n",
            " -3.47381587  2.05103212]. \t  -432.77028943630796 \t -119.61569010596395\n",
            "29     \t [-1.39729661  0.19546049  4.54888908  0.5855098  -1.12615819  1.24724811\n",
            "  4.72873859  4.1976417 ]. \t  -378.64058590963066 \t -119.61569010596395\n",
            "30     \t [-3.64624569  0.88087825  2.87683548 -0.68924864  0.11849335  4.50279018\n",
            " -3.24100156  3.70214501]. \t  -346.4723820638224 \t -119.61569010596395\n",
            "31     \t [ 4.84174076 -1.19773913 -3.75090117  4.48049533  3.71926069 -2.9171414\n",
            " -2.01470603  1.29478388]. \t  -310.86653309339977 \t -119.61569010596395\n",
            "32     \t [-1.71054385 -2.26988071 -3.84949177  1.35449998 -3.61428877  4.6747766\n",
            "  3.15041929 -5.10071556]. \t  -539.0761385472767 \t -119.61569010596395\n",
            "33     \t [ 1.8834428  -4.6809482   3.67236598 -1.12200019 -4.11002182  3.92939418\n",
            "  3.01146371 -4.32536341]. \t  -483.1190353889024 \t -119.61569010596395\n",
            "34     \t [ 2.46208015  2.29132827 -2.78893865 -1.96583515  3.39804356 -4.07539581\n",
            " -4.28998758  5.10469006]. \t  -550.0322222297834 \t -119.61569010596395\n",
            "35     \t [ 2.80091491  4.36015037 -3.35002506 -3.78823741 -0.69698845  3.51848653\n",
            "  4.97971017 -3.81971059]. \t  -503.94947617114946 \t -119.61569010596395\n",
            "36     \t [ 0.95990142  4.66457408 -2.0143922  -1.9278767   5.04893011 -4.53595111\n",
            "  3.73184023 -2.60254524]. \t  -474.05802076939636 \t -119.61569010596395\n",
            "37     \t [-4.48367138 -0.98065441  0.11186851  2.87936772  4.88641542  3.75055453\n",
            "  3.61210251  2.33336099]. \t  -393.90006647006726 \t -119.61569010596395\n",
            "38     \t [ 4.30231968  1.68756926 -5.06903193 -3.48716313  0.18004593 -3.20891317\n",
            "  4.08290134  4.28549517]. \t  -475.49137531798385 \t -119.61569010596395\n",
            "39     \t [ 4.37821812  2.48711013  3.63548237  4.14793758  4.57404222 -1.49107511\n",
            "  2.839356   -2.55087572]. \t  -366.45044202902403 \t -119.61569010596395\n",
            "40     \t [ 3.56763792  0.5267745   2.99097387  3.72707716 -2.48304059 -4.57801922\n",
            " -2.32119373 -4.46944237]. \t  -449.7851301516464 \t -119.61569010596395\n",
            "41     \t [-0.72103581 -0.99835086 -4.46391908  0.42828713 -4.95082816 -5.05593696\n",
            " -4.27913877  3.8083239 ]. \t  -583.1590775874686 \t -119.61569010596395\n",
            "42     \t [ 2.0682184   4.59924497  4.02620849 -1.37049671  3.09480257  3.21792028\n",
            "  3.68424997 -4.70641401]. \t  -484.96537330683316 \t -119.61569010596395\n",
            "43     \t [ 2.22803175 -4.16754412 -3.04889601  4.37096374  2.89699673  4.75640396\n",
            "  3.11483934  2.00041812]. \t  -421.64174186730605 \t -119.61569010596395\n",
            "44     \t [-4.74720999 -3.25772344  3.22870983  3.50994356 -3.19353347  1.31955348\n",
            "  2.93681098 -3.00724618]. \t  -318.47689972810065 \t -119.61569010596395\n",
            "45     \t [ 1.24081508 -1.85203076 -2.17046763  4.77888927  3.67097261  4.27575133\n",
            " -4.99927674 -2.60695549]. \t  -520.2751848016615 \t -119.61569010596395\n",
            "46     \t [ 3.15946657  1.64832252 -0.58385775  0.79347578 -4.55493756  2.22942204\n",
            " -2.98152304 -5.0995205 ]. \t  -422.78369772643555 \t -119.61569010596395\n",
            "47     \t [ 4.46855363 -4.78382361  1.7854193   1.24476391  0.22022937 -4.62949084\n",
            " -4.55922853  1.02749197]. \t  -364.2863119009646 \t -119.61569010596395\n",
            "48     \t [-3.2245506  -2.29506515  0.14023952 -1.29044037  4.92258152 -3.87073495\n",
            "  3.62204169  3.37508692]. \t  -421.67089580687815 \t -119.61569010596395\n",
            "49     \t [-0.44299183 -4.78279835 -3.69538404 -2.56093578  2.8351107  -4.19358677\n",
            "  2.88576386 -4.77600091]. \t  -499.62891202993876 \t -119.61569010596395\n",
            "50     \t [-4.51568559 -0.19406643 -1.86142755 -4.71917188  3.07326595  4.92750195\n",
            "  1.29434449  3.59627559]. \t  -428.0431596732616 \t -119.61569010596395\n",
            "51     \t [-4.23277972 -4.39974622  1.23515499 -4.1672549  -2.5456321  -2.61185632\n",
            "  4.57012308 -2.80632225]. \t  -413.21054144283096 \t -119.61569010596395\n",
            "52     \t [ 0.65819264 -2.51017991  4.47842633  2.19009505  4.53801068  5.0797163\n",
            "  2.57737238 -3.37179835]. \t  -487.6311387951034 \t -119.61569010596395\n",
            "53     \t [ 4.77164335 -3.88525784 -4.84288273  4.01068858 -3.41139859 -0.43613578\n",
            " -1.5659469  -2.20115346]. \t  -302.91749644460594 \t -119.61569010596395\n",
            "54     \t [ 3.78648834 -3.55233041 -2.63887367 -4.53639844 -4.38354071  0.40934378\n",
            " -0.70381297  4.9248389 ]. \t  -437.36449632212475 \t -119.61569010596395\n",
            "55     \t [-3.36030955  5.10856094 -4.09453793  4.63728946  2.6693993  -5.11224703\n",
            " -4.43568796 -2.44286531]. \t  -577.7069097769839 \t -119.61569010596395\n",
            "56     \t [-4.62621079  3.87306767  5.07571633 -4.2188297   4.91712771  0.3141455\n",
            " -4.16237232  1.4245051 ]. \t  -458.8798882399757 \t -119.61569010596395\n",
            "57     \t [-4.30624923 -4.55269616  4.37381265 -1.21020311  4.18521375 -5.10099895\n",
            " -4.94046059  2.71428111]. \t  -596.7437882935039 \t -119.61569010596395\n",
            "58     \t [-3.81177002 -0.66139121  2.96564681 -1.4534853  -3.96926886  2.98455326\n",
            " -4.03097292 -2.86976192]. \t  -362.0864203018644 \t -119.61569010596395\n",
            "59     \t [ 0.09241027  3.00868008 -4.92550294  4.83961506  1.81342378  0.961695\n",
            "  2.71537456 -4.72602061]. \t  -436.868737029425 \t -119.61569010596395\n",
            "60     \t [-5.02346666 -0.52297791 -4.87789073  3.20261283 -1.42344025  4.17663861\n",
            "  3.61392591  4.52366249]. \t  -508.1187719220025 \t -119.61569010596395\n",
            "61     \t [-0.23610693 -0.91272494  3.65118629 -3.31263261  4.06467639  4.26742964\n",
            " -3.40206656 -1.90824315]. \t  -387.632742227511 \t -119.61569010596395\n",
            "62     \t [ 2.74367317  5.01735282  1.90483865 -0.67643117  4.54220228 -0.46738349\n",
            " -4.95815007 -4.45002029]. \t  -505.5637700637708 \t -119.61569010596395\n",
            "63     \t [-3.97088283 -4.30446706 -1.54559502  2.94068085 -3.40274731  4.00509336\n",
            " -4.10671267  2.95997463]. \t  -436.8670954614753 \t -119.61569010596395\n",
            "64     \t [-4.53200576 -2.67959392 -2.2096105   2.11276682 -4.88486764 -2.77741747\n",
            " -2.10035401 -2.27622723]. \t  -305.32583130218103 \t -119.61569010596395\n",
            "65     \t [-5.12       -5.12       -5.12       -5.12       -4.02383523 -2.87116455\n",
            " -5.12       -5.12      ]. \t  -785.7777650405125 \t -119.61569010596395\n",
            "66     \t [ 4.44892565 -0.2278374   4.40008412  0.22297904  4.97489768 -4.73189944\n",
            " -2.13254622  2.94739057]. \t  -437.6022900379078 \t -119.61569010596395\n",
            "67     \t [-4.72440408 -4.41460636 -5.00114584  4.43075531  4.87083582  1.13094855\n",
            " -2.2405986   4.60595881]. \t  -546.0185448365146 \t -119.61569010596395\n",
            "68     \t [ 3.78487742  4.98972385  0.481944    4.55776435 -2.93549453 -3.80301745\n",
            "  1.70013163  4.96113889]. \t  -494.9092755361714 \t -119.61569010596395\n",
            "69     \t [-4.33920325  2.51516461  4.66185162 -4.9107985  -4.36844387  2.89886854\n",
            "  4.22627442  4.07914164]. \t  -597.125222431643 \t -119.61569010596395\n",
            "70     \t [ 1.6160734   4.63270981  5.06254787 -3.79646524 -5.0743171   1.38629089\n",
            " -4.96884793  0.2717629 ]. \t  -493.76773336263716 \t -119.61569010596395\n",
            "71     \t [ 0.67793811 -2.44496901 -3.74400764  0.26794304 -3.391259   -2.71959827\n",
            "  4.97027329  4.82487692]. \t  -515.796591472618 \t -119.61569010596395\n",
            "72     \t [ 2.24394005 -0.17666715 -4.75752806 -2.97469181  1.25026184  3.90628338\n",
            " -5.01615873  4.89791671]. \t  -575.8147905488195 \t -119.61569010596395\n",
            "73     \t [-3.93572627  4.08426114  3.79613761  2.83307373  3.92861389 -4.52860186\n",
            "  4.9663368   4.46529825]. \t  -656.5715889840426 \t -119.61569010596395\n",
            "74     \t [ 4.72578001 -2.62894282 -4.78952392  3.83997745 -4.18149776 -2.59176541\n",
            " -1.15019874  4.86398051]. \t  -490.2112586825202 \t -119.61569010596395\n",
            "75     \t [ 4.67771392  4.26800424  4.78339224 -3.9619595   3.75654532 -3.85451788\n",
            "  3.33782145  1.07267528]. \t  -436.63817884920206 \t -119.61569010596395\n",
            "76     \t [-3.62652782  0.74417735  2.68928604  4.82201462  0.72272469 -4.6618883\n",
            " -3.49804149 -4.43069306]. \t  -504.6766397189092 \t -119.61569010596395\n",
            "77     \t [ 5.0184805  -3.93614794  3.75213617 -3.4200375   3.67896605  0.96578256\n",
            " -2.84439584  5.11214554]. \t  -484.17061297169914 \t -119.61569010596395\n",
            "78     \t [-4.38206922  0.52436981 -5.10297271 -4.30498091 -1.70936803 -4.09730557\n",
            "  4.00605116 -0.87554915]. \t  -405.81387699680704 \t -119.61569010596395\n",
            "79     \t [-3.54176325  5.002253   -2.80441001  0.35305916 -4.75344077  4.94456036\n",
            " -0.71920205 -0.38268097]. \t  -351.1422839182854 \t -119.61569010596395\n",
            "80     \t [-3.86033848  4.10998557  4.80559952  4.47500729 -4.23646103  2.97412019\n",
            " -3.00604804 -5.09475643]. \t  -611.7872715252103 \t -119.61569010596395\n",
            "81     \t [-0.05357049  5.04918771  2.21908522  4.73997839  4.92616665  3.13666882\n",
            "  3.20497659  3.97175211]. \t  -534.1034414197843 \t -119.61569010596395\n",
            "82     \t [ 0.97045141 -4.49988583  3.69915034 -1.60870082 -3.62710184 -4.12509493\n",
            "  4.31985297  2.02958031]. \t  -424.3017994013185 \t -119.61569010596395\n",
            "83     \t [-3.9866777   4.97939484 -3.84436975 -1.22795742  2.45660879 -3.69683673\n",
            "  2.36535185  3.7967259 ]. \t  -382.51088915564253 \t -119.61569010596395\n",
            "84     \t [-3.85553631  4.72627596  2.99315318  4.79942074 -4.84377881  2.94694943\n",
            "  1.77595423  0.90687423]. \t  -376.6306770980302 \t -119.61569010596395\n",
            "85     \t [-3.99504014 -5.01734193  4.1852742  -4.30777797 -2.59269713  1.088131\n",
            "  2.0526925   4.93140311]. \t  -457.8444355993787 \t -119.61569010596395\n",
            "86     \t [-4.9619588  -1.93995357 -1.77562744 -5.11517945  0.4733362   4.82019142\n",
            " -4.56434509 -1.41832191]. \t  -448.71820302914887 \t -119.61569010596395\n",
            "87     \t [ 1.69824639  3.9831586  -0.75077614  3.85272421 -1.11972245 -5.00316038\n",
            " -4.31250666  0.49705538]. \t  -384.2991586992364 \t -119.61569010596395\n",
            "88     \t [-1.85612917  5.09008836 -1.94966128 -4.95066184 -4.44479187  0.459964\n",
            " -2.71862417  3.44345949]. \t  -411.3489652944251 \t -119.61569010596395\n",
            "89     \t [-0.02265727  2.12835794 -4.73503187 -0.99690268 -0.23258619 -1.23447279\n",
            " -0.11477681 -2.05947465]. \t  -123.7348915678179 \t -119.61569010596395\n",
            "90     \t [-4.0152742   2.79181603  5.04478382  1.74349743 -4.33865644 -1.74563945\n",
            " -3.39483208  1.02862102]. \t  -321.761489701928 \t -119.61569010596395\n",
            "91     \t [ 3.49474037  4.97827785  1.64849388 -1.27448164 -2.41430653 -2.78901184\n",
            "  1.28839994 -4.34330338]. \t  -314.7795186867602 \t -119.61569010596395\n",
            "92     \t [-4.93645624 -4.89484584  4.24354743 -0.80568561  2.3531588   0.80487461\n",
            " -0.02805967 -0.6154516 ]. \t  -163.516710595607 \t -119.61569010596395\n",
            "93     \t [-3.15609097  4.96823673  1.77036866 -3.20669021  3.979861   -4.80556595\n",
            " -1.60394114 -3.27105661]. \t  -431.225859490812 \t -119.61569010596395\n",
            "94     \t [ 3.505327   -4.58444055 -4.02804024 -3.56585909  3.51421139 -4.28683108\n",
            "  3.60329879  2.95864892]. \t  -486.7833311251705 \t -119.61569010596395\n",
            "95     \t [-2.76914632 -3.8107073  -0.02848639  4.93530422  4.79941337 -1.30794698\n",
            "  1.70111565 -4.9668936 ]. \t  -477.1955091815802 \t -119.61569010596395\n",
            "96     \t [-4.93675484  1.95487792  4.02003756 -1.90560612 -4.7538452   3.0902354\n",
            "  5.02904314 -4.91364181]. \t  -635.504569193655 \t -119.61569010596395\n",
            "97     \t [ 2.30879785  3.59851668 -4.8372335   4.72141309  2.47642824  1.75586163\n",
            " -0.66993638  4.47287917]. \t  -402.9493142330459 \t -119.61569010596395\n",
            "98     \t [-1.23360823 -2.41410251 -3.49372164 -4.89012411  3.4326156   3.88842442\n",
            "  0.94313942 -3.77589509]. \t  -415.3680688158261 \t -119.61569010596395\n",
            "99     \t [-3.1352625   3.17898472  1.9632741  -4.04640598  1.40703026 -2.65407518\n",
            "  4.08454274  1.75706516]. \t  -300.74471036457425 \t -119.61569010596395\n",
            "100    \t [-4.90088949  2.26813973 -4.54897616  3.53757272  3.14232514  4.65457124\n",
            " -2.87222143 -0.064251  ]. \t  -383.58672255724764 \t -119.61569010596395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bpn-kmNuvqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f5faf37-00e7-4712-cebe-4532bf85ba52"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 13 \n",
        "\n",
        "np.random.seed(run_num_13)\n",
        "surrogate_winner_13 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_13 = dGPGO_stp(surrogate_winner_13, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.64499773 -0.88472932  1.72137019 -2.76537936  3.15062616  1.40102108\n",
            " -3.35673495 -2.45364871]. \t  -232.19635670005127 \t -232.19635670005127\n",
            "init   \t [ 4.2528767  -0.38076919 -3.88924462  3.90026757 -2.80351794  3.18914893\n",
            " -0.55419986 -4.1015814 ]. \t  -361.66026260752943 \t -232.19635670005127\n",
            "init   \t [ 4.03920839  1.42981319  4.41130989  3.62084556  3.50044048  0.52242587\n",
            " -2.97909353  3.81846156]. \t  -372.8981589252669 \t -232.19635670005127\n",
            "init   \t [ 3.80219612  2.41871092 -4.9313143   3.0755089  -1.83535427 -0.17449361\n",
            "  2.95749718 -3.92317458]. \t  -338.32885418149425 \t -232.19635670005127\n",
            "init   \t [-2.96300648  4.98598367  2.14768853 -4.67440231  5.05344835  0.67544515\n",
            "  0.4351207  -3.01593487]. \t  -364.25359293813665 \t -232.19635670005127\n",
            "1      \t [ 4.80987456 -3.46820678  2.58262962 -0.28783238 -2.10049364 -0.26524925\n",
            " -0.19379678  0.5408205 ]. \t  \u001b[92m-92.61843242301455\u001b[0m \t -92.61843242301455\n",
            "2      \t [ 1.9543379   2.0934188  -0.94255966 -1.7405562   0.06261135 -4.8506502\n",
            "  3.45925627  2.40979353]. \t  -298.78210274080607 \t -92.61843242301455\n",
            "3      \t [-1.23180471 -1.94356327 -0.00824713  3.53112869  1.31592708 -0.83747358\n",
            "  3.10154041 -0.85011777]. \t  -144.93286693920209 \t -92.61843242301455\n",
            "4      \t [-4.91891332  2.39222815  0.66520204 -5.07281597 -2.662127   -4.54556063\n",
            " -0.74287733  3.83282923]. \t  -420.69758378886286 \t -92.61843242301455\n",
            "5      \t [-4.68664521  1.70175046 -4.74500152 -1.92806708 -3.9301831   3.56090291\n",
            "  3.61185688 -1.52682267]. \t  -373.45138510689867 \t -92.61843242301455\n",
            "6      \t [-3.39709501 -0.75844229 -0.28988583  0.01269954  5.05807698  4.77249476\n",
            "  1.49596497  2.4718132 ]. \t  -342.06868330388926 \t -92.61843242301455\n",
            "7      \t [ 0.87100098 -4.00755327 -3.96578597 -0.51069636  4.17465138 -0.66640695\n",
            " -1.78421168  2.04307565]. \t  -226.5855315178249 \t -92.61843242301455\n",
            "8      \t [-2.71667671  0.56608726 -4.65744745  1.81555904  3.58337557  2.71601054\n",
            " -3.16488768 -4.56282399]. \t  -431.4153928965887 \t -92.61843242301455\n",
            "9      \t [-1.3712379   4.43342592 -2.34034832  1.15808497  4.58355243 -2.713087\n",
            " -3.48221122  4.82787565]. \t  -483.5446007985546 \t -92.61843242301455\n",
            "10     \t [ 0.55827506  3.56701067  0.69739806 -0.52643575 -3.62135875  4.01257402\n",
            " -0.926893   -1.26369398]. \t  -209.29142411765054 \t -92.61843242301455\n",
            "11     \t [-1.89491308 -4.51478497  4.8018905  -4.00887009  3.78203209 -1.54266179\n",
            " -1.54626734  3.62613613]. \t  -385.5410476967967 \t -92.61843242301455\n",
            "12     \t [-0.840906    1.30182738 -5.0702606  -0.94428849 -2.46262426 -3.16901837\n",
            " -4.33961646  0.33145866]. \t  -308.0694545114881 \t -92.61843242301455\n",
            "13     \t [ 4.94977688 -4.68277233 -1.33876797  2.9531957  -4.10073761 -4.88543912\n",
            " -2.67575729 -5.09230559]. \t  -593.4750491246078 \t -92.61843242301455\n",
            "14     \t [-0.41652349 -4.53064711 -2.60332916 -0.78582198 -2.75861119  3.95062035\n",
            "  4.17043797  3.20451546]. \t  -399.6223614635618 \t -92.61843242301455\n",
            "15     \t [-3.85042816  1.41046709  4.97664168  3.54390539  0.94631968 -4.40687672\n",
            " -4.11689158  2.38758432]. \t  -428.58960482287085 \t -92.61843242301455\n",
            "16     \t [-4.97110094  0.28733202  1.26531007  0.26463666 -3.92034586 -2.39177041\n",
            "  3.54721064 -4.13560123]. \t  -366.03357915512356 \t -92.61843242301455\n",
            "17     \t [-1.52923252  5.01275791  1.0647277   3.50806822  1.16152142 -3.55665886\n",
            " -1.72954469 -4.92838138]. \t  -403.11655327638175 \t -92.61843242301455\n",
            "18     \t [-4.33877585 -0.46941136  4.99224157  0.49748171  3.59173759 -1.7542332\n",
            "  4.08379355  4.95281274]. \t  -490.97436975790083 \t -92.61843242301455\n",
            "19     \t [-3.73376113  5.03449665 -4.32840815 -4.09388753 -3.98862082  3.37635413\n",
            " -3.9107503   2.1874418 ]. \t  -481.15936912416277 \t -92.61843242301455\n",
            "20     \t [ 2.82550194  4.30172305 -4.85986814 -3.65740813  4.81102314 -0.4028026\n",
            "  0.91879643  1.83147431]. \t  -318.80150673084734 \t -92.61843242301455\n",
            "21     \t [-4.26256236  2.20180573 -3.88250667  4.64725405 -1.34128031  3.1159942\n",
            "  4.88884876  4.04286214]. \t  -524.7902427223751 \t -92.61843242301455\n",
            "22     \t [-5.05271706 -0.12297266 -2.30991725  4.56291704 -0.61207719  3.08474988\n",
            " -4.7505473   2.73525112]. \t  -401.64216554510983 \t -92.61843242301455\n",
            "23     \t [ 4.60016117  2.22713599  3.39182879  1.68411498 -3.71306196  3.02448148\n",
            "  2.99429091  5.07815886]. \t  -469.82133361308735 \t -92.61843242301455\n",
            "24     \t [-3.51622025  2.7878051   4.94519657  1.00932252 -2.72751197  2.55209856\n",
            " -3.06292225  4.76732545]. \t  -429.1127885687665 \t -92.61843242301455\n",
            "25     \t [ 2.18662094 -2.51984916  3.14713159 -2.2904857   4.58521492 -3.47418769\n",
            "  4.2545655  -2.33035305]. \t  -415.87371746266956 \t -92.61843242301455\n",
            "26     \t [-4.82713991  4.31556158  3.57451684  1.02807856  4.76765004  4.49767619\n",
            " -5.04359259  1.79163218]. \t  -541.8800486402343 \t -92.61843242301455\n",
            "27     \t [ 0.4918736  -1.94243695  3.5488762   3.53371228 -0.71843494  4.94266523\n",
            " -4.88361499  0.20132935]. \t  -411.9526353161534 \t -92.61843242301455\n",
            "28     \t [-3.73436106 -2.20069437  4.28945961  4.42947074 -2.16596262  5.0130147\n",
            "  3.14453925 -4.56517613]. \t  -567.4932226167601 \t -92.61843242301455\n",
            "29     \t [-5.0427563  -3.60236437 -4.96747242  3.38474474 -3.01540418 -4.51308738\n",
            "  2.78751734  3.64133549]. \t  -499.3742056866213 \t -92.61843242301455\n",
            "30     \t [-3.76374974  4.38076595  0.9145554   2.5771412   1.60653691  3.63818437\n",
            "  4.86189429 -3.74321405]. \t  -451.5063357579247 \t -92.61843242301455\n",
            "31     \t [ 4.80710109  4.10516183 -0.52497993  2.39339049  4.75739497 -4.69847083\n",
            "  3.48621229 -1.77503867]. \t  -436.45264628953385 \t -92.61843242301455\n",
            "32     \t [ 3.33783062  4.93745923  4.47993774  2.46764311 -2.26135487 -3.61573921\n",
            "  1.13495538 -0.35794829]. \t  -258.51662825198724 \t -92.61843242301455\n",
            "33     \t [-3.87541175 -2.64513059  3.53825255 -0.77138561 -2.14612718 -3.99941327\n",
            " -3.81740971 -4.42601441]. \t  -446.6763792600495 \t -92.61843242301455\n",
            "34     \t [ 4.85112157 -2.9857809  -2.03470338 -2.7653437   0.86687476  3.5236601\n",
            "  4.13566978 -2.16002103]. \t  -319.6780328685416 \t -92.61843242301455\n",
            "35     \t [ 0.67709118 -4.8834838  -3.16793499 -3.51046037 -1.61465402 -3.58015242\n",
            "  3.37232634 -2.87379612]. \t  -363.17425857590695 \t -92.61843242301455\n",
            "36     \t [-4.60314753 -3.19706748  2.87981804  2.67582955 -4.56568783 -1.74633567\n",
            " -0.21209673  2.15431485]. \t  -255.12089049617902 \t -92.61843242301455\n",
            "37     \t [ 3.12414101 -3.58892378 -1.38372145  4.83718558 -2.24756551 -2.56274114\n",
            "  5.09447137  4.45859528]. \t  -540.2301686720825 \t -92.61843242301455\n",
            "38     \t [ 1.94368598  4.2380031  -2.56693994 -4.52771341 -2.27091136  1.09734306\n",
            "  4.28452569 -4.47121423]. \t  -462.9118916509084 \t -92.61843242301455\n",
            "39     \t [ 4.96343756  4.6546108   4.94568224 -0.06057723  4.30159176 -0.02167316\n",
            "  3.50469649  5.02145178]. \t  -521.5818958000601 \t -92.61843242301455\n",
            "40     \t [ 3.86843195 -0.56716622 -4.08702598  4.89471024  2.48271805 -3.48356451\n",
            " -4.89231991  3.44230826]. \t  -527.5224406389641 \t -92.61843242301455\n",
            "41     \t [ 2.64948241  4.59544157  4.62797023  2.39208447  4.65314622  2.62507581\n",
            " -2.52267118 -4.7399992 ]. \t  -510.291336759286 \t -92.61843242301455\n",
            "42     \t [ 2.54582891 -0.42326894 -3.11562811 -4.49784626 -2.53935795  4.35649709\n",
            " -1.56398902  4.5878801 ]. \t  -448.51113533973273 \t -92.61843242301455\n",
            "43     \t [-3.49028759  5.07874872 -1.15029519  4.49447964 -3.57735694 -2.477073\n",
            " -1.90749483  3.60927502]. \t  -379.02785266328635 \t -92.61843242301455\n",
            "44     \t [ 2.35582968 -3.34325758 -1.43999351 -4.48706305 -4.02928414  2.50853308\n",
            " -1.89526593 -4.58742575]. \t  -427.0924731539116 \t -92.61843242301455\n",
            "45     \t [-4.96241112  1.10498931  2.3813469  -3.14278266 -1.03508142  4.55082411\n",
            " -4.72116054 -4.6173221 ]. \t  -539.7880705554594 \t -92.61843242301455\n",
            "46     \t [-4.26216974  3.1199414  -4.69527322 -2.1598054   3.59931625 -4.15317722\n",
            "  3.31644849 -4.3976605 ]. \t  -522.4057989995198 \t -92.61843242301455\n",
            "47     \t [-4.03047509 -4.57002261 -4.487526   -4.13445721  0.14544792 -4.69513142\n",
            " -2.0769922   2.9386918 ]. \t  -418.4594390654112 \t -92.61843242301455\n",
            "48     \t [ 3.63841114  0.82087112  0.37256985  3.51073985 -4.65919368 -4.75648946\n",
            " -2.46232349  4.8549445 ]. \t  -539.5940246964117 \t -92.61843242301455\n",
            "49     \t [ 5.00426307  1.1119729  -3.37955451 -4.43495877  2.55047005 -4.49496902\n",
            " -3.36593951 -4.85980025]. \t  -562.4562956222826 \t -92.61843242301455\n",
            "50     \t [ 4.97708192  3.1107325   2.87071391 -2.61507969  3.8303971   5.00653072\n",
            "  4.42977486 -0.35253763]. \t  -458.3086279540523 \t -92.61843242301455\n",
            "51     \t [ 4.91033143 -4.88630636 -1.93852949  2.26229884  3.18570315 -4.33569068\n",
            "  3.54347312 -1.87427055]. \t  -383.138345894241 \t -92.61843242301455\n",
            "52     \t [ 0.11270982  3.39728065  4.96980343 -4.71350792 -2.99866585 -3.31136832\n",
            "  0.48911572 -2.87343856]. \t  -364.5399789818049 \t -92.61843242301455\n",
            "53     \t [ 2.12570339  4.66928862 -4.51380381  4.29043818 -2.12254692  4.34355835\n",
            " -2.79475856  5.01880831]. \t  -574.785086022746 \t -92.61843242301455\n",
            "54     \t [-4.82246305 -3.59121501 -4.98490757  4.1728901  -5.04068701 -4.86281821\n",
            " -1.55870872 -3.99512309]. \t  -606.869469106404 \t -92.61843242301455\n",
            "55     \t [-3.0716737   4.20534023 -4.76344519  4.21932486  2.25271723 -4.14975449\n",
            "  4.85259188  1.21490263]. \t  -489.4248829488794 \t -92.61843242301455\n",
            "56     \t [-1.25341662  2.91470367 -4.95731826 -1.0520786  -4.34625742 -4.64180979\n",
            "  4.51715051 -4.08747168]. \t  -596.934633686558 \t -92.61843242301455\n",
            "57     \t [-0.35348666 -2.43556142  4.92481408  4.77974326 -0.82160893  4.39838465\n",
            "  3.88252101  3.93742199]. \t  -525.1280878506846 \t -92.61843242301455\n",
            "58     \t [-2.72008974  4.61709076  2.57852363 -3.4590608  -3.83556539  0.58372743\n",
            "  4.0666419   3.27572795]. \t  -395.0491202566681 \t -92.61843242301455\n",
            "59     \t [ 4.18084883 -5.11080688 -1.93003793  4.90671476  3.95886384  4.07453722\n",
            "  0.37338911  2.73079379]. \t  -415.80667848151194 \t -92.61843242301455\n",
            "60     \t [-4.02099366  3.4613703   4.08402904 -5.09538916 -3.43066095  5.00030952\n",
            "  2.45337609 -3.80511133]. \t  -560.8505031616601 \t -92.61843242301455\n",
            "61     \t [-3.85642589 -4.57569917  1.80710642 -5.08565046 -3.19584651  1.96558737\n",
            "  4.89146035 -4.24855894]. \t  -556.133421427285 \t -92.61843242301455\n",
            "62     \t [ 3.22220477 -3.32216101  4.39852512  2.82125038  1.81435174  3.89770603\n",
            "  4.65357569 -3.31849768]. \t  -469.6368126341058 \t -92.61843242301455\n",
            "63     \t [-4.44907916 -4.24505096 -3.91123477 -3.96654291  2.52609044  4.19315109\n",
            "  4.12467687 -3.40120218]. \t  -513.6992300618283 \t -92.61843242301455\n",
            "64     \t [ 1.54662259 -1.43675591  4.97130574  5.02181487 -0.27697306 -2.99720862\n",
            "  5.09492169 -4.88737327]. \t  -608.6187737495043 \t -92.61843242301455\n",
            "65     \t [ 4.37746924  4.86772166 -2.53298729  4.84658055  3.65829935  5.07536259\n",
            "  2.32833693 -0.5388517 ]. \t  -441.4996734077333 \t -92.61843242301455\n",
            "66     \t [ 2.0581079  -0.47802048  3.07493697  5.0108699   4.05998279 -3.91349824\n",
            " -1.48606888 -2.29378863]. \t  -365.35444299187145 \t -92.61843242301455\n",
            "67     \t [ 4.93845397 -1.65699281  4.19950831  4.88909926 -4.67352297  1.98632256\n",
            " -4.44690253  4.69708585]. \t  -626.2078217398936 \t -92.61843242301455\n",
            "68     \t [-3.1888032  -4.84704341  1.67964566  4.51847162  2.38545627 -2.14529472\n",
            " -1.8194      4.39301995]. \t  -380.91235030897644 \t -92.61843242301455\n",
            "69     \t [-3.99195268 -0.04010095  4.29443065 -5.02318533  4.58695589 -4.87310243\n",
            "  4.46792371 -4.93330615]. \t  -754.3149275072705 \t -92.61843242301455\n",
            "70     \t [ 0.27173585  4.54771921  2.27652972 -4.90574711  2.15397225 -2.29717312\n",
            " -1.16406224  3.81805442]. \t  -334.216132609718 \t -92.61843242301455\n",
            "71     \t [ 5.07897127 -3.79808938 -1.62953612  2.69500199  5.11127207  4.12992008\n",
            " -3.96565249 -4.86233536]. \t  -623.8514112353189 \t -92.61843242301455\n",
            "72     \t [ 0.10119342 -4.78163087  0.1683013  -1.87207383 -4.32278722 -4.98756756\n",
            " -1.72014512  4.81014918]. \t  -508.34184846902826 \t -92.61843242301455\n",
            "73     \t [ 5.09670379  4.49851062 -3.37445601 -2.39509834 -1.70634459 -0.85747185\n",
            " -1.6868553   4.88554872]. \t  -353.39309256119486 \t -92.61843242301455\n",
            "74     \t [ 5.08333225 -3.46622955  4.64221939 -4.01341436  2.86603389  4.56258497\n",
            "  0.71700286  4.88429915]. \t  -539.3738616508365 \t -92.61843242301455\n",
            "75     \t [-0.12066018 -3.62770667  3.99292696 -3.63189406 -4.84514024 -2.16780656\n",
            "  4.19189835  4.1492087 ]. \t  -533.2328617300483 \t -92.61843242301455\n",
            "76     \t [ 4.71665424 -0.86863011  5.11672343 -4.41955445 -2.17555638 -4.697194\n",
            " -4.48874783 -1.99682876]. \t  -509.4159022675261 \t -92.61843242301455\n",
            "77     \t [-3.75062449  4.38062628 -0.14976612 -1.56319929  4.57772838 -4.78700602\n",
            "  1.64695526  1.1854799 ]. \t  -334.78929227480126 \t -92.61843242301455\n",
            "78     \t [-4.83606342  2.78324019  3.30957235  4.22685542 -3.25219332 -4.09720687\n",
            "  4.94002881  5.02594295]. \t  -669.7198399742448 \t -92.61843242301455\n",
            "79     \t [ 2.85758938 -3.41795705 -4.56957836  3.51542439 -1.12910369  4.20327201\n",
            " -4.78917415  4.99144702]. \t  -615.8556708797253 \t -92.61843242301455\n",
            "80     \t [-4.01279078  0.03213072  4.45720424  2.81416652  1.94279322  0.64917849\n",
            " -3.33016736 -3.65994432]. \t  -313.5751623249911 \t -92.61843242301455\n",
            "81     \t [ 4.14784277  0.78029072 -0.65828665  3.37035988  3.26156621  1.19838254\n",
            "  3.59828048  4.16843474]. \t  -356.60557044263055 \t -92.61843242301455\n",
            "82     \t [-1.212309    2.25507918 -4.51155785 -1.79561457  2.98469277  3.84465713\n",
            "  3.24879146 -1.3536531 ]. \t  -307.3716676075315 \t -92.61843242301455\n",
            "83     \t [ 0.79044185  3.4934753   3.58944753 -1.3430726  -4.48383902 -4.30918319\n",
            " -4.82492839  2.41891929]. \t  -492.60863621804447 \t -92.61843242301455\n",
            "84     \t [-3.18753101 -1.2991842   3.50120491 -5.11990782  0.30335266  4.41192209\n",
            "  5.0943729   1.31509635]. \t  -467.919971939962 \t -92.61843242301455\n",
            "85     \t [ 4.42134143  4.63587038  2.99437202 -3.59591519  2.86454753 -1.96478826\n",
            "  2.49026463 -3.32642653]. \t  -337.2734168783354 \t -92.61843242301455\n",
            "86     \t [-3.7686316  -4.08028438  0.30472636 -4.5852498  -1.54312407  1.44566465\n",
            " -3.91871594  2.36510598]. \t  -308.5666527346285 \t -92.61843242301455\n",
            "87     \t [ 1.70276445 -4.99323249  3.18222707 -1.88866398 -4.98627304  4.95796381\n",
            " -0.38696595  2.32935002]. \t  -413.6702581944995 \t -92.61843242301455\n",
            "88     \t [-4.09189198 -0.18654448 -2.48905477 -4.58630932  5.04443729  0.54018495\n",
            " -2.07458042 -0.51962251]. \t  -280.80607566921685 \t -92.61843242301455\n",
            "89     \t [-5.04138172 -4.43827868 -2.32392822  1.37088656 -0.6644134  -1.7298789\n",
            " -3.45796017 -0.22151133]. \t  -192.78848192949562 \t -92.61843242301455\n",
            "90     \t [-4.21957442  3.08500986 -1.7567479  -4.38375352 -3.83669666 -3.48452774\n",
            " -3.85082997 -4.61198955]. \t  -543.3856781681242 \t -92.61843242301455\n",
            "91     \t [ 2.95379749  4.6566892   4.99785558 -4.37479472  3.05158958  4.0033307\n",
            " -2.98697352 -0.93991282]. \t  -415.827923838069 \t -92.61843242301455\n",
            "92     \t [ 0.58565475  4.2538263   2.01322639  2.94239074 -5.08453338 -0.25256215\n",
            "  4.16543081 -4.84490896]. \t  -522.2089257026767 \t -92.61843242301455\n",
            "93     \t [ 0.86825269 -3.12354442 -5.03312383 -4.59165906  3.9389689   5.03634616\n",
            "  1.15690077  5.1130313 ]. \t  -628.8769841971148 \t -92.61843242301455\n",
            "94     \t [ 3.69160771 -1.35127353  1.94429149 -3.76741628  4.27842944 -5.10559468\n",
            " -4.87645056  4.54404814]. \t  -664.9671104634215 \t -92.61843242301455\n",
            "95     \t [ 2.42741081 -4.01905033  4.80958453 -4.58191994 -4.34666801 -2.81469096\n",
            "  2.77125814 -4.37915474]. \t  -540.7477231250703 \t -92.61843242301455\n",
            "96     \t [-0.92348131 -2.28316879 -4.30188505  4.14541733 -5.07429078 -0.54002033\n",
            " -3.64341996  3.13792458]. \t  -437.7211163678877 \t -92.61843242301455\n",
            "97     \t [ 0.60928452 -3.06015968  0.43918302 -4.07308911  3.83911202 -1.13496975\n",
            "  4.07369629  4.50102349]. \t  -445.70080043556527 \t -92.61843242301455\n",
            "98     \t [-4.56857825  3.25012006 -0.11245167 -2.70862528  3.63264239 -3.80502193\n",
            " -4.92541003 -4.94357405]. \t  -589.5616559038592 \t -92.61843242301455\n",
            "99     \t [ 5.03100616 -1.74266424 -4.91132831 -3.98385117  3.21254429  3.11441159\n",
            " -4.38718064 -2.42975674]. \t  -458.9932797103463 \t -92.61843242301455\n",
            "100    \t [-1.11521759  3.03030847 -3.53157455  4.20054981 -4.53105915  3.39002099\n",
            "  1.38833555 -0.36146839]. \t  -313.74732397507563 \t -92.61843242301455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NdFRXtPuvsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c14867d-6ec2-47a7-a552-bdd276c76e70"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 14 \n",
        "\n",
        "np.random.seed(run_num_14)\n",
        "surrogate_winner_14 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_14 = dGPGO_stp(surrogate_winner_14, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.51092275  0.07321281  0.29021573  4.05796049  2.04790979  2.19440232\n",
            "  2.22554503 -2.83832871]. \t  -217.39677218415014 \t -198.56808439329558\n",
            "init   \t [-3.32641768 -0.44194316  4.39028154 -5.01876852 -4.19919673  3.58605074\n",
            " -0.14724036  3.85879646]. \t  -454.63061220313574 \t -198.56808439329558\n",
            "init   \t [-1.97290047 -1.14723281  0.83400441 -3.95584327  2.74309309 -1.91932375\n",
            "  1.49514711 -4.78516309]. \t  -329.7622575537801 \t -198.56808439329558\n",
            "init   \t [-3.41610929 -0.71369695 -2.78726175  4.77498845  4.14657954  3.74438823\n",
            " -4.79065311  3.06685697]. \t  -533.1877350004759 \t -198.56808439329558\n",
            "init   \t [ 4.15903244  2.08827731 -2.76774455 -0.90689946  4.90131417 -1.75056937\n",
            "  0.97821769  0.36706653]. \t  -198.56808439329558 \t -198.56808439329558\n",
            "1      \t [-0.39837742 -2.80781146  4.30646237  1.1348259  -2.86625872 -4.7177257\n",
            "  0.49038928 -4.19648802]. \t  -393.90076362444245 \t -198.56808439329558\n",
            "2      \t [-3.3024737   5.10871425  3.24433055  2.77252492  0.85991499 -4.37501503\n",
            " -2.86441234 -5.03829863]. \t  -504.48031361068513 \t -198.56808439329558\n",
            "3      \t [-0.92980509 -4.30040138 -3.26462577  4.56516629 -2.88753534  1.82743128\n",
            " -2.1548711   4.26696946]. \t  -393.0746043478335 \t -198.56808439329558\n",
            "4      \t [ 2.32062105 -0.52987264  2.02545308 -0.92383367  4.85772433  2.28575073\n",
            "  4.80523785  3.39209458]. \t  -424.6860545060965 \t -198.56808439329558\n",
            "5      \t [ 0.71655335  4.17073226  3.03368005 -1.0941701  -1.60702984 -0.63587468\n",
            " -4.90966839  1.84839075]. \t  -279.1069775244053 \t -198.56808439329558\n",
            "6      \t [-0.47349161  3.6595987  -0.69062425  3.93976687  0.73643447 -4.52423201\n",
            " -1.53249713  3.04543123]. \t  -306.68823053687424 \t -198.56808439329558\n",
            "7      \t [ 4.14560453  3.03997511  4.23321166  2.36746366  4.13170572 -0.78379134\n",
            " -4.31339484 -4.43490623]. \t  -488.4744193304546 \t -198.56808439329558\n",
            "8      \t [-4.18234718 -3.41118532 -1.39464019 -4.40453038 -1.54514429  4.70888545\n",
            " -1.62965924 -0.62283023]. \t  -290.8718456993242 \t -198.56808439329558\n",
            "9      \t [-2.79957127 -0.61738371 -1.12935732 -1.90533877 -3.50637933 -4.32236621\n",
            "  3.19170153  2.22992574]. \t  -311.6073704877181 \t -198.56808439329558\n",
            "10     \t [ 4.91003047 -1.27290419 -0.01365945 -1.36670559 -0.93914058  2.71328594\n",
            " -2.80968763  3.24767996]. \t  -223.04232741815372 \t -198.56808439329558\n",
            "11     \t [ 4.39589311 -2.63238916 -0.42473053  3.46291368 -4.45295055 -3.32856296\n",
            "  0.33154344  4.17398955]. \t  -387.45788340642343 \t -198.56808439329558\n",
            "12     \t [ 0.51678178 -4.33656642  2.73729925  1.0888125   2.57474767 -4.72429433\n",
            " -2.77048929  2.03866427]. \t  -319.1380140723573 \t -198.56808439329558\n",
            "13     \t [ 4.68999352 -2.56646581 -1.42631916  4.98999437  1.40086326  4.43799073\n",
            "  2.70869882  4.99435532]. \t  -519.7675524460608 \t -198.56808439329558\n",
            "14     \t [-5.0813497  -3.80916529 -3.50982139  2.9269636   4.86626155 -1.05002318\n",
            "  4.28438133 -1.59529189]. \t  -399.9335101190047 \t -198.56808439329558\n",
            "15     \t [ 1.45625919  0.75649195 -3.95074262 -3.47785896 -2.63466893  1.78976944\n",
            "  2.29339112 -2.58523433]. \t  -242.6844064277512 \t -198.56808439329558\n",
            "16     \t [-4.49733451 -4.73888146  1.81382287  3.90473182 -4.84998229  2.13747287\n",
            "  0.490395   -4.36007836]. \t  -434.7876553505125 \t -198.56808439329558\n",
            "17     \t [-4.56511652  3.65748618 -4.01686554 -0.15714328  0.31582471  2.74261894\n",
            " -0.91060344 -3.17805393]. \t  -228.33418410161798 \t -198.56808439329558\n",
            "18     \t [-3.85735527  3.18906896 -0.85910231  2.98121302  4.27714709  4.06490072\n",
            "  4.72665737  3.35759877]. \t  -510.17143472854997 \t -198.56808439329558\n",
            "19     \t [-1.78020824 -4.65452266 -3.12300073 -4.59486091  0.84018186 -1.94795777\n",
            " -3.03817405  2.88643428]. \t  -317.77099000967837 \t -198.56808439329558\n",
            "20     \t [-0.65337491  4.46688102 -4.24303594 -4.81431165 -3.41392968 -4.71532122\n",
            " -4.72758178  4.10636899]. \t  -670.081840532171 \t -198.56808439329558\n",
            "21     \t [ 2.04928035  0.60166887  3.25461067  5.05169102 -4.03670088  4.67005131\n",
            " -3.2430316  -2.61289746]. \t  -479.34904958247716 \t -198.56808439329558\n",
            "22     \t [-2.28514021 -2.06316352  3.7138088  -3.85634823  3.46884547  4.80647995\n",
            " -3.85442187  3.54437277]. \t  -517.8725113613343 \t -198.56808439329558\n",
            "23     \t [ 3.31163667 -4.0136498  -5.05745775  1.58273225 -3.38626979  1.64858821\n",
            " -2.25168731 -3.31960808]. \t  -327.22973580022676 \t -198.56808439329558\n",
            "24     \t [ 0.62428676 -2.08540816 -3.23796858  3.13776215  1.3155054  -4.96549859\n",
            " -0.94704286 -3.60238025]. \t  -346.6083243065781 \t -198.56808439329558\n",
            "25     \t [-4.24152013  2.66029194  3.87378355 -3.72621478  2.49739226 -3.36989734\n",
            "  4.0540886   4.09709682]. \t  -481.36325088646873 \t -198.56808439329558\n",
            "26     \t [-3.26478688  3.41186653  5.10773711  2.27543282  0.54943443  4.35741032\n",
            "  0.47772216 -0.27532317]. \t  -250.55330403365278 \t -198.56808439329558\n",
            "27     \t [-1.04765644  3.71953009 -4.42080179 -0.45853292 -4.47205358  2.75109398\n",
            "  5.09521564  3.63707187]. \t  -521.201183015587 \t -198.56808439329558\n",
            "28     \t [-4.85320752  3.49423447 -3.06054546  1.6517467  -0.27182141 -4.93477661\n",
            "  4.38799752 -4.59888369]. \t  -537.4479171682133 \t -198.56808439329558\n",
            "29     \t [ 4.62372895  2.78262224 -2.93709046 -2.15074762 -1.46193315  3.63220264\n",
            " -4.75425093 -4.65502747]. \t  -502.6653830690235 \t -198.56808439329558\n",
            "30     \t [-1.00756081 -4.39068632  4.06476242  2.35099242  3.37895467  2.75028085\n",
            " -3.93916911 -1.98816465]. \t  -353.95967776320697 \t -198.56808439329558\n",
            "31     \t [ 0.98829805  4.36336243  4.13799771 -1.21705368 -1.59173485  2.55518041\n",
            "  5.0582009  -4.11446994]. \t  -462.71900824579427 \t -198.56808439329558\n",
            "32     \t [ 4.58073842  4.62032066 -4.99666259  0.79779664 -4.97232529 -3.22103025\n",
            "  2.98959596  3.27566147]. \t  -475.39748118350656 \t -198.56808439329558\n",
            "33     \t [ 4.91204161 -4.09448674  0.68528198 -2.83238915 -3.16634376 -3.9481031\n",
            " -3.76429385 -2.52817677]. \t  -385.13289501202144 \t -198.56808439329558\n",
            "34     \t [-0.66419701  4.51059107 -2.40817074 -3.57826431  3.7409368   4.98505851\n",
            "  1.27978334  2.11411458]. \t  -376.0444344775125 \t -198.56808439329558\n",
            "35     \t [-5.10721797 -3.94790907 -5.03239959 -3.04885869 -4.6913326  -3.38896274\n",
            " -4.82605788 -3.94486388]. \t  -636.8978111893483 \t -198.56808439329558\n",
            "36     \t [-0.76898794 -3.04525914 -4.5822224  -2.51921251  4.25733961  4.48021331\n",
            " -4.77644129 -4.04231116]. \t  -608.9961086706174 \t -198.56808439329558\n",
            "37     \t [-4.20183973  0.42189395  2.6194486   4.57678576  4.93148348 -1.58874446\n",
            " -0.26342139  4.27732133]. \t  -405.97570857879555 \t -198.56808439329558\n",
            "38     \t [ 2.94857914 -3.75180266  3.55789776  1.50402823  4.74704491 -4.12939124\n",
            "  4.2935182  -2.39093875]. \t  -473.62668208644084 \t -198.56808439329558\n",
            "39     \t [-2.15300198 -4.96985583  2.1623431   1.34636464 -0.18603995  3.8283524\n",
            "  3.76216038  3.64284117]. \t  -368.6623616902581 \t -198.56808439329558\n",
            "40     \t [-4.9793669   0.36089085 -4.51278272  1.83166975 -5.01711562 -4.86140381\n",
            " -3.70777557  3.90691683]. \t  -585.5721779966067 \t -198.56808439329558\n",
            "41     \t [-2.29867079 -0.05069808  4.99468399 -2.33607439 -4.09331248  2.52623815\n",
            " -4.41217056 -3.9338239 ]. \t  -484.0964243755348 \t -198.56808439329558\n",
            "42     \t [ 4.86532122 -3.34247037 -1.03647706 -4.96077108  3.89456366  2.63455981\n",
            "  3.65074925 -3.70235378]. \t  -468.114161352213 \t -198.56808439329558\n",
            "43     \t [ 3.92415618 -4.95842696  4.90960223 -3.5799509  -4.19303132  4.71710239\n",
            "  3.28667784  3.94726933]. \t  -609.8249010368186 \t -198.56808439329558\n",
            "44     \t [ 4.00769055 -4.88244151  0.99604199 -0.34295385 -3.41459928  4.69899154\n",
            "  5.07903006 -4.71191009]. \t  -616.1579902946902 \t -198.56808439329558\n",
            "45     \t [-1.08736816  1.65235378  1.71699501 -3.78249797  4.53207791 -3.30601936\n",
            " -4.09447918  4.86464344]. \t  -547.6648942292629 \t -198.56808439329558\n",
            "46     \t [ 2.07732714 -5.01987048 -4.35415735 -0.51927177 -4.88830001 -4.84638209\n",
            "  4.40108931 -3.80684396]. \t  -624.5936170037276 \t -198.56808439329558\n",
            "47     \t [ 5.00847839 -1.0888835   1.39170288 -2.58409552 -3.4783154  -3.37337459\n",
            "  4.79479658 -0.10726284]. \t  -349.77078885419775 \t -198.56808439329558\n",
            "48     \t [-2.05448499 -0.44487588 -5.03398918  4.76797657  4.76627514 -3.75226884\n",
            "  2.61521969  4.62538587]. \t  -588.6674774947837 \t -198.56808439329558\n",
            "49     \t [ 5.10347085 -0.51525107 -2.40291896  4.73886819  5.06003041  2.26160765\n",
            " -4.89601707 -3.86885932]. \t  -579.9761426515948 \t -198.56808439329558\n",
            "50     \t [ 3.92118105  4.70425737  4.00724023  2.86409768 -0.74705681  0.10064038\n",
            "  2.74869702  5.08393861]. \t  -403.1319222084397 \t -198.56808439329558\n",
            "51     \t [ 3.58285253 -4.75271958 -4.2601188  -4.88870899  1.73723106 -3.13406583\n",
            "  1.90080677  0.29951342]. \t  -308.09045936307035 \t -198.56808439329558\n",
            "52     \t [ 3.28813079  1.53385702  3.75674363  2.81945191  4.96388212  2.98887233\n",
            " -3.0561607   3.01794408]. \t  -404.6993382528503 \t -198.56808439329558\n",
            "53     \t [-4.06182998  2.71159643  0.21452494  2.04918335 -4.75441908  2.28254514\n",
            " -0.13458182  3.51083991]. \t  -291.1559842051362 \t -198.56808439329558\n",
            "54     \t [ 4.89917505  2.64603688  2.21673948 -3.94335273  1.00891482  0.52027926\n",
            " -0.60966137 -2.9056171 ]. \t  \u001b[92m-191.8032467551518\u001b[0m \t -191.8032467551518\n",
            "55     \t [-0.89478953  2.44338055 -1.70921762 -4.28091813 -1.89789178 -4.84145586\n",
            " -4.00394616 -3.72321812]. \t  -476.5782341078673 \t -191.8032467551518\n",
            "56     \t [ 4.96669245 -4.10632748  3.47889058 -2.10751488 -3.87528403  4.60566688\n",
            " -4.42245649 -2.83365098]. \t  -515.972009029902 \t -191.8032467551518\n",
            "57     \t [-1.75484611  4.92214274 -4.94169711  0.42817006  4.68378577 -3.69615337\n",
            " -4.76612336 -3.2522381 ]. \t  -560.8153813488764 \t -191.8032467551518\n",
            "58     \t [ 0.62839832  4.70889113 -3.46987945  4.39097753 -0.43313369  4.56884717\n",
            " -3.9924195  -4.8522846 ]. \t  -584.1025524241154 \t -191.8032467551518\n",
            "59     \t [-3.15554629 -4.19643382  2.53912025  1.87964509  5.05277064  4.8563878\n",
            "  3.56993121 -4.99662942]. \t  -636.752019753712 \t -191.8032467551518\n",
            "60     \t [-2.99920987 -2.25953015 -3.80907069  2.46485307 -3.24839095 -0.62141223\n",
            "  4.731153   -2.03944173]. \t  -332.07365349601514 \t -191.8032467551518\n",
            "61     \t [ 4.11959732  4.53106539  3.8485956   4.65323453 -2.59576224 -4.77459039\n",
            " -4.42315413 -1.29994038]. \t  -510.0166156812915 \t -191.8032467551518\n",
            "62     \t [-4.04760642  3.63652004  2.35451915 -5.05203185 -4.76246712 -2.91212935\n",
            "  2.10116717 -4.63841204]. \t  -528.8667627840828 \t -191.8032467551518\n",
            "63     \t [-3.73620971 -2.697818   -4.95586096 -4.76982156  4.80736852 -3.70678202\n",
            " -2.54106474 -4.89886925]. \t  -628.3879587117306 \t -191.8032467551518\n",
            "64     \t [ 3.35621159  5.01809225 -1.1808951   3.61710735 -3.65652408  2.73806641\n",
            "  3.95951529 -1.09059214]. \t  -349.23640492675884 \t -191.8032467551518\n",
            "65     \t [ 3.09540135  2.09835983  3.45597745  4.69152006 -3.81841904 -3.649519\n",
            "  3.81804176 -2.80502447]. \t  -460.06347189127314 \t -191.8032467551518\n",
            "66     \t [-4.88456391 -4.83355373  2.73863917 -3.59831811 -1.51374662  1.94790054\n",
            "  4.36315067 -3.6695678 ]. \t  -420.08590631588925 \t -191.8032467551518\n",
            "67     \t [ 2.30436222  1.27264555 -2.36142474  4.62945529 -3.66091596 -0.79412604\n",
            " -4.55181178 -1.73011608]. \t  -350.7804362092147 \t -191.8032467551518\n",
            "68     \t [-3.09301388  4.75845503  3.82113852  1.71179827 -4.92223207 -4.13297743\n",
            " -0.99171788  5.07500063]. \t  -546.9372742425759 \t -191.8032467551518\n",
            "69     \t [ 4.8769272  -4.73929983  3.07899026 -4.72497943  4.46402186 -0.09694603\n",
            " -3.65988745  0.44128387]. \t  -381.46374181209296 \t -191.8032467551518\n",
            "70     \t [-2.12891866  3.66075668  2.75430279  0.81987357  4.76868001 -5.09589027\n",
            "  4.59264299 -2.47702878]. \t  -523.023986867429 \t -191.8032467551518\n",
            "71     \t [-4.16129775 -4.32567848 -4.65503941 -0.58417239  3.2732561   4.66854152\n",
            "  4.88130803  2.38868498]. \t  -517.8920041003479 \t -191.8032467551518\n",
            "72     \t [-4.91055228 -4.63315293  2.95247716  4.36727124  1.03943617 -2.58193276\n",
            "  3.29418306 -2.42559399]. \t  -337.91927477710965 \t -191.8032467551518\n",
            "73     \t [-0.06142008  0.74892798  3.91853989 -4.77187485  3.402458    4.40828943\n",
            " -3.28965448 -4.64420066]. \t  -561.0568623768214 \t -191.8032467551518\n",
            "74     \t [-3.62625629  1.75075587 -4.28449025 -4.40394352  4.49026071 -3.80767519\n",
            "  1.8650292   5.02425839]. \t  -566.025735167776 \t -191.8032467551518\n",
            "75     \t [-3.98653763 -2.60636935  1.68483751  1.58973716 -3.35359414 -3.94526679\n",
            " -3.92708605  0.85226896]. \t  -311.4925756048451 \t -191.8032467551518\n",
            "76     \t [-4.97613396  4.82808205 -0.64149981 -4.92414753 -2.2383558   5.05577022\n",
            "  4.20595758  4.19753595]. \t  -612.807219921953 \t -191.8032467551518\n",
            "77     \t [ 4.79913783  3.20508879 -5.11600711  4.6195374   5.04894524  4.91270602\n",
            "  3.03214638 -3.85154372]. \t  -662.7578187047255 \t -191.8032467551518\n",
            "78     \t [-4.08138981  4.66988426  2.71294586 -3.59492396  4.85743378  4.56707655\n",
            "  4.07190819 -4.30740673]. \t  -641.6630395912307 \t -191.8032467551518\n",
            "79     \t [ 5.06634456  2.52520546 -3.92148285 -4.46249891 -0.50689578  4.58523843\n",
            "  3.38829259  2.62429241]. \t  -427.10099916041906 \t -191.8032467551518\n",
            "80     \t [-4.68791985  3.54327014 -3.72828281  4.67441755 -0.43993621 -4.46347399\n",
            " -2.87293343 -4.92867405]. \t  -548.8012827316522 \t -191.8032467551518\n",
            "81     \t [ 4.90527513  4.97272718 -3.66041115 -0.7728718   1.40873454 -1.71601963\n",
            " -4.1710736   3.44561777]. \t  -360.4571522557052 \t -191.8032467551518\n",
            "82     \t [-3.58048593 -4.68147023 -4.17723225  4.01654278 -3.49497683  1.70440076\n",
            " -4.90580572 -3.50264979]. \t  -518.6516378796205 \t -191.8032467551518\n",
            "83     \t [-4.28114837  4.66266045  1.2629987   4.05104954 -4.63218781  4.39776555\n",
            " -3.19878718 -4.84359044]. \t  -614.8750366844858 \t -191.8032467551518\n",
            "84     \t [-0.40465138 -4.10237563  4.47808135  0.34242571 -3.51213848  1.88906879\n",
            " -3.04958727  4.22725881]. \t  -385.5960560542427 \t -191.8032467551518\n",
            "85     \t [ 3.49500074 -4.54612073 -5.11275315  4.81077974  3.36019835 -0.5365736\n",
            "  4.31336387 -1.78771285]. \t  -438.5298236909285 \t -191.8032467551518\n",
            "86     \t [ 3.63754401  4.56377115  4.93108189 -2.74080216  1.08562868 -4.49489146\n",
            "  3.57333215  0.6397401 ]. \t  -377.654733431407 \t -191.8032467551518\n",
            "87     \t [ 1.28159845 -1.32028297  2.97607213 -5.09433005 -2.4091867  -4.32472006\n",
            " -3.96899404  4.0989378 ]. \t  -521.4294486453209 \t -191.8032467551518\n",
            "88     \t [-2.11465098 -4.59346321  4.00526227 -3.83546817  4.78408638  3.596446\n",
            "  3.383636    0.82533081]. \t  -431.27747039992187 \t -191.8032467551518\n",
            "89     \t [ 0.65346116  4.28638471 -4.92253062  3.84950068  4.55403125 -2.39219739\n",
            "  4.12723153 -1.74698306]. \t  -450.8272763967616 \t -191.8032467551518\n",
            "90     \t [ 1.68165428 -3.39338667  2.20831178 -4.37959208  0.99354527 -5.01415999\n",
            "  3.58249294  4.66434266]. \t  -536.8863299779498 \t -191.8032467551518\n",
            "91     \t [-1.94797555  3.78995682  0.20973045  0.14206588  4.4733702   4.28581641\n",
            " -4.55724932 -0.73258787]. \t  -392.6725139138596 \t -191.8032467551518\n",
            "92     \t [-4.96644063 -5.00887282  3.34364659 -4.66328831  4.4147415  -4.72019774\n",
            "  2.9743149   1.84721239]. \t  -515.7228016651583 \t -191.8032467551518\n",
            "93     \t [-1.50553645  3.65524273 -2.06825842 -3.84529354 -3.16234938  2.1892654\n",
            " -3.07352389  1.46670484]. \t  -263.0616412453976 \t -191.8032467551518\n",
            "94     \t [ 0.04246116 -2.76012825 -2.90148757 -4.22534717 -3.54539465  3.44622703\n",
            "  3.31734645  5.01087239]. \t  -523.9207937025343 \t -191.8032467551518\n",
            "95     \t [ 1.04758068  2.56203466  3.35928506 -0.34110725 -3.85844407  4.53829562\n",
            "  1.44815293  4.49915222]. \t  -423.1789838190038 \t -191.8032467551518\n",
            "96     \t [ 0.41553896  3.8018216   4.87068592 -4.60800636  4.00440344  3.52068508\n",
            "  0.85311276  4.77674434]. \t  -527.3664791358706 \t -191.8032467551518\n",
            "97     \t [ 3.32748045  3.56253559  3.2252929   4.71347622  5.03391871 -4.57745287\n",
            "  0.60660801  0.91485193]. \t  -418.2220033042325 \t -191.8032467551518\n",
            "98     \t [ 3.99713554  4.81301931 -4.00931038  0.5787544  -4.35369962 -5.02445034\n",
            " -4.97007262 -4.10444208]. \t  -665.7979580142039 \t -191.8032467551518\n",
            "99     \t [-4.84609362 -4.46677318 -2.51870555 -1.5412036   3.80665425 -2.43400816\n",
            "  4.19746888  4.30299524]. \t  -471.3784322561186 \t -191.8032467551518\n",
            "100    \t [ 0.39352684 -4.70516544 -5.03163188 -0.48977391  0.08362139  4.7640591\n",
            "  4.57199768 -2.7644327 ]. \t  -465.01486106726117 \t -191.8032467551518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d86panpOuvum",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7be85e-36be-4455-e909-c8ac4a6cf91f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 15 \n",
        "\n",
        "np.random.seed(run_num_15)\n",
        "surrogate_winner_15 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_15 = dGPGO_stp(surrogate_winner_15, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.79751023 -2.50366638 -2.53412486  2.14942059 -0.5370638  -2.79610411\n",
            " -1.00649405  3.91431921]. \t  -228.93586258775446 \t -111.84379356128198\n",
            "init   \t [-0.6429341   3.87507385  2.87260414  0.35035432 -4.99985399 -2.39865368\n",
            " -1.72857241  1.17580582]. \t  -247.18214418832017 \t -111.84379356128198\n",
            "init   \t [ 3.84255585 -0.47241396 -1.33929378  0.83608715  1.37927538 -3.11654164\n",
            " -0.55786658  1.52017343]. \t  -111.84379356128198 \t -111.84379356128198\n",
            "init   \t [ 3.74892071 -4.8478471  -1.40433719  2.34767012  1.9855191   0.6647632\n",
            " -3.76057172  2.51723021]. \t  -261.0681305251046 \t -111.84379356128198\n",
            "init   \t [-0.55198121 -0.67596996 -3.19596718 -4.19216237 -1.4139613  -0.32482896\n",
            " -2.05442948  4.53772941]. \t  -307.060259396398 \t -111.84379356128198\n",
            "1      \t [-0.52388747 -3.42929075  2.89517266  2.53504193  3.75358406 -1.1432719\n",
            "  4.15543613  4.50271513]. \t  -436.00483739485145 \t -111.84379356128198\n",
            "2      \t [ 3.59564778  4.51509721 -4.2532918   4.88423533  4.69189145 -1.53762576\n",
            "  3.6493151   3.60248043]. \t  -524.695792395735 \t -111.84379356128198\n",
            "3      \t [ 3.65838953 -3.65540232  1.39373299  4.45739924 -1.19556836  4.65675434\n",
            "  2.52730654  0.40442687]. \t  -308.68737481626977 \t -111.84379356128198\n",
            "4      \t [ 2.48921905 -4.28456967 -4.18815068 -4.61310118  4.61587021 -3.20488727\n",
            " -3.26093515 -3.56527486]. \t  -524.9403830688307 \t -111.84379356128198\n",
            "5      \t [-4.85272535 -3.89403078 -1.74722506  1.60991698 -1.61244735 -1.07631829\n",
            "  2.57851766 -1.60150022]. \t  -160.41200738036034 \t -111.84379356128198\n",
            "6      \t [-2.09525434  2.85625188 -3.14465335 -4.11513009  1.1189636  -3.74713359\n",
            " -0.04451839 -3.50225484]. \t  -306.7568005812394 \t -111.84379356128198\n",
            "7      \t [ 1.65019235  2.35098964  4.69224662 -1.82231264 -3.68344442  4.79839766\n",
            " -0.42656071 -4.35238171]. \t  -451.9182931973306 \t -111.84379356128198\n",
            "8      \t [ 1.37879942 -1.23725981  3.06041794 -4.41545468 -3.76934309 -0.43982486\n",
            "  5.00168292 -1.05014498]. \t  -367.18681718431725 \t -111.84379356128198\n",
            "9      \t [-2.11419656 -1.8595311  -1.2839357  -0.82536408  4.73413653  4.36129594\n",
            " -4.47917065  4.84092933]. \t  -573.1591344477459 \t -111.84379356128198\n",
            "10     \t [-0.50861462  4.54634625  1.23674036  3.14491108  0.02016445 -3.03349437\n",
            "  4.21594032 -4.60806421]. \t  -435.2553374375713 \t -111.84379356128198\n",
            "11     \t [ 5.02549587  1.117597    1.81591151 -2.3410321  -1.93506609  3.81286408\n",
            " -4.19099904  2.61844649]. \t  -343.3193897552946 \t -111.84379356128198\n",
            "12     \t [-2.60214485 -3.06106299  4.11421391 -2.87815384 -2.49149397 -2.40568351\n",
            " -1.92937413 -2.64611256]. \t  -257.260992611434 \t -111.84379356128198\n",
            "13     \t [ 1.3772806   2.26041333  2.90646201 -2.65631324  4.98328354 -0.17444485\n",
            "  3.77373606  0.55741186]. \t  -292.203814266701 \t -111.84379356128198\n",
            "14     \t [ 1.73207257  2.80211546  2.63827927  4.85084842  2.23263983 -4.99828222\n",
            " -3.15026573 -3.28967883]. \t  -464.57371882184043 \t -111.84379356128198\n",
            "15     \t [ 4.9874552   0.38051921 -2.19049981 -2.86589229  4.59623924 -4.15560802\n",
            "  4.30106517 -4.737449  ]. \t  -590.6955810098972 \t -111.84379356128198\n",
            "16     \t [ 3.95202796  2.89890031 -2.06960118  5.04611886  3.12153692  3.76895063\n",
            " -1.25525191 -3.04033094]. \t  -366.0571764911808 \t -111.84379356128198\n",
            "17     \t [-1.67323843 -1.53222513 -2.29205179 -4.76151903 -3.60925852  3.33289607\n",
            "  0.18410779 -3.08209368]. \t  -321.9585065995703 \t -111.84379356128198\n",
            "18     \t [-3.59909617  2.31017245  1.87351284  3.75977375  2.32437161  3.63143128\n",
            " -2.42080876 -2.00691354]. \t  -270.0821291509479 \t -111.84379356128198\n",
            "19     \t [ 1.58925384  4.00425658 -0.31432874  5.04091127 -4.02914679  1.11263439\n",
            "  4.67933551  2.85297727]. \t  -443.5203737465371 \t -111.84379356128198\n",
            "20     \t [ 3.23781229  2.12612529 -3.52821108  4.01963373 -4.9779655   2.48385168\n",
            " -2.29532249 -4.40688006]. \t  -474.6609773344586 \t -111.84379356128198\n",
            "21     \t [ 2.90410255  2.63797244 -3.44214464 -5.03470822  2.11265143  4.21607998\n",
            "  3.57398996  4.00123743]. \t  -505.75133570191565 \t -111.84379356128198\n",
            "22     \t [-4.98233553  4.58647316 -0.44979913  4.94072869  1.46981966 -3.95863989\n",
            " -0.1249489   3.37054023]. \t  -360.9657422588499 \t -111.84379356128198\n",
            "23     \t [ 3.68451376 -4.78258157 -2.91569537  3.32237528 -2.25603478 -1.14728573\n",
            "  4.87796558 -4.96308057]. \t  -525.9436026882316 \t -111.84379356128198\n",
            "24     \t [-3.00952908  4.61418296 -3.92318642 -2.11941286  3.50860366 -3.46736688\n",
            " -2.94581957  4.56798878]. \t  -477.14489203144285 \t -111.84379356128198\n",
            "25     \t [-3.12981896 -4.99756621  4.43287495  5.01439348  3.38924395 -3.13211226\n",
            "  2.93149432 -3.16912081]. \t  -476.07267386240176 \t -111.84379356128198\n",
            "26     \t [ 2.34833021 -5.11988695  5.07172838 -4.85377777 -0.17599614 -3.46856202\n",
            " -5.06975064  4.89663465]. \t  -673.4183168441568 \t -111.84379356128198\n",
            "27     \t [-4.66695701 -3.08414434  2.13898857  0.0522465  -5.08605359  2.57667348\n",
            "  4.54582994  4.5971454 ]. \t  -537.4382543554907 \t -111.84379356128198\n",
            "28     \t [-4.88406457  0.78452665 -5.1009302  -0.92140704 -0.50877666  3.97554673\n",
            "  2.44361097  2.80744999]. \t  -307.5164262566692 \t -111.84379356128198\n",
            "29     \t [ 4.52622078 -4.24625289  2.57175464  2.68172624 -2.34948507 -4.43585608\n",
            " -3.58637814 -3.22718394]. \t  -424.1701921266098 \t -111.84379356128198\n",
            "30     \t [-5.08985894  5.06900139  4.84670204 -4.31685951  0.14574582  3.75603628\n",
            " -2.47352114 -2.85677445]. \t  -415.1793707871582 \t -111.84379356128198\n",
            "31     \t [ 4.48749471 -4.87221611 -5.00917313 -3.90281427  3.05327729  5.0931248\n",
            "  1.55403876  1.00328693]. \t  -431.02783702515427 \t -111.84379356128198\n",
            "32     \t [-2.56626435 -0.24731955 -4.76119244 -0.23186723  3.29722852  3.29704609\n",
            "  4.94926107 -4.40165266]. \t  -520.9742790292622 \t -111.84379356128198\n",
            "33     \t [-2.06063515  4.90252578 -0.1139602  -2.82344102 -0.19565923 -5.0797275\n",
            "  3.92250593  2.62016541]. \t  -401.87967827189163 \t -111.84379356128198\n",
            "34     \t [ 1.42584053 -4.98846896 -5.04382224 -0.17873995 -4.81602368 -5.08607429\n",
            " -1.69609334 -2.82190647]. \t  -483.27259440141745 \t -111.84379356128198\n",
            "35     \t [-5.10723346 -3.9901281   4.39470678 -4.9183812   0.56382348  4.5586749\n",
            "  1.31403453 -1.54688019]. \t  -370.13641496789126 \t -111.84379356128198\n",
            "36     \t [-1.59124824 -0.35307113  3.15951628  3.3491287   4.11972565 -3.12243119\n",
            " -4.60451011  3.422826  ]. \t  -463.0903237662293 \t -111.84379356128198\n",
            "37     \t [-4.71036109  4.15026493 -4.85794836  2.50821902 -4.88497098  0.34634364\n",
            " -1.05789833 -2.35314708]. \t  -324.76741933025454 \t -111.84379356128198\n",
            "38     \t [-3.6279063  -0.71933167 -4.0105772   3.30970551  2.48218208 -1.57252989\n",
            " -4.18041044 -1.90219505]. \t  -303.1882001133646 \t -111.84379356128198\n",
            "39     \t [ 4.45482303 -2.10731163  4.4518349   1.20262824  4.88618034 -0.17515968\n",
            " -2.40844545 -1.99186687]. \t  -285.8711457905021 \t -111.84379356128198\n",
            "40     \t [-4.72054126  4.69991902  4.34599419 -3.85534331  0.0883614  -3.22893743\n",
            "  3.77396322 -4.92839963]. \t  -539.1875043322538 \t -111.84379356128198\n",
            "41     \t [ 4.28987042 -3.0445427   3.1361287  -1.01625627 -4.57460719 -2.61314419\n",
            "  1.25317584  4.46911164]. \t  -386.96159425549496 \t -111.84379356128198\n",
            "42     \t [ 2.72559146  5.03017876 -0.48616408 -3.12944939 -4.97165254  4.20611814\n",
            "  4.31171077  0.36607525]. \t  -458.8603864402666 \t -111.84379356128198\n",
            "43     \t [ 2.77170037  3.20661927  4.83180191 -5.03869897  3.8088646  -4.98628541\n",
            " -2.72308512  4.73292351]. \t  -652.6663842394453 \t -111.84379356128198\n",
            "44     \t [ 4.27036674  4.81355985 -3.9432464   3.59483531 -4.49320754 -3.17908382\n",
            " -2.78263114  4.33152904]. \t  -528.7981058102932 \t -111.84379356128198\n",
            "45     \t [-4.71157289  3.13913248  5.0362286   3.75980993  1.08583542  0.7049586\n",
            "  4.35663218  3.88677749]. \t  -437.1377170428437 \t -111.84379356128198\n",
            "46     \t [-2.39396847  4.80759665 -4.97673307  4.97618117  3.57268263  4.96474516\n",
            " -3.06220666  3.18204551]. \t  -583.6657373899269 \t -111.84379356128198\n",
            "47     \t [-4.35412703  5.01883957 -2.91160559  4.56595557  5.0683864   0.15113618\n",
            "  2.86341114 -2.25858569]. \t  -404.94336040224425 \t -111.84379356128198\n",
            "48     \t [ 0.1457677  -4.61588259 -4.25749333  3.15210573  4.87712486 -3.97453399\n",
            "  2.40038617 -2.35642499]. \t  -435.22396600101706 \t -111.84379356128198\n",
            "49     \t [-2.37261754 -1.92639556  4.20365156 -5.03049299  4.62201764  1.47180533\n",
            "  1.15188121  4.72340186]. \t  -474.87132625339336 \t -111.84379356128198\n",
            "50     \t [-4.01445499 -4.33107232  4.4076627   0.9640581  -3.93332122 -3.10217497\n",
            " -4.40706516  5.07140131]. \t  -592.4367967395035 \t -111.84379356128198\n",
            "51     \t [ 3.38043959  5.0436027  -5.02442705 -4.1055372  -2.62671486 -0.38398891\n",
            "  3.22839127 -4.25905935]. \t  -458.91667573094094 \t -111.84379356128198\n",
            "52     \t [-4.13546294 -0.3182888   2.55284115 -3.03230813  5.10487166 -1.72093299\n",
            " -3.24761372 -1.96771014]. \t  -326.50749836759434 \t -111.84379356128198\n",
            "53     \t [ 2.68270744 -4.75059365  0.89034292 -4.81948316 -1.14544375  3.62678147\n",
            "  2.6148849   4.29388929]. \t  -428.46571539325055 \t -111.84379356128198\n",
            "54     \t [-4.51496812 -3.51712045 -3.98340053  2.68145345 -4.86445271  3.02192687\n",
            " -3.32936572 -4.85330908]. \t  -560.6247776496343 \t -111.84379356128198\n",
            "55     \t [ 0.44809239  5.01051392 -4.86367235 -2.11186191  1.89446627  3.12698337\n",
            " -3.51351203 -2.20163238]. \t  -341.0210659922983 \t -111.84379356128198\n",
            "56     \t [-3.37878741  3.15771602  1.31444761  4.02792166 -3.90944978  4.84075945\n",
            "  1.57037881 -4.42005333]. \t  -492.0127727549784 \t -111.84379356128198\n",
            "57     \t [-4.82410729 -4.10480178  0.9093515   4.4609276  -1.06814942  2.74990423\n",
            " -4.64751482  2.42693755]. \t  -388.44358743644443 \t -111.84379356128198\n",
            "58     \t [-4.11306715 -4.99688734 -2.93062206 -3.09797588  3.76190498  4.90653129\n",
            " -3.55765547 -4.63782813]. \t  -606.8884690455475 \t -111.84379356128198\n",
            "59     \t [5.0162458  2.68942474 3.51033268 5.02713705 4.36403052 2.17756352\n",
            " 4.31544975 2.45231737]. \t  -479.831606126424 \t -111.84379356128198\n",
            "60     \t [ 0.69748855 -3.20165764  2.57309611 -3.66784949  2.85086598  0.70378716\n",
            "  3.21643967 -4.22867662]. \t  -353.74378267315365 \t -111.84379356128198\n",
            "61     \t [ 5.09697328 -2.7841205  -4.91969199 -5.00049453 -1.32290508  0.82406631\n",
            " -4.00657474 -1.24717525]. \t  -351.7486382995552 \t -111.84379356128198\n",
            "62     \t [-4.98265828  1.15233266  2.85120661 -2.94431747 -3.63397892  4.19805347\n",
            " -5.10585243  4.70052931]. \t  -617.5656249544422 \t -111.84379356128198\n",
            "63     \t [ 1.52162075  4.92091405 -4.51082299 -4.90735343 -3.57482238 -0.90500666\n",
            "  4.53795479  4.97527079]. \t  -619.1059517165777 \t -111.84379356128198\n",
            "64     \t [-4.85967598 -1.3445862   5.0279405   2.78072515  1.14850371  4.21321946\n",
            "  4.54771594 -3.1620877 ]. \t  -471.8676051964984 \t -111.84379356128198\n",
            "65     \t [-5.00300692  4.7903519   2.86504401 -3.42306613 -0.24237479  1.99831555\n",
            "  1.25463432  4.69776777]. \t  -354.24422429501533 \t -111.84379356128198\n",
            "66     \t [-0.8704956  -2.07558054  3.77990911  3.14272296 -3.37821305 -4.63127811\n",
            "  4.8646515   0.00855032]. \t  -443.15226354920077 \t -111.84379356128198\n",
            "67     \t [ 1.54861703  1.5776998   1.24361158  5.06802709 -2.68758715  1.9077622\n",
            " -4.59773391  4.85906897]. \t  -509.5672649125048 \t -111.84379356128198\n",
            "68     \t [ 4.17715329 -3.95447546 -5.0781627  -3.218078   -4.83798504 -0.9496555\n",
            "  4.32249807 -0.92781166]. \t  -427.62784729669323 \t -111.84379356128198\n",
            "69     \t [-2.03816424 -3.98887715 -3.92604522 -2.35583107  4.70600245 -0.21458074\n",
            "  0.95373692  4.35425846]. \t  -373.47004564749034 \t -111.84379356128198\n",
            "70     \t [ 4.74027586  0.91426416  2.1387733  -4.55288262 -4.96389296 -3.65925874\n",
            "  0.30626705 -4.50248391]. \t  -487.15768895519454 \t -111.84379356128198\n",
            "71     \t [ 4.88567921 -1.61507114  3.46104136  3.13387083  4.79948897  3.2105867\n",
            "  5.10535152 -4.32779977]. \t  -613.621558271951 \t -111.84379356128198\n",
            "72     \t [-2.15293757 -2.48016985 -3.35527265 -4.45151539 -4.91721161 -3.94540807\n",
            "  5.07644803  3.50573764]. \t  -622.9813086054397 \t -111.84379356128198\n",
            "73     \t [-0.83916233 -5.00841823 -3.65729336  4.80072929  0.47660704  4.49356629\n",
            "  0.49976683 -0.31771402]. \t  -308.0325957428104 \t -111.84379356128198\n",
            "74     \t [ 5.06030555  4.18673285 -3.99560712 -5.01791721 -1.154041   -2.13521571\n",
            " -3.52804713  2.31440299]. \t  -373.2721932147969 \t -111.84379356128198\n",
            "75     \t [ 3.12257762  4.69702589 -4.84668747  3.19571007  3.89553294 -2.05398589\n",
            "  4.5093936  -4.19070764]. \t  -549.2236760895344 \t -111.84379356128198\n",
            "76     \t [-4.67713792  3.39659925  1.95417148  5.05241469 -4.10243776 -3.42805633\n",
            " -4.7644036  -4.11326319]. \t  -607.4209909284011 \t -111.84379356128198\n",
            "77     \t [ 4.74077394  2.02054436  1.87848268 -3.1128556   3.76888715  3.91167158\n",
            " -3.37043342 -3.68349547]. \t  -430.8791683613199 \t -111.84379356128198\n",
            "78     \t [-4.13168098 -2.44010311  3.72305099 -2.40346141  2.17301432 -4.83896371\n",
            "  3.39958289 -0.7481894 ]. \t  -343.15064828372783 \t -111.84379356128198\n",
            "79     \t [ 0.72417144 -0.76742219 -0.91033001  1.11802725 -1.15320748  0.06008926\n",
            " -2.42587103 -4.60716078]. \t  -226.8608372614065 \t -111.84379356128198\n",
            "80     \t [ 4.86060706 -4.64280076 -4.51613773 -2.61968243 -4.34822303  5.02598351\n",
            " -1.57924104  4.83125861]. \t  -605.658915494005 \t -111.84379356128198\n",
            "81     \t [-0.18322472 -4.26695212 -4.1637479  -4.25445277  2.18157768 -3.72748691\n",
            "  5.10271086 -0.95878767]. \t  -457.63835021355 \t -111.84379356128198\n",
            "82     \t [ 4.37232418 -2.21081725  4.19146394  1.57367374 -3.84657012  3.68772661\n",
            " -4.79237609 -2.76531362]. \t  -469.02378036435357 \t -111.84379356128198\n",
            "83     \t [-5.03350557 -0.05448398 -0.36942072 -4.96955803  1.74793502  4.83536668\n",
            " -3.10126687  0.46272027]. \t  -349.1364421620439 \t -111.84379356128198\n",
            "84     \t [ 4.10931878  3.76676695  4.83534607  0.69713175  0.61360135 -3.44590389\n",
            "  4.97058814  5.0538885 ]. \t  -567.7588448515907 \t -111.84379356128198\n",
            "85     \t [-1.82035864  3.65458057 -0.13793768  5.0084221   3.44397373  5.02205025\n",
            "  4.16421055  4.66602496]. \t  -636.6094380372543 \t -111.84379356128198\n",
            "86     \t [-4.90082092 -4.06520307 -2.35594899 -3.96961962  2.92418149 -4.95037477\n",
            " -0.40051146 -2.99682288]. \t  -399.51469819302594 \t -111.84379356128198\n",
            "87     \t [ 1.68127017  1.61411499 -3.19466243 -0.15465051 -4.68249015 -3.34889543\n",
            "  4.55328809 -1.0284925 ]. \t  -369.2592499722844 \t -111.84379356128198\n",
            "88     \t [-1.9147793  -3.42234304  4.49861871 -2.83694358  4.29715446  4.74241197\n",
            " -4.63464822 -2.75687702]. \t  -558.430175937033 \t -111.84379356128198\n",
            "89     \t [ 2.43520403 -1.75830885  2.18128611  1.80754629  3.86868411 -4.64374866\n",
            "  4.53226717 -5.01899017]. \t  -588.9886515912892 \t -111.84379356128198\n",
            "90     \t [-0.74646639 -2.70532468 -2.41244337  4.24907925 -1.92194483  3.40994684\n",
            "  4.69726373  4.87119964]. \t  -537.387600062446 \t -111.84379356128198\n",
            "91     \t [-3.60757379 -3.0723008  -3.06314835 -4.62578723 -3.41744379 -4.7431579\n",
            " -5.02393733 -4.10809571]. \t  -650.7040348066743 \t -111.84379356128198\n",
            "92     \t [ 3.2371991  -2.52788842 -2.48012289 -3.86695592  4.50803834 -0.82732722\n",
            " -4.96129304  4.95715762]. \t  -576.1334836829162 \t -111.84379356128198\n",
            "93     \t [-4.52246419  4.11503785 -2.49404407 -3.60471121 -5.01091876  0.96768984\n",
            " -3.74581096  0.93640603]. \t  -361.3539185399091 \t -111.84379356128198\n",
            "94     \t [ 3.16570325  3.48632791 -4.28420686  4.13233854  0.36321831 -2.88390424\n",
            " -4.75633091 -1.26574034]. \t  -379.43544879972853 \t -111.84379356128198\n",
            "95     \t [-0.78024507 -1.7615908   4.61039068  3.50028362  1.59267607  4.71259024\n",
            "  0.72546947  3.30612858]. \t  -356.6523918459941 \t -111.84379356128198\n",
            "96     \t [-4.75444874 -1.82568919 -0.47868852 -4.85080086 -3.9641573  -3.95926538\n",
            "  1.97045327 -4.73773893]. \t  -503.4551425999706 \t -111.84379356128198\n",
            "97     \t [-1.78444912 -3.80249304  3.90818017  4.41400396 -4.43274465 -0.03633215\n",
            " -0.77273515 -2.86612487]. \t  -324.0087630780936 \t -111.84379356128198\n",
            "98     \t [ 3.73705402 -1.4544115  -2.86894251  4.88345201  4.31270892 -4.02237234\n",
            " -3.42693813 -4.2593582 ]. \t  -555.6996656444603 \t -111.84379356128198\n",
            "99     \t [ 1.88400949  4.62875794  3.26089601 -2.82491112  0.78430699  4.50065961\n",
            "  0.97897852  3.64531017]. \t  -347.8475031034143 \t -111.84379356128198\n",
            "100    \t [-3.32884009 -0.28790379 -4.86183944  1.53892744 -4.13339617 -0.47405551\n",
            " -4.6548507   4.51468963]. \t  -493.1386084475338 \t -111.84379356128198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "any0xrgYuvxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e8486fa-daa2-42ba-e53e-843b855179ed"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 16 \n",
        "\n",
        "np.random.seed(run_num_16)\n",
        "surrogate_winner_16 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_16 = dGPGO_stp(surrogate_winner_16, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.72683092 -1.88041214  1.76282397  0.08101548  2.88420277 -2.21509961\n",
            " -2.72682205  0.65330879]. \t  -156.8066019097497 \t -156.8066019097497\n",
            "init   \t [ 3.84024949  2.2419755  -3.25497095 -2.62348378 -4.23877911  0.35067282\n",
            "  3.47852441 -0.5561546 ]. \t  -261.8650591886947 \t -156.8066019097497\n",
            "init   \t [ 0.26105361  3.64645501 -0.31006696  0.15828746  1.76956804 -4.75312845\n",
            " -1.21380639  1.33368774]. \t  -202.8033628398822 \t -156.8066019097497\n",
            "init   \t [ 1.67575729 -3.93174065 -4.05292123 -2.2111691  -3.83176859  3.19394297\n",
            " -2.91057129  0.66405444]. \t  -300.0085240682813 \t -156.8066019097497\n",
            "init   \t [-1.33059735  4.11084689 -1.25252503 -4.4633888  -4.89127772 -0.62411111\n",
            " -2.74874149  4.74659878]. \t  -475.05316372608854 \t -156.8066019097497\n",
            "1      \t [-4.38660667  1.62450493 -1.22519012  1.94388211  1.6423205   4.26907265\n",
            "  2.26974299  0.96861339]. \t  -210.5421323027258 \t -156.8066019097497\n",
            "2      \t [-1.50849266 -3.31628152  4.23126597  4.6097352  -1.34433653 -5.11162385\n",
            "  1.26256572  0.79871415]. \t  -345.0509196526117 \t -156.8066019097497\n",
            "3      \t [-2.6753072   4.31716614  3.07622603  2.68213022  4.9079513   0.56893367\n",
            "  3.69165981 -4.94981533]. \t  -515.3837876856595 \t -156.8066019097497\n",
            "4      \t [-0.60799469  2.54052005  4.89827636 -0.38358081  3.38807384 -1.76498353\n",
            "  4.31807573  3.0863238 ]. \t  -368.655837958522 \t -156.8066019097497\n",
            "5      \t [ 4.38406618 -5.093076   -4.47085453  4.58831448 -5.112849    3.04055753\n",
            "  2.3356274   4.319442  ]. \t  -588.8978085784819 \t -156.8066019097497\n",
            "6      \t [ 3.08840881  1.09355518 -2.27221671  0.20362313  5.04563824  3.88780797\n",
            "  4.45226401  4.09078879]. \t  -518.2023890662198 \t -156.8066019097497\n",
            "7      \t [-3.45080578 -0.25583992 -4.55940953  4.95107863  3.06665401  1.69508879\n",
            " -4.47638998 -1.93280567]. \t  -406.8704959003774 \t -156.8066019097497\n",
            "8      \t [-3.46240387 -2.00909558 -2.51403845  0.58022984  4.16791614 -3.02806887\n",
            "  1.25327079 -1.73619207]. \t  -217.3515534416787 \t -156.8066019097497\n",
            "9      \t [ 3.63241089 -4.26388386  2.02919011 -3.23337167  3.08891188  4.48151116\n",
            "  0.96995865 -2.47940952]. \t  -327.7034751421618 \t -156.8066019097497\n",
            "10     \t [-2.48150204  3.79329047 -4.02816999 -4.59914752 -1.69200346  3.99634573\n",
            "  4.31095423  4.96050117]. \t  -605.3049632734368 \t -156.8066019097497\n",
            "11     \t [-1.74419421 -2.97566387 -2.51770045 -0.22404063 -2.57004044 -3.18775746\n",
            "  2.26407505  4.33743539]. \t  -320.3539300741578 \t -156.8066019097497\n",
            "12     \t [ 4.18696991  3.365974   -2.54364089 -3.36838534 -1.45864595  1.08365408\n",
            " -4.60653562 -4.51818089]. \t  -434.52162334900993 \t -156.8066019097497\n",
            "13     \t [-2.53627568 -2.80632001  0.16353384  5.01128334  4.76433233 -0.79457349\n",
            "  2.12261394  5.06715143]. \t  -476.94464498531534 \t -156.8066019097497\n",
            "14     \t [ 0.74494652  0.44326964  1.1439194  -3.24907125  1.49238293  4.56952072\n",
            " -4.80947476  4.19134345]. \t  -485.97479555821917 \t -156.8066019097497\n",
            "15     \t [-1.31218668 -3.9184267  -3.54034996 -4.92513616  4.71252513 -3.37533384\n",
            " -4.66971746 -1.34930083]. \t  -513.6655342720869 \t -156.8066019097497\n",
            "16     \t [-0.54471644  2.86955227  1.78128455 -0.57781785 -3.05534328  2.42888953\n",
            "  0.2326315  -4.83462154]. \t  -297.0597786039208 \t -156.8066019097497\n",
            "17     \t [-1.59156241 -3.81184279  4.65017504 -3.4073155  -4.34539835 -4.09224959\n",
            " -2.10328815  2.03453059]. \t  -401.87768084752315 \t -156.8066019097497\n",
            "18     \t [ 1.19847408 -4.81665388  3.19260034 -0.13902353 -3.93813554  2.36046234\n",
            "  3.20403718 -2.53039654]. \t  -312.55153510407445 \t -156.8066019097497\n",
            "19     \t [ 1.72616837 -2.82504951  4.52511105  4.73361059 -4.41206764  3.21062116\n",
            " -4.50461261 -0.53677221]. \t  -473.5256057926388 \t -156.8066019097497\n",
            "20     \t [-4.33137198  1.11795389  4.40038306  4.33793038 -3.7657871   4.71254744\n",
            "  2.35225502  4.99050392]. \t  -596.7482415006853 \t -156.8066019097497\n",
            "21     \t [ 1.36723193  0.52425837 -4.65019601  4.93451875  0.75602746  0.68584194\n",
            "  2.25857245 -2.83815146]. \t  -270.5189253477478 \t -156.8066019097497\n",
            "22     \t [ 4.99758685  0.24573481 -4.44491465  3.57308703 -4.51711192 -4.19008374\n",
            " -1.12675733  4.79196793]. \t  -535.3892869970293 \t -156.8066019097497\n",
            "23     \t [ 1.7762428   0.41499559 -5.06727792  1.80589238 -1.64805378 -4.84835213\n",
            " -3.69403084 -2.6746722 ]. \t  -400.94792159573166 \t -156.8066019097497\n",
            "24     \t [ 0.04225743  4.66571439  2.65532037  3.72449198  0.7395694   3.30946777\n",
            " -4.72329461  1.3308894 ]. \t  -358.9661008506889 \t -156.8066019097497\n",
            "25     \t [ 0.1302977   3.40487396 -1.99470876 -4.03747961  4.89478187  2.14159484\n",
            "  2.69089617 -2.55115513]. \t  -350.4114802352062 \t -156.8066019097497\n",
            "26     \t [-4.93635129  2.55766944 -1.25848161  4.96559818 -1.43852606 -4.19444241\n",
            " -3.63998264 -3.7665619 ]. \t  -462.979991392237 \t -156.8066019097497\n",
            "27     \t [-4.54420098  4.89547877 -5.09489697  2.95793517 -1.03406976 -4.57905458\n",
            " -2.37816959  4.31242752]. \t  -500.9716637417185 \t -156.8066019097497\n",
            "28     \t [-4.34845271  2.19791687 -2.73300499 -3.74567358  4.80929233 -2.00607732\n",
            " -0.48258594  5.0874749 ]. \t  -455.580921465692 \t -156.8066019097497\n",
            "29     \t [-4.99554505  0.49324644  2.26909368 -4.77396507  0.85337793  3.21803463\n",
            "  4.32958582 -3.30550515]. \t  -416.4552417283923 \t -156.8066019097497\n",
            "30     \t [ 3.93743216  4.78027961  3.3726264   3.50073876 -4.30444377 -2.5629022\n",
            "  4.91475265  0.2177699 ]. \t  -445.8649641850107 \t -156.8066019097497\n",
            "31     \t [-2.72961452  4.59025582 -2.96237344 -0.34812156 -3.11193657 -3.98737154\n",
            "  3.84133375 -3.66064947]. \t  -430.7127037238413 \t -156.8066019097497\n",
            "32     \t [-5.01512742 -2.76230214 -1.0853079  -4.49907389 -3.83583346 -0.82216684\n",
            "  0.91528906 -4.22097547]. \t  -350.9336636344366 \t -156.8066019097497\n",
            "33     \t [-2.86190372 -4.2765308   2.07537157 -3.7601208   3.95761097  2.09114883\n",
            "  1.82717005  2.96591903]. \t  -312.53756107033695 \t -156.8066019097497\n",
            "34     \t [ 4.04521911 -4.82824783 -1.35725976 -4.21044808  3.53132579 -4.24487484\n",
            "  3.03997908  2.24762761]. \t  -414.9957383266309 \t -156.8066019097497\n",
            "35     \t [ 5.04667388 -4.33869883  5.06430427 -2.83017979 -4.51119332  1.40279217\n",
            " -3.83025017  3.41186882]. \t  -481.4825225553088 \t -156.8066019097497\n",
            "36     \t [ 1.07869466  4.51602233 -4.19203408  0.99589117  4.52971288  2.89582014\n",
            " -3.07169753  3.92598917]. \t  -440.8996912185112 \t -156.8066019097497\n",
            "37     \t [-3.9042907  -4.40366364  4.65320756  0.02671839  4.09449059  0.5982716\n",
            " -0.72148888 -3.71363888]. \t  -318.93244299488333 \t -156.8066019097497\n",
            "38     \t [-1.99495872 -4.88696813 -4.62983567 -0.90580179  4.64593721  3.53033548\n",
            " -2.46735596 -3.98478397]. \t  -471.67903610645953 \t -156.8066019097497\n",
            "39     \t [ 3.42067318  4.55042167 -2.70746041  4.12711395  1.28985058 -1.85708075\n",
            "  4.57025558  3.32485592]. \t  -406.89603781782597 \t -156.8066019097497\n",
            "40     \t [ 5.09500714  2.53406823 -3.14990005 -2.74129608  4.75652242 -4.5705135\n",
            " -2.29444926 -4.56049231]. \t  -540.322821763829 \t -156.8066019097497\n",
            "41     \t [-3.27180474  1.18483204  3.52227647 -3.41817601  2.50827484 -2.89990888\n",
            " -4.91003641 -4.66574765]. \t  -522.2942179348121 \t -156.8066019097497\n",
            "42     \t [-4.08432493  3.73067547 -2.51676872  4.72630871 -4.59957162  3.94472287\n",
            " -3.12799085 -3.62420511]. \t  -525.5864549237357 \t -156.8066019097497\n",
            "43     \t [ 4.41740269 -2.36735545  3.00861093 -2.41492275 -0.41517121  2.53840003\n",
            "  4.48493868  5.09975719]. \t  -469.5904133665224 \t -156.8066019097497\n",
            "44     \t [ 1.02218837 -0.24076849  4.46008041 -3.93430991  1.85533541 -3.17131149\n",
            "  3.15227948 -4.59330614]. \t  -438.65333592049797 \t -156.8066019097497\n",
            "45     \t [ 4.31992796 -3.92745657 -4.91472527  2.34137728  2.71240936 -0.50978536\n",
            " -0.92764946  3.94025233]. \t  -312.4769230047498 \t -156.8066019097497\n",
            "46     \t [ 3.40236921 -4.11869625  0.22971092  0.53788587 -4.82949746 -4.11293012\n",
            " -1.02864356 -2.78624305]. \t  -334.4483697344649 \t -156.8066019097497\n",
            "47     \t [ 4.31320019  3.70661202 -2.45694951  4.70068646 -1.67526881  4.25804231\n",
            "  0.12034107  1.4064377 ]. \t  -291.3213400959514 \t -156.8066019097497\n",
            "48     \t [ 3.57000488  1.21763728  4.71687264  4.23940225  1.12154023  3.87740724\n",
            "  2.59857749 -4.52610502]. \t  -461.9952360301086 \t -156.8066019097497\n",
            "49     \t [-0.05738552 -0.86087579 -0.3124594   4.90709452 -3.71788756 -4.02516008\n",
            "  3.11400443 -4.94827089]. \t  -528.183871235126 \t -156.8066019097497\n",
            "50     \t [5.12 5.12 5.12 5.12 5.12 5.12 5.12 5.12]. \t  -943.7184000000001 \t -156.8066019097497\n",
            "51     \t [-5.02791759  2.55534631  5.04553847 -4.56264458  0.50613832  3.04821488\n",
            " -3.50236532  1.57961024]. \t  -360.84067373943356 \t -156.8066019097497\n",
            "52     \t [-4.09641409  0.44100714 -2.60702119  1.49460557 -1.03909807  4.97532564\n",
            " -4.92859504  3.79729263]. \t  -485.80925378200214 \t -156.8066019097497\n",
            "53     \t [ 4.31472767  1.20196802  5.0834425  -4.19248813 -4.87929753 -0.70248663\n",
            "  0.72779827 -3.8654845 ]. \t  -414.5805611338674 \t -156.8066019097497\n",
            "54     \t [ 3.19223747  5.0554682   0.84203938 -2.851315   -3.41475189 -2.3302767\n",
            "  4.90474873  4.80868497]. \t  -540.2202966051871 \t -156.8066019097497\n",
            "55     \t [-3.68164684 -0.02453809  4.47183333  2.4102999   3.36042369 -5.03386025\n",
            " -1.8569878   5.06894121]. \t  -534.9786667284723 \t -156.8066019097497\n",
            "56     \t [-4.78538667 -1.49881935  3.97724371 -0.96283051 -3.75932709  1.89274311\n",
            " -4.84462189 -1.99328643]. \t  -366.79203201310673 \t -156.8066019097497\n",
            "57     \t [-2.81469978 -2.68763012 -4.89336158  4.69049779 -5.08534631  1.36216353\n",
            "  4.11010854 -2.46002523]. \t  -489.30869728708046 \t -156.8066019097497\n",
            "58     \t [ 4.82745585 -4.37769527 -4.51137812  2.21352493  4.62920282  3.29653159\n",
            "  1.4880949  -4.82647331]. \t  -516.4991887037837 \t -156.8066019097497\n",
            "59     \t [ 4.94320718  4.24164054  1.9302371   3.38211587 -2.91114134  0.3588186\n",
            " -3.69480978 -4.01910511]. \t  -385.28380977236304 \t -156.8066019097497\n",
            "60     \t [-3.38602403 -0.41525482 -0.88854535 -4.836665    0.31693361  4.16247784\n",
            " -3.52532721 -3.39073216]. \t  -391.1834893131461 \t -156.8066019097497\n",
            "61     \t [ 3.26991225 -4.21478725  2.58927057  4.78285894  3.0924063  -5.08035916\n",
            "  4.7990503  -3.62595594]. \t  -626.9089303497136 \t -156.8066019097497\n",
            "62     \t [ 3.63916567  2.78889537  4.47644764  4.09556728 -2.5217108  -4.93711052\n",
            " -1.22632227  4.81686433]. \t  -530.1998458187347 \t -156.8066019097497\n",
            "63     \t [-4.89052857  1.60644768 -4.90006605 -3.58821967 -2.98392306 -3.37092505\n",
            " -4.2866997  -0.33910922]. \t  -394.8601609301474 \t -156.8066019097497\n",
            "64     \t [ 1.6879605  -2.49787876  2.35511679  4.08958607  4.58136057  3.580015\n",
            " -5.08426646 -4.35899763]. \t  -613.6651987479415 \t -156.8066019097497\n",
            "65     \t [ 0.51405476 -3.85457987  0.96440356  3.5322989  -1.09149006  4.85346361\n",
            " -2.0229942   4.44533218]. \t  -416.70735964304254 \t -156.8066019097497\n",
            "66     \t [ 4.66622522  2.98824817  5.06997699 -5.02547998 -4.41204872 -3.03198419\n",
            " -5.02063127  1.19762532]. \t  -558.1787662841597 \t -156.8066019097497\n",
            "67     \t [-4.5800052  -3.59589758 -0.43097709 -1.64125697 -3.96168711  4.69075054\n",
            "  0.47832877  3.40395318]. \t  -362.9599621012867 \t -156.8066019097497\n",
            "68     \t [ 4.27339069 -2.11456201 -3.31310737  2.25911948 -4.27353426  4.58179384\n",
            "  1.38717664 -4.16349767]. \t  -449.969137927039 \t -156.8066019097497\n",
            "69     \t [ 1.57242598  3.27928192  4.60415295 -0.84828236  3.3598157  -3.52767511\n",
            " -4.88960515  4.61333522]. \t  -559.1822308746479 \t -156.8066019097497\n",
            "70     \t [ 3.95780072 -1.49775249 -2.0080813  -5.10395269 -2.2502694  -3.42683987\n",
            " -4.13310273  1.43236061]. \t  -368.2181885176443 \t -156.8066019097497\n",
            "71     \t [ 1.03156022 -4.52749394  3.82702437 -4.656528   -1.57677841 -1.56612476\n",
            " -1.96411366 -4.71726424]. \t  -404.9043618897126 \t -156.8066019097497\n",
            "72     \t [ 4.90082817  2.45798618 -3.89390354  3.47890038  2.83264141  0.50365348\n",
            " -4.39482334 -4.16329137]. \t  -445.5065079128009 \t -156.8066019097497\n",
            "73     \t [-4.57246054  3.49997    -0.32697583  4.7930662   0.95861824 -4.3535916\n",
            "  3.47999873  3.34537994]. \t  -430.2442268090353 \t -156.8066019097497\n",
            "74     \t [ 1.14753849 -4.24528835  4.85073844  0.33146607  5.02507769  4.16676096\n",
            "  5.00433803  4.64293137]. \t  -686.5769581142971 \t -156.8066019097497\n",
            "75     \t [ 2.92801821  4.47273032  5.00234988 -2.77927698  3.71964022  4.12496363\n",
            " -0.33577433 -1.15733429]. \t  -337.32711739260947 \t -156.8066019097497\n",
            "76     \t [-0.48021874  0.28201895 -0.16747964  1.44856548 -3.71944748 -1.03644345\n",
            " -4.46807996  2.38363889]. \t  -269.6839778696302 \t -156.8066019097497\n",
            "77     \t [-4.213465   -2.95457365  3.47034518  3.60099425  4.97448422  3.47476849\n",
            " -3.11112862  3.6822397 ]. \t  -495.6073488146653 \t -156.8066019097497\n",
            "78     \t [ 4.25416187 -4.66137062  4.14053243  5.10519263 -0.58689922 -0.15969953\n",
            " -4.87940179  4.75870798]. \t  -566.9362617345502 \t -156.8066019097497\n",
            "79     \t [-1.89957232  1.20233515  5.04820846  3.53209786  0.9753948  -0.88188013\n",
            " -1.20312621 -3.16966112]. \t  -232.78553392261233 \t -156.8066019097497\n",
            "80     \t [-3.87212628  1.19616228  3.4526115   0.65904523  4.00518392  5.08630585\n",
            " -1.73592122 -3.25223393]. \t  -396.4946071333451 \t -156.8066019097497\n",
            "81     \t [-3.14444876 -2.03682024  2.70267317 -4.46570183  4.78972475 -4.66101555\n",
            " -3.41819725  5.06511114]. \t  -651.9571553254289 \t -156.8066019097497\n",
            "82     \t [-0.80562924 -4.25924184 -3.82564838 -2.51048065 -0.11649562  0.96478598\n",
            "  2.83065097 -1.80339376]. \t  -193.80678423021715 \t -156.8066019097497\n",
            "83     \t [-4.48679592  2.78983963  4.86970488 -2.72287813 -2.1532074  -3.08048026\n",
            "  0.3433444   4.98653183]. \t  -416.36294378290313 \t -156.8066019097497\n",
            "84     \t [ 1.80591155 -1.90923933  2.26659889 -4.14560953 -4.77584475 -3.20079918\n",
            "  3.80820097  1.48163206]. \t  -389.30121973133686 \t -156.8066019097497\n",
            "85     \t [ 4.96703557 -0.92578797 -3.37392926 -3.81022088  0.89950217 -2.85292354\n",
            "  3.32216669 -4.09923698]. \t  -383.17498589056413 \t -156.8066019097497\n",
            "86     \t [-4.86378929 -1.65338775  0.32667508  4.84266564  3.95964074 -0.07202492\n",
            "  4.8520292  -2.97092993]. \t  -437.0812280358157 \t -156.8066019097497\n",
            "87     \t [-4.8127301   5.02781768 -4.1941514  -1.76965747  3.06827021 -0.36283341\n",
            " -2.80325485 -0.60844683]. \t  -244.8503639205563 \t -156.8066019097497\n",
            "88     \t [ 4.65526836  0.87562628  4.93081429  4.16781832  0.35692473  1.82600031\n",
            " -0.293538    4.13579541]. \t  -323.7108132186619 \t -156.8066019097497\n",
            "89     \t [-4.78289531 -4.23761    -4.85901696  3.47486778  2.10390228  2.18377799\n",
            "  1.06241423  1.2284295 ]. \t  -248.63844858091727 \t -156.8066019097497\n",
            "90     \t [ 3.98603633  4.88706024 -4.79879405 -4.1861162   4.77261723 -3.72905971\n",
            " -2.83057259  2.55711721]. \t  -508.555219596474 \t -156.8066019097497\n",
            "91     \t [-4.6836957   3.27538059  1.97479356 -0.26684526 -4.68472115 -4.96532827\n",
            " -4.03736984 -1.4726715 ]. \t  -444.4900439706069 \t -156.8066019097497\n",
            "92     \t [-0.76385882  0.8484305  -2.97187113  0.45077527 -4.890244    2.09179994\n",
            "  0.75909477  5.02483526]. \t  -381.1835193028319 \t -156.8066019097497\n",
            "93     \t [ 5.06348997  3.58254901 -0.24364178  1.44248131  3.57462488 -3.31137305\n",
            "  4.65579653 -3.9883531 ]. \t  -468.48097597105703 \t -156.8066019097497\n",
            "94     \t [ 4.43634337  1.46683998  2.43282623  4.3038825   5.10399908 -3.88598876\n",
            "  2.24207439  2.05030308]. \t  -405.5116398089801 \t -156.8066019097497\n",
            "95     \t [-1.90001233  0.10607828 -5.04030538 -3.10984457  3.28783381  3.94222486\n",
            " -0.12548674  1.07929735]. \t  -275.2564872890469 \t -156.8066019097497\n",
            "96     \t [-0.51601658  3.06019574  2.79659915 -3.90701936 -2.55564545  4.06916846\n",
            "  2.01845141  2.42114152]. \t  -310.93781361930445 \t -156.8066019097497\n",
            "97     \t [ 4.72721491 -4.9368871   1.13213171  3.84317292  3.55588041 -0.61975788\n",
            "  3.84513085  4.4855072 ]. \t  -463.9967920562932 \t -156.8066019097497\n",
            "98     \t [-4.69826975 -2.47915133  0.15995136  4.40759255  1.19955204  3.65918652\n",
            " -0.94159875 -4.72016965]. \t  -384.12913410730744 \t -156.8066019097497\n",
            "99     \t [ 1.45790311  4.61687195 -3.94817737  3.50922615 -1.16967981  0.35423674\n",
            " -5.11329838  0.36022872]. \t  -332.43199770749834 \t -156.8066019097497\n",
            "100    \t [-2.39735537 -5.10061712  1.82376367  0.37619678  2.37610989  3.4494455\n",
            "  4.92289297 -2.02341552]. \t  -370.343686901785 \t -156.8066019097497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reLyKt6Quvzx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56844be6-763d-4ab5-bff2-df63870dc523"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 17 \n",
        "\n",
        "np.random.seed(run_num_17)\n",
        "surrogate_winner_17 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_17 = dGPGO_stp(surrogate_winner_17, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 1.55467805  2.36052095 -3.13991821  0.20149492  1.80616465  3.1175155\n",
            "  0.34317173  4.17827   ]. \t  -258.41326242861834 \t -235.79782281711795\n",
            "init   \t [-0.57875324 -2.49884457 -2.26647022 -4.67638414 -0.31769608  4.52212527\n",
            "  1.02815985  3.77559691]. \t  -360.3515407216042 \t -235.79782281711795\n",
            "init   \t [-1.56342663  0.20561354 -4.2801447   1.05706761 -4.41947127 -0.8235598\n",
            "  0.12249555 -4.00962754]. \t  -292.4074163867352 \t -235.79782281711795\n",
            "init   \t [ 4.87253618  0.77758176  1.94038044  4.01713279  4.85251496 -0.60490047\n",
            " -0.9483114   1.04745517]. \t  -235.79782281711795 \t -235.79782281711795\n",
            "init   \t [-1.91993985 -0.06178726  4.23457571  3.73427573  1.95047484 -4.92945438\n",
            "  2.09212815 -3.62478353]. \t  -413.83828931150714 \t -235.79782281711795\n",
            "1      \t [ 2.92453974 -2.51605731 -0.60904243  2.68614124 -0.57198638 -2.52839692\n",
            " -3.69402621  4.20239944]. \t  -327.9829226125071 \t -235.79782281711795\n",
            "2      \t [ 3.8863066   2.5589071  -4.98353817 -4.56667739  1.53215413 -1.86344695\n",
            "  3.9627947   0.2248547 ]. \t  -329.0272762362415 \t -235.79782281711795\n",
            "3      \t [ 2.16672529  3.94234235  4.55864933 -2.41299281  2.00472372  3.74110003\n",
            "  4.74181016  0.87605866]. \t  -389.0155509840251 \t -235.79782281711795\n",
            "4      \t [-4.99925133 -4.18488405 -1.85934976  4.24459381  2.84233518  4.72679143\n",
            "  0.94643919  5.11383892]. \t  -532.3875812684558 \t -235.79782281711795\n",
            "5      \t [-4.32324557  4.16008425  0.73400626  1.37941964  2.39241189  1.2191708\n",
            "  4.5820686   2.43094463]. \t  -294.3103842772912 \t -235.79782281711795\n",
            "6      \t [ 4.42595181  0.54614973  2.56689034 -3.13851565  1.0307697   2.47296272\n",
            " -4.33428986  0.81887648]. \t  -258.2261564362497 \t -235.79782281711795\n",
            "7      \t [-2.64894241  2.33553615 -5.10780976 -4.25671128 -4.05670411 -4.84594794\n",
            " -3.25525895 -0.62605069]. \t  -469.1698806774388 \t -235.79782281711795\n",
            "8      \t [-4.87547998 -1.56374704 -3.87137333  4.60172558 -3.46813326  4.51981227\n",
            " -4.67560113 -2.98692641]. \t  -565.4415383736457 \t -235.79782281711795\n",
            "9      \t [ 5.01018558 -3.23990306  1.04383714  4.28095087 -3.76380738  1.45649926\n",
            "  3.12908065  0.14323236]. \t  -274.93256693980175 \t -235.79782281711795\n",
            "10     \t [-0.42337672  4.61669406 -0.68144138 -2.40854511 -2.2300071  -3.18869405\n",
            "  2.38569872  4.45204396]. \t  -351.6821701601855 \t -235.79782281711795\n",
            "11     \t [ 2.67117625  0.41299568  4.43883274  0.14211974 -1.31876413 -4.67433041\n",
            " -3.51524601 -1.16802904]. \t  -303.8717125415504 \t -235.79782281711795\n",
            "12     \t [-2.39912946 -0.40391774  1.50089901  3.98167608 -0.07684324  3.31681758\n",
            "  4.55010235 -3.45206108]. \t  -382.5502155884982 \t -235.79782281711795\n",
            "13     \t [-4.91803505  2.43422197  4.33040501  1.77553571  4.65284727  0.77129538\n",
            " -2.87632152 -3.95852696]. \t  -399.9916545335009 \t -235.79782281711795\n",
            "14     \t [ 4.11175318  2.80801549 -1.26863971 -3.37463256  3.64211405 -4.6463789\n",
            " -3.17780536  3.49343491]. \t  -447.2371585411927 \t -235.79782281711795\n",
            "15     \t [ 2.71173551 -4.48883927 -1.17375609 -2.07466    -2.88595299 -1.60420718\n",
            "  4.66211335 -4.86499068]. \t  -467.57952055289456 \t -235.79782281711795\n",
            "16     \t [-3.99721755 -4.89643028  0.24902574  4.98268391  0.87508303 -1.69873076\n",
            " -4.24816469 -2.56365359]. \t  -363.4722531738524 \t -235.79782281711795\n",
            "17     \t [-2.3492698   0.23360001 -4.24832167  1.11877893  3.93327539 -4.22850112\n",
            "  0.81081864 -3.73749866]. \t  -365.7673470836286 \t -235.79782281711795\n",
            "18     \t [ 0.22588811 -4.7244156   4.81830482 -4.02245822 -1.87215439  2.07766798\n",
            "  3.62467195  0.82402179]. \t  -319.8849535849431 \t -235.79782281711795\n",
            "19     \t [-0.90152942  4.09186072  4.98192051  4.53977312  3.03038167  4.42184699\n",
            " -3.14089371  4.02928056]. \t  -553.3659171503199 \t -235.79782281711795\n",
            "20     \t [ 1.36183914 -3.95264993  0.5964067   1.60673003  2.84621685 -4.96563471\n",
            "  3.28290177  4.95002935]. \t  -504.4092696086917 \t -235.79782281711795\n",
            "21     \t [-4.96321972 -4.16944412  4.75139811 -2.53929744  3.18619524 -0.70232555\n",
            "  0.51756594 -1.24075349]. \t  \u001b[92m-220.83119955092036\u001b[0m \t -220.83119955092036\n",
            "22     \t [-4.43703409  3.96557084 -3.76612743 -3.90122791 -0.13234085  4.55081576\n",
            " -4.59305978  4.37569763]. \t  -579.7625805028806 \t -220.83119955092036\n",
            "23     \t [-3.65331974  1.38361364  3.26864109 -4.05488092 -1.47161859  5.02080598\n",
            "  1.76695671 -3.68101574]. \t  -407.3290289503428 \t -220.83119955092036\n",
            "24     \t [-3.26179433 -0.2958387  -2.48776736 -4.71089775  4.83068618  2.36668648\n",
            " -1.33147065 -2.04706284]. \t  -314.36983597725276 \t -220.83119955092036\n",
            "25     \t [-0.85826557 -0.67985932  4.19060751  4.85840315 -4.88971669 -0.40410605\n",
            " -5.08539085  1.20509349]. \t  -461.9337956269448 \t -220.83119955092036\n",
            "26     \t [-4.6696752  -1.89912459  3.47568839  0.42439683 -3.42006617  4.27143603\n",
            " -1.10315273  4.33515937]. \t  -392.8036285014716 \t -220.83119955092036\n",
            "27     \t [ 1.70987005 -1.46659499  4.10526643 -4.46520474  4.91944247 -3.62450849\n",
            "  1.71697938 -3.2665722 ]. \t  -443.3643289921355 \t -220.83119955092036\n",
            "28     \t [-0.83512656 -4.9031669   4.59254125  2.90106204  2.47815275  3.56326116\n",
            " -4.36337063  2.83296984]. \t  -450.08443044477997 \t -220.83119955092036\n",
            "29     \t [-5.03658474  2.19741773 -1.81250564 -5.03734992  3.82960213 -4.04760025\n",
            "  3.23929639  0.88273078]. \t  -397.6922483851735 \t -220.83119955092036\n",
            "30     \t [ 0.63351986  0.15783009  5.05722563  1.40278639 -4.50009248 -2.64618684\n",
            "  3.96422938  4.34989383]. \t  -489.69540289718077 \t -220.83119955092036\n",
            "31     \t [-4.43975867  4.84237341 -1.52854437  2.24798874 -3.59272846 -0.02056416\n",
            " -2.57769219  2.01294655]. \t  -237.29991074796197 \t -220.83119955092036\n",
            "32     \t [ 4.84913716 -1.47242746 -1.36125778 -3.88581866  0.46706599  4.46465967\n",
            "  1.0779705  -5.07175436]. \t  -428.41318161578977 \t -220.83119955092036\n",
            "33     \t [-4.22613976 -4.34074043 -4.81022554 -2.1370736   3.949608   -2.39092025\n",
            " -4.69858406  2.82883722]. \t  -474.0788755252838 \t -220.83119955092036\n",
            "34     \t [ 3.95268578  4.15109385 -1.86067712  0.12284429 -4.17245646  3.82576995\n",
            "  3.4921874  -1.80666721]. \t  -346.87964595653995 \t -220.83119955092036\n",
            "35     \t [ 3.59441211  0.02735929 -5.0720281   1.23939876  4.47981018  4.67198041\n",
            " -3.56349122 -3.70365382]. \t  -526.1757423116833 \t -220.83119955092036\n",
            "36     \t [-2.36077224 -1.83521859 -3.72460549  3.30941396 -2.73776209  3.6247377\n",
            "  5.01232755  2.80686516]. \t  -452.9372162053628 \t -220.83119955092036\n",
            "37     \t [ 3.2388431   4.68892488  0.06419265  4.55343367 -3.67688702 -3.69956067\n",
            "  1.96500398 -1.57070058]. \t  -333.89300509758795 \t -220.83119955092036\n",
            "38     \t [ 5.00984969 -4.75358018  3.67958593 -3.9664102  -2.97441938 -0.6986476\n",
            " -2.76115774 -3.70203639]. \t  -384.0123759912306 \t -220.83119955092036\n",
            "39     \t [ 5.0410188  -4.70743079 -2.94974251 -4.76088396 -2.535342   -2.49645058\n",
            " -4.06176041  0.74237105]. \t  -375.92627644881793 \t -220.83119955092036\n",
            "40     \t [ 5.10301839 -0.0937274   0.22189301  2.14508301 -4.05743067  4.48112186\n",
            " -3.45448772  3.85690073]. \t  -449.9479012486381 \t -220.83119955092036\n",
            "41     \t [-3.87516804  4.6397725   4.70942434 -2.80824276 -1.02175933 -2.13351497\n",
            "  0.11060481 -1.42549101]. \t  \u001b[92m-205.02595598207063\u001b[0m \t -205.02595598207063\n",
            "42     \t [ 3.20225819 -4.64997073 -2.3140201   1.11743208  3.60051651  1.7394131\n",
            "  4.50937504  1.57411612]. \t  -319.6935164903707 \t -205.02595598207063\n",
            "43     \t [-1.68037373  2.99309485  3.00744848  4.88009628  5.08240124 -4.86963284\n",
            " -4.1109153   2.70368847]. \t  -591.3472661896043 \t -205.02595598207063\n",
            "44     \t [-4.94816616 -1.97043603  2.08399373 -3.90732487 -0.14484039 -2.60918695\n",
            " -4.9047926  -4.14635006]. \t  -453.2361412261049 \t -205.02595598207063\n",
            "45     \t [-1.49909554 -4.1680457   2.95678514 -0.58863162 -4.68033491  4.4464532\n",
            " -3.4041497  -3.31568499]. \t  -461.82731381194554 \t -205.02595598207063\n",
            "46     \t [ 4.78980614 -4.78015147  4.69514666  3.09370548  2.78784976 -4.57333187\n",
            "  2.52515842 -1.33038845]. \t  -396.2063603686764 \t -205.02595598207063\n",
            "47     \t [-0.05480636  4.88217103 -0.37779927  4.73746432  2.37838828 -0.46693391\n",
            " -2.41735295 -2.28608104]. \t  -250.18297814978087 \t -205.02595598207063\n",
            "48     \t [ 4.20409799 -4.52024413 -4.71758067 -4.41478415  5.02381959 -2.3166208\n",
            " -4.37193515 -4.02680406]. \t  -625.1797668305451 \t -205.02595598207063\n",
            "49     \t [ 0.62464254 -4.6406222   0.77589825 -1.07509506  3.57241657  2.00423113\n",
            " -3.28995348 -4.74340178]. \t  -393.568194739979 \t -205.02595598207063\n",
            "50     \t [-4.49521975 -4.73714789 -1.21702656 -5.01983197 -4.53916275  2.97783395\n",
            "  4.34367029 -2.71759036]. \t  -517.7060960988451 \t -205.02595598207063\n",
            "51     \t [-2.65699505  4.83534246  5.03362752 -1.09319278 -4.43262838  4.5402452\n",
            " -4.32962744  0.04712066]. \t  -487.7746058376343 \t -205.02595598207063\n",
            "52     \t [-3.46948539 -4.65612483  1.22131559  3.84884214 -2.0380224  -2.04906727\n",
            "  4.90682207  1.34264673]. \t  -348.04516240525726 \t -205.02595598207063\n",
            "53     \t [ 0.78357163  4.84182822 -4.33978375  2.18903713  5.08412242  2.27859392\n",
            "  3.61706653 -3.09048344]. \t  -451.55362922567826 \t -205.02595598207063\n",
            "54     \t [-5.00623267e+00  2.03426865e-01 -3.98589712e-04 -4.73021352e+00\n",
            " -3.88520108e+00 -1.98291759e+00 -2.94278167e+00  4.22307715e+00]. \t  -417.00531388592685 \t -205.02595598207063\n",
            "55     \t [ 3.16459652  3.40656449 -2.1256128   0.01318661 -3.60738698 -0.64106391\n",
            " -4.51433723 -1.43181177]. \t  -273.36676457782994 \t -205.02595598207063\n",
            "56     \t [ 4.8735424   5.02114591 -4.41934753 -4.80488511  4.88862602  1.57135164\n",
            " -4.99558317 -2.3600073 ]. \t  -578.6710408501269 \t -205.02595598207063\n",
            "57     \t [-0.23481924 -2.63149418 -2.90137663 -2.71039618 -4.32860317 -1.80870698\n",
            "  3.57787302  2.67165334]. \t  -328.56624456440926 \t -205.02595598207063\n",
            "58     \t [ 5.01294029  4.43078465  0.66675486 -4.80069846 -4.78779884 -1.54983127\n",
            "  0.93312558 -3.0990618 ]. \t  -369.8692706852889 \t -205.02595598207063\n",
            "59     \t [ 4.80145231 -3.89096919 -3.00948812 -1.700837    4.55098885  4.9604921\n",
            " -2.86312225  4.28209729]. \t  -547.3451984729469 \t -205.02595598207063\n",
            "60     \t [ 4.69133748 -1.22322143  3.78302844  3.59997142  3.5654863   3.61800134\n",
            "  5.04335067 -4.79005764]. \t  -623.4822619907247 \t -205.02595598207063\n",
            "61     \t [ 0.44645403 -4.32097596  1.36898319 -5.07255265  1.61439114 -3.11756774\n",
            " -3.60155927  3.22361593]. \t  -391.36536145568886 \t -205.02595598207063\n",
            "62     \t [-1.33201596  3.30656642  5.11805961 -2.16135368  0.96660189 -4.51299684\n",
            " -3.00976272  4.91879553]. \t  -504.7519668898011 \t -205.02595598207063\n",
            "63     \t [-4.709394   -0.90855701 -2.3126079   4.45736341  0.92116073 -3.46605578\n",
            " -4.11301153  4.44249165]. \t  -471.97400846933556 \t -205.02595598207063\n",
            "64     \t [ 2.58713524  2.8130289   3.16169102  1.45031305  4.03076594  4.57595416\n",
            " -3.58430332 -4.84183818]. \t  -545.27133121054 \t -205.02595598207063\n",
            "65     \t [ 4.28273394 -0.21918968  2.78487533 -4.79375839 -4.18986546 -2.76124552\n",
            " -3.43650881  3.9992659 ]. \t  -477.7668631075229 \t -205.02595598207063\n",
            "66     \t [ 3.40412854 -0.56271544  0.60838977  1.05228998  5.08996922 -4.91008819\n",
            " -2.5115292  -3.78610496]. \t  -450.78496697065316 \t -205.02595598207063\n",
            "67     \t [-1.83597245 -3.890787   -4.43567888  1.84144286  0.48428172  3.13482287\n",
            " -4.72210753  3.92063305]. \t  -445.4309656208303 \t -205.02595598207063\n",
            "68     \t [ 3.00680152 -2.31445374  4.72027614 -4.58094882  3.14332075 -2.8175391\n",
            "  2.65152436  4.92181319]. \t  -510.57915351174734 \t -205.02595598207063\n",
            "69     \t [ 3.93322014 -1.23249563 -3.38893041  4.90422009 -0.26986431  4.03503585\n",
            "  2.25782766 -4.22834284]. \t  -425.93714344534067 \t -205.02595598207063\n",
            "70     \t [-5.036661    4.95862167  1.27543981 -2.00052256  4.77638642  3.10684916\n",
            "  4.06865255 -4.96409636]. \t  -580.4323762902309 \t -205.02595598207063\n",
            "71     \t [ 3.43643853  4.86561813 -2.82830931  2.35804048  1.257945   -4.63762292\n",
            "  4.69455667  4.30983671]. \t  -545.2239916608052 \t -205.02595598207063\n",
            "72     \t [-3.11143536  3.66584662 -0.79184491 -1.74974105 -2.95623384 -0.43997248\n",
            "  4.84095619 -3.0621572 ]. \t  -334.6018214603655 \t -205.02595598207063\n",
            "73     \t [-3.91609078  4.93539131 -4.09681164 -2.90362741  4.3958853  -3.18762264\n",
            " -4.30692775 -3.0484357 ]. \t  -509.90348212271005 \t -205.02595598207063\n",
            "74     \t [ 1.98644632  0.43258677 -4.93978106 -5.06522396 -4.14735352 -4.8650203\n",
            "  3.63348669 -2.59279363]. \t  -554.3599683503475 \t -205.02595598207063\n",
            "75     \t [ 3.77323961 -3.03410517  4.00144806  2.59409153 -4.49645754 -3.68266383\n",
            "  4.05747602 -3.88539422]. \t  -526.0757453822283 \t -205.02595598207063\n",
            "76     \t [-5.06967632 -4.20586583 -2.03434115  2.62327392  1.9203913   4.72337951\n",
            "  0.40815848 -3.64132286]. \t  -360.5635373090101 \t -205.02595598207063\n",
            "77     \t [-2.73231808 -4.95278489  3.29332042 -3.91364209 -4.30632973 -2.58435509\n",
            "  1.58401072 -4.39207298]. \t  -455.0117706965909 \t -205.02595598207063\n",
            "78     \t [ 2.29068311 -3.6568479  -4.29098119  4.25845795 -4.53150324 -4.67839536\n",
            "  4.29047449 -1.08641953]. \t  -532.064282931324 \t -205.02595598207063\n",
            "79     \t [-2.00576029  4.89410937 -4.48242706 -4.64834865  3.55292604  4.90747721\n",
            "  3.43421414 -0.95765167]. \t  -496.1426987132206 \t -205.02595598207063\n",
            "80     \t [ 1.10984167 -2.67667576  4.23280529 -0.80036895  4.70724277  4.90827792\n",
            "  1.81936012  2.96417722]. \t  -420.6723153315192 \t -205.02595598207063\n",
            "81     \t [-3.74400663  3.67080985 -5.04099399 -2.89045701 -0.98954821  1.76056058\n",
            " -2.42729915 -4.96087177]. \t  -412.23903161600947 \t -205.02595598207063\n",
            "82     \t [-5.07758312  2.10285873  4.08485673 -3.5204471   3.65860524  1.93946269\n",
            " -4.20706456  2.56198652]. \t  -400.1602339957926 \t -205.02595598207063\n",
            "83     \t [-3.73355403  3.36676048 -2.45982605  4.54229321  4.65249099  0.8921701\n",
            " -0.80552361  4.42095731]. \t  -411.1966742189892 \t -205.02595598207063\n",
            "84     \t [-2.40027779  3.45409221  4.91581768 -1.09877901 -4.05034204  4.43863326\n",
            "  4.00401904  5.04391731]. \t  -622.9370292291547 \t -205.02595598207063\n",
            "85     \t [-0.5612633  -0.46955463 -4.60783304  3.80442318  0.15353174 -3.37681949\n",
            " -4.54989294 -2.98019004]. \t  -406.84515958192 \t -205.02595598207063\n",
            "86     \t [ 4.7606935  -3.97804724  3.399304    4.87169627  0.02531253  1.52317986\n",
            " -3.05106263 -2.95047727]. \t  -332.6424999131109 \t -205.02595598207063\n",
            "87     \t [-5.11102148  4.70893566  3.41853809  4.04475808 -3.56362402  1.62123025\n",
            " -0.34411612 -3.62615267]. \t  -356.25835350096054 \t -205.02595598207063\n",
            "88     \t [-1.25653437  4.12747933 -0.15847774  5.02226809 -5.08260637  1.57991726\n",
            "  4.72258641  4.67641875]. \t  -611.8312666355934 \t -205.02595598207063\n",
            "89     \t [ 4.76254396  3.08572617 -0.44898445  4.81856549 -4.5420816   3.05134397\n",
            " -1.68595412 -4.92107743]. \t  -507.8541319313182 \t -205.02595598207063\n",
            "90     \t [-0.81463591 -3.36125426 -1.31757394 -1.30985479  4.57415835 -0.06401277\n",
            "  4.09360705 -4.03553101]. \t  -387.5571979648348 \t -205.02595598207063\n",
            "91     \t [-4.27679822 -4.04316005 -3.21471678 -2.7925222  -5.02941637 -0.12171552\n",
            " -3.00365824 -1.73546545]. \t  -326.9937174333498 \t -205.02595598207063\n",
            "92     \t [-4.77735319  4.04414258 -2.5334635   2.66927273 -4.02986687  4.92818197\n",
            "  4.68689733 -2.93829773]. \t  -553.0474560941333 \t -205.02595598207063\n",
            "93     \t [-3.70635996  2.07407641 -4.49908431  4.0775599  -1.29915568 -4.71654226\n",
            "  4.15033063  1.97970834]. \t  -443.41627198459395 \t -205.02595598207063\n",
            "94     \t [ 3.642551   -3.16172975 -3.80220264  4.22903359 -4.5622136  -0.12777562\n",
            " -3.56298398 -2.23574934]. \t  -381.1898922605 \t -205.02595598207063\n",
            "95     \t [-2.95317364  3.77739479  3.70785463 -2.93038224  4.14204565 -5.06876145\n",
            " -4.01675845 -4.52136431]. \t  -629.2708632134819 \t -205.02595598207063\n",
            "96     \t [ 5.11608339  3.82500049  3.10860187  4.36924341  0.45399812  4.9231055\n",
            " -0.083523    4.83824593]. \t  -494.55713579548274 \t -205.02595598207063\n",
            "97     \t [-2.81289616 -1.49138288  5.09289535  5.11473124  3.3988393  -3.85103031\n",
            "  4.64262937  4.04776156]. \t  -623.5116735904198 \t -205.02595598207063\n",
            "98     \t [ 4.52750334  0.05474583 -4.2886581   1.95447475  1.86505201 -4.50240119\n",
            "  4.40171197 -1.49705254]. \t  -383.53853413621516 \t -205.02595598207063\n",
            "99     \t [-5.03205441 -2.75645529 -3.8510492   2.27047723  5.01417274 -0.30507402\n",
            "  4.9904504   1.03580178]. \t  -414.8129818978998 \t -205.02595598207063\n",
            "100    \t [-4.48019044 -4.5677739  -3.094116   -2.69135024  2.13444759 -1.11752453\n",
            "  4.24994121  5.01505313]. \t  -477.4079139091402 \t -205.02595598207063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI3FtfYSuv2u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24104b1f-5fab-488b-9d41-9c7aac60c4d2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 18 \n",
        "\n",
        "np.random.seed(run_num_18)\n",
        "surrogate_winner_18 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_18 = dGPGO_stp(surrogate_winner_18, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 3.82391708  4.79785639  3.78055209  0.31596228 -2.73686192 -5.00327624\n",
            " -0.7119993  -0.99992207]. \t  -303.134303896496 \t -81.06401370190679\n",
            "init   \t [ 0.23218863 -0.22126801  0.56685029  0.44427282  2.67157069  2.17471564\n",
            "  1.22554466 -0.75682027]. \t  -81.06401370190679 \t -81.06401370190679\n",
            "init   \t [-2.15987171  4.85227767 -1.70215377 -2.87947714 -4.44612211  4.9445944\n",
            " -3.8107575  -1.82138068]. \t  -467.3384008943868 \t -81.06401370190679\n",
            "init   \t [-4.39354527 -2.81835582 -1.08917847  4.05652485 -1.58247309  4.96383424\n",
            " -4.82578382 -1.5187483 ]. \t  -446.39910875588674 \t -81.06401370190679\n",
            "init   \t [-1.21898097  2.70499975  4.49335207 -1.84637648 -0.69144645 -2.35370761\n",
            "  3.08281228  1.41556537]. \t  -208.5138761485756 \t -81.06401370190679\n",
            "1      \t [-4.72153807 -0.54862943 -3.19311344  1.30104982 -2.91514573 -3.5740661\n",
            "  0.3701177  -4.09203923]. \t  -314.305007357293 \t -81.06401370190679\n",
            "2      \t [ 4.75749964  2.50666145  1.4600848   4.10414325  4.79668006  1.14293188\n",
            " -1.90940471  5.05737721]. \t  -461.98777226929315 \t -81.06401370190679\n",
            "3      \t [ 3.06126016 -5.03739926  1.34009691 -2.83917989  0.15922462 -3.0285552\n",
            "  1.53342461 -0.79266576]. \t  -174.39937676687128 \t -81.06401370190679\n",
            "4      \t [ 0.42370315  2.76051631 -4.28684083 -1.00813757  0.23910174 -4.20360952\n",
            " -5.10789117  4.0388014 ]. \t  -494.0538487164447 \t -81.06401370190679\n",
            "5      \t [-1.31381342  1.34414963 -1.47029586 -3.19585654  3.99004733 -3.77203562\n",
            "  4.83680135 -3.53343442]. \t  -481.29459380418626 \t -81.06401370190679\n",
            "6      \t [ 3.87143811  4.99112582 -2.67262829  3.59590374 -0.99582885 -1.3363236\n",
            " -3.17576347 -2.26273187]. \t  -265.1925272704262 \t -81.06401370190679\n",
            "7      \t [ 3.6239736  -2.07083955  3.38746594  0.9570053  -4.24943996 -3.40232466\n",
            " -1.03826705  4.48450426]. \t  -387.9739458792113 \t -81.06401370190679\n",
            "8      \t [-2.67011192 -4.3861491   0.03339287  4.28335213 -3.32871591  1.9178593\n",
            "  4.60164064 -3.53096187]. \t  -444.4359364235899 \t -81.06401370190679\n",
            "9      \t [-2.91800834  4.94512966 -4.26505397  1.08038774  3.72853718  4.88835747\n",
            " -3.05806134 -0.86423166]. \t  -400.9879197183122 \t -81.06401370190679\n",
            "10     \t [-2.64600344 -3.81202872 -2.09543011 -2.96220218  3.44003821  0.42606833\n",
            " -5.02260132  0.26824148]. \t  -321.7553250826761 \t -81.06401370190679\n",
            "11     \t [-2.6056795   4.54917357 -3.14651348  1.6266389  -1.5347445   3.64704866\n",
            "  4.17425833  1.99667248]. \t  -333.91260727793957 \t -81.06401370190679\n",
            "12     \t [-1.22014713  1.35461272  3.80622469  3.76586181 -1.33734579  4.32559537\n",
            "  3.27711706  4.80301625]. \t  -486.28292551430087 \t -81.06401370190679\n",
            "13     \t [-3.90330747  3.55185923  0.83728002  3.61324973  4.59515387 -4.97165056\n",
            " -0.44420214 -2.14083268]. \t  -386.7202012156301 \t -81.06401370190679\n",
            "14     \t [ 5.08117826  4.94425657  0.1866043   4.59414278  3.91729518 -1.80866883\n",
            "  4.9771769  -4.323152  ]. \t  -578.5156537778839 \t -81.06401370190679\n",
            "15     \t [ 4.75445204 -0.91862731  1.83569572  2.35377966  3.83313582 -1.52291889\n",
            " -3.47518151 -5.09341337]. \t  -436.02444436064064 \t -81.06401370190679\n",
            "16     \t [-4.88682301 -3.99155186 -4.74673714  1.01004651  4.07950327  3.68229071\n",
            "  3.24983814 -1.84439949]. \t  -393.1332631565087 \t -81.06401370190679\n",
            "17     \t [ 3.52157776 -4.85901561 -0.7743586  -4.99596051  1.1542038   5.03552961\n",
            " -1.7038783  -2.12853273]. \t  -376.62685910896926 \t -81.06401370190679\n",
            "18     \t [ 4.2630053  -1.32637586 -4.98225395  1.23955078 -0.22202057  4.16810733\n",
            " -3.64249584  1.147865  ]. \t  -310.2066300432564 \t -81.06401370190679\n",
            "19     \t [ 4.3255579   2.43208629  2.80901089 -0.74812327 -1.71656587  2.37303961\n",
            " -4.9186684   3.78925884]. \t  -389.192764740545 \t -81.06401370190679\n",
            "20     \t [-4.1558945  -2.73328753 -4.40569961 -3.37161887 -1.55874088  0.25645336\n",
            "  0.91485     4.36972202]. \t  -307.07239638706864 \t -81.06401370190679\n",
            "21     \t [-4.5267117   2.77190971  2.60208934  3.86844599  4.32092749  4.28810044\n",
            "  4.94262214 -2.83787841]. \t  -555.1441205944673 \t -81.06401370190679\n",
            "22     \t [ 4.7423395   5.03747397 -4.55515229  1.39590126 -4.36551377 -1.87260315\n",
            "  4.62891756 -0.40094315]. \t  -410.88706603620045 \t -81.06401370190679\n",
            "23     \t [ 4.00367566 -2.64452311 -5.03722255 -3.7701624  -4.98462007  0.78738806\n",
            "  1.73982537 -3.09302869]. \t  -388.66937879676914 \t -81.06401370190679\n",
            "24     \t [-4.61145368  3.6422625   0.87177615 -4.17356508 -3.98149942 -1.00353695\n",
            " -2.42142665  4.66765263]. \t  -420.3954248444994 \t -81.06401370190679\n",
            "25     \t [-0.09940172 -3.7593408   0.72934153 -2.34892622 -4.85248507 -4.4733624\n",
            " -3.91123637 -3.70722472]. \t  -506.77219607313873 \t -81.06401370190679\n",
            "26     \t [ 4.7322549   2.45450633 -3.80456292 -4.96731663 -0.84582793 -1.46169316\n",
            "  0.98967966  3.75015429]. \t  -312.3263979111322 \t -81.06401370190679\n",
            "27     \t [-3.08500626  0.03018548 -4.57292394  1.82921434  2.14156205 -3.44925189\n",
            "  4.42839484  3.34148083]. \t  -406.5522766850934 \t -81.06401370190679\n",
            "28     \t [-3.46350391  4.76172687  0.8113278   4.39629572 -1.36463868  3.12673806\n",
            " -4.47399674  2.39792175]. \t  -390.71526392067415 \t -81.06401370190679\n",
            "29     \t [ 4.96644023  2.11890136  3.29572578 -4.93492309  3.21215367  4.92368311\n",
            "  4.11633011 -0.45694135]. \t  -480.9694696503153 \t -81.06401370190679\n",
            "30     \t [-4.27434826 -4.75167259  5.01585273  1.96264437 -3.65827224 -4.43248943\n",
            "  1.82050017 -0.35853041]. \t  -363.3355178541378 \t -81.06401370190679\n",
            "31     \t [ 3.98172995 -1.98335507  2.22510828  4.35924854 -3.59262444  1.0690832\n",
            " -0.60842807 -1.89138863]. \t  -217.18956587450114 \t -81.06401370190679\n",
            "32     \t [-4.33748721  2.60828047  1.95013698 -4.29588939  2.69979227  0.42015405\n",
            " -2.64248015 -3.40339149]. \t  -296.6948814183274 \t -81.06401370190679\n",
            "33     \t [-1.63410848 -4.03040409  1.08159698 -4.75100418 -0.81415778  4.85708735\n",
            " -2.25570958  4.21036957]. \t  -451.25366829540985 \t -81.06401370190679\n",
            "34     \t [ 2.28414197 -4.31221476 -2.07221893  4.34554907  0.58472264  3.60499811\n",
            "  2.65909693  4.80102296]. \t  -444.40487519429917 \t -81.06401370190679\n",
            "35     \t [ 3.31576885 -4.77868122  4.46468119 -5.0446848   5.0903975   0.71111716\n",
            " -2.6282192   4.89269898]. \t  -590.7170633026457 \t -81.06401370190679\n",
            "36     \t [ 3.72312416 -4.931656    3.96995715  4.73176427  2.24239716 -2.42311674\n",
            "  3.80402702  1.67275657]. \t  -383.39412788663145 \t -81.06401370190679\n",
            "37     \t [-4.60179965 -3.15807307  4.72435448 -2.57124812  3.77690678 -4.38187575\n",
            "  0.38279297  4.45779594]. \t  -481.05865944266355 \t -81.06401370190679\n",
            "38     \t [ 4.88174211 -0.32220004  3.96513949 -3.93664237 -3.10262133  2.43797588\n",
            "  2.0702309  -5.11566669]. \t  -456.34964917405085 \t -81.06401370190679\n",
            "39     \t [-2.44351324 -4.27534621  5.05601371 -5.05925586 -3.45054224 -0.43082563\n",
            "  2.77014506 -2.89815142]. \t  -403.1570824755569 \t -81.06401370190679\n",
            "40     \t [-4.75650543 -4.45494567  4.76909976  2.78129452  2.46539107  4.45400311\n",
            " -2.24630396  4.21969062]. \t  -488.6798694144187 \t -81.06401370190679\n",
            "41     \t [-3.27201417  4.06706917 -5.0402363  -2.36719301  4.56905956 -1.19090822\n",
            " -0.05648644  5.02633206]. \t  -457.44008427368806 \t -81.06401370190679\n",
            "42     \t [ 4.7831904   1.258516    4.75191963 -3.77408499  3.52474327  3.64596322\n",
            " -4.41334133 -4.87581385]. \t  -619.1726458444527 \t -81.06401370190679\n",
            "43     \t [ 3.58475976  2.87334066  2.47355483 -3.43187076  4.6069875  -4.25049139\n",
            " -2.46918052 -1.15397507]. \t  -362.68201010633834 \t -81.06401370190679\n",
            "44     \t [-3.84134844  2.12131206  4.69784164  4.92012942 -3.92894185  5.00409841\n",
            "  0.61213143 -3.29082384]. \t  -503.48376152908827 \t -81.06401370190679\n",
            "45     \t [-2.18456297 -4.53639129  1.25858833  4.61483024 -0.91100653 -4.91821825\n",
            " -4.14146324  2.15537693]. \t  -442.3788846454878 \t -81.06401370190679\n",
            "46     \t [-3.31150466 -2.31947059  5.07268278 -3.984883   -3.24944383  4.93322232\n",
            " -4.86227937 -3.42614648]. \t  -620.6541359001819 \t -81.06401370190679\n",
            "47     \t [-4.6200198  -3.05873743 -3.0129435   2.50291932  5.04898909  2.7259044\n",
            " -4.51305148  4.9319423 ]. \t  -601.5588961140031 \t -81.06401370190679\n",
            "48     \t [ 2.07226183e+00 -4.44302497e+00 -4.99460197e+00  3.03735663e+00\n",
            "  8.76434789e-01 -2.48803936e-04  4.26523539e+00 -4.99397929e+00]. \t  -486.2204519720578 \t -81.06401370190679\n",
            "49     \t [-2.7694886   2.2075048   3.35602544  2.44639063  1.43947814 -2.56681729\n",
            " -2.42729701  4.95203606]. \t  -362.4597274287164 \t -81.06401370190679\n",
            "50     \t [ 4.87922706  3.75295175 -3.60587812 -2.6709506   2.27780989  1.28831097\n",
            "  1.30528719 -4.63460948]. \t  -339.18295341376813 \t -81.06401370190679\n",
            "51     \t [ 3.84855428  3.51726439  2.72884973 -2.91947549 -2.25912324  2.46870496\n",
            "  4.95723305  5.02634915]. \t  -532.2046960390614 \t -81.06401370190679\n",
            "52     \t [-0.84634296 -4.53088322 -2.80718366  3.20500061  3.97066302 -4.85276684\n",
            " -4.87850393 -4.46780861]. \t  -652.9190721300588 \t -81.06401370190679\n",
            "53     \t [ 4.71519299 -4.76147773 -3.02118575 -3.41387917 -3.34825505 -0.09087317\n",
            " -3.58048455  3.92228606]. \t  -410.49467702372175 \t -81.06401370190679\n",
            "54     \t [ 0.70305189  4.80245338  3.56399267  4.27598892 -4.68883722 -1.2158213\n",
            "  3.03199885 -4.01219239]. \t  -469.79177770668036 \t -81.06401370190679\n",
            "55     \t [-3.3495296  -4.43371061 -0.06696515 -4.4322153   2.41993485 -4.39999306\n",
            " -0.7843403  -3.61445865]. \t  -383.38738672660725 \t -81.06401370190679\n",
            "56     \t [-0.32145891  1.34735181 -0.87586002 -2.86746321 -3.50642788 -0.25386599\n",
            "  4.77018035 -4.51805057]. \t  -423.3712845715715 \t -81.06401370190679\n",
            "57     \t [ 1.02158437  3.88560267  3.4986697   4.34079991 -2.78894628 -5.07569651\n",
            "  4.53419292  3.67482352]. \t  -588.7459338931741 \t -81.06401370190679\n",
            "58     \t [-2.36626385  4.35008119 -4.63165369  5.02428938 -0.9382117  -3.27572993\n",
            "  5.11908183 -2.69735713]. \t  -519.2007206198745 \t -81.06401370190679\n",
            "59     \t [-4.9828632  -1.19522556 -4.07039595  2.81607842 -3.45048605 -1.24995082\n",
            " -4.98040154  4.78504904]. \t  -534.8194976540077 \t -81.06401370190679\n",
            "60     \t [-1.04972728 -4.54998593 -3.22352271  4.99031611 -4.02337011 -4.75241527\n",
            "  4.28848036 -0.26426774]. \t  -519.0393734472926 \t -81.06401370190679\n",
            "61     \t [-4.5886668   3.8745019   1.11862306 -2.75503148  5.07270094  4.87999168\n",
            "  5.0431641   3.29682019]. \t  -621.7282418282285 \t -81.06401370190679\n",
            "62     \t [-4.77491482  1.32515195 -0.41043974 -4.65390123 -4.74451534 -1.5982478\n",
            " -3.52936768 -3.21378782]. \t  -411.1534520820159 \t -81.06401370190679\n",
            "63     \t [ 0.1191111  -2.31708872  2.22894563  1.05851393  4.63258719  5.01524388\n",
            " -3.40959924 -4.62782881]. \t  -541.070703240611 \t -81.06401370190679\n",
            "64     \t [-0.53476343  0.57081205 -1.65514107 -4.28852159  4.94722844 -4.16158605\n",
            "  4.81359251  4.40562242]. \t  -626.4806883848486 \t -81.06401370190679\n",
            "65     \t [ 3.63613716  4.70455568 -4.08262919  4.67108247  1.90389387 -1.91451658\n",
            "  3.85789018  4.66321389]. \t  -513.0308389932916 \t -81.06401370190679\n",
            "66     \t [ 3.83723072 -4.00834688 -3.6460942   0.68935332  4.61750014 -3.7234163\n",
            " -2.01129861  4.32763565]. \t  -456.5750786293993 \t -81.06401370190679\n",
            "67     \t [ 3.21359478 -4.22358242 -3.28239437  4.79701792  5.07258569  2.18249161\n",
            " -4.80468577 -1.47696118]. \t  -506.6539483015838 \t -81.06401370190679\n",
            "68     \t [-4.67664345  1.80040022  2.18710213 -3.97669561 -2.94398525  3.77896671\n",
            "  2.20715191 -0.36225442]. \t  -270.1298000787562 \t -81.06401370190679\n",
            "69     \t [ 3.25379901  3.16445704  5.07918889  3.30408815  0.24241666  4.16313956\n",
            " -5.09939547 -3.97661412]. \t  -564.495991147676 \t -81.06401370190679\n",
            "70     \t [ 4.48438671  3.72980338 -3.68670335  4.33706856  0.75645832  4.38481119\n",
            "  3.0468733  -1.23899927]. \t  -359.4341629546412 \t -81.06401370190679\n",
            "71     \t [ 3.3751119  -5.09941389  4.94327867 -4.63558396 -4.95303967  0.97283334\n",
            " -4.28847243 -1.10463529]. \t  -489.50215266879707 \t -81.06401370190679\n",
            "72     \t [ 4.2847544  -4.66465208  4.31796247 -4.60235499  3.69470046 -3.05180182\n",
            " -4.04504373 -2.99683573]. \t  -513.0580340386916 \t -81.06401370190679\n",
            "73     \t [-0.74898158  1.00506749 -4.56618554  2.32641812 -4.2320123   2.61788828\n",
            " -0.17292544 -2.4724629 ]. \t  -266.56391017892616 \t -81.06401370190679\n",
            "74     \t [ 4.19693252 -3.85580846 -4.35036687  2.93927826 -2.71963414 -2.58612162\n",
            " -0.1427993   4.6771161 ]. \t  -390.93952380884343 \t -81.06401370190679\n",
            "75     \t [ 2.63166151 -3.59799653  4.63731933  4.79767935  3.79569233  0.85272054\n",
            " -4.67037249  1.12653862]. \t  -428.6404639611209 \t -81.06401370190679\n",
            "76     \t [ 4.73809578  2.44203172 -0.18877941 -3.45155274  4.70527201  3.05247532\n",
            " -5.04711975  0.8179252 ]. \t  -432.40586225662463 \t -81.06401370190679\n",
            "77     \t [ 0.29139535  3.86152188 -0.48818806  5.03888233  5.02150134  2.05280379\n",
            " -3.91008963 -4.13023109]. \t  -527.0374132149791 \t -81.06401370190679\n",
            "78     \t [ 2.61448126  1.82391347 -4.48375546 -2.07421439 -4.98793096 -2.28612102\n",
            " -4.49603735 -1.51887957]. \t  -406.7222798811069 \t -81.06401370190679\n",
            "79     \t [-1.00094775 -1.92644165  4.92088795 -4.55315363  4.3430194   4.97977381\n",
            "  2.0895649   5.04226956]. \t  -641.0522974657667 \t -81.06401370190679\n",
            "80     \t [-1.37973052  4.95890003  4.53849757  2.01034946  3.79519985  4.32101058\n",
            " -2.59629503 -0.06762615]. \t  -360.3112613507633 \t -81.06401370190679\n",
            "81     \t [5.12       5.12       5.12       5.12       0.61047235 3.80173403\n",
            " 5.12       1.47890544]. \t  -551.7245625984319 \t -81.06401370190679\n",
            "82     \t [-3.93858884  5.09165132 -2.55621601  3.42938193  5.02942059 -4.99131033\n",
            " -4.6261735   4.4626711 ]. \t  -719.0959367490492 \t -81.06401370190679\n",
            "83     \t [ 3.40611398 -4.39022359 -2.07538622 -1.48536154 -4.68573954  3.64340384\n",
            " -4.2590988  -4.72745492]. \t  -567.0938407347105 \t -81.06401370190679\n",
            "84     \t [ 1.72126989  0.77033935 -1.26122968  1.26620044 -0.97087038 -4.7657264\n",
            "  3.06804546 -1.01884531]. \t  -230.51529264833167 \t -81.06401370190679\n",
            "85     \t [ 2.2644728  -4.23645439 -5.00314977  3.37562349 -4.11020592  2.45613943\n",
            "  3.48046371  0.0731325 ]. \t  -367.1996564037859 \t -81.06401370190679\n",
            "86     \t [-5.0807791  -1.42605787  3.99728216  1.38872716  1.4542865  -0.59056244\n",
            "  0.78167099 -4.40405759]. \t  -257.6408274335402 \t -81.06401370190679\n",
            "87     \t [-4.22794591 -1.46882208  0.84198417  4.68620288  4.41592491  0.64341254\n",
            "  2.76642118  2.93457091]. \t  -334.6103015248775 \t -81.06401370190679\n",
            "88     \t [ 3.47199467 -2.79317693 -3.72337549  2.66733183 -4.50034661 -2.16154575\n",
            " -3.42552501 -4.50178909]. \t  -471.2753024744644 \t -81.06401370190679\n",
            "89     \t [ 3.10147518  4.82704895  4.92704107 -4.58450518 -3.17090038  2.2974675\n",
            " -2.5611166  -1.68906185]. \t  -363.7997582447187 \t -81.06401370190679\n",
            "90     \t [-3.3211227   4.34213367 -4.64799383 -4.38942223 -2.92680495 -1.60363013\n",
            "  1.99555831  1.03837503]. \t  -285.38002183686393 \t -81.06401370190679\n",
            "91     \t [-3.43237087 -3.65362625  1.39470203 -5.08261437  2.42450644  0.42547184\n",
            "  4.65690425  2.16451436]. \t  -367.41219049414616 \t -81.06401370190679\n",
            "92     \t [-2.35871386 -2.99564123 -2.95141651 -2.4428525  -0.20970854  4.38263864\n",
            " -0.64871509 -3.68391428]. \t  -300.49458690696554 \t -81.06401370190679\n",
            "93     \t [ 4.11259556 -4.11755424 -4.71639741 -3.98695533  4.27579626 -1.73979887\n",
            "  3.01502893 -0.85775114]. \t  -360.230674192261 \t -81.06401370190679\n",
            "94     \t [-3.70801216  2.7343568  -3.21124949 -4.64775611  3.41478676  3.85492597\n",
            "  2.93241002 -3.51574448]. \t  -452.5891279796706 \t -81.06401370190679\n",
            "95     \t [ 3.1040836   0.62160301  4.37658301 -5.05655729 -4.74484474 -2.73876438\n",
            " -0.30387552  1.3511085 ]. \t  -342.96971439489425 \t -81.06401370190679\n",
            "96     \t [ 0.68419682 -4.86779853  1.63762911 -2.07249145  3.91409233  4.8088265\n",
            "  3.59163112 -4.71779716]. \t  -556.7944668128923 \t -81.06401370190679\n",
            "97     \t [ 3.53355418  3.46901635  4.00365455  3.89028445  4.84287477 -3.04236556\n",
            " -1.00369965 -0.86418914]. \t  -331.00873885877974 \t -81.06401370190679\n",
            "98     \t [ 1.97289225 -4.90060232 -2.1260286  -3.53208204  4.23984524  4.1308505\n",
            "  4.12025256  3.50658786]. \t  -524.8561456132422 \t -81.06401370190679\n",
            "99     \t [-2.96651337  4.43171363 -4.57645758  2.58770547  4.25125486  5.03232819\n",
            "  3.70994501 -3.9904192 ]. \t  -603.7423519545919 \t -81.06401370190679\n",
            "100    \t [-3.39063343 -3.73342932  4.59549441 -3.80247025 -4.499458   -1.34010231\n",
            " -2.63609754  4.86386563]. \t  -510.465650110653 \t -81.06401370190679\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUDqFEwVvuNg",
        "outputId": "c3ece448-9889-43e8-da47-b63c1fcf376d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 19 \n",
        "\n",
        "np.random.seed(run_num_19)\n",
        "surrogate_winner_19 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_19 = dGPGO_stp(surrogate_winner_19, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.60872271  2.67767798 -2.61599688  2.78210017 -1.49020588  3.03818137\n",
            " -1.57695977 -0.57472578]. \t  -152.73804339453181 \t -152.73804339453181\n",
            "init   \t [-2.01417124 -0.59275346  0.74966386 -4.44760047 -4.87332982  3.28317578\n",
            " -1.38099049  2.2742428 ]. \t  -323.7197488227736 \t -152.73804339453181\n",
            "init   \t [-1.01293527  0.56350397 -2.8300206   3.21862419  2.65507157  2.99837476\n",
            "  1.85657419  0.54493065]. \t  -182.81852961404186 \t -152.73804339453181\n",
            "init   \t [ 2.7452723   4.7291508   4.64956866  0.49623227 -2.52475319 -2.84587614\n",
            "  1.92234127  1.96987691]. \t  -255.4837579570394 \t -152.73804339453181\n",
            "init   \t [-4.14230197  2.55639339 -5.00090869 -3.49701125 -2.12620717  3.13206479\n",
            "  2.96251747  5.00628454]. \t  -497.5739847629385 \t -152.73804339453181\n",
            "1      \t [ 3.77167886 -0.27993601 -4.78320819 -1.34075489  2.82884601 -4.92635204\n",
            "  1.29065387 -1.40572344]. \t  -303.3045201888178 \t -152.73804339453181\n",
            "2      \t [-4.77552039 -1.68941064  4.9572144   1.36923121  0.74443524 -0.86130392\n",
            " -4.11036966 -2.93642896]. \t  -304.20378932332414 \t -152.73804339453181\n",
            "3      \t [ 2.03295518 -3.75539881  1.44540034 -0.22722052 -3.20263597 -1.71487982\n",
            "  0.81219779 -4.07442271]. \t  -245.16729287500243 \t -152.73804339453181\n",
            "4      \t [-4.36139948  0.07187841  2.45009087  4.60212028 -0.53552725 -2.73599636\n",
            "  4.74768334 -3.86521375]. \t  -445.40952121063077 \t -152.73804339453181\n",
            "5      \t [-4.90125363 -4.48066987  0.6215702  -4.11322459  2.5725056   4.56065263\n",
            " -3.11784557  2.13903663]. \t  -395.5453956718856 \t -152.73804339453181\n",
            "6      \t [-3.59204616  2.01157128 -1.37932814 -3.91230147  0.87501658 -2.67283951\n",
            " -1.30867742  2.09829245]. \t  -181.83148528143957 \t -152.73804339453181\n",
            "7      \t [ 5.0368601  -1.56669821  3.14670899  2.96383245  1.34472085  2.5478463\n",
            " -3.84363162  0.61363107]. \t  -249.538958127328 \t -152.73804339453181\n",
            "8      \t [-4.64072358  3.76605906 -0.23213637 -2.64484313  1.60312724  4.68959072\n",
            "  2.77064081 -1.66185675]. \t  -298.6781074101207 \t -152.73804339453181\n",
            "9      \t [-3.2021821   0.70813428  3.09642565  2.4482258  -4.42832512  2.385681\n",
            "  3.19372935  1.60694619]. \t  -288.2523905752722 \t -152.73804339453181\n",
            "10     \t [ 4.49860651  2.21914322 -1.53566997  0.55052004 -3.66602015 -3.83697642\n",
            " -4.24059599  4.80338382]. \t  -504.3651866837903 \t -152.73804339453181\n",
            "11     \t [-4.60798887  4.80081407  4.2657334   3.49892023 -2.59662533  4.88472772\n",
            " -4.04592816  2.58390716]. \t  -515.7634656835737 \t -152.73804339453181\n",
            "12     \t [ 3.57336309 -4.79541426  0.52386156  1.03379669 -4.49853273 -4.02206645\n",
            "  4.34995938  4.08148867]. \t  -527.8286741696135 \t -152.73804339453181\n",
            "13     \t [ 3.02880458  5.00302092  3.38575986 -2.78758691  0.68090204 -4.410365\n",
            " -4.87902353 -0.4338765 ]. \t  -411.8729054727788 \t -152.73804339453181\n",
            "14     \t [ 3.32415297 -0.84638792 -3.92627618  1.7002047  -4.62714747  3.73485388\n",
            "  4.64219141  1.23417114]. \t  -424.07474031118045 \t -152.73804339453181\n",
            "15     \t [ 0.53896904 -4.45741272  3.14519144 -4.01813576 -1.95697437  4.84904002\n",
            "  4.14976278 -4.43621621]. \t  -572.4976011451986 \t -152.73804339453181\n",
            "16     \t [-3.55630932  4.95453312  0.2449662  -1.82321095 -4.83449408 -4.39921768\n",
            "  1.64070992 -3.42458482]. \t  -420.8646659728716 \t -152.73804339453181\n",
            "17     \t [ 5.10978026  3.74553786 -2.84322704 -4.22900246 -2.97423225 -1.75263774\n",
            " -1.4385042  -3.29812288]. \t  -314.1243273597763 \t -152.73804339453181\n",
            "18     \t [ 4.41187953  0.87313913  4.48110574 -0.01597955  4.06675153 -0.70648342\n",
            "  3.29504565 -2.55397191]. \t  -295.1018861139921 \t -152.73804339453181\n",
            "19     \t [-3.88652504 -4.89704157  4.60009126 -4.05566084  0.87564413 -2.77372175\n",
            "  1.94801258 -4.79740835]. \t  -453.02241109067313 \t -152.73804339453181\n",
            "20     \t [-4.61948412 -4.85587688 -3.07057751 -3.75915602 -3.69236167 -2.64717453\n",
            "  4.55145547  2.98572713]. \t  -479.84870046839177 \t -152.73804339453181\n",
            "21     \t [-3.9603856  -2.5720168  -4.59534337  3.34975508 -4.74229181  0.7786447\n",
            "  2.47217516 -1.77371653]. \t  -321.18466937580513 \t -152.73804339453181\n",
            "22     \t [-1.61427162 -4.15026084  0.22544761  4.80374524 -3.40959853 -1.58396604\n",
            " -3.63691654  2.23754469]. \t  -335.3350405868437 \t -152.73804339453181\n",
            "23     \t [ 3.87280287 -4.66630273 -4.13777053 -0.77482852  3.61635662 -4.96966346\n",
            " -4.54761957  3.81614065]. \t  -587.1570836493127 \t -152.73804339453181\n",
            "24     \t [-3.89444635 -4.91019495 -1.87187534  3.20506307  4.96483354 -1.57254108\n",
            " -2.29742688 -1.09956698]. \t  -299.69295556893707 \t -152.73804339453181\n",
            "25     \t [-2.81610447  4.09988855  0.04828216  5.09773296  3.65477043 -0.65877624\n",
            " -3.88874067 -3.35871886]. \t  -410.9978538947405 \t -152.73804339453181\n",
            "26     \t [ 1.63433211 -3.73216677  2.9352001  -0.85019206  0.99512693  3.37904777\n",
            "  4.06200782  4.82821393]. \t  -434.71840633629273 \t -152.73804339453181\n",
            "27     \t [ 2.245991   -1.14395927 -0.52585546 -4.87558607  5.05135174 -2.0214649\n",
            " -3.29488033 -4.56483155]. \t  -498.370536386387 \t -152.73804339453181\n",
            "28     \t [ 2.61408715 -4.96592971 -3.16871861 -4.38390125  3.84078805  4.67054258\n",
            " -2.10416751  5.03485293]. \t  -601.5837319508023 \t -152.73804339453181\n",
            "29     \t [-4.96183132  4.01680434  4.70286008  2.9163099   2.85853967  4.75263514\n",
            "  2.50100646  4.99338502]. \t  -576.8972109555848 \t -152.73804339453181\n",
            "30     \t [-3.62951729  4.17433959  2.0518327   4.81065802  4.00564639  3.98518187\n",
            "  5.02884186 -4.15704126]. \t  -644.0121440071655 \t -152.73804339453181\n",
            "31     \t [-1.59241278 -1.45503228  1.9868023   3.47652923  3.11290744 -3.07991683\n",
            "  2.53011944  3.61847477]. \t  -321.8808858422739 \t -152.73804339453181\n",
            "32     \t [ 1.54910232 -3.44539654  4.88603297 -1.46249094 -0.03252964 -3.5965531\n",
            " -3.95960623  4.84231553]. \t  -481.26669019763324 \t -152.73804339453181\n",
            "33     \t [-2.79268894  4.96592541  1.70428206  2.81515619 -4.03304888 -4.7185839\n",
            " -4.76241122  2.48714575]. \t  -520.7027884169621 \t -152.73804339453181\n",
            "34     \t [ 3.99652146  4.72648197  2.09905972  4.69227766  2.28004521 -5.09356477\n",
            " -2.62019567  1.73637952]. \t  -415.7770123655761 \t -152.73804339453181\n",
            "35     \t [ 4.37594681  4.66156853  4.05290811 -3.97748703 -0.8526223   3.72704547\n",
            "  4.0377304  -1.2065484 ]. \t  -387.9181289587795 \t -152.73804339453181\n",
            "36     \t [ 4.15326632 -4.57769354  2.50486947 -4.06460951  2.62807919 -4.21272419\n",
            "  4.68720421 -0.37830553]. \t  -440.0178679545328 \t -152.73804339453181\n",
            "37     \t [ 3.86587848  4.57441136 -5.04090449 -3.08665502 -0.68360909  3.58913007\n",
            " -0.70802875  3.2622309 ]. \t  -339.4114776132042 \t -152.73804339453181\n",
            "38     \t [ 4.73847946  3.19733533  3.59621008 -2.79212097 -2.43502122  2.77966179\n",
            " -4.94097081  3.98422819]. \t  -486.77173471484025 \t -152.73804339453181\n",
            "39     \t [ 0.02898559  1.99719603  5.06225205  3.4508822  -4.68329864  3.32263075\n",
            " -4.95913962 -4.34621301]. \t  -631.665645563653 \t -152.73804339453181\n",
            "40     \t [ 1.46108197  0.36311376 -3.32397571 -4.16812231  0.40245011  2.07173028\n",
            "  4.21414838 -2.96554822]. \t  -326.26924589591295 \t -152.73804339453181\n",
            "41     \t [ 2.10331538 -4.14447245 -3.97319781  3.87594648 -1.13660545 -3.342088\n",
            " -4.4649422  -5.013079  ]. \t  -560.3023098157398 \t -152.73804339453181\n",
            "42     \t [-4.51699393  4.79540182 -1.77921271  0.56402975  3.94210901  4.02440963\n",
            " -2.8733995   4.33161557]. \t  -459.93877848891935 \t -152.73804339453181\n",
            "43     \t [ 4.55928366  4.81049067 -0.61775329  5.03191528 -4.81113242 -4.16264321\n",
            "  0.0653753  -1.85002272]. \t  -416.6054081357776 \t -152.73804339453181\n",
            "44     \t [-3.82780795 -4.25500799 -1.48622083 -0.23473592 -2.05042119  3.91096591\n",
            " -3.23774996 -4.24793734]. \t  -388.24526838564714 \t -152.73804339453181\n",
            "45     \t [-0.98703995 -4.45105812 -4.87567682  4.35945768  2.38448242 -1.43526139\n",
            "  5.06993752 -2.15101253]. \t  -445.66758128931014 \t -152.73804339453181\n",
            "46     \t [-4.21470969 -1.66233315 -4.74874654 -4.27888543 -0.18454174 -4.80348491\n",
            " -3.69032682 -4.43308516]. \t  -555.3363226345597 \t -152.73804339453181\n",
            "47     \t [ 4.57073323 -1.06570563 -4.4602447  -5.05372205 -5.05034328 -4.10368125\n",
            "  4.72605926 -1.96513248]. \t  -600.8192870512336 \t -152.73804339453181\n",
            "48     \t [ 4.65582945 -2.52058603 -1.60327049 -4.07391098 -2.41382282  4.7775618\n",
            " -3.34325785 -0.29355021]. \t  -353.4961564671846 \t -152.73804339453181\n",
            "49     \t [-4.93592507 -4.99796226 -4.77415104 -2.1238525   3.61410101  3.22530684\n",
            "  4.86006102  3.53076071]. \t  -553.5389387363554 \t -152.73804339453181\n",
            "50     \t [-1.11247726  1.61812555  0.49543948 -2.88954519  4.85509545 -4.57541894\n",
            "  3.77778141 -3.30418898]. \t  -471.3177878181041 \t -152.73804339453181\n",
            "51     \t [-4.81925376  4.51866071  4.90666757  1.96687806  3.74473169 -2.85411271\n",
            " -4.8901082   4.85155259]. \t  -626.4458334362118 \t -152.73804339453181\n",
            "52     \t [ 4.97916238 -1.80226332 -2.28109421  5.01783993 -5.01048035  4.14894308\n",
            " -3.59336208  3.63300972]. \t  -572.3961796919259 \t -152.73804339453181\n",
            "53     \t [-1.4189488  -4.89473582 -4.52593092  3.4984157   0.56616195  5.03917428\n",
            " -4.4712237   4.01671165]. \t  -583.3151252846966 \t -152.73804339453181\n",
            "54     \t [-3.34207549  2.52952002  2.99790645  4.7308945  -4.38271236 -3.84115709\n",
            " -2.03171206 -5.01464233]. \t  -555.090035871229 \t -152.73804339453181\n",
            "55     \t [-5.11884857  4.42328004 -3.99258448  4.12744093  2.0405134  -1.98160325\n",
            "  4.02575357  3.70586908]. \t  -448.99224153452093 \t -152.73804339453181\n",
            "56     \t [-0.17244947  2.94449227  4.81544118 -4.14836948  4.34348628  1.5094396\n",
            " -4.34975589  3.57706421]. \t  -498.5766604144212 \t -152.73804339453181\n",
            "57     \t [-3.71144126 -4.768226    0.86036269  0.40662042  4.00114117  2.40852222\n",
            "  4.70584109 -4.96987361]. \t  -529.592048089718 \t -152.73804339453181\n",
            "58     \t [ 4.98685181  2.09405715 -2.64017382  0.96523726  4.13205156  0.24330877\n",
            "  5.01154705  3.2692004 ]. \t  -405.3121692906537 \t -152.73804339453181\n",
            "59     \t [-3.95270565  5.01543997  3.79868226 -2.22762893  3.43708462 -0.15820437\n",
            " -2.20263111 -1.9785136 ]. \t  -253.56758179227134 \t -152.73804339453181\n",
            "60     \t [ 2.1104257   4.022894   -2.18121977  4.69585814 -1.72991396 -3.97494322\n",
            "  4.50131795  4.44728127]. \t  -549.1223234712056 \t -152.73804339453181\n",
            "61     \t [ 4.63098062 -3.2569492  -3.64845283  2.20450539  3.57466966  4.97991155\n",
            " -1.44467502 -4.92809281]. \t  -523.6212394336617 \t -152.73804339453181\n",
            "62     \t [ 5.09908184 -4.98028369  0.52170711  4.16245517  3.94755688 -2.32380009\n",
            " -1.70082854 -3.12992963]. \t  -354.66546170471287 \t -152.73804339453181\n",
            "63     \t [ 4.35379883  3.84396557 -1.96493208  0.93740612  3.81297815 -0.78722673\n",
            " -4.44758753 -3.03567035]. \t  -352.2074692697008 \t -152.73804339453181\n",
            "64     \t [-4.18177807 -4.85986226  2.51927913 -1.27746275  4.84029031 -3.96416093\n",
            " -2.06672091  4.29103929]. \t  -478.92471224940925 \t -152.73804339453181\n",
            "65     \t [-0.00943887  4.51341158 -0.81069905 -3.81670475 -0.15799502  4.1616594\n",
            " -4.19375215 -2.02626106]. \t  -360.9825336104709 \t -152.73804339453181\n",
            "66     \t [ 4.55476954  1.83092178  2.39044804  5.0443548  -2.87697124  4.5613506\n",
            "  4.81787746  2.21255569]. \t  -514.2424186933007 \t -152.73804339453181\n",
            "67     \t [ 4.74474344  0.84162097  0.07126178 -3.85921871  2.7697921  -4.20558532\n",
            " -1.42284347  5.04760937]. \t  -445.99744910249944 \t -152.73804339453181\n",
            "68     \t [-3.17418614  1.09319445 -4.79251046  4.47422307 -4.10836737 -3.31879839\n",
            " -4.38095114  3.69581796]. \t  -555.5464053848718 \t -152.73804339453181\n",
            "69     \t [-4.72680331  3.70832664 -0.90926523  4.30710235 -4.29226819  4.47372587\n",
            "  3.49228393 -3.63576314]. \t  -529.8565429776139 \t -152.73804339453181\n",
            "70     \t [ 4.74155762 -0.17592528  3.38122441  2.16387832 -0.44782741 -3.69412666\n",
            " -4.31157726 -4.61587099]. \t  -459.03196789001936 \t -152.73804339453181\n",
            "71     \t [-2.08717889  4.55282375 -4.08183878  4.75829095  3.38186084 -4.42986494\n",
            " -4.7749391   2.72006027]. \t  -580.0795395337511 \t -152.73804339453181\n",
            "72     \t [ 4.51148979 -0.44797685 -5.10457772  2.90117275 -2.58791633  2.9671466\n",
            " -4.74694791 -4.95605421]. \t  -573.1369575515316 \t -152.73804339453181\n",
            "73     \t [ 3.39300292  3.60424112  1.11355805  1.87803378 -3.7894127   1.6744638\n",
            "  3.41642646 -4.22401949]. \t  -368.38538552248554 \t -152.73804339453181\n",
            "74     \t [ 0.52071054  0.88459892 -2.49359456 -0.58692417  3.80946191 -0.69607612\n",
            " -4.29482526  5.08766874]. \t  -433.5289171035445 \t -152.73804339453181\n",
            "75     \t [-4.7942542  -4.22281181  3.50973008 -1.72857622  4.62191318  0.40752908\n",
            "  4.88253998  4.48779745]. \t  -543.3595420113043 \t -152.73804339453181\n",
            "76     \t [-1.54209978  0.4176844   4.09785131 -4.95133652 -4.84739722 -3.80826142\n",
            "  1.65436899  4.2283215 ]. \t  -517.8586906024942 \t -152.73804339453181\n",
            "77     \t [ 2.95547036  4.53818769 -4.68454091  3.84464601  1.31385614 -3.83359633\n",
            "  3.91226708 -2.74437229]. \t  -439.08840681397686 \t -152.73804339453181\n",
            "78     \t [ 0.04724938 -3.30961413  3.03857589  3.94377522 -3.86595875  4.97546475\n",
            "  5.00516969 -4.90541589]. \t  -702.9481934040339 \t -152.73804339453181\n",
            "79     \t [-1.90066829  2.79517646  3.87779444 -4.12515375 -4.75135651 -2.7870946\n",
            " -4.66204249 -2.73730078]. \t  -503.98733296814623 \t -152.73804339453181\n",
            "80     \t [ 3.36773984 -4.23693214  4.85062268 -4.60073238  2.66193082  1.39658085\n",
            " -4.90635354  0.1069927 ]. \t  -418.2271558777464 \t -152.73804339453181\n",
            "81     \t [-0.7717431   1.77004593 -4.86879927 -3.86544135  3.35799217 -1.07459534\n",
            "  5.01712457  2.86748548]. \t  -443.03352353749665 \t -152.73804339453181\n",
            "82     \t [-3.95274868  3.34846517 -4.2294089  -3.29819595  3.86264671  0.27560214\n",
            "  2.83581468 -5.11314852]. \t  -475.727899004582 \t -152.73804339453181\n",
            "83     \t [-4.34897256 -4.49924336  1.81442219 -1.56261365 -3.06983417 -1.05803612\n",
            " -2.70989823  4.75142986]. \t  -364.8929498094601 \t -152.73804339453181\n",
            "84     \t [-3.29538453 -4.68133777 -2.97143579 -3.0443383  -3.19585063 -0.55231533\n",
            "  2.83245943 -4.25023271]. \t  -371.82290985998225 \t -152.73804339453181\n",
            "85     \t [-4.5686148   2.83808034 -4.70054814  4.579604   -3.93188441 -4.33920373\n",
            "  3.5262541  -2.71487804]. \t  -523.4346777587742 \t -152.73804339453181\n",
            "86     \t [ 0.25435918  3.8137666  -2.36249111 -2.56899883 -3.96335321 -2.14649662\n",
            "  4.50450847  3.71540965]. \t  -430.95129854788394 \t -152.73804339453181\n",
            "87     \t [4.61383875 3.16475955 3.34368211 3.05623156 4.7346308  4.32440306\n",
            " 4.7051924  3.0268156 ]. \t  -564.7729147756469 \t -152.73804339453181\n",
            "88     \t [ 1.47405762 -1.50305507 -3.33137327 -2.03862425 -5.02982777 -4.01889909\n",
            " -3.65968749 -0.89356248]. \t  -380.1552488502448 \t -152.73804339453181\n",
            "89     \t [-4.80726043  0.73910248 -2.13939838 -3.2844017  -4.9169255   4.74015475\n",
            "  3.96886744 -3.15878437]. \t  -526.864446547305 \t -152.73804339453181\n",
            "90     \t [-0.7229003   0.94519823  4.90279301 -3.07332498  3.45283347  4.01926056\n",
            "  2.22485795 -4.96681155]. \t  -500.74354173640995 \t -152.73804339453181\n",
            "91     \t [ 0.4408179   3.81464501  4.14440214  2.84706237  3.09142607  3.6756433\n",
            " -1.01771992 -2.12386961]. \t  -285.432168742497 \t -152.73804339453181\n",
            "92     \t [ 0.70181799 -4.11183948  4.3626538   4.11696069 -4.2362639   4.32446976\n",
            " -1.21136667  3.06441766]. \t  -446.53570332524015 \t -152.73804339453181\n",
            "93     \t [-0.17985187  3.4874858   1.58871511 -3.74888272  0.76645232  1.87100282\n",
            "  4.95144677  4.67108997]. \t  -458.2575777876832 \t -152.73804339453181\n",
            "94     \t [ 4.67671492 -1.17491569 -3.08116806  4.93089519 -0.36677642 -1.8747107\n",
            "  0.84692053  0.18860321]. \t  -177.43357136321822 \t -152.73804339453181\n",
            "95     \t [-3.18631218  1.80264896 -3.93291374  2.37633537  4.21840134  4.75704896\n",
            " -4.3002283  -1.70178894]. \t  -463.00704963997447 \t -152.73804339453181\n",
            "96     \t [ 4.92179008 -4.88548553 -4.27679429  0.24118463 -0.56927822 -1.49667122\n",
            "  4.81341683 -0.52700371]. \t  -306.5308148734378 \t -152.73804339453181\n",
            "97     \t [ 1.45535956 -2.03522413  3.18805539 -1.20439518 -1.6814874   4.67948189\n",
            " -2.16238333 -4.51089465]. \t  -387.7346884171935 \t -152.73804339453181\n",
            "98     \t [ 3.60782682  4.89599413  0.87781794 -1.40359149  4.41504409  1.19256161\n",
            " -0.28995345  3.66864067]. \t  -285.40609695089194 \t -152.73804339453181\n",
            "99     \t [-1.40420444 -4.87440865 -4.13850014 -2.37223056 -3.53036057  3.71080105\n",
            "  1.70525747  3.38737459]. \t  -380.4702407534102 \t -152.73804339453181\n",
            "100    \t [ 2.27142634  4.66580428 -3.64274785  4.89691507  2.84631371  4.58121714\n",
            " -1.54709621  4.18604854]. \t  -507.7981582068912 \t -152.73804339453181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHz_Jg2_uv7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d0e077-ca45-4f0d-f58a-af6854437368"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 20 \n",
        "\n",
        "np.random.seed(run_num_20)\n",
        "surrogate_winner_20 = dtStudentProcess(d_cov_func, nu = df)\n",
        "\n",
        "winner_20 = dGPGO_stp(surrogate_winner_20, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\n",
        "winner_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [ 0.722097    0.66077445 -0.11835563 -1.6744678  -1.27110986  0.3280473\n",
            " -4.42259161  0.86557758]. \t  -164.28536719065698 \t -132.28213531381235\n",
            "init   \t [-2.6839269  -3.47385261 -3.56229991 -3.8188112  -1.76700246  1.98813566\n",
            " -1.44418335  4.00758432]. \t  -310.1550894686203 \t -132.28213531381235\n",
            "init   \t [-3.05275003 -3.98743036  0.28218124  3.76479057 -2.43840637 -0.00619396\n",
            " -0.73150053  0.30723982]. \t  -132.28213531381235 \t -132.28213531381235\n",
            "init   \t [ 0.75721546 -1.10739814 -4.30577546  3.76095755 -3.43548334  3.1076518\n",
            " -2.17161474 -2.36983115]. \t  -310.1222484793693 \t -132.28213531381235\n",
            "init   \t [ 2.22697488  3.90559391  5.0393091  -0.42649562  2.91972373  2.4442259\n",
            " -0.2705103  -0.15529262]. \t  -191.55277957356324 \t -132.28213531381235\n",
            "1      \t [ 4.30728864  2.61813474 -2.20410079  4.60389393  3.48040036  3.22508805\n",
            "  2.4952604   4.24826238]. \t  -442.5587609971722 \t -132.28213531381235\n",
            "2      \t [-3.67810551 -4.48116665 -0.74199632 -3.37059583 -3.9425506  -2.29259788\n",
            "  4.31213333 -3.89016012]. \t  -461.26828963432035 \t -132.28213531381235\n",
            "3      \t [ 1.56366458  1.97029779 -1.88321714 -2.27776188  3.1870926  -3.83192746\n",
            " -0.64438653  4.95979293]. \t  -380.19432108174544 \t -132.28213531381235\n",
            "4      \t [ 2.46536058  0.00386685  1.05461748  3.63660883  0.94112637  0.81605284\n",
            "  3.66553642 -3.42598353]. \t  -258.6906356513254 \t -132.28213531381235\n",
            "5      \t [-4.39978814  0.90360721  2.91222914  0.57730316 -4.78505713  2.86512769\n",
            "  4.63430967  0.70651503]. \t  -365.83618901626903 \t -132.28213531381235\n",
            "6      \t [-2.29089101  0.96324983 -3.67061926  2.56765292  4.17925858 -2.88542368\n",
            "  2.46704165 -4.5907166 ]. \t  -422.3821079805308 \t -132.28213531381235\n",
            "7      \t [-2.60318915  4.91446954 -3.68630877 -3.57702537  4.36703787 -3.54053091\n",
            " -4.06260887 -1.76682508]. \t  -458.10183104301075 \t -132.28213531381235\n",
            "8      \t [-1.3660865   4.41521204  3.40253855 -4.85484974 -2.7320969  -5.02809654\n",
            " -2.46778548  2.94861325]. \t  -471.0610700186468 \t -132.28213531381235\n",
            "9      \t [ 3.44669653 -5.04747822  2.63711296 -4.46744958 -4.59315593 -3.41243311\n",
            "  3.34615084  3.91770876]. \t  -540.0475264259259 \t -132.28213531381235\n",
            "10     \t [ 3.81508618 -5.04446628 -3.700409    4.36649921  0.54330584  3.96256502\n",
            "  4.38942842  0.57567637]. \t  -416.00073903197176 \t -132.28213531381235\n",
            "11     \t [ 1.69528244 -4.64544672  3.92063525 -4.78095307 -2.51589383 -2.0454116\n",
            " -1.76034366 -3.79240704]. \t  -377.07986305126 \t -132.28213531381235\n",
            "12     \t [ 4.3201642   2.20704124 -0.95603605 -2.14067184 -4.98861162  3.3441296\n",
            "  4.8115412  -3.51809955]. \t  -502.08094121787286 \t -132.28213531381235\n",
            "13     \t [-3.64979062  1.53534038 -1.27717485  2.6365398  -2.42441841 -3.27020112\n",
            "  3.33811734  5.00876465]. \t  -422.9917004201742 \t -132.28213531381235\n",
            "14     \t [-4.83766673  0.82015191  4.2579765  -4.48553217  3.33894184 -4.04686968\n",
            "  0.73014261  3.76692121]. \t  -430.8743136055249 \t -132.28213531381235\n",
            "15     \t [ 3.19777464 -1.78327635  2.04952307 -4.71559084  5.0062765  -3.93455479\n",
            " -0.93029129 -5.03091812]. \t  -544.8722744087588 \t -132.28213531381235\n",
            "16     \t [-0.77941715 -4.96947151 -2.86473006 -2.40486458  4.25734728 -2.01508581\n",
            "  3.63414579  3.33295283]. \t  -394.0584748324677 \t -132.28213531381235\n",
            "17     \t [ 3.29635659  3.58792725  2.50456418 -0.0179199  -4.66536148  4.79387894\n",
            "  1.46254555  3.69503566]. \t  -426.3474457244342 \t -132.28213531381235\n",
            "18     \t [-4.23988115  1.70365654 -4.80559244  4.80343443 -3.80191874 -2.01772545\n",
            "  3.51717818 -4.48507273]. \t  -529.5756104458185 \t -132.28213531381235\n",
            "19     \t [-5.07606234  0.9638008  -4.14526419 -2.07942412 -2.32555821 -2.47158545\n",
            " -4.72345959 -4.0008729 ]. \t  -444.3967745335917 \t -132.28213531381235\n",
            "20     \t [ 4.53368641  4.3114872   4.38641669 -3.88829055 -1.122391   -4.86120584\n",
            " -1.06986619 -3.27298428]. \t  -417.72776899134567 \t -132.28213531381235\n",
            "21     \t [ 3.54825217 -3.18632793 -0.10844551  3.75329994  2.1648108  -2.43702222\n",
            " -2.31077887  3.1078005 ]. \t  -262.99156561308814 \t -132.28213531381235\n",
            "22     \t [ 0.61505324 -2.23383853  0.89237124  4.07004063  4.98427924 -5.04819691\n",
            " -4.11143005 -4.89688224]. \t  -666.2918574743164 \t -132.28213531381235\n",
            "23     \t [-4.97431192 -3.34444973  0.37337155 -3.75951157  4.94108708 -3.1438911\n",
            "  3.03040635 -3.50354189]. \t  -447.9263949242355 \t -132.28213531381235\n",
            "24     \t [-4.66961723 -3.68300976 -4.8785549   4.13191667  3.94993046  3.64265174\n",
            " -1.62541699 -2.63351054]. \t  -420.22639056078464 \t -132.28213531381235\n",
            "25     \t [ 3.07459142 -4.11801838  0.88571336 -0.71992001  4.26898233  4.9365567\n",
            "  2.27291424  4.4659778 ]. \t  -480.8571058053926 \t -132.28213531381235\n",
            "26     \t [-4.73358359  0.35401167  1.08036012 -5.09279157  0.85489432  3.80346997\n",
            "  4.43695619 -4.22235364]. \t  -500.7898477309751 \t -132.28213531381235\n",
            "27     \t [ 3.97435802  2.22445806 -4.82000303  1.5719269  -3.67360534 -2.6859575\n",
            "  2.39839406 -0.29925714]. \t  -257.0186373890937 \t -132.28213531381235\n",
            "28     \t [-3.14934271  4.79377109 -1.29678636  2.13466816  2.7078652   3.29333077\n",
            " -4.92906274 -2.09372794]. \t  -386.0290641726807 \t -132.28213531381235\n",
            "29     \t [ 4.16002719  5.01064587  4.40799539  2.94127371 -0.34456423 -4.98773779\n",
            " -3.70513327  3.55302764]. \t  -507.361527872999 \t -132.28213531381235\n",
            "30     \t [-2.97651883  4.16932961 -4.5273907  -3.55673881  3.77315654  4.47810203\n",
            "  2.75580802  1.19915438]. \t  -411.88869963691997 \t -132.28213531381235\n",
            "31     \t [-4.42136096  2.48162613  4.67023329  4.62621141 -4.54954091 -3.08321006\n",
            "  0.0283955  -3.84364368]. \t  -461.62906971870746 \t -132.28213531381235\n",
            "32     \t [ 5.06799526 -3.38734556  3.3282687  -3.11389257  4.06746539  2.33745256\n",
            " -4.76229199  0.30578138]. \t  -395.6576946528338 \t -132.28213531381235\n",
            "33     \t [-4.84910345 -2.50630761 -1.21861276  0.6159511   4.27262113  4.24907818\n",
            " -2.95505352  4.56255183]. \t  -469.31546607597295 \t -132.28213531381235\n",
            "34     \t [ 4.0661048  -1.26619564 -5.03146293 -4.15480839  0.55060648  1.57277371\n",
            "  1.08762458 -1.13287063]. \t  -199.64149766009652 \t -132.28213531381235\n",
            "35     \t [ 4.75137226 -0.13719385 -3.12788513 -4.60092937 -5.09266686 -1.97923527\n",
            " -1.32921528  3.14331369]. \t  -381.229955674267 \t -132.28213531381235\n",
            "36     \t [ 4.92677125  1.53912033 -3.04542069 -0.59011188  4.72885737  4.76827568\n",
            " -3.90562594 -0.6927353 ]. \t  -417.0731802779107 \t -132.28213531381235\n",
            "37     \t [-4.15036771  0.67535899  2.78422263 -3.10839806 -2.61218327  5.07704401\n",
            " -2.99520735 -3.92397591]. \t  -454.79733995262444 \t -132.28213531381235\n",
            "38     \t [-4.79120194  2.72934832 -5.07500303  4.57142576  4.96870946 -0.93584052\n",
            "  0.68118374  4.18431687]. \t  -470.72429530907766 \t -132.28213531381235\n",
            "39     \t [ 0.11959911 -3.60705651 -4.47515972  3.74949567 -4.90271954 -5.0080979\n",
            " -1.87077107  3.66045893]. \t  -544.7117813730761 \t -132.28213531381235\n",
            "40     \t [-4.93285115 -4.99463519  1.8829621  -3.32733623  0.07534394 -4.97301395\n",
            " -4.62917869 -3.98942939]. \t  -554.890118692461 \t -132.28213531381235\n",
            "41     \t [-5.01077957 -3.9118739  -5.11122172 -2.44739227  1.16224012  4.92996297\n",
            "  3.68420342 -2.1295822 ]. \t  -441.92177104314663 \t -132.28213531381235\n",
            "42     \t [-4.4648382   5.08236313  2.43524676 -3.71873577  4.93433777  4.45813467\n",
            " -4.58826527  3.03632041]. \t  -606.8102886009244 \t -132.28213531381235\n",
            "43     \t [-4.79618324 -3.61455167  3.32070133  1.90439758  4.38069866  4.23636021\n",
            "  1.22925485 -5.05736154]. \t  -515.547243040212 \t -132.28213531381235\n",
            "44     \t [ 3.78498995  4.97554896  1.61737184  4.79065016 -3.4943812   1.67711616\n",
            " -1.99822289 -1.35462983]. \t  -284.0475648637635 \t -132.28213531381235\n",
            "45     \t [ 3.16679933 -1.73325899  4.49037326  3.66273958 -0.50641695 -0.06879729\n",
            " -4.44194758 -3.15211053]. \t  -349.1033756348098 \t -132.28213531381235\n",
            "46     \t [-0.60836326 -0.88972474  5.08434963  1.42449104  3.96103224 -0.80734127\n",
            "  2.40993614  3.47919155]. \t  -307.47427575300804 \t -132.28213531381235\n",
            "47     \t [ 4.07945992 -2.33967635 -4.96292765  4.83292019 -0.26780146 -5.11853538\n",
            "  4.31033865  4.30639536]. \t  -630.8790645993743 \t -132.28213531381235\n",
            "48     \t [ 3.58612927 -3.03701128 -3.99415754 -3.47152936 -1.94715499 -4.69015715\n",
            " -4.98316373 -2.57974446]. \t  -505.37975045664393 \t -132.28213531381235\n",
            "49     \t [-3.77582637  4.98222861 -3.66552052 -1.02724095 -1.92817913  5.04492423\n",
            "  2.67925737 -4.46482571]. \t  -489.4543124977028 \t -132.28213531381235\n",
            "50     \t [ 4.39864384 -1.32333128  1.46251649 -4.62551971  3.40549783  4.36847059\n",
            "  3.06115061 -4.69946182]. \t  -529.6113941437528 \t -132.28213531381235\n",
            "51     \t [-3.72418967  0.95515743  4.45262695  4.9555865  -0.2856468   2.06310209\n",
            " -3.85058406  4.76957311]. \t  -485.1291664648287 \t -132.28213531381235\n",
            "52     \t [-3.14277781 -1.54808201 -0.56315132 -3.31796124  5.09239925  0.7475513\n",
            " -4.7438683  -3.56019285]. \t  -451.60249188647765 \t -132.28213531381235\n",
            "53     \t [ 1.7608328  -4.87322785  4.72813598  0.50069042 -4.26941634  4.35281707\n",
            "  3.36577453 -2.03496202]. \t  -435.9151135900272 \t -132.28213531381235\n",
            "54     \t [ 2.10682648  2.69175735  3.88648768  3.85411328 -0.22561332 -4.69349297\n",
            "  5.01428736  4.70715475]. \t  -609.348704185287 \t -132.28213531381235\n",
            "55     \t [-4.14631509  1.7829162  -4.98331302  5.04223771 -4.22073157  3.93060933\n",
            "  2.50858448  1.3572897 ]. \t  -440.30624824531185 \t -132.28213531381235\n",
            "56     \t [-0.44645873  1.92709727  0.02554277 -3.14422102 -5.02295086 -2.33333905\n",
            " -0.07139715 -3.94438462]. \t  -330.49124033243595 \t -132.28213531381235\n",
            "57     \t [ 1.00981801  1.71727102  3.06668801 -1.23438963 -4.81696159 -3.33864368\n",
            "  4.23951974  1.51318941]. \t  -368.25384411705545 \t -132.28213531381235\n",
            "58     \t [ 0.50325262  3.20335408 -4.66581995 -3.11949106 -3.09819357  4.80048592\n",
            " -4.45590797 -3.65618892]. \t  -557.2003006615876 \t -132.28213531381235\n",
            "59     \t [ 4.3911269  -0.68998891  4.64416565 -5.02367222  2.28312721 -3.22796775\n",
            "  2.39804721  2.01628663]. \t  -347.2478303103264 \t -132.28213531381235\n",
            "60     \t [-2.29770934 -4.93295879  5.07763805 -3.13804519 -0.22392412  0.91197692\n",
            " -0.7882029   2.23523221]. \t  -220.24404073168063 \t -132.28213531381235\n",
            "61     \t [ 4.37837236e+00 -4.68151088e+00  3.79781015e+00  2.98847088e-03\n",
            " -3.82600785e+00 -3.05298886e+00 -4.58088088e+00  4.28281806e+00]. \t  -529.0210121069344 \t -132.28213531381235\n",
            "62     \t [-4.53873902  2.97475987 -3.85584802 -1.80605711 -5.11114032 -0.45220798\n",
            " -3.23866748  4.80011797]. \t  -485.5461644980237 \t -132.28213531381235\n",
            "63     \t [5.12 5.12 5.12 5.12 5.12 5.12 5.12 5.12]. \t  -943.7184000000001 \t -132.28213531381235\n",
            "64     \t [-3.55756388  0.64151576 -4.72153174  0.73778709  1.15266819 -4.39342862\n",
            " -4.78943896  3.8887673 ]. \t  -486.5429288085654 \t -132.28213531381235\n",
            "65     \t [-3.88253763 -1.55071724  3.65164374  3.15405572  3.48169458 -3.70781779\n",
            "  3.40092501 -4.46274484]. \t  -483.0705531728214 \t -132.28213531381235\n",
            "66     \t [-2.52763687  1.79345791  4.56368652 -4.97358675  1.239331   -2.56989152\n",
            "  4.63895217 -2.42954553]. \t  -419.4163291833765 \t -132.28213531381235\n",
            "67     \t [-0.45756687 -4.40986208 -3.58918584  3.88651265 -3.81059781  2.75316107\n",
            " -5.01705454  4.62050288]. \t  -603.2407046382656 \t -132.28213531381235\n",
            "68     \t [ 4.63997718  4.19734457  2.07651108  4.93433894  4.20938974  4.81648833\n",
            " -3.92953661  2.4808046 ]. \t  -552.2013953848776 \t -132.28213531381235\n",
            "69     \t [ 4.51123942 -0.74376175 -3.75304821  3.61137998 -3.28646366 -5.0283513\n",
            " -3.91104046 -4.93055945]. \t  -623.1491306895864 \t -132.28213531381235\n",
            "70     \t [-4.01103075  4.4512908   4.149523    4.00241333  3.26322799 -1.42255677\n",
            " -0.82475841 -0.51591477]. \t  -243.7254410324303 \t -132.28213531381235\n",
            "71     \t [-1.05850059  4.91305619  5.06060779  2.00358607 -2.52672704  3.75549498\n",
            "  0.53387371 -3.99652429]. \t  -388.6003498630443 \t -132.28213531381235\n",
            "72     \t [ 1.32723519  4.59736317 -2.29790054 -4.06327296  5.06642424 -1.70805853\n",
            "  3.28241285 -1.56997654]. \t  -366.90114498298686 \t -132.28213531381235\n",
            "73     \t [ 2.78925194  5.08043705  4.89255477 -4.55331525 -0.18230072  4.08146189\n",
            " -4.02230663 -3.82696386]. \t  -544.6776314774282 \t -132.28213531381235\n",
            "74     \t [-4.63219946 -1.64662431  4.67898059  1.1958906   3.29811676 -3.88551604\n",
            " -4.04930218  0.73002684]. \t  -362.29194087425265 \t -132.28213531381235\n",
            "75     \t [-2.14548257 -4.00502945  1.47516772 -3.55111216  5.01909395  4.18107572\n",
            "  0.718661   -0.25911622]. \t  -328.6508975172938 \t -132.28213531381235\n",
            "76     \t [ 2.30775492  0.35474608 -3.53251004 -2.38852346 -3.43008893  4.02730922\n",
            "  3.57140864  3.70312837]. \t  -420.9663442754371 \t -132.28213531381235\n",
            "77     \t [ 3.6361053   3.32225613 -3.88868651  1.91483149  4.5709722   4.2834161\n",
            "  3.58425025 -4.85550169]. \t  -588.4179772219699 \t -132.28213531381235\n",
            "78     \t [-2.92469903  4.11515043  4.90732723 -4.01665882 -2.29451126  5.00933093\n",
            "  3.1894498   3.37059351]. \t  -518.1821872128941 \t -132.28213531381235\n",
            "79     \t [ 2.61952587  4.7710714   0.35049775  1.27411031  4.62224079 -4.58498099\n",
            " -3.68745771 -2.05871003]. \t  -421.2956947560565 \t -132.28213531381235\n",
            "80     \t [ 4.32072468 -1.31758487  5.09942455 -0.67004728 -1.95323867 -4.95956685\n",
            "  3.1481498  -5.10336804]. \t  -546.3393468936549 \t -132.28213531381235\n",
            "81     \t [-5.05027486 -0.80507134 -0.89800279  3.49091416 -3.3305223   4.04637615\n",
            " -4.93048148 -0.71717324]. \t  -405.94979677409316 \t -132.28213531381235\n",
            "82     \t [-2.49530059  3.29379717 -2.556796   -4.08745411 -4.34565028 -2.26946709\n",
            "  4.86408705  3.06949929]. \t  -480.68174052302106 \t -132.28213531381235\n",
            "83     \t [ 4.71732384 -0.73198817 -3.22604065  3.59028613  4.51787768 -0.55639744\n",
            " -1.84302732 -3.9989497 ]. \t  -361.7309902620037 \t -132.28213531381235\n",
            "84     \t [ 0.25174591  4.74278969 -0.85353317  4.3648694  -4.02178371 -2.11393074\n",
            " -4.94697451  4.27622255]. \t  -548.7278521979439 \t -132.28213531381235\n",
            "85     \t [-2.43039706 -4.6105716  -1.32083894  4.45987062  3.05647944  0.28727048\n",
            "  3.40263373  3.72630803]. \t  -372.55106611707834 \t -132.28213531381235\n",
            "86     \t [-3.44997377 -3.67438725  4.64178392  2.30378187 -2.14345038 -3.43755492\n",
            "  4.64109277  4.18216898]. \t  -509.3477737474184 \t -132.28213531381235\n",
            "87     \t [ 3.17584601  5.10840944  2.34716699  4.65308916  4.75561237  4.18964369\n",
            "  1.44578582 -3.32551339]. \t  -486.91254662930027 \t -132.28213531381235\n",
            "88     \t [-3.34067715 -4.14144951 -3.0748922   3.43381337 -1.33325843 -4.24143768\n",
            " -4.39449587 -2.67513199]. \t  -430.25097367726306 \t -132.28213531381235\n",
            "89     \t [ 4.40622151 -2.13455261  4.17720551  4.98732548 -2.30512604  4.95647031\n",
            " -1.5498831   3.39581602]. \t  -463.40332972693284 \t -132.28213531381235\n",
            "90     \t [-3.78853614  4.98844258  0.27202448 -0.93402905 -3.29317371 -4.80291045\n",
            "  4.81051679 -3.53499218]. \t  -522.4232761254669 \t -132.28213531381235\n",
            "91     \t [ 3.36218088 -4.26097272 -4.52729774 -1.30897827 -0.86240214  4.18370173\n",
            " -3.32945349 -5.09728578]. \t  -510.1532591849149 \t -132.28213531381235\n",
            "92     \t [-3.87577577 -4.47525395 -4.3031703  -3.87304734 -4.22046478 -3.16926655\n",
            " -1.55400172 -0.3404917 ]. \t  -337.79028443279367 \t -132.28213531381235\n",
            "93     \t [ 3.77155461  2.06466064  2.90506093 -4.08594021  2.26034781  4.91804369\n",
            "  4.84562906  4.19907908]. \t  -590.9357893874806 \t -132.28213531381235\n",
            "94     \t [ 3.21460076 -0.67192827  2.1683428  -4.84322446 -2.69890877  3.58349716\n",
            "  0.02674631  0.19946053]. \t  -232.96159504331843 \t -132.28213531381235\n",
            "95     \t [ 0.47884247  2.25464327 -4.7923606  -1.37624234 -0.70428935 -4.98195842\n",
            "  4.23078325 -4.18286854]. \t  -503.5398329162781 \t -132.28213531381235\n",
            "96     \t [-3.95491318 -4.96561533 -3.03360534  3.38479251 -4.18462808  4.49476065\n",
            "  3.31255324 -4.830339  ]. \t  -610.6328375651256 \t -132.28213531381235\n",
            "97     \t [ 0.90003294  3.01133295 -4.87453873  1.65999186 -0.60361857  3.42855736\n",
            " -4.34027799  4.79996057]. \t  -489.78685993434556 \t -132.28213531381235\n",
            "98     \t [ 1.63600609 -3.6976587  -3.23057164  4.46856466  5.07933551  4.58095245\n",
            "  1.22308613 -4.90732221]. \t  -599.2390015963817 \t -132.28213531381235\n",
            "99     \t [-2.99290684  2.41611679  4.34391994 -4.85612967  4.11107399  3.02925082\n",
            " -1.15710379 -2.55713865]. \t  -372.8163337635158 \t -132.28213531381235\n",
            "100    \t [-1.64005766 -4.15398295  4.04896389  1.88151745  2.42123529  3.84659316\n",
            " -3.64651377 -0.05092919]. \t  -311.73345928455177 \t -132.28213531381235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUnhsKpCuv9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "468b1a3e-5d70-4074-eed3-b4682a53120b"
      },
      "source": [
        "end_win = time.time()\n",
        "end_win\n",
        "\n",
        "time_win = end_win - start_win\n",
        "time_win"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9119.067081928253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJG0SLpwuwAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "547a9fa0-a0e7-461e-8150-75bf5581af7e"
      },
      "source": [
        "### Training regret minimization: run number = 1\n",
        "\n",
        "loser_output_1 = np.append(np.max(loser_1.GP.y[0:n_init]),loser_1.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_1 = np.append(np.max(winner_1.GP.y[0:n_init]),winner_1.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_1 = np.log(y_global_orig - loser_output_1)\n",
        "regret_winner_1 = np.log(y_global_orig - winner_output_1)\n",
        "\n",
        "train_regret_loser_1 = min_max_array(regret_loser_1)\n",
        "train_regret_winner_1 = min_max_array(regret_winner_1)\n",
        "\n",
        "min_train_regret_loser_1 = min(train_regret_loser_1)\n",
        "min_train_regret_winner_1 = min(train_regret_winner_1)\n",
        "\n",
        "min_train_regret_loser_1, min_train_regret_winner_1"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.185168623851889, 5.306021247004787)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lA9eZf0uwCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "748449e7-6571-4122-e665-6a04c2457924"
      },
      "source": [
        "### Training regret minimization: run number = 2\n",
        "\n",
        "loser_output_2 = np.append(np.max(loser_2.GP.y[0:n_init]),loser_2.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_2 = np.append(np.max(winner_2.GP.y[0:n_init]),winner_2.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_2 = np.log(y_global_orig - loser_output_2)\n",
        "regret_winner_2 = np.log(y_global_orig - winner_output_2)\n",
        "\n",
        "train_regret_loser_2 = min_max_array(regret_loser_2)\n",
        "train_regret_winner_2 = min_max_array(regret_winner_2)\n",
        "\n",
        "min_train_regret_loser_2 = min(train_regret_loser_2)\n",
        "min_train_regret_winner_2 = min(train_regret_winner_2)\n",
        "\n",
        "min_train_regret_loser_2, min_train_regret_winner_2"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.264080017248812, 5.131750129144026)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glrTGcpAuwFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36586d1-07a9-4c58-dd52-f1fd60e1d672"
      },
      "source": [
        "### Training regret minimization: run number = 3\n",
        "\n",
        "loser_output_3 = np.append(np.max(loser_3.GP.y[0:n_init]),loser_3.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_3 = np.append(np.max(winner_3.GP.y[0:n_init]),winner_3.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_3 = np.log(y_global_orig - loser_output_3)\n",
        "regret_winner_3 = np.log(y_global_orig - winner_output_3)\n",
        "\n",
        "train_regret_loser_3 = min_max_array(regret_loser_3)\n",
        "train_regret_winner_3 = min_max_array(regret_winner_3)\n",
        "\n",
        "min_train_regret_loser_3 = min(train_regret_loser_3)\n",
        "min_train_regret_winner_3 = min(train_regret_winner_3)\n",
        "\n",
        "min_train_regret_loser_3, min_train_regret_winner_3"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.109665301060218, 5.109665301060218)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaRwfbxeuwIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f89c641-0b30-4bda-be38-4e0b18b5858b"
      },
      "source": [
        "### Training regret minimization: run number = 4\n",
        "\n",
        "loser_output_4 = np.append(np.max(loser_4.GP.y[0:n_init]),loser_4.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_4 = np.append(np.max(winner_4.GP.y[0:n_init]),winner_4.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_4 = np.log(y_global_orig - loser_output_4)\n",
        "regret_winner_4 = np.log(y_global_orig - winner_output_4)\n",
        "\n",
        "train_regret_loser_4 = min_max_array(regret_loser_4)\n",
        "train_regret_winner_4 = min_max_array(regret_winner_4)\n",
        "\n",
        "min_train_regret_loser_4 = min(train_regret_loser_4)\n",
        "min_train_regret_winner_4 = min(train_regret_winner_4)\n",
        "\n",
        "min_train_regret_loser_4, min_train_regret_winner_4"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.109733786005427, 4.985673966280516)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nb5NkfyuwKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4ae1d0-e542-4ae1-cc62-06e8132e907e"
      },
      "source": [
        "### Training regret minimization: run number = 5\n",
        "\n",
        "loser_output_5 = np.append(np.max(loser_5.GP.y[0:n_init]),loser_5.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_5 = np.append(np.max(winner_5.GP.y[0:n_init]),winner_5.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_5 = np.log(y_global_orig - loser_output_5)\n",
        "regret_winner_5 = np.log(y_global_orig - winner_output_5)\n",
        "\n",
        "train_regret_loser_5 = min_max_array(regret_loser_5)\n",
        "train_regret_winner_5 = min_max_array(regret_winner_5)\n",
        "\n",
        "min_train_regret_loser_5 = min(train_regret_loser_5)\n",
        "min_train_regret_winner_5 = min(train_regret_winner_5)\n",
        "\n",
        "min_train_regret_loser_5, min_train_regret_winner_5"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.139102336415449, 5.079955552793153)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0Q-WfXbuwNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4c9cdc-b3f8-4210-cdbb-68ef9a22a9df"
      },
      "source": [
        "### Training regret minimization: run number = 6\n",
        "\n",
        "loser_output_6 = np.append(np.max(loser_6.GP.y[0:n_init]),loser_6.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_6 = np.append(np.max(winner_6.GP.y[0:n_init]),winner_6.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_6 = np.log(y_global_orig - loser_output_6)\n",
        "regret_winner_6 = np.log(y_global_orig - winner_output_6)\n",
        "\n",
        "train_regret_loser_6 = min_max_array(regret_loser_6)\n",
        "train_regret_winner_6 = min_max_array(regret_winner_6)\n",
        "\n",
        "min_train_regret_loser_6 = min(train_regret_loser_6)\n",
        "min_train_regret_winner_6 = min(train_regret_winner_6)\n",
        "\n",
        "min_train_regret_loser_6, min_train_regret_winner_6"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.10459496818004, 4.664712630548057)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqqS7VLcuwPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671a3630-b8d0-467a-9ced-92db33ff74b2"
      },
      "source": [
        "### Training regret minimization: run number = 7\n",
        "\n",
        "loser_output_7 = np.append(np.max(loser_7.GP.y[0:n_init]),loser_7.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_7 = np.append(np.max(winner_7.GP.y[0:n_init]),winner_7.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_7 = np.log(y_global_orig - loser_output_7)\n",
        "regret_winner_7 = np.log(y_global_orig - winner_output_7)\n",
        "\n",
        "train_regret_loser_7 = min_max_array(regret_loser_7)\n",
        "train_regret_winner_7 = min_max_array(regret_winner_7)\n",
        "\n",
        "min_train_regret_loser_7 = min(train_regret_loser_7)\n",
        "min_train_regret_winner_7 = min(train_regret_winner_7)\n",
        "\n",
        "min_train_regret_loser_7, min_train_regret_winner_7"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.836780871006718, 4.836780871006718)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOi5iX8guwSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e27badf-b88c-454b-b028-0124664144aa"
      },
      "source": [
        "### Training regret minimization: run number = 8\n",
        "\n",
        "loser_output_8 = np.append(np.max(loser_8.GP.y[0:n_init]),loser_8.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_8 = np.append(np.max(winner_8.GP.y[0:n_init]),winner_8.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_8 = np.log(y_global_orig - loser_output_8)\n",
        "regret_winner_8 = np.log(y_global_orig - winner_output_8)\n",
        "\n",
        "train_regret_loser_8 = min_max_array(regret_loser_8)\n",
        "train_regret_winner_8 = min_max_array(regret_winner_8)\n",
        "\n",
        "min_train_regret_loser_8 = min(train_regret_loser_8)\n",
        "min_train_regret_winner_8 = min(train_regret_winner_8)\n",
        "\n",
        "min_train_regret_loser_8, min_train_regret_winner_8"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.195836937766768, 5.195836937766768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFVApeazuwU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb55c9d2-eaae-4b0c-fcbc-8d278abcbf4d"
      },
      "source": [
        "### Training regret minimization: run number = 9\n",
        "\n",
        "loser_output_9 = np.append(np.max(loser_9.GP.y[0:n_init]),loser_9.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_9 = np.append(np.max(winner_9.GP.y[0:n_init]),winner_9.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_9 = np.log(y_global_orig - loser_output_9)\n",
        "regret_winner_9 = np.log(y_global_orig - winner_output_9)\n",
        "\n",
        "train_regret_loser_9 = min_max_array(regret_loser_9)\n",
        "train_regret_winner_9 = min_max_array(regret_winner_9)\n",
        "\n",
        "min_train_regret_loser_9 = min(train_regret_loser_9)\n",
        "min_train_regret_winner_9 = min(train_regret_winner_9)\n",
        "\n",
        "min_train_regret_loser_9, min_train_regret_winner_9"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.168530738268499, 5.232365849416937)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g92jk9WJuwXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1be2147-9115-4451-ccfb-4c8ff4d5d2d0"
      },
      "source": [
        "### Training regret minimization: run number = 10\n",
        "\n",
        "loser_output_10 = np.append(np.max(loser_10.GP.y[0:n_init]),loser_10.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_10 = np.append(np.max(winner_10.GP.y[0:n_init]),winner_10.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_10 = np.log(y_global_orig - loser_output_10)\n",
        "regret_winner_10 = np.log(y_global_orig - winner_output_10)\n",
        "\n",
        "train_regret_loser_10 = min_max_array(regret_loser_10)\n",
        "train_regret_winner_10 = min_max_array(regret_winner_10)\n",
        "\n",
        "min_train_regret_loser_10 = min(train_regret_loser_10)\n",
        "min_train_regret_winner_10 = min(train_regret_winner_10)\n",
        "\n",
        "min_train_regret_loser_10, min_train_regret_winner_10"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.105519060338369, 5.140244007795881)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmcF1x-NuwZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aff801f-89da-4fdb-e2cc-64827c928ece"
      },
      "source": [
        "### Training regret minimization: run number = 11\n",
        "\n",
        "loser_output_11 = np.append(np.max(loser_11.GP.y[0:n_init]),loser_11.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_11 = np.append(np.max(winner_11.GP.y[0:n_init]),winner_11.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_11 = np.log(y_global_orig - loser_output_11)\n",
        "regret_winner_11 = np.log(y_global_orig - winner_output_11)\n",
        "\n",
        "train_regret_loser_11 = min_max_array(regret_loser_11)\n",
        "train_regret_winner_11 = min_max_array(regret_winner_11)\n",
        "\n",
        "min_train_regret_loser_11 = min(train_regret_loser_11)\n",
        "min_train_regret_winner_11 = min(train_regret_winner_11)\n",
        "\n",
        "min_train_regret_loser_11, min_train_regret_winner_11"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.294954859607875, 5.294954859607875)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8axVhb6uwcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac09821-e600-4611-b6f5-3b811aa50054"
      },
      "source": [
        "### Training regret minimization: run number = 12\n",
        "\n",
        "loser_output_12 = np.append(np.max(loser_12.GP.y[0:n_init]),loser_12.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_12 = np.append(np.max(winner_12.GP.y[0:n_init]),winner_12.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_12 = np.log(y_global_orig - loser_output_12)\n",
        "regret_winner_12 = np.log(y_global_orig - winner_output_12)\n",
        "\n",
        "train_regret_loser_12 = min_max_array(regret_loser_12)\n",
        "train_regret_winner_12 = min_max_array(regret_winner_12)\n",
        "\n",
        "min_train_regret_loser_12 = min(train_regret_loser_12)\n",
        "min_train_regret_winner_12 = min(train_regret_winner_12)\n",
        "\n",
        "min_train_regret_loser_12, min_train_regret_winner_12"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.784284021089071, 4.784284021089071)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzlrL8XFuwfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f44b9bd0-f7da-415d-c37d-85e3fac139c1"
      },
      "source": [
        "### Training regret minimization: run number = 13\n",
        "\n",
        "loser_output_13 = np.append(np.max(loser_13.GP.y[0:n_init]),loser_13.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_13 = np.append(np.max(winner_13.GP.y[0:n_init]),winner_13.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_13 = np.log(y_global_orig - loser_output_13)\n",
        "regret_winner_13 = np.log(y_global_orig - winner_output_13)\n",
        "\n",
        "train_regret_loser_13 = min_max_array(regret_loser_13)\n",
        "train_regret_winner_13 = min_max_array(regret_winner_13)\n",
        "\n",
        "min_train_regret_loser_13 = min(train_regret_loser_13)\n",
        "min_train_regret_winner_13 = min(train_regret_winner_13)\n",
        "\n",
        "min_train_regret_loser_13, min_train_regret_winner_13"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.388682173250253, 4.528488176087684)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uZlLJ1quwh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c0e8ab-00af-4b65-9656-e4554488bf12"
      },
      "source": [
        "### Training regret minimization: run number = 14\n",
        "\n",
        "loser_output_14 = np.append(np.max(loser_14.GP.y[0:n_init]),loser_14.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_14 = np.append(np.max(winner_14.GP.y[0:n_init]),winner_14.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_14 = np.log(y_global_orig - loser_output_14)\n",
        "regret_winner_14 = np.log(y_global_orig - winner_output_14)\n",
        "\n",
        "train_regret_loser_14 = min_max_array(regret_loser_14)\n",
        "train_regret_winner_14 = min_max_array(regret_winner_14)\n",
        "\n",
        "min_train_regret_loser_14 = min(train_regret_loser_14)\n",
        "min_train_regret_winner_14 = min(train_regret_winner_14)\n",
        "\n",
        "min_train_regret_loser_14, min_train_regret_winner_14"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.188190270709808, 5.2564700901222885)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVBcHRiMuwjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1059195e-6311-417c-dce2-f551f4cdd01d"
      },
      "source": [
        "### Training regret minimization: run number = 15\n",
        "\n",
        "loser_output_15 = np.append(np.max(loser_15.GP.y[0:n_init]),loser_15.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_15 = np.append(np.max(winner_15.GP.y[0:n_init]),winner_15.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_15 = np.log(y_global_orig - loser_output_15)\n",
        "regret_winner_15 = np.log(y_global_orig - winner_output_15)\n",
        "\n",
        "train_regret_loser_15 = min_max_array(regret_loser_15)\n",
        "train_regret_winner_15 = min_max_array(regret_winner_15)\n",
        "\n",
        "min_train_regret_loser_15 = min(train_regret_loser_15)\n",
        "min_train_regret_winner_15 = min(train_regret_winner_15)\n",
        "\n",
        "min_train_regret_loser_15, min_train_regret_winner_15"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.717103197449605, 4.717103197449605)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8nZ_DrKuwnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12cbef2d-b4c1-4664-d241-6c0599282f6f"
      },
      "source": [
        "### Training regret minimization: run number = 16\n",
        "\n",
        "loser_output_16 = np.append(np.max(loser_16.GP.y[0:n_init]),loser_16.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_16 = np.append(np.max(winner_16.GP.y[0:n_init]),winner_16.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_16 = np.log(y_global_orig - loser_output_16)\n",
        "regret_winner_16 = np.log(y_global_orig - winner_output_16)\n",
        "\n",
        "train_regret_loser_16 = min_max_array(regret_loser_16)\n",
        "train_regret_winner_16 = min_max_array(regret_winner_16)\n",
        "\n",
        "min_train_regret_loser_16 = min(train_regret_loser_16)\n",
        "min_train_regret_winner_16 = min(train_regret_winner_16)\n",
        "\n",
        "min_train_regret_loser_16, min_train_regret_winner_16"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.055013211046219, 5.055013211046219)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg6qzzQFuwpU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e14943-0224-4686-9480-3db53fab1287"
      },
      "source": [
        "### Training regret minimization: run number = 17\n",
        "\n",
        "loser_output_17 = np.append(np.max(loser_17.GP.y[0:n_init]),loser_17.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_17 = np.append(np.max(winner_17.GP.y[0:n_init]),winner_17.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_17 = np.log(y_global_orig - loser_output_17)\n",
        "regret_winner_17 = np.log(y_global_orig - winner_output_17)\n",
        "\n",
        "train_regret_loser_17 = min_max_array(regret_loser_17)\n",
        "train_regret_winner_17 = min_max_array(regret_winner_17)\n",
        "\n",
        "min_train_regret_loser_17 = min(train_regret_loser_17)\n",
        "min_train_regret_winner_17 = min(train_regret_winner_17)\n",
        "\n",
        "min_train_regret_loser_17, min_train_regret_winner_17"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.042343049744377, 5.323136585670149)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrRtDLMFuwsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3101c19f-c9b3-44e5-9c19-5dbced3ddba5"
      },
      "source": [
        "### Training regret minimization: run number = 18\n",
        "\n",
        "loser_output_18 = np.append(np.max(loser_18.GP.y[0:n_init]),loser_18.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_18 = np.append(np.max(winner_18.GP.y[0:n_init]),winner_18.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_18 = np.log(y_global_orig - loser_output_18)\n",
        "regret_winner_18 = np.log(y_global_orig - winner_output_18)\n",
        "\n",
        "train_regret_loser_18 = min_max_array(regret_loser_18)\n",
        "train_regret_winner_18 = min_max_array(regret_winner_18)\n",
        "\n",
        "min_train_regret_loser_18 = min(train_regret_loser_18)\n",
        "min_train_regret_winner_18 = min(train_regret_winner_18)\n",
        "\n",
        "min_train_regret_loser_18, min_train_regret_winner_18"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.395239135171794, 4.395239135171794)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkmSu4CUuwuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3547f408-b74a-4e04-ef68-f640b7038308"
      },
      "source": [
        "### Training regret minimization: run number = 19\n",
        "\n",
        "loser_output_19 = np.append(np.max(loser_19.GP.y[0:n_init]),loser_19.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_19 = np.append(np.max(winner_19.GP.y[0:n_init]),winner_19.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_19 = np.log(y_global_orig - loser_output_19)\n",
        "regret_winner_19 = np.log(y_global_orig - winner_output_19)\n",
        "\n",
        "train_regret_loser_19 = min_max_array(regret_loser_19)\n",
        "train_regret_winner_19 = min_max_array(regret_winner_19)\n",
        "\n",
        "min_train_regret_loser_19 = min(train_regret_loser_19)\n",
        "min_train_regret_winner_19 = min(train_regret_winner_19)\n",
        "\n",
        "min_train_regret_loser_19, min_train_regret_winner_19"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5.02872431933846, 5.02872431933846)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eymecjwkuwxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91477b0-9194-4dc4-d862-33dec3ff27a9"
      },
      "source": [
        "### Training regret minimization: run number = 20\n",
        "\n",
        "loser_output_20 = np.append(np.max(loser_20.GP.y[0:n_init]),loser_20.GP.y[n_init:(n_init+max_iter)]) \n",
        "winner_output_20 = np.append(np.max(winner_20.GP.y[0:n_init]),winner_20.GP.y[n_init:(n_init+max_iter)]) \n",
        "\n",
        "regret_loser_20 = np.log(y_global_orig - loser_output_20)\n",
        "regret_winner_20 = np.log(y_global_orig - winner_output_20)\n",
        "\n",
        "train_regret_loser_20 = min_max_array(regret_loser_20)\n",
        "train_regret_winner_20 = min_max_array(regret_winner_20)\n",
        "\n",
        "min_train_regret_loser_20 = min(train_regret_loser_20)\n",
        "min_train_regret_winner_20 = min(train_regret_winner_20)\n",
        "\n",
        "min_train_regret_loser_20, min_train_regret_winner_20"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.884937030361687, 4.884937030361687)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5P6kq2Kuw0d"
      },
      "source": [
        "# Iteration1 :\n",
        "\n",
        "slice1 = 0\n",
        "\n",
        "loser1 = [train_regret_loser_1[slice1],\n",
        "       train_regret_loser_2[slice1],\n",
        "       train_regret_loser_3[slice1],\n",
        "       train_regret_loser_4[slice1],\n",
        "       train_regret_loser_5[slice1],\n",
        "       train_regret_loser_6[slice1],\n",
        "       train_regret_loser_7[slice1],\n",
        "       train_regret_loser_8[slice1],\n",
        "       train_regret_loser_9[slice1],\n",
        "       train_regret_loser_10[slice1],\n",
        "       train_regret_loser_11[slice1],\n",
        "       train_regret_loser_12[slice1],\n",
        "       train_regret_loser_13[slice1],\n",
        "       train_regret_loser_14[slice1],\n",
        "       train_regret_loser_15[slice1],\n",
        "       train_regret_loser_16[slice1],\n",
        "       train_regret_loser_17[slice1],\n",
        "       train_regret_loser_18[slice1],\n",
        "       train_regret_loser_19[slice1],\n",
        "       train_regret_loser_20[slice1]]\n",
        "\n",
        "winner1 = [train_regret_winner_1[slice1],\n",
        "       train_regret_winner_2[slice1],\n",
        "       train_regret_winner_3[slice1],\n",
        "       train_regret_winner_4[slice1],\n",
        "       train_regret_winner_5[slice1],\n",
        "       train_regret_winner_6[slice1],\n",
        "       train_regret_winner_7[slice1],\n",
        "       train_regret_winner_8[slice1],\n",
        "       train_regret_winner_9[slice1],\n",
        "       train_regret_winner_10[slice1],\n",
        "       train_regret_winner_11[slice1],\n",
        "       train_regret_winner_12[slice1],\n",
        "       train_regret_winner_13[slice1],\n",
        "       train_regret_winner_14[slice1],\n",
        "       train_regret_winner_15[slice1],\n",
        "       train_regret_winner_16[slice1],\n",
        "       train_regret_winner_17[slice1],\n",
        "       train_regret_winner_18[slice1],\n",
        "       train_regret_winner_19[slice1],\n",
        "       train_regret_winner_20[slice1]]\n",
        "\n",
        "loser1_results = pd.DataFrame(loser1).sort_values(by=[0], ascending=False)\n",
        "winner1_results = pd.DataFrame(winner1).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser1 = np.asarray(loser1_results[4:5][0])[0]\n",
        "median_loser1 = np.asarray(loser1_results[9:10][0])[0]\n",
        "upper_loser1 = np.asarray(loser1_results[14:15][0])[0]\n",
        "\n",
        "lower_winner1 = np.asarray(winner1_results[4:5][0])[0]\n",
        "median_winner1 = np.asarray(winner1_results[9:10][0])[0]\n",
        "upper_winner1 = np.asarray(winner1_results[14:15][0])[0]"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXcnj2pNuw3X"
      },
      "source": [
        "# Iteration11 :\n",
        "\n",
        "slice11 = 10\n",
        "\n",
        "loser11 = [train_regret_loser_1[slice11],\n",
        "       train_regret_loser_2[slice11],\n",
        "       train_regret_loser_3[slice11],\n",
        "       train_regret_loser_4[slice11],\n",
        "       train_regret_loser_5[slice11],\n",
        "       train_regret_loser_6[slice11],\n",
        "       train_regret_loser_7[slice11],\n",
        "       train_regret_loser_8[slice11],\n",
        "       train_regret_loser_9[slice11],\n",
        "       train_regret_loser_10[slice11],\n",
        "       train_regret_loser_11[slice11],\n",
        "       train_regret_loser_12[slice11],\n",
        "       train_regret_loser_13[slice11],\n",
        "       train_regret_loser_14[slice11],\n",
        "       train_regret_loser_15[slice11],\n",
        "       train_regret_loser_16[slice11],\n",
        "       train_regret_loser_17[slice11],\n",
        "       train_regret_loser_18[slice11],\n",
        "       train_regret_loser_19[slice11],\n",
        "       train_regret_loser_20[slice11]]\n",
        "\n",
        "winner11 = [train_regret_winner_1[slice11],\n",
        "       train_regret_winner_2[slice11],\n",
        "       train_regret_winner_3[slice11],\n",
        "       train_regret_winner_4[slice11],\n",
        "       train_regret_winner_5[slice11],\n",
        "       train_regret_winner_6[slice11],\n",
        "       train_regret_winner_7[slice11],\n",
        "       train_regret_winner_8[slice11],\n",
        "       train_regret_winner_9[slice11],\n",
        "       train_regret_winner_10[slice11],\n",
        "       train_regret_winner_11[slice11],\n",
        "       train_regret_winner_12[slice11],\n",
        "       train_regret_winner_13[slice11],\n",
        "       train_regret_winner_14[slice11],\n",
        "       train_regret_winner_15[slice11],\n",
        "       train_regret_winner_16[slice11],\n",
        "       train_regret_winner_17[slice11],\n",
        "       train_regret_winner_18[slice11],\n",
        "       train_regret_winner_19[slice11],\n",
        "       train_regret_winner_20[slice11]]\n",
        "\n",
        "loser11_results = pd.DataFrame(loser11).sort_values(by=[0], ascending=False)\n",
        "winner11_results = pd.DataFrame(winner11).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser11 = np.asarray(loser11_results[4:5][0])[0]\n",
        "median_loser11 = np.asarray(loser11_results[9:10][0])[0]\n",
        "upper_loser11 = np.asarray(loser11_results[14:15][0])[0]\n",
        "\n",
        "lower_winner11 = np.asarray(winner11_results[4:5][0])[0]\n",
        "median_winner11 = np.asarray(winner11_results[9:10][0])[0]\n",
        "upper_winner11 = np.asarray(winner11_results[14:15][0])[0]"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxQa6BAVuw6L"
      },
      "source": [
        "# Iteration21 :\n",
        "\n",
        "slice21 = 20\n",
        "\n",
        "loser21 = [train_regret_loser_1[slice21],\n",
        "       train_regret_loser_2[slice21],\n",
        "       train_regret_loser_3[slice21],\n",
        "       train_regret_loser_4[slice21],\n",
        "       train_regret_loser_5[slice21],\n",
        "       train_regret_loser_6[slice21],\n",
        "       train_regret_loser_7[slice21],\n",
        "       train_regret_loser_8[slice21],\n",
        "       train_regret_loser_9[slice21],\n",
        "       train_regret_loser_10[slice21],\n",
        "       train_regret_loser_11[slice21],\n",
        "       train_regret_loser_12[slice21],\n",
        "       train_regret_loser_13[slice21],\n",
        "       train_regret_loser_14[slice21],\n",
        "       train_regret_loser_15[slice21],\n",
        "       train_regret_loser_16[slice21],\n",
        "       train_regret_loser_17[slice21],\n",
        "       train_regret_loser_18[slice21],\n",
        "       train_regret_loser_19[slice21],\n",
        "       train_regret_loser_20[slice21]]\n",
        "\n",
        "winner21 = [train_regret_winner_1[slice21],\n",
        "       train_regret_winner_2[slice21],\n",
        "       train_regret_winner_3[slice21],\n",
        "       train_regret_winner_4[slice21],\n",
        "       train_regret_winner_5[slice21],\n",
        "       train_regret_winner_6[slice21],\n",
        "       train_regret_winner_7[slice21],\n",
        "       train_regret_winner_8[slice21],\n",
        "       train_regret_winner_9[slice21],\n",
        "       train_regret_winner_10[slice21],\n",
        "       train_regret_winner_11[slice21],\n",
        "       train_regret_winner_12[slice21],\n",
        "       train_regret_winner_13[slice21],\n",
        "       train_regret_winner_14[slice21],\n",
        "       train_regret_winner_15[slice21],\n",
        "       train_regret_winner_16[slice21],\n",
        "       train_regret_winner_17[slice21],\n",
        "       train_regret_winner_18[slice21],\n",
        "       train_regret_winner_19[slice21],\n",
        "       train_regret_winner_20[slice21]]\n",
        "\n",
        "loser21_results = pd.DataFrame(loser21).sort_values(by=[0], ascending=False)\n",
        "winner21_results = pd.DataFrame(winner21).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser21 = np.asarray(loser21_results[4:5][0])[0]\n",
        "median_loser21 = np.asarray(loser21_results[9:10][0])[0]\n",
        "upper_loser21 = np.asarray(loser21_results[14:15][0])[0]\n",
        "\n",
        "lower_winner21 = np.asarray(winner21_results[4:5][0])[0]\n",
        "median_winner21 = np.asarray(winner21_results[9:10][0])[0]\n",
        "upper_winner21 = np.asarray(winner21_results[14:15][0])[0]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wdJdIsWuw8r"
      },
      "source": [
        "# Iteration31 :\n",
        "\n",
        "slice31 = 30\n",
        "\n",
        "loser31 = [train_regret_loser_1[slice31],\n",
        "       train_regret_loser_2[slice31],\n",
        "       train_regret_loser_3[slice31],\n",
        "       train_regret_loser_4[slice31],\n",
        "       train_regret_loser_5[slice31],\n",
        "       train_regret_loser_6[slice31],\n",
        "       train_regret_loser_7[slice31],\n",
        "       train_regret_loser_8[slice31],\n",
        "       train_regret_loser_9[slice31],\n",
        "       train_regret_loser_10[slice31],\n",
        "       train_regret_loser_11[slice31],\n",
        "       train_regret_loser_12[slice31],\n",
        "       train_regret_loser_13[slice31],\n",
        "       train_regret_loser_14[slice31],\n",
        "       train_regret_loser_15[slice31],\n",
        "       train_regret_loser_16[slice31],\n",
        "       train_regret_loser_17[slice31],\n",
        "       train_regret_loser_18[slice31],\n",
        "       train_regret_loser_19[slice31],\n",
        "       train_regret_loser_20[slice31]]\n",
        "\n",
        "winner31 = [train_regret_winner_1[slice31],\n",
        "       train_regret_winner_2[slice31],\n",
        "       train_regret_winner_3[slice31],\n",
        "       train_regret_winner_4[slice31],\n",
        "       train_regret_winner_5[slice31],\n",
        "       train_regret_winner_6[slice31],\n",
        "       train_regret_winner_7[slice31],\n",
        "       train_regret_winner_8[slice31],\n",
        "       train_regret_winner_9[slice31],\n",
        "       train_regret_winner_10[slice31],\n",
        "       train_regret_winner_11[slice31],\n",
        "       train_regret_winner_12[slice31],\n",
        "       train_regret_winner_13[slice31],\n",
        "       train_regret_winner_14[slice31],\n",
        "       train_regret_winner_15[slice31],\n",
        "       train_regret_winner_16[slice31],\n",
        "       train_regret_winner_17[slice31],\n",
        "       train_regret_winner_18[slice31],\n",
        "       train_regret_winner_19[slice31],\n",
        "       train_regret_winner_20[slice31]]\n",
        "\n",
        "loser31_results = pd.DataFrame(loser31).sort_values(by=[0], ascending=False)\n",
        "winner31_results = pd.DataFrame(winner31).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser31 = np.asarray(loser31_results[4:5][0])[0]\n",
        "median_loser31 = np.asarray(loser31_results[9:10][0])[0]\n",
        "upper_loser31 = np.asarray(loser31_results[14:15][0])[0]\n",
        "\n",
        "lower_winner31 = np.asarray(winner31_results[4:5][0])[0]\n",
        "median_winner31 = np.asarray(winner31_results[9:10][0])[0]\n",
        "upper_winner31 = np.asarray(winner31_results[14:15][0])[0]"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vWZBDufuw_Z"
      },
      "source": [
        "# Iteration41 :\n",
        "\n",
        "slice41 = 40\n",
        "\n",
        "loser41 = [train_regret_loser_1[slice41],\n",
        "       train_regret_loser_2[slice41],\n",
        "       train_regret_loser_3[slice41],\n",
        "       train_regret_loser_4[slice41],\n",
        "       train_regret_loser_5[slice41],\n",
        "       train_regret_loser_6[slice41],\n",
        "       train_regret_loser_7[slice41],\n",
        "       train_regret_loser_8[slice41],\n",
        "       train_regret_loser_9[slice41],\n",
        "       train_regret_loser_10[slice41],\n",
        "       train_regret_loser_11[slice41],\n",
        "       train_regret_loser_12[slice41],\n",
        "       train_regret_loser_13[slice41],\n",
        "       train_regret_loser_14[slice41],\n",
        "       train_regret_loser_15[slice41],\n",
        "       train_regret_loser_16[slice41],\n",
        "       train_regret_loser_17[slice41],\n",
        "       train_regret_loser_18[slice41],\n",
        "       train_regret_loser_19[slice41],\n",
        "       train_regret_loser_20[slice41]]\n",
        "\n",
        "winner41 = [train_regret_winner_1[slice41],\n",
        "       train_regret_winner_2[slice41],\n",
        "       train_regret_winner_3[slice41],\n",
        "       train_regret_winner_4[slice41],\n",
        "       train_regret_winner_5[slice41],\n",
        "       train_regret_winner_6[slice41],\n",
        "       train_regret_winner_7[slice41],\n",
        "       train_regret_winner_8[slice41],\n",
        "       train_regret_winner_9[slice41],\n",
        "       train_regret_winner_10[slice41],\n",
        "       train_regret_winner_11[slice41],\n",
        "       train_regret_winner_12[slice41],\n",
        "       train_regret_winner_13[slice41],\n",
        "       train_regret_winner_14[slice41],\n",
        "       train_regret_winner_15[slice41],\n",
        "       train_regret_winner_16[slice41],\n",
        "       train_regret_winner_17[slice41],\n",
        "       train_regret_winner_18[slice41],\n",
        "       train_regret_winner_19[slice41],\n",
        "       train_regret_winner_20[slice41]]\n",
        "\n",
        "loser41_results = pd.DataFrame(loser41).sort_values(by=[0], ascending=False)\n",
        "winner41_results = pd.DataFrame(winner41).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser41 = np.asarray(loser41_results[4:5][0])[0]\n",
        "median_loser41 = np.asarray(loser41_results[9:10][0])[0]\n",
        "upper_loser41 = np.asarray(loser41_results[14:15][0])[0]\n",
        "\n",
        "lower_winner41 = np.asarray(winner41_results[4:5][0])[0]\n",
        "median_winner41 = np.asarray(winner41_results[9:10][0])[0]\n",
        "upper_winner41 = np.asarray(winner41_results[14:15][0])[0]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwi_GzjiuxB6"
      },
      "source": [
        "# Iteration51 :\n",
        "\n",
        "slice51 = 50\n",
        "\n",
        "loser51 = [train_regret_loser_1[slice51],\n",
        "       train_regret_loser_2[slice51],\n",
        "       train_regret_loser_3[slice51],\n",
        "       train_regret_loser_4[slice51],\n",
        "       train_regret_loser_5[slice51],\n",
        "       train_regret_loser_6[slice51],\n",
        "       train_regret_loser_7[slice51],\n",
        "       train_regret_loser_8[slice51],\n",
        "       train_regret_loser_9[slice51],\n",
        "       train_regret_loser_10[slice51],\n",
        "       train_regret_loser_11[slice51],\n",
        "       train_regret_loser_12[slice51],\n",
        "       train_regret_loser_13[slice51],\n",
        "       train_regret_loser_14[slice51],\n",
        "       train_regret_loser_15[slice51],\n",
        "       train_regret_loser_16[slice51],\n",
        "       train_regret_loser_17[slice51],\n",
        "       train_regret_loser_18[slice51],\n",
        "       train_regret_loser_19[slice51],\n",
        "       train_regret_loser_20[slice51]]\n",
        "\n",
        "winner51 = [train_regret_winner_1[slice51],\n",
        "       train_regret_winner_2[slice51],\n",
        "       train_regret_winner_3[slice51],\n",
        "       train_regret_winner_4[slice51],\n",
        "       train_regret_winner_5[slice51],\n",
        "       train_regret_winner_6[slice51],\n",
        "       train_regret_winner_7[slice51],\n",
        "       train_regret_winner_8[slice51],\n",
        "       train_regret_winner_9[slice51],\n",
        "       train_regret_winner_10[slice51],\n",
        "       train_regret_winner_11[slice51],\n",
        "       train_regret_winner_12[slice51],\n",
        "       train_regret_winner_13[slice51],\n",
        "       train_regret_winner_14[slice51],\n",
        "       train_regret_winner_15[slice51],\n",
        "       train_regret_winner_16[slice51],\n",
        "       train_regret_winner_17[slice51],\n",
        "       train_regret_winner_18[slice51],\n",
        "       train_regret_winner_19[slice51],\n",
        "       train_regret_winner_20[slice51]]\n",
        "\n",
        "loser51_results = pd.DataFrame(loser51).sort_values(by=[0], ascending=False)\n",
        "winner51_results = pd.DataFrame(winner51).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser51 = np.asarray(loser51_results[4:5][0])[0]\n",
        "median_loser51 = np.asarray(loser51_results[9:10][0])[0]\n",
        "upper_loser51 = np.asarray(loser51_results[14:15][0])[0]\n",
        "\n",
        "lower_winner51 = np.asarray(winner51_results[4:5][0])[0]\n",
        "median_winner51 = np.asarray(winner51_results[9:10][0])[0]\n",
        "upper_winner51 = np.asarray(winner51_results[14:15][0])[0]"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk9nlS6puxFZ"
      },
      "source": [
        "# Iteration61 :\n",
        "\n",
        "slice61 = 60\n",
        "\n",
        "loser61 = [train_regret_loser_1[slice61],\n",
        "       train_regret_loser_2[slice61],\n",
        "       train_regret_loser_3[slice61],\n",
        "       train_regret_loser_4[slice61],\n",
        "       train_regret_loser_5[slice61],\n",
        "       train_regret_loser_6[slice61],\n",
        "       train_regret_loser_7[slice61],\n",
        "       train_regret_loser_8[slice61],\n",
        "       train_regret_loser_9[slice61],\n",
        "       train_regret_loser_10[slice61],\n",
        "       train_regret_loser_11[slice61],\n",
        "       train_regret_loser_12[slice61],\n",
        "       train_regret_loser_13[slice61],\n",
        "       train_regret_loser_14[slice61],\n",
        "       train_regret_loser_15[slice61],\n",
        "       train_regret_loser_16[slice61],\n",
        "       train_regret_loser_17[slice61],\n",
        "       train_regret_loser_18[slice61],\n",
        "       train_regret_loser_19[slice61],\n",
        "       train_regret_loser_20[slice61]]\n",
        "\n",
        "winner61 = [train_regret_winner_1[slice61],\n",
        "       train_regret_winner_2[slice61],\n",
        "       train_regret_winner_3[slice61],\n",
        "       train_regret_winner_4[slice61],\n",
        "       train_regret_winner_5[slice61],\n",
        "       train_regret_winner_6[slice61],\n",
        "       train_regret_winner_7[slice61],\n",
        "       train_regret_winner_8[slice61],\n",
        "       train_regret_winner_9[slice61],\n",
        "       train_regret_winner_10[slice61],\n",
        "       train_regret_winner_11[slice61],\n",
        "       train_regret_winner_12[slice61],\n",
        "       train_regret_winner_13[slice61],\n",
        "       train_regret_winner_14[slice61],\n",
        "       train_regret_winner_15[slice61],\n",
        "       train_regret_winner_16[slice61],\n",
        "       train_regret_winner_17[slice61],\n",
        "       train_regret_winner_18[slice61],\n",
        "       train_regret_winner_19[slice61],\n",
        "       train_regret_winner_20[slice61]]\n",
        "\n",
        "loser61_results = pd.DataFrame(loser61).sort_values(by=[0], ascending=False)\n",
        "winner61_results = pd.DataFrame(winner61).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser61 = np.asarray(loser61_results[4:5][0])[0]\n",
        "median_loser61 = np.asarray(loser61_results[9:10][0])[0]\n",
        "upper_loser61 = np.asarray(loser61_results[14:15][0])[0]\n",
        "\n",
        "lower_winner61 = np.asarray(winner61_results[4:5][0])[0]\n",
        "median_winner61 = np.asarray(winner61_results[9:10][0])[0]\n",
        "upper_winner61 = np.asarray(winner61_results[14:15][0])[0]"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMus9vDpuxHN"
      },
      "source": [
        "# Iteration71 :\n",
        "\n",
        "slice71 = 70\n",
        "\n",
        "loser71 = [train_regret_loser_1[slice71],\n",
        "       train_regret_loser_2[slice71],\n",
        "       train_regret_loser_3[slice71],\n",
        "       train_regret_loser_4[slice71],\n",
        "       train_regret_loser_5[slice71],\n",
        "       train_regret_loser_6[slice71],\n",
        "       train_regret_loser_7[slice71],\n",
        "       train_regret_loser_8[slice71],\n",
        "       train_regret_loser_9[slice71],\n",
        "       train_regret_loser_10[slice71],\n",
        "       train_regret_loser_11[slice71],\n",
        "       train_regret_loser_12[slice71],\n",
        "       train_regret_loser_13[slice71],\n",
        "       train_regret_loser_14[slice71],\n",
        "       train_regret_loser_15[slice71],\n",
        "       train_regret_loser_16[slice71],\n",
        "       train_regret_loser_17[slice71],\n",
        "       train_regret_loser_18[slice71],\n",
        "       train_regret_loser_19[slice71],\n",
        "       train_regret_loser_20[slice71]]\n",
        "\n",
        "winner71 = [train_regret_winner_1[slice71],\n",
        "       train_regret_winner_2[slice71],\n",
        "       train_regret_winner_3[slice71],\n",
        "       train_regret_winner_4[slice71],\n",
        "       train_regret_winner_5[slice71],\n",
        "       train_regret_winner_6[slice71],\n",
        "       train_regret_winner_7[slice71],\n",
        "       train_regret_winner_8[slice71],\n",
        "       train_regret_winner_9[slice71],\n",
        "       train_regret_winner_10[slice71],\n",
        "       train_regret_winner_11[slice71],\n",
        "       train_regret_winner_12[slice71],\n",
        "       train_regret_winner_13[slice71],\n",
        "       train_regret_winner_14[slice71],\n",
        "       train_regret_winner_15[slice71],\n",
        "       train_regret_winner_16[slice71],\n",
        "       train_regret_winner_17[slice71],\n",
        "       train_regret_winner_18[slice71],\n",
        "       train_regret_winner_19[slice71],\n",
        "       train_regret_winner_20[slice71]]\n",
        "\n",
        "loser71_results = pd.DataFrame(loser71).sort_values(by=[0], ascending=False)\n",
        "winner71_results = pd.DataFrame(winner71).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser71 = np.asarray(loser71_results[4:5][0])[0]\n",
        "median_loser71 = np.asarray(loser71_results[9:10][0])[0]\n",
        "upper_loser71 = np.asarray(loser71_results[14:15][0])[0]\n",
        "\n",
        "lower_winner71 = np.asarray(winner71_results[4:5][0])[0]\n",
        "median_winner71 = np.asarray(winner71_results[9:10][0])[0]\n",
        "upper_winner71 = np.asarray(winner71_results[14:15][0])[0]"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Mg0x9vuxL4"
      },
      "source": [
        "# Iteration81 :\n",
        "\n",
        "slice81 = 80\n",
        "\n",
        "loser81 = [train_regret_loser_1[slice81],\n",
        "       train_regret_loser_2[slice81],\n",
        "       train_regret_loser_3[slice81],\n",
        "       train_regret_loser_4[slice81],\n",
        "       train_regret_loser_5[slice81],\n",
        "       train_regret_loser_6[slice81],\n",
        "       train_regret_loser_7[slice81],\n",
        "       train_regret_loser_8[slice81],\n",
        "       train_regret_loser_9[slice81],\n",
        "       train_regret_loser_10[slice81],\n",
        "       train_regret_loser_11[slice81],\n",
        "       train_regret_loser_12[slice81],\n",
        "       train_regret_loser_13[slice81],\n",
        "       train_regret_loser_14[slice81],\n",
        "       train_regret_loser_15[slice81],\n",
        "       train_regret_loser_16[slice81],\n",
        "       train_regret_loser_17[slice81],\n",
        "       train_regret_loser_18[slice81],\n",
        "       train_regret_loser_19[slice81],\n",
        "       train_regret_loser_20[slice81]]\n",
        "\n",
        "winner81 = [train_regret_winner_1[slice81],\n",
        "       train_regret_winner_2[slice81],\n",
        "       train_regret_winner_3[slice81],\n",
        "       train_regret_winner_4[slice81],\n",
        "       train_regret_winner_5[slice81],\n",
        "       train_regret_winner_6[slice81],\n",
        "       train_regret_winner_7[slice81],\n",
        "       train_regret_winner_8[slice81],\n",
        "       train_regret_winner_9[slice81],\n",
        "       train_regret_winner_10[slice81],\n",
        "       train_regret_winner_11[slice81],\n",
        "       train_regret_winner_12[slice81],\n",
        "       train_regret_winner_13[slice81],\n",
        "       train_regret_winner_14[slice81],\n",
        "       train_regret_winner_15[slice81],\n",
        "       train_regret_winner_16[slice81],\n",
        "       train_regret_winner_17[slice81],\n",
        "       train_regret_winner_18[slice81],\n",
        "       train_regret_winner_19[slice81],\n",
        "       train_regret_winner_20[slice81]]\n",
        "\n",
        "loser81_results = pd.DataFrame(loser81).sort_values(by=[0], ascending=False)\n",
        "winner81_results = pd.DataFrame(winner81).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser81 = np.asarray(loser81_results[4:5][0])[0]\n",
        "median_loser81 = np.asarray(loser81_results[9:10][0])[0]\n",
        "upper_loser81 = np.asarray(loser81_results[14:15][0])[0]\n",
        "\n",
        "lower_winner81 = np.asarray(winner81_results[4:5][0])[0]\n",
        "median_winner81 = np.asarray(winner81_results[9:10][0])[0]\n",
        "upper_winner81 = np.asarray(winner81_results[14:15][0])[0]"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gu9K8XlteV4"
      },
      "source": [
        "# Iteration91 :\n",
        "\n",
        "slice91 = 90\n",
        "\n",
        "loser91 = [train_regret_loser_1[slice91],\n",
        "       train_regret_loser_2[slice91],\n",
        "       train_regret_loser_3[slice91],\n",
        "       train_regret_loser_4[slice91],\n",
        "       train_regret_loser_5[slice91],\n",
        "       train_regret_loser_6[slice91],\n",
        "       train_regret_loser_7[slice91],\n",
        "       train_regret_loser_8[slice91],\n",
        "       train_regret_loser_9[slice91],\n",
        "       train_regret_loser_10[slice91],\n",
        "       train_regret_loser_11[slice91],\n",
        "       train_regret_loser_12[slice91],\n",
        "       train_regret_loser_13[slice91],\n",
        "       train_regret_loser_14[slice91],\n",
        "       train_regret_loser_15[slice91],\n",
        "       train_regret_loser_16[slice91],\n",
        "       train_regret_loser_17[slice91],\n",
        "       train_regret_loser_18[slice91],\n",
        "       train_regret_loser_19[slice91],\n",
        "       train_regret_loser_20[slice91]]\n",
        "\n",
        "winner91 = [train_regret_winner_1[slice91],\n",
        "       train_regret_winner_2[slice91],\n",
        "       train_regret_winner_3[slice91],\n",
        "       train_regret_winner_4[slice91],\n",
        "       train_regret_winner_5[slice91],\n",
        "       train_regret_winner_6[slice91],\n",
        "       train_regret_winner_7[slice91],\n",
        "       train_regret_winner_8[slice91],\n",
        "       train_regret_winner_9[slice91],\n",
        "       train_regret_winner_10[slice91],\n",
        "       train_regret_winner_11[slice91],\n",
        "       train_regret_winner_12[slice91],\n",
        "       train_regret_winner_13[slice91],\n",
        "       train_regret_winner_14[slice91],\n",
        "       train_regret_winner_15[slice91],\n",
        "       train_regret_winner_16[slice91],\n",
        "       train_regret_winner_17[slice91],\n",
        "       train_regret_winner_18[slice91],\n",
        "       train_regret_winner_19[slice91],\n",
        "       train_regret_winner_20[slice91]]\n",
        "\n",
        "loser91_results = pd.DataFrame(loser91).sort_values(by=[0], ascending=False)\n",
        "winner91_results = pd.DataFrame(winner91).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser91 = np.asarray(loser91_results[4:5][0])[0]\n",
        "median_loser91 = np.asarray(loser91_results[9:10][0])[0]\n",
        "upper_loser91 = np.asarray(loser91_results[14:15][0])[0]\n",
        "\n",
        "lower_winner91 = np.asarray(winner91_results[4:5][0])[0]\n",
        "median_winner91 = np.asarray(winner91_results[9:10][0])[0]\n",
        "upper_winner91 = np.asarray(winner91_results[14:15][0])[0]"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVVeft6steXv"
      },
      "source": [
        "# Iteration101 :\n",
        "\n",
        "slice101 = 100\n",
        "\n",
        "loser101 = [train_regret_loser_1[slice101],\n",
        "       train_regret_loser_2[slice101],\n",
        "       train_regret_loser_3[slice101],\n",
        "       train_regret_loser_4[slice101],\n",
        "       train_regret_loser_5[slice101],\n",
        "       train_regret_loser_6[slice101],\n",
        "       train_regret_loser_7[slice101],\n",
        "       train_regret_loser_8[slice101],\n",
        "       train_regret_loser_9[slice101],\n",
        "       train_regret_loser_10[slice101],\n",
        "       train_regret_loser_11[slice101],\n",
        "       train_regret_loser_12[slice101],\n",
        "       train_regret_loser_13[slice101],\n",
        "       train_regret_loser_14[slice101],\n",
        "       train_regret_loser_15[slice101],\n",
        "       train_regret_loser_16[slice101],\n",
        "       train_regret_loser_17[slice101],\n",
        "       train_regret_loser_18[slice101],\n",
        "       train_regret_loser_19[slice101],\n",
        "       train_regret_loser_20[slice101]]\n",
        "\n",
        "winner101 = [train_regret_winner_1[slice101],\n",
        "       train_regret_winner_2[slice101],\n",
        "       train_regret_winner_3[slice101],\n",
        "       train_regret_winner_4[slice101],\n",
        "       train_regret_winner_5[slice101],\n",
        "       train_regret_winner_6[slice101],\n",
        "       train_regret_winner_7[slice101],\n",
        "       train_regret_winner_8[slice101],\n",
        "       train_regret_winner_9[slice101],\n",
        "       train_regret_winner_10[slice101],\n",
        "       train_regret_winner_11[slice101],\n",
        "       train_regret_winner_12[slice101],\n",
        "       train_regret_winner_13[slice101],\n",
        "       train_regret_winner_14[slice101],\n",
        "       train_regret_winner_15[slice101],\n",
        "       train_regret_winner_16[slice101],\n",
        "       train_regret_winner_17[slice101],\n",
        "       train_regret_winner_18[slice101],\n",
        "       train_regret_winner_19[slice101],\n",
        "       train_regret_winner_20[slice101]]\n",
        "\n",
        "loser101_results = pd.DataFrame(loser101).sort_values(by=[0], ascending=False)\n",
        "winner101_results = pd.DataFrame(winner101).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser101 = np.asarray(loser101_results[4:5][0])[0]\n",
        "median_loser101 = np.asarray(loser101_results[9:10][0])[0]\n",
        "upper_loser101 = np.asarray(loser101_results[14:15][0])[0]\n",
        "\n",
        "lower_winner101 = np.asarray(winner101_results[4:5][0])[0]\n",
        "median_winner101 = np.asarray(winner101_results[9:10][0])[0]\n",
        "upper_winner101 = np.asarray(winner101_results[14:15][0])[0]"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maqbtTXXtebT"
      },
      "source": [
        "# Iteration2 :\n",
        "\n",
        "slice2 = 1\n",
        "\n",
        "loser2 = [train_regret_loser_1[slice2],\n",
        "       train_regret_loser_2[slice2],\n",
        "       train_regret_loser_3[slice2],\n",
        "       train_regret_loser_4[slice2],\n",
        "       train_regret_loser_5[slice2],\n",
        "       train_regret_loser_6[slice2],\n",
        "       train_regret_loser_7[slice2],\n",
        "       train_regret_loser_8[slice2],\n",
        "       train_regret_loser_9[slice2],\n",
        "       train_regret_loser_10[slice2],\n",
        "       train_regret_loser_11[slice2],\n",
        "       train_regret_loser_12[slice2],\n",
        "       train_regret_loser_13[slice2],\n",
        "       train_regret_loser_14[slice2],\n",
        "       train_regret_loser_15[slice2],\n",
        "       train_regret_loser_16[slice2],\n",
        "       train_regret_loser_17[slice2],\n",
        "       train_regret_loser_18[slice2],\n",
        "       train_regret_loser_19[slice2],\n",
        "       train_regret_loser_20[slice2]]\n",
        "\n",
        "winner2 = [train_regret_winner_1[slice2],\n",
        "       train_regret_winner_2[slice2],\n",
        "       train_regret_winner_3[slice2],\n",
        "       train_regret_winner_4[slice2],\n",
        "       train_regret_winner_5[slice2],\n",
        "       train_regret_winner_6[slice2],\n",
        "       train_regret_winner_7[slice2],\n",
        "       train_regret_winner_8[slice2],\n",
        "       train_regret_winner_9[slice2],\n",
        "       train_regret_winner_10[slice2],\n",
        "       train_regret_winner_11[slice2],\n",
        "       train_regret_winner_12[slice2],\n",
        "       train_regret_winner_13[slice2],\n",
        "       train_regret_winner_14[slice2],\n",
        "       train_regret_winner_15[slice2],\n",
        "       train_regret_winner_16[slice2],\n",
        "       train_regret_winner_17[slice2],\n",
        "       train_regret_winner_18[slice2],\n",
        "       train_regret_winner_19[slice2],\n",
        "       train_regret_winner_20[slice2]]\n",
        "\n",
        "loser2_results = pd.DataFrame(loser2).sort_values(by=[0], ascending=False)\n",
        "winner2_results = pd.DataFrame(winner2).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser2 = np.asarray(loser2_results[4:5][0])[0]\n",
        "median_loser2 = np.asarray(loser2_results[9:10][0])[0]\n",
        "upper_loser2 = np.asarray(loser2_results[14:15][0])[0]\n",
        "\n",
        "lower_winner2 = np.asarray(winner2_results[4:5][0])[0]\n",
        "median_winner2 = np.asarray(winner2_results[9:10][0])[0]\n",
        "upper_winner2 = np.asarray(winner2_results[14:15][0])[0]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWIBh0dQw-ZM"
      },
      "source": [
        "# Iteration12 :\n",
        "\n",
        "slice12 = 11\n",
        "\n",
        "loser12 = [train_regret_loser_1[slice12],\n",
        "       train_regret_loser_2[slice12],\n",
        "       train_regret_loser_3[slice12],\n",
        "       train_regret_loser_4[slice12],\n",
        "       train_regret_loser_5[slice12],\n",
        "       train_regret_loser_6[slice12],\n",
        "       train_regret_loser_7[slice12],\n",
        "       train_regret_loser_8[slice12],\n",
        "       train_regret_loser_9[slice12],\n",
        "       train_regret_loser_10[slice12],\n",
        "       train_regret_loser_11[slice12],\n",
        "       train_regret_loser_12[slice12],\n",
        "       train_regret_loser_13[slice12],\n",
        "       train_regret_loser_14[slice12],\n",
        "       train_regret_loser_15[slice12],\n",
        "       train_regret_loser_16[slice12],\n",
        "       train_regret_loser_17[slice12],\n",
        "       train_regret_loser_18[slice12],\n",
        "       train_regret_loser_19[slice12],\n",
        "       train_regret_loser_20[slice12]]\n",
        "\n",
        "winner12 = [train_regret_winner_1[slice12],\n",
        "       train_regret_winner_2[slice12],\n",
        "       train_regret_winner_3[slice12],\n",
        "       train_regret_winner_4[slice12],\n",
        "       train_regret_winner_5[slice12],\n",
        "       train_regret_winner_6[slice12],\n",
        "       train_regret_winner_7[slice12],\n",
        "       train_regret_winner_8[slice12],\n",
        "       train_regret_winner_9[slice12],\n",
        "       train_regret_winner_10[slice12],\n",
        "       train_regret_winner_11[slice12],\n",
        "       train_regret_winner_12[slice12],\n",
        "       train_regret_winner_13[slice12],\n",
        "       train_regret_winner_14[slice12],\n",
        "       train_regret_winner_15[slice12],\n",
        "       train_regret_winner_16[slice12],\n",
        "       train_regret_winner_17[slice12],\n",
        "       train_regret_winner_18[slice12],\n",
        "       train_regret_winner_19[slice12],\n",
        "       train_regret_winner_20[slice12]]\n",
        "\n",
        "loser12_results = pd.DataFrame(loser12).sort_values(by=[0], ascending=False)\n",
        "winner12_results = pd.DataFrame(winner12).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser12 = np.asarray(loser12_results[4:5][0])[0]\n",
        "median_loser12 = np.asarray(loser12_results[9:10][0])[0]\n",
        "upper_loser12 = np.asarray(loser12_results[14:15][0])[0]\n",
        "\n",
        "lower_winner12 = np.asarray(winner12_results[4:5][0])[0]\n",
        "median_winner12 = np.asarray(winner12_results[9:10][0])[0]\n",
        "upper_winner12 = np.asarray(winner12_results[14:15][0])[0]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjIhsei3w-cV"
      },
      "source": [
        "# Iteration22 :\n",
        "\n",
        "slice22 = 21\n",
        "\n",
        "loser22 = [train_regret_loser_1[slice22],\n",
        "       train_regret_loser_2[slice22],\n",
        "       train_regret_loser_3[slice22],\n",
        "       train_regret_loser_4[slice22],\n",
        "       train_regret_loser_5[slice22],\n",
        "       train_regret_loser_6[slice22],\n",
        "       train_regret_loser_7[slice22],\n",
        "       train_regret_loser_8[slice22],\n",
        "       train_regret_loser_9[slice22],\n",
        "       train_regret_loser_10[slice22],\n",
        "       train_regret_loser_11[slice22],\n",
        "       train_regret_loser_12[slice22],\n",
        "       train_regret_loser_13[slice22],\n",
        "       train_regret_loser_14[slice22],\n",
        "       train_regret_loser_15[slice22],\n",
        "       train_regret_loser_16[slice22],\n",
        "       train_regret_loser_17[slice22],\n",
        "       train_regret_loser_18[slice22],\n",
        "       train_regret_loser_19[slice22],\n",
        "       train_regret_loser_20[slice22]]\n",
        "\n",
        "winner22 = [train_regret_winner_1[slice22],\n",
        "       train_regret_winner_2[slice22],\n",
        "       train_regret_winner_3[slice22],\n",
        "       train_regret_winner_4[slice22],\n",
        "       train_regret_winner_5[slice22],\n",
        "       train_regret_winner_6[slice22],\n",
        "       train_regret_winner_7[slice22],\n",
        "       train_regret_winner_8[slice22],\n",
        "       train_regret_winner_9[slice22],\n",
        "       train_regret_winner_10[slice22],\n",
        "       train_regret_winner_11[slice22],\n",
        "       train_regret_winner_12[slice22],\n",
        "       train_regret_winner_13[slice22],\n",
        "       train_regret_winner_14[slice22],\n",
        "       train_regret_winner_15[slice22],\n",
        "       train_regret_winner_16[slice22],\n",
        "       train_regret_winner_17[slice22],\n",
        "       train_regret_winner_18[slice22],\n",
        "       train_regret_winner_19[slice22],\n",
        "       train_regret_winner_20[slice22]]\n",
        "\n",
        "loser22_results = pd.DataFrame(loser22).sort_values(by=[0], ascending=False)\n",
        "winner22_results = pd.DataFrame(winner22).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser22 = np.asarray(loser22_results[4:5][0])[0]\n",
        "median_loser22 = np.asarray(loser22_results[9:10][0])[0]\n",
        "upper_loser22 = np.asarray(loser22_results[14:15][0])[0]\n",
        "\n",
        "lower_winner22 = np.asarray(winner22_results[4:5][0])[0]\n",
        "median_winner22 = np.asarray(winner22_results[9:10][0])[0]\n",
        "upper_winner22 = np.asarray(winner22_results[14:15][0])[0]"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur9p9GkHw-fq"
      },
      "source": [
        "# Iteration32 :\n",
        "\n",
        "slice32 = 31\n",
        "\n",
        "loser32 = [train_regret_loser_1[slice32],\n",
        "       train_regret_loser_2[slice32],\n",
        "       train_regret_loser_3[slice32],\n",
        "       train_regret_loser_4[slice32],\n",
        "       train_regret_loser_5[slice32],\n",
        "       train_regret_loser_6[slice32],\n",
        "       train_regret_loser_7[slice32],\n",
        "       train_regret_loser_8[slice32],\n",
        "       train_regret_loser_9[slice32],\n",
        "       train_regret_loser_10[slice32],\n",
        "       train_regret_loser_11[slice32],\n",
        "       train_regret_loser_12[slice32],\n",
        "       train_regret_loser_13[slice32],\n",
        "       train_regret_loser_14[slice32],\n",
        "       train_regret_loser_15[slice32],\n",
        "       train_regret_loser_16[slice32],\n",
        "       train_regret_loser_17[slice32],\n",
        "       train_regret_loser_18[slice32],\n",
        "       train_regret_loser_19[slice32],\n",
        "       train_regret_loser_20[slice32]]\n",
        "\n",
        "winner32 = [train_regret_winner_1[slice32],\n",
        "       train_regret_winner_2[slice32],\n",
        "       train_regret_winner_3[slice32],\n",
        "       train_regret_winner_4[slice32],\n",
        "       train_regret_winner_5[slice32],\n",
        "       train_regret_winner_6[slice32],\n",
        "       train_regret_winner_7[slice32],\n",
        "       train_regret_winner_8[slice32],\n",
        "       train_regret_winner_9[slice32],\n",
        "       train_regret_winner_10[slice32],\n",
        "       train_regret_winner_11[slice32],\n",
        "       train_regret_winner_12[slice32],\n",
        "       train_regret_winner_13[slice32],\n",
        "       train_regret_winner_14[slice32],\n",
        "       train_regret_winner_15[slice32],\n",
        "       train_regret_winner_16[slice32],\n",
        "       train_regret_winner_17[slice32],\n",
        "       train_regret_winner_18[slice32],\n",
        "       train_regret_winner_19[slice32],\n",
        "       train_regret_winner_20[slice32]]\n",
        "\n",
        "loser32_results = pd.DataFrame(loser32).sort_values(by=[0], ascending=False)\n",
        "winner32_results = pd.DataFrame(winner32).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser32 = np.asarray(loser32_results[4:5][0])[0]\n",
        "median_loser32 = np.asarray(loser32_results[9:10][0])[0]\n",
        "upper_loser32 = np.asarray(loser32_results[14:15][0])[0]\n",
        "\n",
        "lower_winner32 = np.asarray(winner32_results[4:5][0])[0]\n",
        "median_winner32 = np.asarray(winner32_results[9:10][0])[0]\n",
        "upper_winner32 = np.asarray(winner32_results[14:15][0])[0]"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_rzHB8w-hy"
      },
      "source": [
        "# Iteration42 :\n",
        "\n",
        "slice42 = 41\n",
        "\n",
        "loser42 = [train_regret_loser_1[slice42],\n",
        "       train_regret_loser_2[slice42],\n",
        "       train_regret_loser_3[slice42],\n",
        "       train_regret_loser_4[slice42],\n",
        "       train_regret_loser_5[slice42],\n",
        "       train_regret_loser_6[slice42],\n",
        "       train_regret_loser_7[slice42],\n",
        "       train_regret_loser_8[slice42],\n",
        "       train_regret_loser_9[slice42],\n",
        "       train_regret_loser_10[slice42],\n",
        "       train_regret_loser_11[slice42],\n",
        "       train_regret_loser_12[slice42],\n",
        "       train_regret_loser_13[slice42],\n",
        "       train_regret_loser_14[slice42],\n",
        "       train_regret_loser_15[slice42],\n",
        "       train_regret_loser_16[slice42],\n",
        "       train_regret_loser_17[slice42],\n",
        "       train_regret_loser_18[slice42],\n",
        "       train_regret_loser_19[slice42],\n",
        "       train_regret_loser_20[slice42]]\n",
        "\n",
        "winner42 = [train_regret_winner_1[slice42],\n",
        "       train_regret_winner_2[slice42],\n",
        "       train_regret_winner_3[slice42],\n",
        "       train_regret_winner_4[slice42],\n",
        "       train_regret_winner_5[slice42],\n",
        "       train_regret_winner_6[slice42],\n",
        "       train_regret_winner_7[slice42],\n",
        "       train_regret_winner_8[slice42],\n",
        "       train_regret_winner_9[slice42],\n",
        "       train_regret_winner_10[slice42],\n",
        "       train_regret_winner_11[slice42],\n",
        "       train_regret_winner_12[slice42],\n",
        "       train_regret_winner_13[slice42],\n",
        "       train_regret_winner_14[slice42],\n",
        "       train_regret_winner_15[slice42],\n",
        "       train_regret_winner_16[slice42],\n",
        "       train_regret_winner_17[slice42],\n",
        "       train_regret_winner_18[slice42],\n",
        "       train_regret_winner_19[slice42],\n",
        "       train_regret_winner_20[slice42]]\n",
        "\n",
        "loser42_results = pd.DataFrame(loser42).sort_values(by=[0], ascending=False)\n",
        "winner42_results = pd.DataFrame(winner42).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser42 = np.asarray(loser42_results[4:5][0])[0]\n",
        "median_loser42 = np.asarray(loser42_results[9:10][0])[0]\n",
        "upper_loser42 = np.asarray(loser42_results[14:15][0])[0]\n",
        "\n",
        "lower_winner42 = np.asarray(winner42_results[4:5][0])[0]\n",
        "median_winner42 = np.asarray(winner42_results[9:10][0])[0]\n",
        "upper_winner42 = np.asarray(winner42_results[14:15][0])[0]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKUUG6vAw-kz"
      },
      "source": [
        "# Iteration52 :\n",
        "\n",
        "slice52 = 51\n",
        "\n",
        "loser52 = [train_regret_loser_1[slice52],\n",
        "       train_regret_loser_2[slice52],\n",
        "       train_regret_loser_3[slice52],\n",
        "       train_regret_loser_4[slice52],\n",
        "       train_regret_loser_5[slice52],\n",
        "       train_regret_loser_6[slice52],\n",
        "       train_regret_loser_7[slice52],\n",
        "       train_regret_loser_8[slice52],\n",
        "       train_regret_loser_9[slice52],\n",
        "       train_regret_loser_10[slice52],\n",
        "       train_regret_loser_11[slice52],\n",
        "       train_regret_loser_12[slice52],\n",
        "       train_regret_loser_13[slice52],\n",
        "       train_regret_loser_14[slice52],\n",
        "       train_regret_loser_15[slice52],\n",
        "       train_regret_loser_16[slice52],\n",
        "       train_regret_loser_17[slice52],\n",
        "       train_regret_loser_18[slice52],\n",
        "       train_regret_loser_19[slice52],\n",
        "       train_regret_loser_20[slice52]]\n",
        "\n",
        "winner52 = [train_regret_winner_1[slice52],\n",
        "       train_regret_winner_2[slice52],\n",
        "       train_regret_winner_3[slice52],\n",
        "       train_regret_winner_4[slice52],\n",
        "       train_regret_winner_5[slice52],\n",
        "       train_regret_winner_6[slice52],\n",
        "       train_regret_winner_7[slice52],\n",
        "       train_regret_winner_8[slice52],\n",
        "       train_regret_winner_9[slice52],\n",
        "       train_regret_winner_10[slice52],\n",
        "       train_regret_winner_11[slice52],\n",
        "       train_regret_winner_12[slice52],\n",
        "       train_regret_winner_13[slice52],\n",
        "       train_regret_winner_14[slice52],\n",
        "       train_regret_winner_15[slice52],\n",
        "       train_regret_winner_16[slice52],\n",
        "       train_regret_winner_17[slice52],\n",
        "       train_regret_winner_18[slice52],\n",
        "       train_regret_winner_19[slice52],\n",
        "       train_regret_winner_20[slice52]]\n",
        "\n",
        "loser52_results = pd.DataFrame(loser52).sort_values(by=[0], ascending=False)\n",
        "winner52_results = pd.DataFrame(winner52).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser52 = np.asarray(loser52_results[4:5][0])[0]\n",
        "median_loser52 = np.asarray(loser52_results[9:10][0])[0]\n",
        "upper_loser52 = np.asarray(loser52_results[14:15][0])[0]\n",
        "\n",
        "lower_winner52 = np.asarray(winner52_results[4:5][0])[0]\n",
        "median_winner52 = np.asarray(winner52_results[9:10][0])[0]\n",
        "upper_winner52 = np.asarray(winner52_results[14:15][0])[0]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-9cJNkew-nY"
      },
      "source": [
        "# Iteration62 :\n",
        "\n",
        "slice62 = 61\n",
        "\n",
        "loser62 = [train_regret_loser_1[slice62],\n",
        "       train_regret_loser_2[slice62],\n",
        "       train_regret_loser_3[slice62],\n",
        "       train_regret_loser_4[slice62],\n",
        "       train_regret_loser_5[slice62],\n",
        "       train_regret_loser_6[slice62],\n",
        "       train_regret_loser_7[slice62],\n",
        "       train_regret_loser_8[slice62],\n",
        "       train_regret_loser_9[slice62],\n",
        "       train_regret_loser_10[slice62],\n",
        "       train_regret_loser_11[slice62],\n",
        "       train_regret_loser_12[slice62],\n",
        "       train_regret_loser_13[slice62],\n",
        "       train_regret_loser_14[slice62],\n",
        "       train_regret_loser_15[slice62],\n",
        "       train_regret_loser_16[slice62],\n",
        "       train_regret_loser_17[slice62],\n",
        "       train_regret_loser_18[slice62],\n",
        "       train_regret_loser_19[slice62],\n",
        "       train_regret_loser_20[slice62]]\n",
        "\n",
        "winner62 = [train_regret_winner_1[slice62],\n",
        "       train_regret_winner_2[slice62],\n",
        "       train_regret_winner_3[slice62],\n",
        "       train_regret_winner_4[slice62],\n",
        "       train_regret_winner_5[slice62],\n",
        "       train_regret_winner_6[slice62],\n",
        "       train_regret_winner_7[slice62],\n",
        "       train_regret_winner_8[slice62],\n",
        "       train_regret_winner_9[slice62],\n",
        "       train_regret_winner_10[slice62],\n",
        "       train_regret_winner_11[slice62],\n",
        "       train_regret_winner_12[slice62],\n",
        "       train_regret_winner_13[slice62],\n",
        "       train_regret_winner_14[slice62],\n",
        "       train_regret_winner_15[slice62],\n",
        "       train_regret_winner_16[slice62],\n",
        "       train_regret_winner_17[slice62],\n",
        "       train_regret_winner_18[slice62],\n",
        "       train_regret_winner_19[slice62],\n",
        "       train_regret_winner_20[slice62]]\n",
        "\n",
        "loser62_results = pd.DataFrame(loser62).sort_values(by=[0], ascending=False)\n",
        "winner62_results = pd.DataFrame(winner62).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser62 = np.asarray(loser62_results[4:5][0])[0]\n",
        "median_loser62 = np.asarray(loser62_results[9:10][0])[0]\n",
        "upper_loser62 = np.asarray(loser62_results[14:15][0])[0]\n",
        "\n",
        "lower_winner62 = np.asarray(winner62_results[4:5][0])[0]\n",
        "median_winner62 = np.asarray(winner62_results[9:10][0])[0]\n",
        "upper_winner62 = np.asarray(winner62_results[14:15][0])[0]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DZ8kHHmw-qK"
      },
      "source": [
        "# Iteration72 :\n",
        "\n",
        "slice72 = 71\n",
        "\n",
        "loser72 = [train_regret_loser_1[slice72],\n",
        "       train_regret_loser_2[slice72],\n",
        "       train_regret_loser_3[slice72],\n",
        "       train_regret_loser_4[slice72],\n",
        "       train_regret_loser_5[slice72],\n",
        "       train_regret_loser_6[slice72],\n",
        "       train_regret_loser_7[slice72],\n",
        "       train_regret_loser_8[slice72],\n",
        "       train_regret_loser_9[slice72],\n",
        "       train_regret_loser_10[slice72],\n",
        "       train_regret_loser_11[slice72],\n",
        "       train_regret_loser_12[slice72],\n",
        "       train_regret_loser_13[slice72],\n",
        "       train_regret_loser_14[slice72],\n",
        "       train_regret_loser_15[slice72],\n",
        "       train_regret_loser_16[slice72],\n",
        "       train_regret_loser_17[slice72],\n",
        "       train_regret_loser_18[slice72],\n",
        "       train_regret_loser_19[slice72],\n",
        "       train_regret_loser_20[slice72]]\n",
        "\n",
        "winner72 = [train_regret_winner_1[slice72],\n",
        "       train_regret_winner_2[slice72],\n",
        "       train_regret_winner_3[slice72],\n",
        "       train_regret_winner_4[slice72],\n",
        "       train_regret_winner_5[slice72],\n",
        "       train_regret_winner_6[slice72],\n",
        "       train_regret_winner_7[slice72],\n",
        "       train_regret_winner_8[slice72],\n",
        "       train_regret_winner_9[slice72],\n",
        "       train_regret_winner_10[slice72],\n",
        "       train_regret_winner_11[slice72],\n",
        "       train_regret_winner_12[slice72],\n",
        "       train_regret_winner_13[slice72],\n",
        "       train_regret_winner_14[slice72],\n",
        "       train_regret_winner_15[slice72],\n",
        "       train_regret_winner_16[slice72],\n",
        "       train_regret_winner_17[slice72],\n",
        "       train_regret_winner_18[slice72],\n",
        "       train_regret_winner_19[slice72],\n",
        "       train_regret_winner_20[slice72]]\n",
        "\n",
        "loser72_results = pd.DataFrame(loser72).sort_values(by=[0], ascending=False)\n",
        "winner72_results = pd.DataFrame(winner72).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser72 = np.asarray(loser72_results[4:5][0])[0]\n",
        "median_loser72 = np.asarray(loser72_results[9:10][0])[0]\n",
        "upper_loser72 = np.asarray(loser72_results[14:15][0])[0]\n",
        "\n",
        "lower_winner72 = np.asarray(winner72_results[4:5][0])[0]\n",
        "median_winner72 = np.asarray(winner72_results[9:10][0])[0]\n",
        "upper_winner72 = np.asarray(winner72_results[14:15][0])[0]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBzBvnVyw-sz"
      },
      "source": [
        "# Iteration82 :\n",
        "\n",
        "slice82 = 81\n",
        "\n",
        "loser82 = [train_regret_loser_1[slice82],\n",
        "       train_regret_loser_2[slice82],\n",
        "       train_regret_loser_3[slice82],\n",
        "       train_regret_loser_4[slice82],\n",
        "       train_regret_loser_5[slice82],\n",
        "       train_regret_loser_6[slice82],\n",
        "       train_regret_loser_7[slice82],\n",
        "       train_regret_loser_8[slice82],\n",
        "       train_regret_loser_9[slice82],\n",
        "       train_regret_loser_10[slice82],\n",
        "       train_regret_loser_11[slice82],\n",
        "       train_regret_loser_12[slice82],\n",
        "       train_regret_loser_13[slice82],\n",
        "       train_regret_loser_14[slice82],\n",
        "       train_regret_loser_15[slice82],\n",
        "       train_regret_loser_16[slice82],\n",
        "       train_regret_loser_17[slice82],\n",
        "       train_regret_loser_18[slice82],\n",
        "       train_regret_loser_19[slice82],\n",
        "       train_regret_loser_20[slice82]]\n",
        "\n",
        "winner82 = [train_regret_winner_1[slice82],\n",
        "       train_regret_winner_2[slice82],\n",
        "       train_regret_winner_3[slice82],\n",
        "       train_regret_winner_4[slice82],\n",
        "       train_regret_winner_5[slice82],\n",
        "       train_regret_winner_6[slice82],\n",
        "       train_regret_winner_7[slice82],\n",
        "       train_regret_winner_8[slice82],\n",
        "       train_regret_winner_9[slice82],\n",
        "       train_regret_winner_10[slice82],\n",
        "       train_regret_winner_11[slice82],\n",
        "       train_regret_winner_12[slice82],\n",
        "       train_regret_winner_13[slice82],\n",
        "       train_regret_winner_14[slice82],\n",
        "       train_regret_winner_15[slice82],\n",
        "       train_regret_winner_16[slice82],\n",
        "       train_regret_winner_17[slice82],\n",
        "       train_regret_winner_18[slice82],\n",
        "       train_regret_winner_19[slice82],\n",
        "       train_regret_winner_20[slice82]]\n",
        "\n",
        "loser82_results = pd.DataFrame(loser82).sort_values(by=[0], ascending=False)\n",
        "winner82_results = pd.DataFrame(winner82).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser82 = np.asarray(loser82_results[4:5][0])[0]\n",
        "median_loser82 = np.asarray(loser82_results[9:10][0])[0]\n",
        "upper_loser82 = np.asarray(loser82_results[14:15][0])[0]\n",
        "\n",
        "lower_winner82 = np.asarray(winner82_results[4:5][0])[0]\n",
        "median_winner82 = np.asarray(winner82_results[9:10][0])[0]\n",
        "upper_winner82 = np.asarray(winner82_results[14:15][0])[0]"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qj--n6Bw-y2"
      },
      "source": [
        "# Iteration92 :\n",
        "\n",
        "slice92 = 91\n",
        "\n",
        "loser92 = [train_regret_loser_1[slice92],\n",
        "       train_regret_loser_2[slice92],\n",
        "       train_regret_loser_3[slice92],\n",
        "       train_regret_loser_4[slice92],\n",
        "       train_regret_loser_5[slice92],\n",
        "       train_regret_loser_6[slice92],\n",
        "       train_regret_loser_7[slice92],\n",
        "       train_regret_loser_8[slice92],\n",
        "       train_regret_loser_9[slice92],\n",
        "       train_regret_loser_10[slice92],\n",
        "       train_regret_loser_11[slice92],\n",
        "       train_regret_loser_12[slice92],\n",
        "       train_regret_loser_13[slice92],\n",
        "       train_regret_loser_14[slice92],\n",
        "       train_regret_loser_15[slice92],\n",
        "       train_regret_loser_16[slice92],\n",
        "       train_regret_loser_17[slice92],\n",
        "       train_regret_loser_18[slice92],\n",
        "       train_regret_loser_19[slice92],\n",
        "       train_regret_loser_20[slice92]]\n",
        "\n",
        "winner92 = [train_regret_winner_1[slice92],\n",
        "       train_regret_winner_2[slice92],\n",
        "       train_regret_winner_3[slice92],\n",
        "       train_regret_winner_4[slice92],\n",
        "       train_regret_winner_5[slice92],\n",
        "       train_regret_winner_6[slice92],\n",
        "       train_regret_winner_7[slice92],\n",
        "       train_regret_winner_8[slice92],\n",
        "       train_regret_winner_9[slice92],\n",
        "       train_regret_winner_10[slice92],\n",
        "       train_regret_winner_11[slice92],\n",
        "       train_regret_winner_12[slice92],\n",
        "       train_regret_winner_13[slice92],\n",
        "       train_regret_winner_14[slice92],\n",
        "       train_regret_winner_15[slice92],\n",
        "       train_regret_winner_16[slice92],\n",
        "       train_regret_winner_17[slice92],\n",
        "       train_regret_winner_18[slice92],\n",
        "       train_regret_winner_19[slice92],\n",
        "       train_regret_winner_20[slice92]]\n",
        "\n",
        "loser92_results = pd.DataFrame(loser92).sort_values(by=[0], ascending=False)\n",
        "winner92_results = pd.DataFrame(winner92).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser92 = np.asarray(loser92_results[4:5][0])[0]\n",
        "median_loser92 = np.asarray(loser92_results[9:10][0])[0]\n",
        "upper_loser92 = np.asarray(loser92_results[14:15][0])[0]\n",
        "\n",
        "lower_winner92 = np.asarray(winner92_results[4:5][0])[0]\n",
        "median_winner92 = np.asarray(winner92_results[9:10][0])[0]\n",
        "upper_winner92 = np.asarray(winner92_results[14:15][0])[0]"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaJ5KqLdw-0L"
      },
      "source": [
        "# Iteration3 :\n",
        "\n",
        "slice3 = 2\n",
        "\n",
        "loser3 = [train_regret_loser_1[slice3],\n",
        "       train_regret_loser_2[slice3],\n",
        "       train_regret_loser_3[slice3],\n",
        "       train_regret_loser_4[slice3],\n",
        "       train_regret_loser_5[slice3],\n",
        "       train_regret_loser_6[slice3],\n",
        "       train_regret_loser_7[slice3],\n",
        "       train_regret_loser_8[slice3],\n",
        "       train_regret_loser_9[slice3],\n",
        "       train_regret_loser_10[slice3],\n",
        "       train_regret_loser_11[slice3],\n",
        "       train_regret_loser_12[slice3],\n",
        "       train_regret_loser_13[slice3],\n",
        "       train_regret_loser_14[slice3],\n",
        "       train_regret_loser_15[slice3],\n",
        "       train_regret_loser_16[slice3],\n",
        "       train_regret_loser_17[slice3],\n",
        "       train_regret_loser_18[slice3],\n",
        "       train_regret_loser_19[slice3],\n",
        "       train_regret_loser_20[slice3]]\n",
        "\n",
        "winner3 = [train_regret_winner_1[slice3],\n",
        "       train_regret_winner_2[slice3],\n",
        "       train_regret_winner_3[slice3],\n",
        "       train_regret_winner_4[slice3],\n",
        "       train_regret_winner_5[slice3],\n",
        "       train_regret_winner_6[slice3],\n",
        "       train_regret_winner_7[slice3],\n",
        "       train_regret_winner_8[slice3],\n",
        "       train_regret_winner_9[slice3],\n",
        "       train_regret_winner_10[slice3],\n",
        "       train_regret_winner_11[slice3],\n",
        "       train_regret_winner_12[slice3],\n",
        "       train_regret_winner_13[slice3],\n",
        "       train_regret_winner_14[slice3],\n",
        "       train_regret_winner_15[slice3],\n",
        "       train_regret_winner_16[slice3],\n",
        "       train_regret_winner_17[slice3],\n",
        "       train_regret_winner_18[slice3],\n",
        "       train_regret_winner_19[slice3],\n",
        "       train_regret_winner_20[slice3]]\n",
        "\n",
        "loser3_results = pd.DataFrame(loser3).sort_values(by=[0], ascending=False)\n",
        "winner3_results = pd.DataFrame(winner3).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser3 = np.asarray(loser3_results[4:5][0])[0]\n",
        "median_loser3 = np.asarray(loser3_results[9:10][0])[0]\n",
        "upper_loser3 = np.asarray(loser3_results[14:15][0])[0]\n",
        "\n",
        "lower_winner3 = np.asarray(winner3_results[4:5][0])[0]\n",
        "median_winner3 = np.asarray(winner3_results[9:10][0])[0]\n",
        "upper_winner3 = np.asarray(winner3_results[14:15][0])[0]"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkaoT1dyw-16"
      },
      "source": [
        "# Iteration13 :\n",
        "\n",
        "slice13 = 12\n",
        "\n",
        "loser13 = [train_regret_loser_1[slice13],\n",
        "       train_regret_loser_2[slice13],\n",
        "       train_regret_loser_3[slice13],\n",
        "       train_regret_loser_4[slice13],\n",
        "       train_regret_loser_5[slice13],\n",
        "       train_regret_loser_6[slice13],\n",
        "       train_regret_loser_7[slice13],\n",
        "       train_regret_loser_8[slice13],\n",
        "       train_regret_loser_9[slice13],\n",
        "       train_regret_loser_10[slice13],\n",
        "       train_regret_loser_11[slice13],\n",
        "       train_regret_loser_12[slice13],\n",
        "       train_regret_loser_13[slice13],\n",
        "       train_regret_loser_14[slice13],\n",
        "       train_regret_loser_15[slice13],\n",
        "       train_regret_loser_16[slice13],\n",
        "       train_regret_loser_17[slice13],\n",
        "       train_regret_loser_18[slice13],\n",
        "       train_regret_loser_19[slice13],\n",
        "       train_regret_loser_20[slice13]]\n",
        "\n",
        "winner13 = [train_regret_winner_1[slice13],\n",
        "       train_regret_winner_2[slice13],\n",
        "       train_regret_winner_3[slice13],\n",
        "       train_regret_winner_4[slice13],\n",
        "       train_regret_winner_5[slice13],\n",
        "       train_regret_winner_6[slice13],\n",
        "       train_regret_winner_7[slice13],\n",
        "       train_regret_winner_8[slice13],\n",
        "       train_regret_winner_9[slice13],\n",
        "       train_regret_winner_10[slice13],\n",
        "       train_regret_winner_11[slice13],\n",
        "       train_regret_winner_12[slice13],\n",
        "       train_regret_winner_13[slice13],\n",
        "       train_regret_winner_14[slice13],\n",
        "       train_regret_winner_15[slice13],\n",
        "       train_regret_winner_16[slice13],\n",
        "       train_regret_winner_17[slice13],\n",
        "       train_regret_winner_18[slice13],\n",
        "       train_regret_winner_19[slice13],\n",
        "       train_regret_winner_20[slice13]]\n",
        "\n",
        "loser13_results = pd.DataFrame(loser12).sort_values(by=[0], ascending=False)\n",
        "winner13_results = pd.DataFrame(winner12).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser13 = np.asarray(loser13_results[4:5][0])[0]\n",
        "median_loser13 = np.asarray(loser13_results[9:10][0])[0]\n",
        "upper_loser13 = np.asarray(loser13_results[14:15][0])[0]\n",
        "\n",
        "lower_winner13 = np.asarray(winner13_results[4:5][0])[0]\n",
        "median_winner13 = np.asarray(winner13_results[9:10][0])[0]\n",
        "upper_winner13 = np.asarray(winner13_results[14:15][0])[0]"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZbVMrBaw-4B"
      },
      "source": [
        "# Iteration23 :\n",
        "\n",
        "slice23 = 22\n",
        "\n",
        "loser23 = [train_regret_loser_1[slice23],\n",
        "       train_regret_loser_2[slice23],\n",
        "       train_regret_loser_3[slice23],\n",
        "       train_regret_loser_4[slice23],\n",
        "       train_regret_loser_5[slice23],\n",
        "       train_regret_loser_6[slice23],\n",
        "       train_regret_loser_7[slice23],\n",
        "       train_regret_loser_8[slice23],\n",
        "       train_regret_loser_9[slice23],\n",
        "       train_regret_loser_10[slice23],\n",
        "       train_regret_loser_11[slice23],\n",
        "       train_regret_loser_12[slice23],\n",
        "       train_regret_loser_13[slice23],\n",
        "       train_regret_loser_14[slice23],\n",
        "       train_regret_loser_15[slice23],\n",
        "       train_regret_loser_16[slice23],\n",
        "       train_regret_loser_17[slice23],\n",
        "       train_regret_loser_18[slice23],\n",
        "       train_regret_loser_19[slice23],\n",
        "       train_regret_loser_20[slice23]]\n",
        "\n",
        "winner23 = [train_regret_winner_1[slice23],\n",
        "       train_regret_winner_2[slice23],\n",
        "       train_regret_winner_3[slice23],\n",
        "       train_regret_winner_4[slice23],\n",
        "       train_regret_winner_5[slice23],\n",
        "       train_regret_winner_6[slice23],\n",
        "       train_regret_winner_7[slice23],\n",
        "       train_regret_winner_8[slice23],\n",
        "       train_regret_winner_9[slice23],\n",
        "       train_regret_winner_10[slice23],\n",
        "       train_regret_winner_11[slice23],\n",
        "       train_regret_winner_12[slice23],\n",
        "       train_regret_winner_13[slice23],\n",
        "       train_regret_winner_14[slice23],\n",
        "       train_regret_winner_15[slice23],\n",
        "       train_regret_winner_16[slice23],\n",
        "       train_regret_winner_17[slice23],\n",
        "       train_regret_winner_18[slice23],\n",
        "       train_regret_winner_19[slice23],\n",
        "       train_regret_winner_20[slice23]]\n",
        "\n",
        "loser23_results = pd.DataFrame(loser23).sort_values(by=[0], ascending=False)\n",
        "winner23_results = pd.DataFrame(winner23).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser23 = np.asarray(loser23_results[4:5][0])[0]\n",
        "median_loser23 = np.asarray(loser23_results[9:10][0])[0]\n",
        "upper_loser23 = np.asarray(loser23_results[14:15][0])[0]\n",
        "\n",
        "lower_winner23 = np.asarray(winner23_results[4:5][0])[0]\n",
        "median_winner23 = np.asarray(winner23_results[9:10][0])[0]\n",
        "upper_winner23 = np.asarray(winner23_results[14:15][0])[0]"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUa6HRCUw-7G"
      },
      "source": [
        "# Iteration33 :\n",
        "\n",
        "slice33 = 32\n",
        "\n",
        "loser33 = [train_regret_loser_1[slice33],\n",
        "       train_regret_loser_2[slice33],\n",
        "       train_regret_loser_3[slice33],\n",
        "       train_regret_loser_4[slice33],\n",
        "       train_regret_loser_5[slice33],\n",
        "       train_regret_loser_6[slice33],\n",
        "       train_regret_loser_7[slice33],\n",
        "       train_regret_loser_8[slice33],\n",
        "       train_regret_loser_9[slice33],\n",
        "       train_regret_loser_10[slice33],\n",
        "       train_regret_loser_11[slice33],\n",
        "       train_regret_loser_12[slice33],\n",
        "       train_regret_loser_13[slice33],\n",
        "       train_regret_loser_14[slice33],\n",
        "       train_regret_loser_15[slice33],\n",
        "       train_regret_loser_16[slice33],\n",
        "       train_regret_loser_17[slice33],\n",
        "       train_regret_loser_18[slice33],\n",
        "       train_regret_loser_19[slice33],\n",
        "       train_regret_loser_20[slice33]]\n",
        "\n",
        "winner33 = [train_regret_winner_1[slice33],\n",
        "       train_regret_winner_2[slice33],\n",
        "       train_regret_winner_3[slice33],\n",
        "       train_regret_winner_4[slice33],\n",
        "       train_regret_winner_5[slice33],\n",
        "       train_regret_winner_6[slice33],\n",
        "       train_regret_winner_7[slice33],\n",
        "       train_regret_winner_8[slice33],\n",
        "       train_regret_winner_9[slice33],\n",
        "       train_regret_winner_10[slice33],\n",
        "       train_regret_winner_11[slice33],\n",
        "       train_regret_winner_12[slice33],\n",
        "       train_regret_winner_13[slice33],\n",
        "       train_regret_winner_14[slice33],\n",
        "       train_regret_winner_15[slice33],\n",
        "       train_regret_winner_16[slice33],\n",
        "       train_regret_winner_17[slice33],\n",
        "       train_regret_winner_18[slice33],\n",
        "       train_regret_winner_19[slice33],\n",
        "       train_regret_winner_20[slice33]]\n",
        "\n",
        "loser33_results = pd.DataFrame(loser33).sort_values(by=[0], ascending=False)\n",
        "winner33_results = pd.DataFrame(winner33).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser33 = np.asarray(loser33_results[4:5][0])[0]\n",
        "median_loser33 = np.asarray(loser33_results[9:10][0])[0]\n",
        "upper_loser33 = np.asarray(loser33_results[14:15][0])[0]\n",
        "\n",
        "lower_winner33 = np.asarray(winner33_results[4:5][0])[0]\n",
        "median_winner33 = np.asarray(winner33_results[9:10][0])[0]\n",
        "upper_winner33 = np.asarray(winner33_results[14:15][0])[0]"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EVxQwsxw-9n"
      },
      "source": [
        "# Iteration43 :\n",
        "\n",
        "slice43 = 42\n",
        "\n",
        "loser43 = [train_regret_loser_1[slice43],\n",
        "       train_regret_loser_2[slice43],\n",
        "       train_regret_loser_3[slice43],\n",
        "       train_regret_loser_4[slice43],\n",
        "       train_regret_loser_5[slice43],\n",
        "       train_regret_loser_6[slice43],\n",
        "       train_regret_loser_7[slice43],\n",
        "       train_regret_loser_8[slice43],\n",
        "       train_regret_loser_9[slice43],\n",
        "       train_regret_loser_10[slice43],\n",
        "       train_regret_loser_11[slice43],\n",
        "       train_regret_loser_12[slice43],\n",
        "       train_regret_loser_13[slice43],\n",
        "       train_regret_loser_14[slice43],\n",
        "       train_regret_loser_15[slice43],\n",
        "       train_regret_loser_16[slice43],\n",
        "       train_regret_loser_17[slice43],\n",
        "       train_regret_loser_18[slice43],\n",
        "       train_regret_loser_19[slice43],\n",
        "       train_regret_loser_20[slice43]]\n",
        "\n",
        "winner43 = [train_regret_winner_1[slice43],\n",
        "       train_regret_winner_2[slice43],\n",
        "       train_regret_winner_3[slice43],\n",
        "       train_regret_winner_4[slice43],\n",
        "       train_regret_winner_5[slice43],\n",
        "       train_regret_winner_6[slice43],\n",
        "       train_regret_winner_7[slice43],\n",
        "       train_regret_winner_8[slice43],\n",
        "       train_regret_winner_9[slice43],\n",
        "       train_regret_winner_10[slice43],\n",
        "       train_regret_winner_11[slice43],\n",
        "       train_regret_winner_12[slice43],\n",
        "       train_regret_winner_13[slice43],\n",
        "       train_regret_winner_14[slice43],\n",
        "       train_regret_winner_15[slice43],\n",
        "       train_regret_winner_16[slice43],\n",
        "       train_regret_winner_17[slice43],\n",
        "       train_regret_winner_18[slice43],\n",
        "       train_regret_winner_19[slice43],\n",
        "       train_regret_winner_20[slice43]]\n",
        "\n",
        "loser43_results = pd.DataFrame(loser43).sort_values(by=[0], ascending=False)\n",
        "winner43_results = pd.DataFrame(winner43).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser43 = np.asarray(loser43_results[4:5][0])[0]\n",
        "median_loser43 = np.asarray(loser43_results[9:10][0])[0]\n",
        "upper_loser43 = np.asarray(loser43_results[14:15][0])[0]\n",
        "\n",
        "lower_winner43 = np.asarray(winner43_results[4:5][0])[0]\n",
        "median_winner43 = np.asarray(winner43_results[9:10][0])[0]\n",
        "upper_winner43 = np.asarray(winner43_results[14:15][0])[0]"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQtRyMv-w_AZ"
      },
      "source": [
        "# Iteration53 :\n",
        "\n",
        "slice53 = 52\n",
        "\n",
        "loser53 = [train_regret_loser_1[slice53],\n",
        "       train_regret_loser_2[slice53],\n",
        "       train_regret_loser_3[slice53],\n",
        "       train_regret_loser_4[slice53],\n",
        "       train_regret_loser_5[slice53],\n",
        "       train_regret_loser_6[slice53],\n",
        "       train_regret_loser_7[slice53],\n",
        "       train_regret_loser_8[slice53],\n",
        "       train_regret_loser_9[slice53],\n",
        "       train_regret_loser_10[slice53],\n",
        "       train_regret_loser_11[slice53],\n",
        "       train_regret_loser_12[slice53],\n",
        "       train_regret_loser_13[slice53],\n",
        "       train_regret_loser_14[slice53],\n",
        "       train_regret_loser_15[slice53],\n",
        "       train_regret_loser_16[slice53],\n",
        "       train_regret_loser_17[slice53],\n",
        "       train_regret_loser_18[slice53],\n",
        "       train_regret_loser_19[slice53],\n",
        "       train_regret_loser_20[slice53]]\n",
        "\n",
        "winner53 = [train_regret_winner_1[slice53],\n",
        "       train_regret_winner_2[slice53],\n",
        "       train_regret_winner_3[slice53],\n",
        "       train_regret_winner_4[slice53],\n",
        "       train_regret_winner_5[slice53],\n",
        "       train_regret_winner_6[slice53],\n",
        "       train_regret_winner_7[slice53],\n",
        "       train_regret_winner_8[slice53],\n",
        "       train_regret_winner_9[slice53],\n",
        "       train_regret_winner_10[slice53],\n",
        "       train_regret_winner_11[slice53],\n",
        "       train_regret_winner_12[slice53],\n",
        "       train_regret_winner_13[slice53],\n",
        "       train_regret_winner_14[slice53],\n",
        "       train_regret_winner_15[slice53],\n",
        "       train_regret_winner_16[slice53],\n",
        "       train_regret_winner_17[slice53],\n",
        "       train_regret_winner_18[slice53],\n",
        "       train_regret_winner_19[slice53],\n",
        "       train_regret_winner_20[slice53]]\n",
        "\n",
        "loser53_results = pd.DataFrame(loser53).sort_values(by=[0], ascending=False)\n",
        "winner53_results = pd.DataFrame(winner53).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser53 = np.asarray(loser53_results[4:5][0])[0]\n",
        "median_loser53 = np.asarray(loser53_results[9:10][0])[0]\n",
        "upper_loser53 = np.asarray(loser53_results[14:15][0])[0]\n",
        "\n",
        "lower_winner53 = np.asarray(winner53_results[4:5][0])[0]\n",
        "median_winner53 = np.asarray(winner53_results[9:10][0])[0]\n",
        "upper_winner53 = np.asarray(winner53_results[14:15][0])[0]"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CIMEXXYw_DR"
      },
      "source": [
        "# Iteration63 :\n",
        "\n",
        "slice63 = 62\n",
        "\n",
        "loser63 = [train_regret_loser_1[slice63],\n",
        "       train_regret_loser_2[slice63],\n",
        "       train_regret_loser_3[slice63],\n",
        "       train_regret_loser_4[slice63],\n",
        "       train_regret_loser_5[slice63],\n",
        "       train_regret_loser_6[slice63],\n",
        "       train_regret_loser_7[slice63],\n",
        "       train_regret_loser_8[slice63],\n",
        "       train_regret_loser_9[slice63],\n",
        "       train_regret_loser_10[slice63],\n",
        "       train_regret_loser_11[slice63],\n",
        "       train_regret_loser_12[slice63],\n",
        "       train_regret_loser_13[slice63],\n",
        "       train_regret_loser_14[slice63],\n",
        "       train_regret_loser_15[slice63],\n",
        "       train_regret_loser_16[slice63],\n",
        "       train_regret_loser_17[slice63],\n",
        "       train_regret_loser_18[slice63],\n",
        "       train_regret_loser_19[slice63],\n",
        "       train_regret_loser_20[slice63]]\n",
        "\n",
        "winner63 = [train_regret_winner_1[slice63],\n",
        "       train_regret_winner_2[slice63],\n",
        "       train_regret_winner_3[slice63],\n",
        "       train_regret_winner_4[slice63],\n",
        "       train_regret_winner_5[slice63],\n",
        "       train_regret_winner_6[slice63],\n",
        "       train_regret_winner_7[slice63],\n",
        "       train_regret_winner_8[slice63],\n",
        "       train_regret_winner_9[slice63],\n",
        "       train_regret_winner_10[slice63],\n",
        "       train_regret_winner_11[slice63],\n",
        "       train_regret_winner_12[slice63],\n",
        "       train_regret_winner_13[slice63],\n",
        "       train_regret_winner_14[slice63],\n",
        "       train_regret_winner_15[slice63],\n",
        "       train_regret_winner_16[slice63],\n",
        "       train_regret_winner_17[slice63],\n",
        "       train_regret_winner_18[slice63],\n",
        "       train_regret_winner_19[slice63],\n",
        "       train_regret_winner_20[slice63]]\n",
        "\n",
        "loser63_results = pd.DataFrame(loser63).sort_values(by=[0], ascending=False)\n",
        "winner63_results = pd.DataFrame(winner63).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser63 = np.asarray(loser63_results[4:5][0])[0]\n",
        "median_loser63 = np.asarray(loser63_results[9:10][0])[0]\n",
        "upper_loser63 = np.asarray(loser63_results[14:15][0])[0]\n",
        "\n",
        "lower_winner63 = np.asarray(winner63_results[4:5][0])[0]\n",
        "median_winner63 = np.asarray(winner63_results[9:10][0])[0]\n",
        "upper_winner63 = np.asarray(winner63_results[14:15][0])[0]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg4GfwU_w_GF"
      },
      "source": [
        "# Iteration73 :\n",
        "\n",
        "slice73 = 72\n",
        "\n",
        "loser73 = [train_regret_loser_1[slice73],\n",
        "       train_regret_loser_2[slice73],\n",
        "       train_regret_loser_3[slice73],\n",
        "       train_regret_loser_4[slice73],\n",
        "       train_regret_loser_5[slice73],\n",
        "       train_regret_loser_6[slice73],\n",
        "       train_regret_loser_7[slice73],\n",
        "       train_regret_loser_8[slice73],\n",
        "       train_regret_loser_9[slice73],\n",
        "       train_regret_loser_10[slice73],\n",
        "       train_regret_loser_11[slice73],\n",
        "       train_regret_loser_12[slice73],\n",
        "       train_regret_loser_13[slice73],\n",
        "       train_regret_loser_14[slice73],\n",
        "       train_regret_loser_15[slice73],\n",
        "       train_regret_loser_16[slice73],\n",
        "       train_regret_loser_17[slice73],\n",
        "       train_regret_loser_18[slice73],\n",
        "       train_regret_loser_19[slice73],\n",
        "       train_regret_loser_20[slice73]]\n",
        "\n",
        "winner73 = [train_regret_winner_1[slice73],\n",
        "       train_regret_winner_2[slice73],\n",
        "       train_regret_winner_3[slice73],\n",
        "       train_regret_winner_4[slice73],\n",
        "       train_regret_winner_5[slice73],\n",
        "       train_regret_winner_6[slice73],\n",
        "       train_regret_winner_7[slice73],\n",
        "       train_regret_winner_8[slice73],\n",
        "       train_regret_winner_9[slice73],\n",
        "       train_regret_winner_10[slice73],\n",
        "       train_regret_winner_11[slice73],\n",
        "       train_regret_winner_12[slice73],\n",
        "       train_regret_winner_13[slice73],\n",
        "       train_regret_winner_14[slice73],\n",
        "       train_regret_winner_15[slice73],\n",
        "       train_regret_winner_16[slice73],\n",
        "       train_regret_winner_17[slice73],\n",
        "       train_regret_winner_18[slice73],\n",
        "       train_regret_winner_19[slice73],\n",
        "       train_regret_winner_20[slice73]]\n",
        "\n",
        "loser73_results = pd.DataFrame(loser73).sort_values(by=[0], ascending=False)\n",
        "winner73_results = pd.DataFrame(winner73).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser73 = np.asarray(loser73_results[4:5][0])[0]\n",
        "median_loser73 = np.asarray(loser73_results[9:10][0])[0]\n",
        "upper_loser73 = np.asarray(loser73_results[14:15][0])[0]\n",
        "\n",
        "lower_winner73 = np.asarray(winner73_results[4:5][0])[0]\n",
        "median_winner73 = np.asarray(winner73_results[9:10][0])[0]\n",
        "upper_winner73 = np.asarray(winner73_results[14:15][0])[0]"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WmpcEV4w_I9"
      },
      "source": [
        "# Iteration83 :\n",
        "\n",
        "slice83 = 82\n",
        "\n",
        "loser83 = [train_regret_loser_1[slice83],\n",
        "       train_regret_loser_2[slice83],\n",
        "       train_regret_loser_3[slice83],\n",
        "       train_regret_loser_4[slice83],\n",
        "       train_regret_loser_5[slice83],\n",
        "       train_regret_loser_6[slice83],\n",
        "       train_regret_loser_7[slice83],\n",
        "       train_regret_loser_8[slice83],\n",
        "       train_regret_loser_9[slice83],\n",
        "       train_regret_loser_10[slice83],\n",
        "       train_regret_loser_11[slice83],\n",
        "       train_regret_loser_12[slice83],\n",
        "       train_regret_loser_13[slice83],\n",
        "       train_regret_loser_14[slice83],\n",
        "       train_regret_loser_15[slice83],\n",
        "       train_regret_loser_16[slice83],\n",
        "       train_regret_loser_17[slice83],\n",
        "       train_regret_loser_18[slice83],\n",
        "       train_regret_loser_19[slice83],\n",
        "       train_regret_loser_20[slice83]]\n",
        "\n",
        "winner83 = [train_regret_winner_1[slice83],\n",
        "       train_regret_winner_2[slice83],\n",
        "       train_regret_winner_3[slice83],\n",
        "       train_regret_winner_4[slice83],\n",
        "       train_regret_winner_5[slice83],\n",
        "       train_regret_winner_6[slice83],\n",
        "       train_regret_winner_7[slice83],\n",
        "       train_regret_winner_8[slice83],\n",
        "       train_regret_winner_9[slice83],\n",
        "       train_regret_winner_10[slice83],\n",
        "       train_regret_winner_11[slice83],\n",
        "       train_regret_winner_12[slice83],\n",
        "       train_regret_winner_13[slice83],\n",
        "       train_regret_winner_14[slice83],\n",
        "       train_regret_winner_15[slice83],\n",
        "       train_regret_winner_16[slice83],\n",
        "       train_regret_winner_17[slice83],\n",
        "       train_regret_winner_18[slice83],\n",
        "       train_regret_winner_19[slice83],\n",
        "       train_regret_winner_20[slice83]]\n",
        "\n",
        "loser83_results = pd.DataFrame(loser83).sort_values(by=[0], ascending=False)\n",
        "winner83_results = pd.DataFrame(winner83).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser83 = np.asarray(loser83_results[4:5][0])[0]\n",
        "median_loser83 = np.asarray(loser83_results[9:10][0])[0]\n",
        "upper_loser83 = np.asarray(loser83_results[14:15][0])[0]\n",
        "\n",
        "lower_winner83 = np.asarray(winner83_results[4:5][0])[0]\n",
        "median_winner83 = np.asarray(winner83_results[9:10][0])[0]\n",
        "upper_winner83 = np.asarray(winner83_results[14:15][0])[0]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGPwoBZyw_MF"
      },
      "source": [
        "# Iteration93 :\n",
        "\n",
        "slice93 = 92\n",
        "\n",
        "loser93 = [train_regret_loser_1[slice93],\n",
        "       train_regret_loser_2[slice93],\n",
        "       train_regret_loser_3[slice93],\n",
        "       train_regret_loser_4[slice93],\n",
        "       train_regret_loser_5[slice93],\n",
        "       train_regret_loser_6[slice93],\n",
        "       train_regret_loser_7[slice93],\n",
        "       train_regret_loser_8[slice93],\n",
        "       train_regret_loser_9[slice93],\n",
        "       train_regret_loser_10[slice93],\n",
        "       train_regret_loser_11[slice93],\n",
        "       train_regret_loser_12[slice93],\n",
        "       train_regret_loser_13[slice93],\n",
        "       train_regret_loser_14[slice93],\n",
        "       train_regret_loser_15[slice93],\n",
        "       train_regret_loser_16[slice93],\n",
        "       train_regret_loser_17[slice93],\n",
        "       train_regret_loser_18[slice93],\n",
        "       train_regret_loser_19[slice93],\n",
        "       train_regret_loser_20[slice93]]\n",
        "\n",
        "winner93 = [train_regret_winner_1[slice93],\n",
        "       train_regret_winner_2[slice93],\n",
        "       train_regret_winner_3[slice93],\n",
        "       train_regret_winner_4[slice93],\n",
        "       train_regret_winner_5[slice93],\n",
        "       train_regret_winner_6[slice93],\n",
        "       train_regret_winner_7[slice93],\n",
        "       train_regret_winner_8[slice93],\n",
        "       train_regret_winner_9[slice93],\n",
        "       train_regret_winner_10[slice93],\n",
        "       train_regret_winner_11[slice93],\n",
        "       train_regret_winner_12[slice93],\n",
        "       train_regret_winner_13[slice93],\n",
        "       train_regret_winner_14[slice93],\n",
        "       train_regret_winner_15[slice93],\n",
        "       train_regret_winner_16[slice93],\n",
        "       train_regret_winner_17[slice93],\n",
        "       train_regret_winner_18[slice93],\n",
        "       train_regret_winner_19[slice93],\n",
        "       train_regret_winner_20[slice93]]\n",
        "\n",
        "loser93_results = pd.DataFrame(loser93).sort_values(by=[0], ascending=False)\n",
        "winner93_results = pd.DataFrame(winner93).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser93 = np.asarray(loser93_results[4:5][0])[0]\n",
        "median_loser93 = np.asarray(loser93_results[9:10][0])[0]\n",
        "upper_loser93 = np.asarray(loser93_results[14:15][0])[0]\n",
        "\n",
        "lower_winner93 = np.asarray(winner93_results[4:5][0])[0]\n",
        "median_winner93 = np.asarray(winner93_results[9:10][0])[0]\n",
        "upper_winner93 = np.asarray(winner93_results[14:15][0])[0]"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_ghdGzPw_Oq"
      },
      "source": [
        "# Iteration4 :\n",
        "\n",
        "slice4 = 3\n",
        "\n",
        "loser4 = [train_regret_loser_1[slice4],\n",
        "       train_regret_loser_2[slice4],\n",
        "       train_regret_loser_3[slice4],\n",
        "       train_regret_loser_4[slice4],\n",
        "       train_regret_loser_5[slice4],\n",
        "       train_regret_loser_6[slice4],\n",
        "       train_regret_loser_7[slice4],\n",
        "       train_regret_loser_8[slice4],\n",
        "       train_regret_loser_9[slice4],\n",
        "       train_regret_loser_10[slice4],\n",
        "       train_regret_loser_11[slice4],\n",
        "       train_regret_loser_12[slice4],\n",
        "       train_regret_loser_13[slice4],\n",
        "       train_regret_loser_14[slice4],\n",
        "       train_regret_loser_15[slice4],\n",
        "       train_regret_loser_16[slice4],\n",
        "       train_regret_loser_17[slice4],\n",
        "       train_regret_loser_18[slice4],\n",
        "       train_regret_loser_19[slice4],\n",
        "       train_regret_loser_20[slice4]]\n",
        "\n",
        "winner4 = [train_regret_winner_1[slice4],\n",
        "       train_regret_winner_2[slice4],\n",
        "       train_regret_winner_3[slice4],\n",
        "       train_regret_winner_4[slice4],\n",
        "       train_regret_winner_5[slice4],\n",
        "       train_regret_winner_6[slice4],\n",
        "       train_regret_winner_7[slice4],\n",
        "       train_regret_winner_8[slice4],\n",
        "       train_regret_winner_9[slice4],\n",
        "       train_regret_winner_10[slice4],\n",
        "       train_regret_winner_11[slice4],\n",
        "       train_regret_winner_12[slice4],\n",
        "       train_regret_winner_13[slice4],\n",
        "       train_regret_winner_14[slice4],\n",
        "       train_regret_winner_15[slice4],\n",
        "       train_regret_winner_16[slice4],\n",
        "       train_regret_winner_17[slice4],\n",
        "       train_regret_winner_18[slice4],\n",
        "       train_regret_winner_19[slice4],\n",
        "       train_regret_winner_20[slice4]]\n",
        "\n",
        "loser4_results = pd.DataFrame(loser4).sort_values(by=[0], ascending=False)\n",
        "winner4_results = pd.DataFrame(winner4).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser4 = np.asarray(loser4_results[4:5][0])[0]\n",
        "median_loser4 = np.asarray(loser4_results[9:10][0])[0]\n",
        "upper_loser4 = np.asarray(loser4_results[14:15][0])[0]\n",
        "\n",
        "lower_winner4 = np.asarray(winner4_results[4:5][0])[0]\n",
        "median_winner4 = np.asarray(winner4_results[9:10][0])[0]\n",
        "upper_winner4 = np.asarray(winner4_results[14:15][0])[0]"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNvDt4QMw_Rz"
      },
      "source": [
        "# Iteration14 :\n",
        "\n",
        "slice14 = 13\n",
        "\n",
        "loser14 = [train_regret_loser_1[slice14],\n",
        "       train_regret_loser_2[slice14],\n",
        "       train_regret_loser_3[slice14],\n",
        "       train_regret_loser_4[slice14],\n",
        "       train_regret_loser_5[slice14],\n",
        "       train_regret_loser_6[slice14],\n",
        "       train_regret_loser_7[slice14],\n",
        "       train_regret_loser_8[slice14],\n",
        "       train_regret_loser_9[slice14],\n",
        "       train_regret_loser_10[slice14],\n",
        "       train_regret_loser_11[slice14],\n",
        "       train_regret_loser_12[slice14],\n",
        "       train_regret_loser_13[slice14],\n",
        "       train_regret_loser_14[slice14],\n",
        "       train_regret_loser_15[slice14],\n",
        "       train_regret_loser_16[slice14],\n",
        "       train_regret_loser_17[slice14],\n",
        "       train_regret_loser_18[slice14],\n",
        "       train_regret_loser_19[slice14],\n",
        "       train_regret_loser_20[slice14]]\n",
        "\n",
        "winner14 = [train_regret_winner_1[slice14],\n",
        "       train_regret_winner_2[slice14],\n",
        "       train_regret_winner_3[slice14],\n",
        "       train_regret_winner_4[slice14],\n",
        "       train_regret_winner_5[slice14],\n",
        "       train_regret_winner_6[slice14],\n",
        "       train_regret_winner_7[slice14],\n",
        "       train_regret_winner_8[slice14],\n",
        "       train_regret_winner_9[slice14],\n",
        "       train_regret_winner_10[slice14],\n",
        "       train_regret_winner_11[slice14],\n",
        "       train_regret_winner_12[slice14],\n",
        "       train_regret_winner_13[slice14],\n",
        "       train_regret_winner_14[slice14],\n",
        "       train_regret_winner_15[slice14],\n",
        "       train_regret_winner_16[slice14],\n",
        "       train_regret_winner_17[slice14],\n",
        "       train_regret_winner_18[slice14],\n",
        "       train_regret_winner_19[slice14],\n",
        "       train_regret_winner_20[slice14]]\n",
        "\n",
        "loser14_results = pd.DataFrame(loser14).sort_values(by=[0], ascending=False)\n",
        "winner14_results = pd.DataFrame(winner14).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser14 = np.asarray(loser14_results[4:5][0])[0]\n",
        "median_loser14 = np.asarray(loser14_results[9:10][0])[0]\n",
        "upper_loser14 = np.asarray(loser14_results[14:15][0])[0]\n",
        "\n",
        "lower_winner14 = np.asarray(winner14_results[4:5][0])[0]\n",
        "median_winner14 = np.asarray(winner14_results[9:10][0])[0]\n",
        "upper_winner14 = np.asarray(winner14_results[14:15][0])[0]"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx3kMQV0w_Ua"
      },
      "source": [
        "# Iteration24 :\n",
        "\n",
        "slice24 = 23\n",
        "\n",
        "loser24 = [train_regret_loser_1[slice24],\n",
        "       train_regret_loser_2[slice24],\n",
        "       train_regret_loser_3[slice24],\n",
        "       train_regret_loser_4[slice24],\n",
        "       train_regret_loser_5[slice24],\n",
        "       train_regret_loser_6[slice24],\n",
        "       train_regret_loser_7[slice24],\n",
        "       train_regret_loser_8[slice24],\n",
        "       train_regret_loser_9[slice24],\n",
        "       train_regret_loser_10[slice24],\n",
        "       train_regret_loser_11[slice24],\n",
        "       train_regret_loser_12[slice24],\n",
        "       train_regret_loser_13[slice24],\n",
        "       train_regret_loser_14[slice24],\n",
        "       train_regret_loser_15[slice24],\n",
        "       train_regret_loser_16[slice24],\n",
        "       train_regret_loser_17[slice24],\n",
        "       train_regret_loser_18[slice24],\n",
        "       train_regret_loser_19[slice24],\n",
        "       train_regret_loser_20[slice24]]\n",
        "\n",
        "winner24 = [train_regret_winner_1[slice24],\n",
        "       train_regret_winner_2[slice24],\n",
        "       train_regret_winner_3[slice24],\n",
        "       train_regret_winner_4[slice24],\n",
        "       train_regret_winner_5[slice24],\n",
        "       train_regret_winner_6[slice24],\n",
        "       train_regret_winner_7[slice24],\n",
        "       train_regret_winner_8[slice24],\n",
        "       train_regret_winner_9[slice24],\n",
        "       train_regret_winner_10[slice24],\n",
        "       train_regret_winner_11[slice24],\n",
        "       train_regret_winner_12[slice24],\n",
        "       train_regret_winner_13[slice24],\n",
        "       train_regret_winner_14[slice24],\n",
        "       train_regret_winner_15[slice24],\n",
        "       train_regret_winner_16[slice24],\n",
        "       train_regret_winner_17[slice24],\n",
        "       train_regret_winner_18[slice24],\n",
        "       train_regret_winner_19[slice24],\n",
        "       train_regret_winner_20[slice24]]\n",
        "\n",
        "loser24_results = pd.DataFrame(loser24).sort_values(by=[0], ascending=False)\n",
        "winner24_results = pd.DataFrame(winner24).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser24 = np.asarray(loser24_results[4:5][0])[0]\n",
        "median_loser24 = np.asarray(loser24_results[9:10][0])[0]\n",
        "upper_loser24 = np.asarray(loser24_results[14:15][0])[0]\n",
        "\n",
        "lower_winner24 = np.asarray(winner24_results[4:5][0])[0]\n",
        "median_winner24 = np.asarray(winner24_results[9:10][0])[0]\n",
        "upper_winner24 = np.asarray(winner24_results[14:15][0])[0]"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4ljkyMfw_Xj"
      },
      "source": [
        "# Iteration34 :\n",
        "\n",
        "slice34 = 33\n",
        "\n",
        "loser34 = [train_regret_loser_1[slice34],\n",
        "       train_regret_loser_2[slice34],\n",
        "       train_regret_loser_3[slice34],\n",
        "       train_regret_loser_4[slice34],\n",
        "       train_regret_loser_5[slice34],\n",
        "       train_regret_loser_6[slice34],\n",
        "       train_regret_loser_7[slice34],\n",
        "       train_regret_loser_8[slice34],\n",
        "       train_regret_loser_9[slice34],\n",
        "       train_regret_loser_10[slice34],\n",
        "       train_regret_loser_11[slice34],\n",
        "       train_regret_loser_12[slice34],\n",
        "       train_regret_loser_13[slice34],\n",
        "       train_regret_loser_14[slice34],\n",
        "       train_regret_loser_15[slice34],\n",
        "       train_regret_loser_16[slice34],\n",
        "       train_regret_loser_17[slice34],\n",
        "       train_regret_loser_18[slice34],\n",
        "       train_regret_loser_19[slice34],\n",
        "       train_regret_loser_20[slice34]]\n",
        "\n",
        "winner34 = [train_regret_winner_1[slice34],\n",
        "       train_regret_winner_2[slice34],\n",
        "       train_regret_winner_3[slice34],\n",
        "       train_regret_winner_4[slice34],\n",
        "       train_regret_winner_5[slice34],\n",
        "       train_regret_winner_6[slice34],\n",
        "       train_regret_winner_7[slice34],\n",
        "       train_regret_winner_8[slice34],\n",
        "       train_regret_winner_9[slice34],\n",
        "       train_regret_winner_10[slice34],\n",
        "       train_regret_winner_11[slice34],\n",
        "       train_regret_winner_12[slice34],\n",
        "       train_regret_winner_13[slice34],\n",
        "       train_regret_winner_14[slice34],\n",
        "       train_regret_winner_15[slice34],\n",
        "       train_regret_winner_16[slice34],\n",
        "       train_regret_winner_17[slice34],\n",
        "       train_regret_winner_18[slice34],\n",
        "       train_regret_winner_19[slice34],\n",
        "       train_regret_winner_20[slice34]]\n",
        "\n",
        "loser34_results = pd.DataFrame(loser34).sort_values(by=[0], ascending=False)\n",
        "winner34_results = pd.DataFrame(winner34).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser34 = np.asarray(loser34_results[4:5][0])[0]\n",
        "median_loser34 = np.asarray(loser34_results[9:10][0])[0]\n",
        "upper_loser34 = np.asarray(loser34_results[14:15][0])[0]\n",
        "\n",
        "lower_winner34 = np.asarray(winner34_results[4:5][0])[0]\n",
        "median_winner34 = np.asarray(winner34_results[9:10][0])[0]\n",
        "upper_winner34 = np.asarray(winner34_results[14:15][0])[0]"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGKj-NR8w_ae"
      },
      "source": [
        "# Iteration44 :\n",
        "\n",
        "slice44 = 43\n",
        "\n",
        "loser44 = [train_regret_loser_1[slice44],\n",
        "       train_regret_loser_2[slice44],\n",
        "       train_regret_loser_3[slice44],\n",
        "       train_regret_loser_4[slice44],\n",
        "       train_regret_loser_5[slice44],\n",
        "       train_regret_loser_6[slice44],\n",
        "       train_regret_loser_7[slice44],\n",
        "       train_regret_loser_8[slice44],\n",
        "       train_regret_loser_9[slice44],\n",
        "       train_regret_loser_10[slice44],\n",
        "       train_regret_loser_11[slice44],\n",
        "       train_regret_loser_12[slice44],\n",
        "       train_regret_loser_13[slice44],\n",
        "       train_regret_loser_14[slice44],\n",
        "       train_regret_loser_15[slice44],\n",
        "       train_regret_loser_16[slice44],\n",
        "       train_regret_loser_17[slice44],\n",
        "       train_regret_loser_18[slice44],\n",
        "       train_regret_loser_19[slice44],\n",
        "       train_regret_loser_20[slice44]]\n",
        "\n",
        "winner44 = [train_regret_winner_1[slice44],\n",
        "       train_regret_winner_2[slice44],\n",
        "       train_regret_winner_3[slice44],\n",
        "       train_regret_winner_4[slice44],\n",
        "       train_regret_winner_5[slice44],\n",
        "       train_regret_winner_6[slice44],\n",
        "       train_regret_winner_7[slice44],\n",
        "       train_regret_winner_8[slice44],\n",
        "       train_regret_winner_9[slice44],\n",
        "       train_regret_winner_10[slice44],\n",
        "       train_regret_winner_11[slice44],\n",
        "       train_regret_winner_12[slice44],\n",
        "       train_regret_winner_13[slice44],\n",
        "       train_regret_winner_14[slice44],\n",
        "       train_regret_winner_15[slice44],\n",
        "       train_regret_winner_16[slice44],\n",
        "       train_regret_winner_17[slice44],\n",
        "       train_regret_winner_18[slice44],\n",
        "       train_regret_winner_19[slice44],\n",
        "       train_regret_winner_20[slice44]]\n",
        "\n",
        "loser44_results = pd.DataFrame(loser44).sort_values(by=[0], ascending=False)\n",
        "winner44_results = pd.DataFrame(winner44).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser44 = np.asarray(loser44_results[4:5][0])[0]\n",
        "median_loser44 = np.asarray(loser44_results[9:10][0])[0]\n",
        "upper_loser44 = np.asarray(loser44_results[14:15][0])[0]\n",
        "\n",
        "lower_winner44 = np.asarray(winner44_results[4:5][0])[0]\n",
        "median_winner44 = np.asarray(winner44_results[9:10][0])[0]\n",
        "upper_winner44 = np.asarray(winner44_results[14:15][0])[0]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJzx094Fw_c_"
      },
      "source": [
        "# Iteration54 :\n",
        "\n",
        "slice54 = 53\n",
        "\n",
        "loser54 = [train_regret_loser_1[slice54],\n",
        "       train_regret_loser_2[slice54],\n",
        "       train_regret_loser_3[slice54],\n",
        "       train_regret_loser_4[slice54],\n",
        "       train_regret_loser_5[slice54],\n",
        "       train_regret_loser_6[slice54],\n",
        "       train_regret_loser_7[slice54],\n",
        "       train_regret_loser_8[slice54],\n",
        "       train_regret_loser_9[slice54],\n",
        "       train_regret_loser_10[slice54],\n",
        "       train_regret_loser_11[slice54],\n",
        "       train_regret_loser_12[slice54],\n",
        "       train_regret_loser_13[slice54],\n",
        "       train_regret_loser_14[slice54],\n",
        "       train_regret_loser_15[slice54],\n",
        "       train_regret_loser_16[slice54],\n",
        "       train_regret_loser_17[slice54],\n",
        "       train_regret_loser_18[slice54],\n",
        "       train_regret_loser_19[slice54],\n",
        "       train_regret_loser_20[slice54]]\n",
        "\n",
        "winner54 = [train_regret_winner_1[slice54],\n",
        "       train_regret_winner_2[slice54],\n",
        "       train_regret_winner_3[slice54],\n",
        "       train_regret_winner_4[slice54],\n",
        "       train_regret_winner_5[slice54],\n",
        "       train_regret_winner_6[slice54],\n",
        "       train_regret_winner_7[slice54],\n",
        "       train_regret_winner_8[slice54],\n",
        "       train_regret_winner_9[slice54],\n",
        "       train_regret_winner_10[slice54],\n",
        "       train_regret_winner_11[slice54],\n",
        "       train_regret_winner_12[slice54],\n",
        "       train_regret_winner_13[slice54],\n",
        "       train_regret_winner_14[slice54],\n",
        "       train_regret_winner_15[slice54],\n",
        "       train_regret_winner_16[slice54],\n",
        "       train_regret_winner_17[slice54],\n",
        "       train_regret_winner_18[slice54],\n",
        "       train_regret_winner_19[slice54],\n",
        "       train_regret_winner_20[slice54]]\n",
        "\n",
        "loser54_results = pd.DataFrame(loser54).sort_values(by=[0], ascending=False)\n",
        "winner54_results = pd.DataFrame(winner54).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser54 = np.asarray(loser54_results[4:5][0])[0]\n",
        "median_loser54 = np.asarray(loser54_results[9:10][0])[0]\n",
        "upper_loser54 = np.asarray(loser54_results[14:15][0])[0]\n",
        "\n",
        "lower_winner54 = np.asarray(winner54_results[4:5][0])[0]\n",
        "median_winner54 = np.asarray(winner54_results[9:10][0])[0]\n",
        "upper_winner54 = np.asarray(winner54_results[14:15][0])[0]"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEVYMqj_w_fr"
      },
      "source": [
        "# Iteration64 :\n",
        "\n",
        "slice64 = 63\n",
        "\n",
        "loser64 = [train_regret_loser_1[slice64],\n",
        "       train_regret_loser_2[slice64],\n",
        "       train_regret_loser_3[slice64],\n",
        "       train_regret_loser_4[slice64],\n",
        "       train_regret_loser_5[slice64],\n",
        "       train_regret_loser_6[slice64],\n",
        "       train_regret_loser_7[slice64],\n",
        "       train_regret_loser_8[slice64],\n",
        "       train_regret_loser_9[slice64],\n",
        "       train_regret_loser_10[slice64],\n",
        "       train_regret_loser_11[slice64],\n",
        "       train_regret_loser_12[slice64],\n",
        "       train_regret_loser_13[slice64],\n",
        "       train_regret_loser_14[slice64],\n",
        "       train_regret_loser_15[slice64],\n",
        "       train_regret_loser_16[slice64],\n",
        "       train_regret_loser_17[slice64],\n",
        "       train_regret_loser_18[slice64],\n",
        "       train_regret_loser_19[slice64],\n",
        "       train_regret_loser_20[slice64]]\n",
        "\n",
        "winner64 = [train_regret_winner_1[slice64],\n",
        "       train_regret_winner_2[slice64],\n",
        "       train_regret_winner_3[slice64],\n",
        "       train_regret_winner_4[slice64],\n",
        "       train_regret_winner_5[slice64],\n",
        "       train_regret_winner_6[slice64],\n",
        "       train_regret_winner_7[slice64],\n",
        "       train_regret_winner_8[slice64],\n",
        "       train_regret_winner_9[slice64],\n",
        "       train_regret_winner_10[slice64],\n",
        "       train_regret_winner_11[slice64],\n",
        "       train_regret_winner_12[slice64],\n",
        "       train_regret_winner_13[slice64],\n",
        "       train_regret_winner_14[slice64],\n",
        "       train_regret_winner_15[slice64],\n",
        "       train_regret_winner_16[slice64],\n",
        "       train_regret_winner_17[slice64],\n",
        "       train_regret_winner_18[slice64],\n",
        "       train_regret_winner_19[slice64],\n",
        "       train_regret_winner_20[slice64]]\n",
        "\n",
        "loser64_results = pd.DataFrame(loser64).sort_values(by=[0], ascending=False)\n",
        "winner64_results = pd.DataFrame(winner64).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser64 = np.asarray(loser64_results[4:5][0])[0]\n",
        "median_loser64 = np.asarray(loser64_results[9:10][0])[0]\n",
        "upper_loser64 = np.asarray(loser64_results[14:15][0])[0]\n",
        "\n",
        "lower_winner64 = np.asarray(winner64_results[4:5][0])[0]\n",
        "median_winner64 = np.asarray(winner64_results[9:10][0])[0]\n",
        "upper_winner64 = np.asarray(winner64_results[14:15][0])[0]"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvr3S_p0w_ii"
      },
      "source": [
        "# Iteration74 :\n",
        "\n",
        "slice74 = 73\n",
        "\n",
        "loser74 = [train_regret_loser_1[slice74],\n",
        "       train_regret_loser_2[slice74],\n",
        "       train_regret_loser_3[slice74],\n",
        "       train_regret_loser_4[slice74],\n",
        "       train_regret_loser_5[slice74],\n",
        "       train_regret_loser_6[slice74],\n",
        "       train_regret_loser_7[slice74],\n",
        "       train_regret_loser_8[slice74],\n",
        "       train_regret_loser_9[slice74],\n",
        "       train_regret_loser_10[slice74],\n",
        "       train_regret_loser_11[slice74],\n",
        "       train_regret_loser_12[slice74],\n",
        "       train_regret_loser_13[slice74],\n",
        "       train_regret_loser_14[slice74],\n",
        "       train_regret_loser_15[slice74],\n",
        "       train_regret_loser_16[slice74],\n",
        "       train_regret_loser_17[slice74],\n",
        "       train_regret_loser_18[slice74],\n",
        "       train_regret_loser_19[slice74],\n",
        "       train_regret_loser_20[slice74]]\n",
        "\n",
        "winner74 = [train_regret_winner_1[slice74],\n",
        "       train_regret_winner_2[slice74],\n",
        "       train_regret_winner_3[slice74],\n",
        "       train_regret_winner_4[slice74],\n",
        "       train_regret_winner_5[slice74],\n",
        "       train_regret_winner_6[slice74],\n",
        "       train_regret_winner_7[slice74],\n",
        "       train_regret_winner_8[slice74],\n",
        "       train_regret_winner_9[slice74],\n",
        "       train_regret_winner_10[slice74],\n",
        "       train_regret_winner_11[slice74],\n",
        "       train_regret_winner_12[slice74],\n",
        "       train_regret_winner_13[slice74],\n",
        "       train_regret_winner_14[slice74],\n",
        "       train_regret_winner_15[slice74],\n",
        "       train_regret_winner_16[slice74],\n",
        "       train_regret_winner_17[slice74],\n",
        "       train_regret_winner_18[slice74],\n",
        "       train_regret_winner_19[slice74],\n",
        "       train_regret_winner_20[slice74]]\n",
        "\n",
        "loser74_results = pd.DataFrame(loser74).sort_values(by=[0], ascending=False)\n",
        "winner74_results = pd.DataFrame(winner74).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser74 = np.asarray(loser74_results[4:5][0])[0]\n",
        "median_loser74 = np.asarray(loser74_results[9:10][0])[0]\n",
        "upper_loser74 = np.asarray(loser74_results[14:15][0])[0]\n",
        "\n",
        "lower_winner74 = np.asarray(winner74_results[4:5][0])[0]\n",
        "median_winner74 = np.asarray(winner74_results[9:10][0])[0]\n",
        "upper_winner74 = np.asarray(winner74_results[14:15][0])[0]"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEAvUVK7w_lO"
      },
      "source": [
        "# Iteration84 :\n",
        "\n",
        "slice84 = 83\n",
        "\n",
        "loser84 = [train_regret_loser_1[slice84],\n",
        "       train_regret_loser_2[slice84],\n",
        "       train_regret_loser_3[slice84],\n",
        "       train_regret_loser_4[slice84],\n",
        "       train_regret_loser_5[slice84],\n",
        "       train_regret_loser_6[slice84],\n",
        "       train_regret_loser_7[slice84],\n",
        "       train_regret_loser_8[slice84],\n",
        "       train_regret_loser_9[slice84],\n",
        "       train_regret_loser_10[slice84],\n",
        "       train_regret_loser_11[slice84],\n",
        "       train_regret_loser_12[slice84],\n",
        "       train_regret_loser_13[slice84],\n",
        "       train_regret_loser_14[slice84],\n",
        "       train_regret_loser_15[slice84],\n",
        "       train_regret_loser_16[slice84],\n",
        "       train_regret_loser_17[slice84],\n",
        "       train_regret_loser_18[slice84],\n",
        "       train_regret_loser_19[slice84],\n",
        "       train_regret_loser_20[slice84]]\n",
        "\n",
        "winner84 = [train_regret_winner_1[slice84],\n",
        "       train_regret_winner_2[slice84],\n",
        "       train_regret_winner_3[slice84],\n",
        "       train_regret_winner_4[slice84],\n",
        "       train_regret_winner_5[slice84],\n",
        "       train_regret_winner_6[slice84],\n",
        "       train_regret_winner_7[slice84],\n",
        "       train_regret_winner_8[slice84],\n",
        "       train_regret_winner_9[slice84],\n",
        "       train_regret_winner_10[slice84],\n",
        "       train_regret_winner_11[slice84],\n",
        "       train_regret_winner_12[slice84],\n",
        "       train_regret_winner_13[slice84],\n",
        "       train_regret_winner_14[slice84],\n",
        "       train_regret_winner_15[slice84],\n",
        "       train_regret_winner_16[slice84],\n",
        "       train_regret_winner_17[slice84],\n",
        "       train_regret_winner_18[slice84],\n",
        "       train_regret_winner_19[slice84],\n",
        "       train_regret_winner_20[slice84]]\n",
        "\n",
        "loser84_results = pd.DataFrame(loser84).sort_values(by=[0], ascending=False)\n",
        "winner84_results = pd.DataFrame(winner84).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser84 = np.asarray(loser84_results[4:5][0])[0]\n",
        "median_loser84 = np.asarray(loser84_results[9:10][0])[0]\n",
        "upper_loser84 = np.asarray(loser84_results[14:15][0])[0]\n",
        "\n",
        "lower_winner84 = np.asarray(winner84_results[4:5][0])[0]\n",
        "median_winner84 = np.asarray(winner84_results[9:10][0])[0]\n",
        "upper_winner84 = np.asarray(winner84_results[14:15][0])[0]"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMZzhdGw_oC"
      },
      "source": [
        "# Iteration94 :\n",
        "\n",
        "slice94 = 93\n",
        "\n",
        "loser94 = [train_regret_loser_1[slice94],\n",
        "       train_regret_loser_2[slice94],\n",
        "       train_regret_loser_3[slice94],\n",
        "       train_regret_loser_4[slice94],\n",
        "       train_regret_loser_5[slice94],\n",
        "       train_regret_loser_6[slice94],\n",
        "       train_regret_loser_7[slice94],\n",
        "       train_regret_loser_8[slice94],\n",
        "       train_regret_loser_9[slice94],\n",
        "       train_regret_loser_10[slice94],\n",
        "       train_regret_loser_11[slice94],\n",
        "       train_regret_loser_12[slice94],\n",
        "       train_regret_loser_13[slice94],\n",
        "       train_regret_loser_14[slice94],\n",
        "       train_regret_loser_15[slice94],\n",
        "       train_regret_loser_16[slice94],\n",
        "       train_regret_loser_17[slice94],\n",
        "       train_regret_loser_18[slice94],\n",
        "       train_regret_loser_19[slice94],\n",
        "       train_regret_loser_20[slice94]]\n",
        "\n",
        "winner94 = [train_regret_winner_1[slice94],\n",
        "       train_regret_winner_2[slice94],\n",
        "       train_regret_winner_3[slice94],\n",
        "       train_regret_winner_4[slice94],\n",
        "       train_regret_winner_5[slice94],\n",
        "       train_regret_winner_6[slice94],\n",
        "       train_regret_winner_7[slice94],\n",
        "       train_regret_winner_8[slice94],\n",
        "       train_regret_winner_9[slice94],\n",
        "       train_regret_winner_10[slice94],\n",
        "       train_regret_winner_11[slice94],\n",
        "       train_regret_winner_12[slice94],\n",
        "       train_regret_winner_13[slice94],\n",
        "       train_regret_winner_14[slice94],\n",
        "       train_regret_winner_15[slice94],\n",
        "       train_regret_winner_16[slice94],\n",
        "       train_regret_winner_17[slice94],\n",
        "       train_regret_winner_18[slice94],\n",
        "       train_regret_winner_19[slice94],\n",
        "       train_regret_winner_20[slice94]]\n",
        "\n",
        "loser94_results = pd.DataFrame(loser94).sort_values(by=[0], ascending=False)\n",
        "winner94_results = pd.DataFrame(winner94).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser94 = np.asarray(loser94_results[4:5][0])[0]\n",
        "median_loser94 = np.asarray(loser94_results[9:10][0])[0]\n",
        "upper_loser94 = np.asarray(loser94_results[14:15][0])[0]\n",
        "\n",
        "lower_winner94 = np.asarray(winner94_results[4:5][0])[0]\n",
        "median_winner94 = np.asarray(winner94_results[9:10][0])[0]\n",
        "upper_winner94 = np.asarray(winner94_results[14:15][0])[0]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMxHQOgaw_qu"
      },
      "source": [
        "# Iteration5 :\n",
        "\n",
        "slice5 = 4\n",
        "\n",
        "loser5 = [train_regret_loser_1[slice5],\n",
        "       train_regret_loser_2[slice5],\n",
        "       train_regret_loser_3[slice5],\n",
        "       train_regret_loser_4[slice5],\n",
        "       train_regret_loser_5[slice5],\n",
        "       train_regret_loser_6[slice5],\n",
        "       train_regret_loser_7[slice5],\n",
        "       train_regret_loser_8[slice5],\n",
        "       train_regret_loser_9[slice5],\n",
        "       train_regret_loser_10[slice5],\n",
        "       train_regret_loser_11[slice5],\n",
        "       train_regret_loser_12[slice5],\n",
        "       train_regret_loser_13[slice5],\n",
        "       train_regret_loser_14[slice5],\n",
        "       train_regret_loser_15[slice5],\n",
        "       train_regret_loser_16[slice5],\n",
        "       train_regret_loser_17[slice5],\n",
        "       train_regret_loser_18[slice5],\n",
        "       train_regret_loser_19[slice5],\n",
        "       train_regret_loser_20[slice5]]\n",
        "\n",
        "winner5 = [train_regret_winner_1[slice5],\n",
        "       train_regret_winner_2[slice5],\n",
        "       train_regret_winner_3[slice5],\n",
        "       train_regret_winner_4[slice5],\n",
        "       train_regret_winner_5[slice5],\n",
        "       train_regret_winner_6[slice5],\n",
        "       train_regret_winner_7[slice5],\n",
        "       train_regret_winner_8[slice5],\n",
        "       train_regret_winner_9[slice5],\n",
        "       train_regret_winner_10[slice5],\n",
        "       train_regret_winner_11[slice5],\n",
        "       train_regret_winner_12[slice5],\n",
        "       train_regret_winner_13[slice5],\n",
        "       train_regret_winner_14[slice5],\n",
        "       train_regret_winner_15[slice5],\n",
        "       train_regret_winner_16[slice5],\n",
        "       train_regret_winner_17[slice5],\n",
        "       train_regret_winner_18[slice5],\n",
        "       train_regret_winner_19[slice5],\n",
        "       train_regret_winner_20[slice5]]\n",
        "\n",
        "loser5_results = pd.DataFrame(loser5).sort_values(by=[0], ascending=False)\n",
        "winner5_results = pd.DataFrame(winner5).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser5 = np.asarray(loser5_results[4:5][0])[0]\n",
        "median_loser5 = np.asarray(loser5_results[9:10][0])[0]\n",
        "upper_loser5 = np.asarray(loser5_results[14:15][0])[0]\n",
        "\n",
        "lower_winner5 = np.asarray(winner5_results[4:5][0])[0]\n",
        "median_winner5 = np.asarray(winner5_results[9:10][0])[0]\n",
        "upper_winner5 = np.asarray(winner5_results[14:15][0])[0]"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPVFQTfNw_wF"
      },
      "source": [
        "# Iteration15 :\n",
        "\n",
        "slice15 = 14\n",
        "\n",
        "loser15 = [train_regret_loser_1[slice15],\n",
        "       train_regret_loser_2[slice15],\n",
        "       train_regret_loser_3[slice15],\n",
        "       train_regret_loser_4[slice15],\n",
        "       train_regret_loser_5[slice15],\n",
        "       train_regret_loser_6[slice15],\n",
        "       train_regret_loser_7[slice15],\n",
        "       train_regret_loser_8[slice15],\n",
        "       train_regret_loser_9[slice15],\n",
        "       train_regret_loser_10[slice15],\n",
        "       train_regret_loser_11[slice15],\n",
        "       train_regret_loser_12[slice15],\n",
        "       train_regret_loser_13[slice15],\n",
        "       train_regret_loser_14[slice15],\n",
        "       train_regret_loser_15[slice15],\n",
        "       train_regret_loser_16[slice15],\n",
        "       train_regret_loser_17[slice15],\n",
        "       train_regret_loser_18[slice15],\n",
        "       train_regret_loser_19[slice15],\n",
        "       train_regret_loser_20[slice15]]\n",
        "\n",
        "winner15 = [train_regret_winner_1[slice15],\n",
        "       train_regret_winner_2[slice15],\n",
        "       train_regret_winner_3[slice15],\n",
        "       train_regret_winner_4[slice15],\n",
        "       train_regret_winner_5[slice15],\n",
        "       train_regret_winner_6[slice15],\n",
        "       train_regret_winner_7[slice15],\n",
        "       train_regret_winner_8[slice15],\n",
        "       train_regret_winner_9[slice15],\n",
        "       train_regret_winner_10[slice15],\n",
        "       train_regret_winner_11[slice15],\n",
        "       train_regret_winner_12[slice15],\n",
        "       train_regret_winner_13[slice15],\n",
        "       train_regret_winner_14[slice15],\n",
        "       train_regret_winner_15[slice15],\n",
        "       train_regret_winner_16[slice15],\n",
        "       train_regret_winner_17[slice15],\n",
        "       train_regret_winner_18[slice15],\n",
        "       train_regret_winner_19[slice15],\n",
        "       train_regret_winner_20[slice15]]\n",
        "\n",
        "loser15_results = pd.DataFrame(loser15).sort_values(by=[0], ascending=False)\n",
        "winner15_results = pd.DataFrame(winner15).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser15 = np.asarray(loser15_results[4:5][0])[0]\n",
        "median_loser15 = np.asarray(loser15_results[9:10][0])[0]\n",
        "upper_loser15 = np.asarray(loser15_results[14:15][0])[0]\n",
        "\n",
        "lower_winner15 = np.asarray(winner15_results[4:5][0])[0]\n",
        "median_winner15 = np.asarray(winner15_results[9:10][0])[0]\n",
        "upper_winner15 = np.asarray(winner15_results[14:15][0])[0]"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADBmBA3ew_zK"
      },
      "source": [
        "# Iteration25 :\n",
        "\n",
        "slice25 = 24\n",
        "\n",
        "loser25 = [train_regret_loser_1[slice25],\n",
        "       train_regret_loser_2[slice25],\n",
        "       train_regret_loser_3[slice25],\n",
        "       train_regret_loser_4[slice25],\n",
        "       train_regret_loser_5[slice25],\n",
        "       train_regret_loser_6[slice25],\n",
        "       train_regret_loser_7[slice25],\n",
        "       train_regret_loser_8[slice25],\n",
        "       train_regret_loser_9[slice25],\n",
        "       train_regret_loser_10[slice25],\n",
        "       train_regret_loser_11[slice25],\n",
        "       train_regret_loser_12[slice25],\n",
        "       train_regret_loser_13[slice25],\n",
        "       train_regret_loser_14[slice25],\n",
        "       train_regret_loser_15[slice25],\n",
        "       train_regret_loser_16[slice25],\n",
        "       train_regret_loser_17[slice25],\n",
        "       train_regret_loser_18[slice25],\n",
        "       train_regret_loser_19[slice25],\n",
        "       train_regret_loser_20[slice25]]\n",
        "\n",
        "winner25 = [train_regret_winner_1[slice25],\n",
        "       train_regret_winner_2[slice25],\n",
        "       train_regret_winner_3[slice25],\n",
        "       train_regret_winner_4[slice25],\n",
        "       train_regret_winner_5[slice25],\n",
        "       train_regret_winner_6[slice25],\n",
        "       train_regret_winner_7[slice25],\n",
        "       train_regret_winner_8[slice25],\n",
        "       train_regret_winner_9[slice25],\n",
        "       train_regret_winner_10[slice25],\n",
        "       train_regret_winner_11[slice25],\n",
        "       train_regret_winner_12[slice25],\n",
        "       train_regret_winner_13[slice25],\n",
        "       train_regret_winner_14[slice25],\n",
        "       train_regret_winner_15[slice25],\n",
        "       train_regret_winner_16[slice25],\n",
        "       train_regret_winner_17[slice25],\n",
        "       train_regret_winner_18[slice25],\n",
        "       train_regret_winner_19[slice25],\n",
        "       train_regret_winner_20[slice25]]\n",
        "\n",
        "loser25_results = pd.DataFrame(loser25).sort_values(by=[0], ascending=False)\n",
        "winner25_results = pd.DataFrame(winner25).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser25 = np.asarray(loser25_results[4:5][0])[0]\n",
        "median_loser25 = np.asarray(loser25_results[9:10][0])[0]\n",
        "upper_loser25 = np.asarray(loser25_results[14:15][0])[0]\n",
        "\n",
        "lower_winner25 = np.asarray(winner25_results[4:5][0])[0]\n",
        "median_winner25 = np.asarray(winner25_results[9:10][0])[0]\n",
        "upper_winner25 = np.asarray(winner25_results[14:15][0])[0]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUk9UtSTw_2N"
      },
      "source": [
        "# Iteration35 :\n",
        "\n",
        "slice35 = 34\n",
        "\n",
        "loser35 = [train_regret_loser_1[slice35],\n",
        "       train_regret_loser_2[slice35],\n",
        "       train_regret_loser_3[slice35],\n",
        "       train_regret_loser_4[slice35],\n",
        "       train_regret_loser_5[slice35],\n",
        "       train_regret_loser_6[slice35],\n",
        "       train_regret_loser_7[slice35],\n",
        "       train_regret_loser_8[slice35],\n",
        "       train_regret_loser_9[slice35],\n",
        "       train_regret_loser_10[slice35],\n",
        "       train_regret_loser_11[slice35],\n",
        "       train_regret_loser_12[slice35],\n",
        "       train_regret_loser_13[slice35],\n",
        "       train_regret_loser_14[slice35],\n",
        "       train_regret_loser_15[slice35],\n",
        "       train_regret_loser_16[slice35],\n",
        "       train_regret_loser_17[slice35],\n",
        "       train_regret_loser_18[slice35],\n",
        "       train_regret_loser_19[slice35],\n",
        "       train_regret_loser_20[slice35]]\n",
        "\n",
        "winner35 = [train_regret_winner_1[slice35],\n",
        "       train_regret_winner_2[slice35],\n",
        "       train_regret_winner_3[slice35],\n",
        "       train_regret_winner_4[slice35],\n",
        "       train_regret_winner_5[slice35],\n",
        "       train_regret_winner_6[slice35],\n",
        "       train_regret_winner_7[slice35],\n",
        "       train_regret_winner_8[slice35],\n",
        "       train_regret_winner_9[slice35],\n",
        "       train_regret_winner_10[slice35],\n",
        "       train_regret_winner_11[slice35],\n",
        "       train_regret_winner_12[slice35],\n",
        "       train_regret_winner_13[slice35],\n",
        "       train_regret_winner_14[slice35],\n",
        "       train_regret_winner_15[slice35],\n",
        "       train_regret_winner_16[slice35],\n",
        "       train_regret_winner_17[slice35],\n",
        "       train_regret_winner_18[slice35],\n",
        "       train_regret_winner_19[slice35],\n",
        "       train_regret_winner_20[slice35]]\n",
        "\n",
        "loser35_results = pd.DataFrame(loser35).sort_values(by=[0], ascending=False)\n",
        "winner35_results = pd.DataFrame(winner35).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser35 = np.asarray(loser35_results[4:5][0])[0]\n",
        "median_loser35 = np.asarray(loser35_results[9:10][0])[0]\n",
        "upper_loser35 = np.asarray(loser35_results[14:15][0])[0]\n",
        "\n",
        "lower_winner35 = np.asarray(winner35_results[4:5][0])[0]\n",
        "median_winner35 = np.asarray(winner35_results[9:10][0])[0]\n",
        "upper_winner35 = np.asarray(winner35_results[14:15][0])[0]"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX3VgqD_w_4z"
      },
      "source": [
        "# Iteration45 :\n",
        "\n",
        "slice45 = 44\n",
        "\n",
        "loser45 = [train_regret_loser_1[slice45],\n",
        "       train_regret_loser_2[slice45],\n",
        "       train_regret_loser_3[slice45],\n",
        "       train_regret_loser_4[slice45],\n",
        "       train_regret_loser_5[slice45],\n",
        "       train_regret_loser_6[slice45],\n",
        "       train_regret_loser_7[slice45],\n",
        "       train_regret_loser_8[slice45],\n",
        "       train_regret_loser_9[slice45],\n",
        "       train_regret_loser_10[slice45],\n",
        "       train_regret_loser_11[slice45],\n",
        "       train_regret_loser_12[slice45],\n",
        "       train_regret_loser_13[slice45],\n",
        "       train_regret_loser_14[slice45],\n",
        "       train_regret_loser_15[slice45],\n",
        "       train_regret_loser_16[slice45],\n",
        "       train_regret_loser_17[slice45],\n",
        "       train_regret_loser_18[slice45],\n",
        "       train_regret_loser_19[slice45],\n",
        "       train_regret_loser_20[slice45]]\n",
        "\n",
        "winner45 = [train_regret_winner_1[slice45],\n",
        "       train_regret_winner_2[slice45],\n",
        "       train_regret_winner_3[slice45],\n",
        "       train_regret_winner_4[slice45],\n",
        "       train_regret_winner_5[slice45],\n",
        "       train_regret_winner_6[slice45],\n",
        "       train_regret_winner_7[slice45],\n",
        "       train_regret_winner_8[slice45],\n",
        "       train_regret_winner_9[slice45],\n",
        "       train_regret_winner_10[slice45],\n",
        "       train_regret_winner_11[slice45],\n",
        "       train_regret_winner_12[slice45],\n",
        "       train_regret_winner_13[slice45],\n",
        "       train_regret_winner_14[slice45],\n",
        "       train_regret_winner_15[slice45],\n",
        "       train_regret_winner_16[slice45],\n",
        "       train_regret_winner_17[slice45],\n",
        "       train_regret_winner_18[slice45],\n",
        "       train_regret_winner_19[slice45],\n",
        "       train_regret_winner_20[slice45]]\n",
        "\n",
        "loser45_results = pd.DataFrame(loser45).sort_values(by=[0], ascending=False)\n",
        "winner45_results = pd.DataFrame(winner45).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser45 = np.asarray(loser45_results[4:5][0])[0]\n",
        "median_loser45 = np.asarray(loser45_results[9:10][0])[0]\n",
        "upper_loser45 = np.asarray(loser45_results[14:15][0])[0]\n",
        "\n",
        "lower_winner45 = np.asarray(winner45_results[4:5][0])[0]\n",
        "median_winner45 = np.asarray(winner45_results[9:10][0])[0]\n",
        "upper_winner45 = np.asarray(winner45_results[14:15][0])[0]"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o35W-AOzw_8F"
      },
      "source": [
        "# Iteration55 :\n",
        "\n",
        "slice55 = 54\n",
        "\n",
        "loser55 = [train_regret_loser_1[slice55],\n",
        "       train_regret_loser_2[slice55],\n",
        "       train_regret_loser_3[slice55],\n",
        "       train_regret_loser_4[slice55],\n",
        "       train_regret_loser_5[slice55],\n",
        "       train_regret_loser_6[slice55],\n",
        "       train_regret_loser_7[slice55],\n",
        "       train_regret_loser_8[slice55],\n",
        "       train_regret_loser_9[slice55],\n",
        "       train_regret_loser_10[slice55],\n",
        "       train_regret_loser_11[slice55],\n",
        "       train_regret_loser_12[slice55],\n",
        "       train_regret_loser_13[slice55],\n",
        "       train_regret_loser_14[slice55],\n",
        "       train_regret_loser_15[slice55],\n",
        "       train_regret_loser_16[slice55],\n",
        "       train_regret_loser_17[slice55],\n",
        "       train_regret_loser_18[slice55],\n",
        "       train_regret_loser_19[slice55],\n",
        "       train_regret_loser_20[slice55]]\n",
        "\n",
        "winner55 = [train_regret_winner_1[slice55],\n",
        "       train_regret_winner_2[slice55],\n",
        "       train_regret_winner_3[slice55],\n",
        "       train_regret_winner_4[slice55],\n",
        "       train_regret_winner_5[slice55],\n",
        "       train_regret_winner_6[slice55],\n",
        "       train_regret_winner_7[slice55],\n",
        "       train_regret_winner_8[slice55],\n",
        "       train_regret_winner_9[slice55],\n",
        "       train_regret_winner_10[slice55],\n",
        "       train_regret_winner_11[slice55],\n",
        "       train_regret_winner_12[slice55],\n",
        "       train_regret_winner_13[slice55],\n",
        "       train_regret_winner_14[slice55],\n",
        "       train_regret_winner_15[slice55],\n",
        "       train_regret_winner_16[slice55],\n",
        "       train_regret_winner_17[slice55],\n",
        "       train_regret_winner_18[slice55],\n",
        "       train_regret_winner_19[slice55],\n",
        "       train_regret_winner_20[slice55]]\n",
        "\n",
        "loser55_results = pd.DataFrame(loser55).sort_values(by=[0], ascending=False)\n",
        "winner55_results = pd.DataFrame(winner55).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser55 = np.asarray(loser55_results[4:5][0])[0]\n",
        "median_loser55 = np.asarray(loser55_results[9:10][0])[0]\n",
        "upper_loser55 = np.asarray(loser55_results[14:15][0])[0]\n",
        "\n",
        "lower_winner55 = np.asarray(winner55_results[4:5][0])[0]\n",
        "median_winner55 = np.asarray(winner55_results[9:10][0])[0]\n",
        "upper_winner55 = np.asarray(winner55_results[14:15][0])[0]"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUAjKXWdw__J"
      },
      "source": [
        "# Iteration65 :\n",
        "\n",
        "slice65 = 64\n",
        "\n",
        "loser65 = [train_regret_loser_1[slice65],\n",
        "       train_regret_loser_2[slice65],\n",
        "       train_regret_loser_3[slice65],\n",
        "       train_regret_loser_4[slice65],\n",
        "       train_regret_loser_5[slice65],\n",
        "       train_regret_loser_6[slice65],\n",
        "       train_regret_loser_7[slice65],\n",
        "       train_regret_loser_8[slice65],\n",
        "       train_regret_loser_9[slice65],\n",
        "       train_regret_loser_10[slice65],\n",
        "       train_regret_loser_11[slice65],\n",
        "       train_regret_loser_12[slice65],\n",
        "       train_regret_loser_13[slice65],\n",
        "       train_regret_loser_14[slice65],\n",
        "       train_regret_loser_15[slice65],\n",
        "       train_regret_loser_16[slice65],\n",
        "       train_regret_loser_17[slice65],\n",
        "       train_regret_loser_18[slice65],\n",
        "       train_regret_loser_19[slice65],\n",
        "       train_regret_loser_20[slice65]]\n",
        "\n",
        "winner65 = [train_regret_winner_1[slice65],\n",
        "       train_regret_winner_2[slice65],\n",
        "       train_regret_winner_3[slice65],\n",
        "       train_regret_winner_4[slice65],\n",
        "       train_regret_winner_5[slice65],\n",
        "       train_regret_winner_6[slice65],\n",
        "       train_regret_winner_7[slice65],\n",
        "       train_regret_winner_8[slice65],\n",
        "       train_regret_winner_9[slice65],\n",
        "       train_regret_winner_10[slice65],\n",
        "       train_regret_winner_11[slice65],\n",
        "       train_regret_winner_12[slice65],\n",
        "       train_regret_winner_13[slice65],\n",
        "       train_regret_winner_14[slice65],\n",
        "       train_regret_winner_15[slice65],\n",
        "       train_regret_winner_16[slice65],\n",
        "       train_regret_winner_17[slice65],\n",
        "       train_regret_winner_18[slice65],\n",
        "       train_regret_winner_19[slice65],\n",
        "       train_regret_winner_20[slice65]]\n",
        "\n",
        "loser65_results = pd.DataFrame(loser65).sort_values(by=[0], ascending=False)\n",
        "winner65_results = pd.DataFrame(winner65).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser65 = np.asarray(loser65_results[4:5][0])[0]\n",
        "median_loser65 = np.asarray(loser65_results[9:10][0])[0]\n",
        "upper_loser65 = np.asarray(loser65_results[14:15][0])[0]\n",
        "\n",
        "lower_winner65 = np.asarray(winner65_results[4:5][0])[0]\n",
        "median_winner65 = np.asarray(winner65_results[9:10][0])[0]\n",
        "upper_winner65 = np.asarray(winner65_results[14:15][0])[0]"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D00FcmZwxAB9"
      },
      "source": [
        "# Iteration75 :\n",
        "\n",
        "slice75 = 74\n",
        "\n",
        "loser75 = [train_regret_loser_1[slice75],\n",
        "       train_regret_loser_2[slice75],\n",
        "       train_regret_loser_3[slice75],\n",
        "       train_regret_loser_4[slice75],\n",
        "       train_regret_loser_5[slice75],\n",
        "       train_regret_loser_6[slice75],\n",
        "       train_regret_loser_7[slice75],\n",
        "       train_regret_loser_8[slice75],\n",
        "       train_regret_loser_9[slice75],\n",
        "       train_regret_loser_10[slice75],\n",
        "       train_regret_loser_11[slice75],\n",
        "       train_regret_loser_12[slice75],\n",
        "       train_regret_loser_13[slice75],\n",
        "       train_regret_loser_14[slice75],\n",
        "       train_regret_loser_15[slice75],\n",
        "       train_regret_loser_16[slice75],\n",
        "       train_regret_loser_17[slice75],\n",
        "       train_regret_loser_18[slice75],\n",
        "       train_regret_loser_19[slice75],\n",
        "       train_regret_loser_20[slice75]]\n",
        "\n",
        "winner75 = [train_regret_winner_1[slice75],\n",
        "       train_regret_winner_2[slice75],\n",
        "       train_regret_winner_3[slice75],\n",
        "       train_regret_winner_4[slice75],\n",
        "       train_regret_winner_5[slice75],\n",
        "       train_regret_winner_6[slice75],\n",
        "       train_regret_winner_7[slice75],\n",
        "       train_regret_winner_8[slice75],\n",
        "       train_regret_winner_9[slice75],\n",
        "       train_regret_winner_10[slice75],\n",
        "       train_regret_winner_11[slice75],\n",
        "       train_regret_winner_12[slice75],\n",
        "       train_regret_winner_13[slice75],\n",
        "       train_regret_winner_14[slice75],\n",
        "       train_regret_winner_15[slice75],\n",
        "       train_regret_winner_16[slice75],\n",
        "       train_regret_winner_17[slice75],\n",
        "       train_regret_winner_18[slice75],\n",
        "       train_regret_winner_19[slice75],\n",
        "       train_regret_winner_20[slice75]]\n",
        "\n",
        "loser75_results = pd.DataFrame(loser75).sort_values(by=[0], ascending=False)\n",
        "winner75_results = pd.DataFrame(winner75).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser75 = np.asarray(loser75_results[4:5][0])[0]\n",
        "median_loser75 = np.asarray(loser75_results[9:10][0])[0]\n",
        "upper_loser75 = np.asarray(loser75_results[14:15][0])[0]\n",
        "\n",
        "lower_winner75 = np.asarray(winner75_results[4:5][0])[0]\n",
        "median_winner75 = np.asarray(winner75_results[9:10][0])[0]\n",
        "upper_winner75 = np.asarray(winner75_results[14:15][0])[0]"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvnzmprxxAFB"
      },
      "source": [
        "# Iteration85 :\n",
        "\n",
        "slice85 = 84\n",
        "\n",
        "loser85 = [train_regret_loser_1[slice85],\n",
        "       train_regret_loser_2[slice85],\n",
        "       train_regret_loser_3[slice85],\n",
        "       train_regret_loser_4[slice85],\n",
        "       train_regret_loser_5[slice85],\n",
        "       train_regret_loser_6[slice85],\n",
        "       train_regret_loser_7[slice85],\n",
        "       train_regret_loser_8[slice85],\n",
        "       train_regret_loser_9[slice85],\n",
        "       train_regret_loser_10[slice85],\n",
        "       train_regret_loser_11[slice85],\n",
        "       train_regret_loser_12[slice85],\n",
        "       train_regret_loser_13[slice85],\n",
        "       train_regret_loser_14[slice85],\n",
        "       train_regret_loser_15[slice85],\n",
        "       train_regret_loser_16[slice85],\n",
        "       train_regret_loser_17[slice85],\n",
        "       train_regret_loser_18[slice85],\n",
        "       train_regret_loser_19[slice85],\n",
        "       train_regret_loser_20[slice85]]\n",
        "\n",
        "winner85 = [train_regret_winner_1[slice85],\n",
        "       train_regret_winner_2[slice85],\n",
        "       train_regret_winner_3[slice85],\n",
        "       train_regret_winner_4[slice85],\n",
        "       train_regret_winner_5[slice85],\n",
        "       train_regret_winner_6[slice85],\n",
        "       train_regret_winner_7[slice85],\n",
        "       train_regret_winner_8[slice85],\n",
        "       train_regret_winner_9[slice85],\n",
        "       train_regret_winner_10[slice85],\n",
        "       train_regret_winner_11[slice85],\n",
        "       train_regret_winner_12[slice85],\n",
        "       train_regret_winner_13[slice85],\n",
        "       train_regret_winner_14[slice85],\n",
        "       train_regret_winner_15[slice85],\n",
        "       train_regret_winner_16[slice85],\n",
        "       train_regret_winner_17[slice85],\n",
        "       train_regret_winner_18[slice85],\n",
        "       train_regret_winner_19[slice85],\n",
        "       train_regret_winner_20[slice85]]\n",
        "\n",
        "loser85_results = pd.DataFrame(loser85).sort_values(by=[0], ascending=False)\n",
        "winner85_results = pd.DataFrame(winner85).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser85 = np.asarray(loser85_results[4:5][0])[0]\n",
        "median_loser85 = np.asarray(loser85_results[9:10][0])[0]\n",
        "upper_loser85 = np.asarray(loser85_results[14:15][0])[0]\n",
        "\n",
        "lower_winner85 = np.asarray(winner85_results[4:5][0])[0]\n",
        "median_winner85 = np.asarray(winner85_results[9:10][0])[0]\n",
        "upper_winner85 = np.asarray(winner85_results[14:15][0])[0]"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztvJhrN6xAH1"
      },
      "source": [
        "# Iteration95 :\n",
        "\n",
        "slice95 = 94\n",
        "\n",
        "loser95 = [train_regret_loser_1[slice95],\n",
        "       train_regret_loser_2[slice95],\n",
        "       train_regret_loser_3[slice95],\n",
        "       train_regret_loser_4[slice95],\n",
        "       train_regret_loser_5[slice95],\n",
        "       train_regret_loser_6[slice95],\n",
        "       train_regret_loser_7[slice95],\n",
        "       train_regret_loser_8[slice95],\n",
        "       train_regret_loser_9[slice95],\n",
        "       train_regret_loser_10[slice95],\n",
        "       train_regret_loser_11[slice95],\n",
        "       train_regret_loser_12[slice95],\n",
        "       train_regret_loser_13[slice95],\n",
        "       train_regret_loser_14[slice95],\n",
        "       train_regret_loser_15[slice95],\n",
        "       train_regret_loser_16[slice95],\n",
        "       train_regret_loser_17[slice95],\n",
        "       train_regret_loser_18[slice95],\n",
        "       train_regret_loser_19[slice95],\n",
        "       train_regret_loser_20[slice95]]\n",
        "\n",
        "winner95 = [train_regret_winner_1[slice95],\n",
        "       train_regret_winner_2[slice95],\n",
        "       train_regret_winner_3[slice95],\n",
        "       train_regret_winner_4[slice95],\n",
        "       train_regret_winner_5[slice95],\n",
        "       train_regret_winner_6[slice95],\n",
        "       train_regret_winner_7[slice95],\n",
        "       train_regret_winner_8[slice95],\n",
        "       train_regret_winner_9[slice95],\n",
        "       train_regret_winner_10[slice95],\n",
        "       train_regret_winner_11[slice95],\n",
        "       train_regret_winner_12[slice95],\n",
        "       train_regret_winner_13[slice95],\n",
        "       train_regret_winner_14[slice95],\n",
        "       train_regret_winner_15[slice95],\n",
        "       train_regret_winner_16[slice95],\n",
        "       train_regret_winner_17[slice95],\n",
        "       train_regret_winner_18[slice95],\n",
        "       train_regret_winner_19[slice95],\n",
        "       train_regret_winner_20[slice95]]\n",
        "\n",
        "loser95_results = pd.DataFrame(loser95).sort_values(by=[0], ascending=False)\n",
        "winner95_results = pd.DataFrame(winner95).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser95 = np.asarray(loser95_results[4:5][0])[0]\n",
        "median_loser95 = np.asarray(loser95_results[9:10][0])[0]\n",
        "upper_loser95 = np.asarray(loser95_results[14:15][0])[0]\n",
        "\n",
        "lower_winner95 = np.asarray(winner95_results[4:5][0])[0]\n",
        "median_winner95 = np.asarray(winner95_results[9:10][0])[0]\n",
        "upper_winner95 = np.asarray(winner95_results[14:15][0])[0]"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK-4nr-OxALA"
      },
      "source": [
        "# Iteration6 :\n",
        "\n",
        "slice6 = 5\n",
        "\n",
        "loser6 = [train_regret_loser_1[slice6],\n",
        "       train_regret_loser_2[slice6],\n",
        "       train_regret_loser_3[slice6],\n",
        "       train_regret_loser_4[slice6],\n",
        "       train_regret_loser_5[slice6],\n",
        "       train_regret_loser_6[slice6],\n",
        "       train_regret_loser_7[slice6],\n",
        "       train_regret_loser_8[slice6],\n",
        "       train_regret_loser_9[slice6],\n",
        "       train_regret_loser_10[slice6],\n",
        "       train_regret_loser_11[slice6],\n",
        "       train_regret_loser_12[slice6],\n",
        "       train_regret_loser_13[slice6],\n",
        "       train_regret_loser_14[slice6],\n",
        "       train_regret_loser_15[slice6],\n",
        "       train_regret_loser_16[slice6],\n",
        "       train_regret_loser_17[slice6],\n",
        "       train_regret_loser_18[slice6],\n",
        "       train_regret_loser_19[slice6],\n",
        "       train_regret_loser_20[slice6]]\n",
        "\n",
        "winner6 = [train_regret_winner_1[slice6],\n",
        "       train_regret_winner_2[slice6],\n",
        "       train_regret_winner_3[slice6],\n",
        "       train_regret_winner_4[slice6],\n",
        "       train_regret_winner_5[slice6],\n",
        "       train_regret_winner_6[slice6],\n",
        "       train_regret_winner_7[slice6],\n",
        "       train_regret_winner_8[slice6],\n",
        "       train_regret_winner_9[slice6],\n",
        "       train_regret_winner_10[slice6],\n",
        "       train_regret_winner_11[slice6],\n",
        "       train_regret_winner_12[slice6],\n",
        "       train_regret_winner_13[slice6],\n",
        "       train_regret_winner_14[slice6],\n",
        "       train_regret_winner_15[slice6],\n",
        "       train_regret_winner_16[slice6],\n",
        "       train_regret_winner_17[slice6],\n",
        "       train_regret_winner_18[slice6],\n",
        "       train_regret_winner_19[slice6],\n",
        "       train_regret_winner_20[slice6]]\n",
        "\n",
        "loser6_results = pd.DataFrame(loser6).sort_values(by=[0], ascending=False)\n",
        "winner6_results = pd.DataFrame(winner6).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser6 = np.asarray(loser6_results[4:5][0])[0]\n",
        "median_loser6 = np.asarray(loser6_results[9:10][0])[0]\n",
        "upper_loser6 = np.asarray(loser6_results[14:15][0])[0]\n",
        "\n",
        "lower_winner6 = np.asarray(winner6_results[4:5][0])[0]\n",
        "median_winner6 = np.asarray(winner6_results[9:10][0])[0]\n",
        "upper_winner6 = np.asarray(winner6_results[14:15][0])[0]"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSwfNX5ExANt"
      },
      "source": [
        "# Iteration16 :\n",
        "\n",
        "slice16 = 15\n",
        "\n",
        "loser16 = [train_regret_loser_1[slice16],\n",
        "       train_regret_loser_2[slice16],\n",
        "       train_regret_loser_3[slice16],\n",
        "       train_regret_loser_4[slice16],\n",
        "       train_regret_loser_5[slice16],\n",
        "       train_regret_loser_6[slice16],\n",
        "       train_regret_loser_7[slice16],\n",
        "       train_regret_loser_8[slice16],\n",
        "       train_regret_loser_9[slice16],\n",
        "       train_regret_loser_10[slice16],\n",
        "       train_regret_loser_11[slice16],\n",
        "       train_regret_loser_12[slice16],\n",
        "       train_regret_loser_13[slice16],\n",
        "       train_regret_loser_14[slice16],\n",
        "       train_regret_loser_15[slice16],\n",
        "       train_regret_loser_16[slice16],\n",
        "       train_regret_loser_17[slice16],\n",
        "       train_regret_loser_18[slice16],\n",
        "       train_regret_loser_19[slice16],\n",
        "       train_regret_loser_20[slice16]]\n",
        "\n",
        "winner16 = [train_regret_winner_1[slice16],\n",
        "       train_regret_winner_2[slice16],\n",
        "       train_regret_winner_3[slice16],\n",
        "       train_regret_winner_4[slice16],\n",
        "       train_regret_winner_5[slice16],\n",
        "       train_regret_winner_6[slice16],\n",
        "       train_regret_winner_7[slice16],\n",
        "       train_regret_winner_8[slice16],\n",
        "       train_regret_winner_9[slice16],\n",
        "       train_regret_winner_10[slice16],\n",
        "       train_regret_winner_11[slice16],\n",
        "       train_regret_winner_12[slice16],\n",
        "       train_regret_winner_13[slice16],\n",
        "       train_regret_winner_14[slice16],\n",
        "       train_regret_winner_15[slice16],\n",
        "       train_regret_winner_16[slice16],\n",
        "       train_regret_winner_17[slice16],\n",
        "       train_regret_winner_18[slice16],\n",
        "       train_regret_winner_19[slice16],\n",
        "       train_regret_winner_20[slice16]]\n",
        "\n",
        "loser16_results = pd.DataFrame(loser16).sort_values(by=[0], ascending=False)\n",
        "winner16_results = pd.DataFrame(winner16).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser16 = np.asarray(loser16_results[4:5][0])[0]\n",
        "median_loser16 = np.asarray(loser16_results[9:10][0])[0]\n",
        "upper_loser16 = np.asarray(loser16_results[14:15][0])[0]\n",
        "\n",
        "lower_winner16 = np.asarray(winner16_results[4:5][0])[0]\n",
        "median_winner16 = np.asarray(winner16_results[9:10][0])[0]\n",
        "upper_winner16 = np.asarray(winner16_results[14:15][0])[0]"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOB3hOLIxAQy"
      },
      "source": [
        "# Iteration26 :\n",
        "\n",
        "slice26 = 25\n",
        "\n",
        "loser26 = [train_regret_loser_1[slice26],\n",
        "       train_regret_loser_2[slice26],\n",
        "       train_regret_loser_3[slice26],\n",
        "       train_regret_loser_4[slice26],\n",
        "       train_regret_loser_5[slice26],\n",
        "       train_regret_loser_6[slice26],\n",
        "       train_regret_loser_7[slice26],\n",
        "       train_regret_loser_8[slice26],\n",
        "       train_regret_loser_9[slice26],\n",
        "       train_regret_loser_10[slice26],\n",
        "       train_regret_loser_11[slice26],\n",
        "       train_regret_loser_12[slice26],\n",
        "       train_regret_loser_13[slice26],\n",
        "       train_regret_loser_14[slice26],\n",
        "       train_regret_loser_15[slice26],\n",
        "       train_regret_loser_16[slice26],\n",
        "       train_regret_loser_17[slice26],\n",
        "       train_regret_loser_18[slice26],\n",
        "       train_regret_loser_19[slice26],\n",
        "       train_regret_loser_20[slice26]]\n",
        "\n",
        "winner26 = [train_regret_winner_1[slice26],\n",
        "       train_regret_winner_2[slice26],\n",
        "       train_regret_winner_3[slice26],\n",
        "       train_regret_winner_4[slice26],\n",
        "       train_regret_winner_5[slice26],\n",
        "       train_regret_winner_6[slice26],\n",
        "       train_regret_winner_7[slice26],\n",
        "       train_regret_winner_8[slice26],\n",
        "       train_regret_winner_9[slice26],\n",
        "       train_regret_winner_10[slice26],\n",
        "       train_regret_winner_11[slice26],\n",
        "       train_regret_winner_12[slice26],\n",
        "       train_regret_winner_13[slice26],\n",
        "       train_regret_winner_14[slice26],\n",
        "       train_regret_winner_15[slice26],\n",
        "       train_regret_winner_16[slice26],\n",
        "       train_regret_winner_17[slice26],\n",
        "       train_regret_winner_18[slice26],\n",
        "       train_regret_winner_19[slice26],\n",
        "       train_regret_winner_20[slice26]]\n",
        "\n",
        "loser26_results = pd.DataFrame(loser26).sort_values(by=[0], ascending=False)\n",
        "winner26_results = pd.DataFrame(winner26).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser26 = np.asarray(loser26_results[4:5][0])[0]\n",
        "median_loser26 = np.asarray(loser26_results[9:10][0])[0]\n",
        "upper_loser26 = np.asarray(loser26_results[14:15][0])[0]\n",
        "\n",
        "lower_winner26 = np.asarray(winner26_results[4:5][0])[0]\n",
        "median_winner26 = np.asarray(winner26_results[9:10][0])[0]\n",
        "upper_winner26 = np.asarray(winner26_results[14:15][0])[0]"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-0hQMtOxATh"
      },
      "source": [
        "# Iteration36 :\n",
        "\n",
        "slice36 = 35\n",
        "\n",
        "loser36 = [train_regret_loser_1[slice36],\n",
        "       train_regret_loser_2[slice36],\n",
        "       train_regret_loser_3[slice36],\n",
        "       train_regret_loser_4[slice36],\n",
        "       train_regret_loser_5[slice36],\n",
        "       train_regret_loser_6[slice36],\n",
        "       train_regret_loser_7[slice36],\n",
        "       train_regret_loser_8[slice36],\n",
        "       train_regret_loser_9[slice36],\n",
        "       train_regret_loser_10[slice36],\n",
        "       train_regret_loser_11[slice36],\n",
        "       train_regret_loser_12[slice36],\n",
        "       train_regret_loser_13[slice36],\n",
        "       train_regret_loser_14[slice36],\n",
        "       train_regret_loser_15[slice36],\n",
        "       train_regret_loser_16[slice36],\n",
        "       train_regret_loser_17[slice36],\n",
        "       train_regret_loser_18[slice36],\n",
        "       train_regret_loser_19[slice36],\n",
        "       train_regret_loser_20[slice36]]\n",
        "\n",
        "winner36 = [train_regret_winner_1[slice36],\n",
        "       train_regret_winner_2[slice36],\n",
        "       train_regret_winner_3[slice36],\n",
        "       train_regret_winner_4[slice36],\n",
        "       train_regret_winner_5[slice36],\n",
        "       train_regret_winner_6[slice36],\n",
        "       train_regret_winner_7[slice36],\n",
        "       train_regret_winner_8[slice36],\n",
        "       train_regret_winner_9[slice36],\n",
        "       train_regret_winner_10[slice36],\n",
        "       train_regret_winner_11[slice36],\n",
        "       train_regret_winner_12[slice36],\n",
        "       train_regret_winner_13[slice36],\n",
        "       train_regret_winner_14[slice36],\n",
        "       train_regret_winner_15[slice36],\n",
        "       train_regret_winner_16[slice36],\n",
        "       train_regret_winner_17[slice36],\n",
        "       train_regret_winner_18[slice36],\n",
        "       train_regret_winner_19[slice36],\n",
        "       train_regret_winner_20[slice36]]\n",
        "\n",
        "loser36_results = pd.DataFrame(loser36).sort_values(by=[0], ascending=False)\n",
        "winner36_results = pd.DataFrame(winner36).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser36 = np.asarray(loser36_results[4:5][0])[0]\n",
        "median_loser36 = np.asarray(loser36_results[9:10][0])[0]\n",
        "upper_loser36 = np.asarray(loser36_results[14:15][0])[0]\n",
        "\n",
        "lower_winner36 = np.asarray(winner36_results[4:5][0])[0]\n",
        "median_winner36 = np.asarray(winner36_results[9:10][0])[0]\n",
        "upper_winner36 = np.asarray(winner36_results[14:15][0])[0]"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSqBLqTgxAWs"
      },
      "source": [
        "# Iteration46 :\n",
        "\n",
        "slice46 = 45\n",
        "\n",
        "loser46 = [train_regret_loser_1[slice46],\n",
        "       train_regret_loser_2[slice46],\n",
        "       train_regret_loser_3[slice46],\n",
        "       train_regret_loser_4[slice46],\n",
        "       train_regret_loser_5[slice46],\n",
        "       train_regret_loser_6[slice46],\n",
        "       train_regret_loser_7[slice46],\n",
        "       train_regret_loser_8[slice46],\n",
        "       train_regret_loser_9[slice46],\n",
        "       train_regret_loser_10[slice46],\n",
        "       train_regret_loser_11[slice46],\n",
        "       train_regret_loser_12[slice46],\n",
        "       train_regret_loser_13[slice46],\n",
        "       train_regret_loser_14[slice46],\n",
        "       train_regret_loser_15[slice46],\n",
        "       train_regret_loser_16[slice46],\n",
        "       train_regret_loser_17[slice46],\n",
        "       train_regret_loser_18[slice46],\n",
        "       train_regret_loser_19[slice46],\n",
        "       train_regret_loser_20[slice46]]\n",
        "\n",
        "winner46 = [train_regret_winner_1[slice46],\n",
        "       train_regret_winner_2[slice46],\n",
        "       train_regret_winner_3[slice46],\n",
        "       train_regret_winner_4[slice46],\n",
        "       train_regret_winner_5[slice46],\n",
        "       train_regret_winner_6[slice46],\n",
        "       train_regret_winner_7[slice46],\n",
        "       train_regret_winner_8[slice46],\n",
        "       train_regret_winner_9[slice46],\n",
        "       train_regret_winner_10[slice46],\n",
        "       train_regret_winner_11[slice46],\n",
        "       train_regret_winner_12[slice46],\n",
        "       train_regret_winner_13[slice46],\n",
        "       train_regret_winner_14[slice46],\n",
        "       train_regret_winner_15[slice46],\n",
        "       train_regret_winner_16[slice46],\n",
        "       train_regret_winner_17[slice46],\n",
        "       train_regret_winner_18[slice46],\n",
        "       train_regret_winner_19[slice46],\n",
        "       train_regret_winner_20[slice46]]\n",
        "\n",
        "loser46_results = pd.DataFrame(loser46).sort_values(by=[0], ascending=False)\n",
        "winner46_results = pd.DataFrame(winner46).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser46 = np.asarray(loser46_results[4:5][0])[0]\n",
        "median_loser46 = np.asarray(loser46_results[9:10][0])[0]\n",
        "upper_loser46 = np.asarray(loser46_results[14:15][0])[0]\n",
        "\n",
        "lower_winner46 = np.asarray(winner46_results[4:5][0])[0]\n",
        "median_winner46 = np.asarray(winner46_results[9:10][0])[0]\n",
        "upper_winner46 = np.asarray(winner46_results[14:15][0])[0]"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFwO80w6xAZZ"
      },
      "source": [
        "# Iteration56 :\n",
        "\n",
        "slice56 = 55\n",
        "\n",
        "loser56 = [train_regret_loser_1[slice56],\n",
        "       train_regret_loser_2[slice56],\n",
        "       train_regret_loser_3[slice56],\n",
        "       train_regret_loser_4[slice56],\n",
        "       train_regret_loser_5[slice56],\n",
        "       train_regret_loser_6[slice56],\n",
        "       train_regret_loser_7[slice56],\n",
        "       train_regret_loser_8[slice56],\n",
        "       train_regret_loser_9[slice56],\n",
        "       train_regret_loser_10[slice56],\n",
        "       train_regret_loser_11[slice56],\n",
        "       train_regret_loser_12[slice56],\n",
        "       train_regret_loser_13[slice56],\n",
        "       train_regret_loser_14[slice56],\n",
        "       train_regret_loser_15[slice56],\n",
        "       train_regret_loser_16[slice56],\n",
        "       train_regret_loser_17[slice56],\n",
        "       train_regret_loser_18[slice56],\n",
        "       train_regret_loser_19[slice56],\n",
        "       train_regret_loser_20[slice56]]\n",
        "\n",
        "winner56 = [train_regret_winner_1[slice56],\n",
        "       train_regret_winner_2[slice56],\n",
        "       train_regret_winner_3[slice56],\n",
        "       train_regret_winner_4[slice56],\n",
        "       train_regret_winner_5[slice56],\n",
        "       train_regret_winner_6[slice56],\n",
        "       train_regret_winner_7[slice56],\n",
        "       train_regret_winner_8[slice56],\n",
        "       train_regret_winner_9[slice56],\n",
        "       train_regret_winner_10[slice56],\n",
        "       train_regret_winner_11[slice56],\n",
        "       train_regret_winner_12[slice56],\n",
        "       train_regret_winner_13[slice56],\n",
        "       train_regret_winner_14[slice56],\n",
        "       train_regret_winner_15[slice56],\n",
        "       train_regret_winner_16[slice56],\n",
        "       train_regret_winner_17[slice56],\n",
        "       train_regret_winner_18[slice56],\n",
        "       train_regret_winner_19[slice56],\n",
        "       train_regret_winner_20[slice56]]\n",
        "\n",
        "loser56_results = pd.DataFrame(loser56).sort_values(by=[0], ascending=False)\n",
        "winner56_results = pd.DataFrame(winner56).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser56 = np.asarray(loser56_results[4:5][0])[0]\n",
        "median_loser56 = np.asarray(loser56_results[9:10][0])[0]\n",
        "upper_loser56 = np.asarray(loser56_results[14:15][0])[0]\n",
        "\n",
        "lower_winner56 = np.asarray(winner56_results[4:5][0])[0]\n",
        "median_winner56 = np.asarray(winner56_results[9:10][0])[0]\n",
        "upper_winner56 = np.asarray(winner56_results[14:15][0])[0]"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfVZBDP8xAcC"
      },
      "source": [
        "# Iteration66 :\n",
        "\n",
        "slice66 = 65\n",
        "\n",
        "loser66 = [train_regret_loser_1[slice66],\n",
        "       train_regret_loser_2[slice66],\n",
        "       train_regret_loser_3[slice66],\n",
        "       train_regret_loser_4[slice66],\n",
        "       train_regret_loser_5[slice66],\n",
        "       train_regret_loser_6[slice66],\n",
        "       train_regret_loser_7[slice66],\n",
        "       train_regret_loser_8[slice66],\n",
        "       train_regret_loser_9[slice66],\n",
        "       train_regret_loser_10[slice66],\n",
        "       train_regret_loser_11[slice66],\n",
        "       train_regret_loser_12[slice66],\n",
        "       train_regret_loser_13[slice66],\n",
        "       train_regret_loser_14[slice66],\n",
        "       train_regret_loser_15[slice66],\n",
        "       train_regret_loser_16[slice66],\n",
        "       train_regret_loser_17[slice66],\n",
        "       train_regret_loser_18[slice66],\n",
        "       train_regret_loser_19[slice66],\n",
        "       train_regret_loser_20[slice66]]\n",
        "\n",
        "winner66 = [train_regret_winner_1[slice66],\n",
        "       train_regret_winner_2[slice66],\n",
        "       train_regret_winner_3[slice66],\n",
        "       train_regret_winner_4[slice66],\n",
        "       train_regret_winner_5[slice66],\n",
        "       train_regret_winner_6[slice66],\n",
        "       train_regret_winner_7[slice66],\n",
        "       train_regret_winner_8[slice66],\n",
        "       train_regret_winner_9[slice66],\n",
        "       train_regret_winner_10[slice66],\n",
        "       train_regret_winner_11[slice66],\n",
        "       train_regret_winner_12[slice66],\n",
        "       train_regret_winner_13[slice66],\n",
        "       train_regret_winner_14[slice66],\n",
        "       train_regret_winner_15[slice66],\n",
        "       train_regret_winner_16[slice66],\n",
        "       train_regret_winner_17[slice66],\n",
        "       train_regret_winner_18[slice66],\n",
        "       train_regret_winner_19[slice66],\n",
        "       train_regret_winner_20[slice66]]\n",
        "\n",
        "loser66_results = pd.DataFrame(loser66).sort_values(by=[0], ascending=False)\n",
        "winner66_results = pd.DataFrame(winner66).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser66 = np.asarray(loser66_results[4:5][0])[0]\n",
        "median_loser66 = np.asarray(loser66_results[9:10][0])[0]\n",
        "upper_loser66 = np.asarray(loser66_results[14:15][0])[0]\n",
        "\n",
        "lower_winner66 = np.asarray(winner66_results[4:5][0])[0]\n",
        "median_winner66 = np.asarray(winner66_results[9:10][0])[0]\n",
        "upper_winner66 = np.asarray(winner66_results[14:15][0])[0]"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnSYoG7bxAfL"
      },
      "source": [
        "# Iteration76 :\n",
        "\n",
        "slice76 = 75\n",
        "\n",
        "loser76 = [train_regret_loser_1[slice76],\n",
        "       train_regret_loser_2[slice76],\n",
        "       train_regret_loser_3[slice76],\n",
        "       train_regret_loser_4[slice76],\n",
        "       train_regret_loser_5[slice76],\n",
        "       train_regret_loser_6[slice76],\n",
        "       train_regret_loser_7[slice76],\n",
        "       train_regret_loser_8[slice76],\n",
        "       train_regret_loser_9[slice76],\n",
        "       train_regret_loser_10[slice76],\n",
        "       train_regret_loser_11[slice76],\n",
        "       train_regret_loser_12[slice76],\n",
        "       train_regret_loser_13[slice76],\n",
        "       train_regret_loser_14[slice76],\n",
        "       train_regret_loser_15[slice76],\n",
        "       train_regret_loser_16[slice76],\n",
        "       train_regret_loser_17[slice76],\n",
        "       train_regret_loser_18[slice76],\n",
        "       train_regret_loser_19[slice76],\n",
        "       train_regret_loser_20[slice76]]\n",
        "\n",
        "winner76 = [train_regret_winner_1[slice76],\n",
        "       train_regret_winner_2[slice76],\n",
        "       train_regret_winner_3[slice76],\n",
        "       train_regret_winner_4[slice76],\n",
        "       train_regret_winner_5[slice76],\n",
        "       train_regret_winner_6[slice76],\n",
        "       train_regret_winner_7[slice76],\n",
        "       train_regret_winner_8[slice76],\n",
        "       train_regret_winner_9[slice76],\n",
        "       train_regret_winner_10[slice76],\n",
        "       train_regret_winner_11[slice76],\n",
        "       train_regret_winner_12[slice76],\n",
        "       train_regret_winner_13[slice76],\n",
        "       train_regret_winner_14[slice76],\n",
        "       train_regret_winner_15[slice76],\n",
        "       train_regret_winner_16[slice76],\n",
        "       train_regret_winner_17[slice76],\n",
        "       train_regret_winner_18[slice76],\n",
        "       train_regret_winner_19[slice76],\n",
        "       train_regret_winner_20[slice76]]\n",
        "\n",
        "loser76_results = pd.DataFrame(loser76).sort_values(by=[0], ascending=False)\n",
        "winner76_results = pd.DataFrame(winner76).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser76 = np.asarray(loser76_results[4:5][0])[0]\n",
        "median_loser76 = np.asarray(loser76_results[9:10][0])[0]\n",
        "upper_loser76 = np.asarray(loser76_results[14:15][0])[0]\n",
        "\n",
        "lower_winner76 = np.asarray(winner76_results[4:5][0])[0]\n",
        "median_winner76 = np.asarray(winner76_results[9:10][0])[0]\n",
        "upper_winner76 = np.asarray(winner76_results[14:15][0])[0]"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ze_Oy9mxAiO"
      },
      "source": [
        "# Iteration86 :\n",
        "\n",
        "slice86 = 85\n",
        "\n",
        "loser86 = [train_regret_loser_1[slice86],\n",
        "       train_regret_loser_2[slice86],\n",
        "       train_regret_loser_3[slice86],\n",
        "       train_regret_loser_4[slice86],\n",
        "       train_regret_loser_5[slice86],\n",
        "       train_regret_loser_6[slice86],\n",
        "       train_regret_loser_7[slice86],\n",
        "       train_regret_loser_8[slice86],\n",
        "       train_regret_loser_9[slice86],\n",
        "       train_regret_loser_10[slice86],\n",
        "       train_regret_loser_11[slice86],\n",
        "       train_regret_loser_12[slice86],\n",
        "       train_regret_loser_13[slice86],\n",
        "       train_regret_loser_14[slice86],\n",
        "       train_regret_loser_15[slice86],\n",
        "       train_regret_loser_16[slice86],\n",
        "       train_regret_loser_17[slice86],\n",
        "       train_regret_loser_18[slice86],\n",
        "       train_regret_loser_19[slice86],\n",
        "       train_regret_loser_20[slice86]]\n",
        "\n",
        "winner86 = [train_regret_winner_1[slice86],\n",
        "       train_regret_winner_2[slice86],\n",
        "       train_regret_winner_3[slice86],\n",
        "       train_regret_winner_4[slice86],\n",
        "       train_regret_winner_5[slice86],\n",
        "       train_regret_winner_6[slice86],\n",
        "       train_regret_winner_7[slice86],\n",
        "       train_regret_winner_8[slice86],\n",
        "       train_regret_winner_9[slice86],\n",
        "       train_regret_winner_10[slice86],\n",
        "       train_regret_winner_11[slice86],\n",
        "       train_regret_winner_12[slice86],\n",
        "       train_regret_winner_13[slice86],\n",
        "       train_regret_winner_14[slice86],\n",
        "       train_regret_winner_15[slice86],\n",
        "       train_regret_winner_16[slice86],\n",
        "       train_regret_winner_17[slice86],\n",
        "       train_regret_winner_18[slice86],\n",
        "       train_regret_winner_19[slice86],\n",
        "       train_regret_winner_20[slice86]]\n",
        "\n",
        "loser86_results = pd.DataFrame(loser86).sort_values(by=[0], ascending=False)\n",
        "winner86_results = pd.DataFrame(winner86).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser86 = np.asarray(loser86_results[4:5][0])[0]\n",
        "median_loser86 = np.asarray(loser86_results[9:10][0])[0]\n",
        "upper_loser86 = np.asarray(loser86_results[14:15][0])[0]\n",
        "\n",
        "lower_winner86 = np.asarray(winner86_results[4:5][0])[0]\n",
        "median_winner86 = np.asarray(winner86_results[9:10][0])[0]\n",
        "upper_winner86 = np.asarray(winner86_results[14:15][0])[0]"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glsE9_RPxAlS"
      },
      "source": [
        "# Iteration96 :\n",
        "\n",
        "slice96 = 95\n",
        "\n",
        "loser96 = [train_regret_loser_1[slice96],\n",
        "       train_regret_loser_2[slice96],\n",
        "       train_regret_loser_3[slice96],\n",
        "       train_regret_loser_4[slice96],\n",
        "       train_regret_loser_5[slice96],\n",
        "       train_regret_loser_6[slice96],\n",
        "       train_regret_loser_7[slice96],\n",
        "       train_regret_loser_8[slice96],\n",
        "       train_regret_loser_9[slice96],\n",
        "       train_regret_loser_10[slice96],\n",
        "       train_regret_loser_11[slice96],\n",
        "       train_regret_loser_12[slice96],\n",
        "       train_regret_loser_13[slice96],\n",
        "       train_regret_loser_14[slice96],\n",
        "       train_regret_loser_15[slice96],\n",
        "       train_regret_loser_16[slice96],\n",
        "       train_regret_loser_17[slice96],\n",
        "       train_regret_loser_18[slice96],\n",
        "       train_regret_loser_19[slice96],\n",
        "       train_regret_loser_20[slice96]]\n",
        "\n",
        "winner96 = [train_regret_winner_1[slice96],\n",
        "       train_regret_winner_2[slice96],\n",
        "       train_regret_winner_3[slice96],\n",
        "       train_regret_winner_4[slice96],\n",
        "       train_regret_winner_5[slice96],\n",
        "       train_regret_winner_6[slice96],\n",
        "       train_regret_winner_7[slice96],\n",
        "       train_regret_winner_8[slice96],\n",
        "       train_regret_winner_9[slice96],\n",
        "       train_regret_winner_10[slice96],\n",
        "       train_regret_winner_11[slice96],\n",
        "       train_regret_winner_12[slice96],\n",
        "       train_regret_winner_13[slice96],\n",
        "       train_regret_winner_14[slice96],\n",
        "       train_regret_winner_15[slice96],\n",
        "       train_regret_winner_16[slice96],\n",
        "       train_regret_winner_17[slice96],\n",
        "       train_regret_winner_18[slice96],\n",
        "       train_regret_winner_19[slice96],\n",
        "       train_regret_winner_20[slice96]]\n",
        "\n",
        "loser96_results = pd.DataFrame(loser96).sort_values(by=[0], ascending=False)\n",
        "winner96_results = pd.DataFrame(winner96).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser96 = np.asarray(loser96_results[4:5][0])[0]\n",
        "median_loser96 = np.asarray(loser96_results[9:10][0])[0]\n",
        "upper_loser96 = np.asarray(loser96_results[14:15][0])[0]\n",
        "\n",
        "lower_winner96 = np.asarray(winner96_results[4:5][0])[0]\n",
        "median_winner96 = np.asarray(winner96_results[9:10][0])[0]\n",
        "upper_winner96 = np.asarray(winner96_results[14:15][0])[0]"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhsEfl1RxAoA"
      },
      "source": [
        "# Iteration7 :\n",
        "\n",
        "slice7 = 6\n",
        "\n",
        "loser7 = [train_regret_loser_1[slice7],\n",
        "       train_regret_loser_2[slice7],\n",
        "       train_regret_loser_3[slice7],\n",
        "       train_regret_loser_4[slice7],\n",
        "       train_regret_loser_5[slice7],\n",
        "       train_regret_loser_6[slice7],\n",
        "       train_regret_loser_7[slice7],\n",
        "       train_regret_loser_8[slice7],\n",
        "       train_regret_loser_9[slice7],\n",
        "       train_regret_loser_10[slice7],\n",
        "       train_regret_loser_11[slice7],\n",
        "       train_regret_loser_12[slice7],\n",
        "       train_regret_loser_13[slice7],\n",
        "       train_regret_loser_14[slice7],\n",
        "       train_regret_loser_15[slice7],\n",
        "       train_regret_loser_16[slice7],\n",
        "       train_regret_loser_17[slice7],\n",
        "       train_regret_loser_18[slice7],\n",
        "       train_regret_loser_19[slice7],\n",
        "       train_regret_loser_20[slice7]]\n",
        "\n",
        "winner7 = [train_regret_winner_1[slice7],\n",
        "       train_regret_winner_2[slice7],\n",
        "       train_regret_winner_3[slice7],\n",
        "       train_regret_winner_4[slice7],\n",
        "       train_regret_winner_5[slice7],\n",
        "       train_regret_winner_6[slice7],\n",
        "       train_regret_winner_7[slice7],\n",
        "       train_regret_winner_8[slice7],\n",
        "       train_regret_winner_9[slice7],\n",
        "       train_regret_winner_10[slice7],\n",
        "       train_regret_winner_11[slice7],\n",
        "       train_regret_winner_12[slice7],\n",
        "       train_regret_winner_13[slice7],\n",
        "       train_regret_winner_14[slice7],\n",
        "       train_regret_winner_15[slice7],\n",
        "       train_regret_winner_16[slice7],\n",
        "       train_regret_winner_17[slice7],\n",
        "       train_regret_winner_18[slice7],\n",
        "       train_regret_winner_19[slice7],\n",
        "       train_regret_winner_20[slice7]]\n",
        "\n",
        "loser7_results = pd.DataFrame(loser7).sort_values(by=[0], ascending=False)\n",
        "winner7_results = pd.DataFrame(winner7).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser7 = np.asarray(loser7_results[4:5][0])[0]\n",
        "median_loser7 = np.asarray(loser7_results[9:10][0])[0]\n",
        "upper_loser7 = np.asarray(loser7_results[14:15][0])[0]\n",
        "\n",
        "lower_winner7 = np.asarray(winner7_results[4:5][0])[0]\n",
        "median_winner7 = np.asarray(winner7_results[9:10][0])[0]\n",
        "upper_winner7 = np.asarray(winner7_results[14:15][0])[0]"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUCMheLKxArL"
      },
      "source": [
        "# Iteration17 :\n",
        "\n",
        "slice17 = 16\n",
        "\n",
        "loser17 = [train_regret_loser_1[slice17],\n",
        "       train_regret_loser_2[slice17],\n",
        "       train_regret_loser_3[slice17],\n",
        "       train_regret_loser_4[slice17],\n",
        "       train_regret_loser_5[slice17],\n",
        "       train_regret_loser_6[slice17],\n",
        "       train_regret_loser_7[slice17],\n",
        "       train_regret_loser_8[slice17],\n",
        "       train_regret_loser_9[slice17],\n",
        "       train_regret_loser_10[slice17],\n",
        "       train_regret_loser_11[slice17],\n",
        "       train_regret_loser_12[slice17],\n",
        "       train_regret_loser_13[slice17],\n",
        "       train_regret_loser_14[slice17],\n",
        "       train_regret_loser_15[slice17],\n",
        "       train_regret_loser_16[slice17],\n",
        "       train_regret_loser_17[slice17],\n",
        "       train_regret_loser_18[slice17],\n",
        "       train_regret_loser_19[slice17],\n",
        "       train_regret_loser_20[slice17]]\n",
        "\n",
        "winner17 = [train_regret_winner_1[slice17],\n",
        "       train_regret_winner_2[slice17],\n",
        "       train_regret_winner_3[slice17],\n",
        "       train_regret_winner_4[slice17],\n",
        "       train_regret_winner_5[slice17],\n",
        "       train_regret_winner_6[slice17],\n",
        "       train_regret_winner_7[slice17],\n",
        "       train_regret_winner_8[slice17],\n",
        "       train_regret_winner_9[slice17],\n",
        "       train_regret_winner_10[slice17],\n",
        "       train_regret_winner_11[slice17],\n",
        "       train_regret_winner_12[slice17],\n",
        "       train_regret_winner_13[slice17],\n",
        "       train_regret_winner_14[slice17],\n",
        "       train_regret_winner_15[slice17],\n",
        "       train_regret_winner_16[slice17],\n",
        "       train_regret_winner_17[slice17],\n",
        "       train_regret_winner_18[slice17],\n",
        "       train_regret_winner_19[slice17],\n",
        "       train_regret_winner_20[slice17]]\n",
        "\n",
        "loser17_results = pd.DataFrame(loser17).sort_values(by=[0], ascending=False)\n",
        "winner17_results = pd.DataFrame(winner17).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser17 = np.asarray(loser17_results[4:5][0])[0]\n",
        "median_loser17 = np.asarray(loser17_results[9:10][0])[0]\n",
        "upper_loser17 = np.asarray(loser17_results[14:15][0])[0]\n",
        "\n",
        "lower_winner17 = np.asarray(winner17_results[4:5][0])[0]\n",
        "median_winner17 = np.asarray(winner17_results[9:10][0])[0]\n",
        "upper_winner17 = np.asarray(winner17_results[14:15][0])[0]"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYnBmq7_xAuB"
      },
      "source": [
        "# Iteration27 :\n",
        "\n",
        "slice27 = 26\n",
        "\n",
        "loser27 = [train_regret_loser_1[slice27],\n",
        "       train_regret_loser_2[slice27],\n",
        "       train_regret_loser_3[slice27],\n",
        "       train_regret_loser_4[slice27],\n",
        "       train_regret_loser_5[slice27],\n",
        "       train_regret_loser_6[slice27],\n",
        "       train_regret_loser_7[slice27],\n",
        "       train_regret_loser_8[slice27],\n",
        "       train_regret_loser_9[slice27],\n",
        "       train_regret_loser_10[slice27],\n",
        "       train_regret_loser_11[slice27],\n",
        "       train_regret_loser_12[slice27],\n",
        "       train_regret_loser_13[slice27],\n",
        "       train_regret_loser_14[slice27],\n",
        "       train_regret_loser_15[slice27],\n",
        "       train_regret_loser_16[slice27],\n",
        "       train_regret_loser_17[slice27],\n",
        "       train_regret_loser_18[slice27],\n",
        "       train_regret_loser_19[slice27],\n",
        "       train_regret_loser_20[slice27]]\n",
        "\n",
        "winner27 = [train_regret_winner_1[slice27],\n",
        "       train_regret_winner_2[slice27],\n",
        "       train_regret_winner_3[slice27],\n",
        "       train_regret_winner_4[slice27],\n",
        "       train_regret_winner_5[slice27],\n",
        "       train_regret_winner_6[slice27],\n",
        "       train_regret_winner_7[slice27],\n",
        "       train_regret_winner_8[slice27],\n",
        "       train_regret_winner_9[slice27],\n",
        "       train_regret_winner_10[slice27],\n",
        "       train_regret_winner_11[slice27],\n",
        "       train_regret_winner_12[slice27],\n",
        "       train_regret_winner_13[slice27],\n",
        "       train_regret_winner_14[slice27],\n",
        "       train_regret_winner_15[slice27],\n",
        "       train_regret_winner_16[slice27],\n",
        "       train_regret_winner_17[slice27],\n",
        "       train_regret_winner_18[slice27],\n",
        "       train_regret_winner_19[slice27],\n",
        "       train_regret_winner_20[slice27]]\n",
        "\n",
        "loser27_results = pd.DataFrame(loser27).sort_values(by=[0], ascending=False)\n",
        "winner27_results = pd.DataFrame(winner27).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser27 = np.asarray(loser27_results[4:5][0])[0]\n",
        "median_loser27 = np.asarray(loser27_results[9:10][0])[0]\n",
        "upper_loser27 = np.asarray(loser27_results[14:15][0])[0]\n",
        "\n",
        "lower_winner27 = np.asarray(winner27_results[4:5][0])[0]\n",
        "median_winner27 = np.asarray(winner27_results[9:10][0])[0]\n",
        "upper_winner27 = np.asarray(winner27_results[14:15][0])[0]"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ChA8KOUxAw6"
      },
      "source": [
        "# Iteration37 :\n",
        "\n",
        "slice37 = 36\n",
        "\n",
        "loser37 = [train_regret_loser_1[slice37],\n",
        "       train_regret_loser_2[slice37],\n",
        "       train_regret_loser_3[slice37],\n",
        "       train_regret_loser_4[slice37],\n",
        "       train_regret_loser_5[slice37],\n",
        "       train_regret_loser_6[slice37],\n",
        "       train_regret_loser_7[slice37],\n",
        "       train_regret_loser_8[slice37],\n",
        "       train_regret_loser_9[slice37],\n",
        "       train_regret_loser_10[slice37],\n",
        "       train_regret_loser_11[slice37],\n",
        "       train_regret_loser_12[slice37],\n",
        "       train_regret_loser_13[slice37],\n",
        "       train_regret_loser_14[slice37],\n",
        "       train_regret_loser_15[slice37],\n",
        "       train_regret_loser_16[slice37],\n",
        "       train_regret_loser_17[slice37],\n",
        "       train_regret_loser_18[slice37],\n",
        "       train_regret_loser_19[slice37],\n",
        "       train_regret_loser_20[slice37]]\n",
        "\n",
        "winner37 = [train_regret_winner_1[slice37],\n",
        "       train_regret_winner_2[slice37],\n",
        "       train_regret_winner_3[slice37],\n",
        "       train_regret_winner_4[slice37],\n",
        "       train_regret_winner_5[slice37],\n",
        "       train_regret_winner_6[slice37],\n",
        "       train_regret_winner_7[slice37],\n",
        "       train_regret_winner_8[slice37],\n",
        "       train_regret_winner_9[slice37],\n",
        "       train_regret_winner_10[slice37],\n",
        "       train_regret_winner_11[slice37],\n",
        "       train_regret_winner_12[slice37],\n",
        "       train_regret_winner_13[slice37],\n",
        "       train_regret_winner_14[slice37],\n",
        "       train_regret_winner_15[slice37],\n",
        "       train_regret_winner_16[slice37],\n",
        "       train_regret_winner_17[slice37],\n",
        "       train_regret_winner_18[slice37],\n",
        "       train_regret_winner_19[slice37],\n",
        "       train_regret_winner_20[slice37]]\n",
        "\n",
        "loser37_results = pd.DataFrame(loser37).sort_values(by=[0], ascending=False)\n",
        "winner37_results = pd.DataFrame(winner37).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser37 = np.asarray(loser37_results[4:5][0])[0]\n",
        "median_loser37 = np.asarray(loser37_results[9:10][0])[0]\n",
        "upper_loser37 = np.asarray(loser37_results[14:15][0])[0]\n",
        "\n",
        "lower_winner37 = np.asarray(winner37_results[4:5][0])[0]\n",
        "median_winner37 = np.asarray(winner37_results[9:10][0])[0]\n",
        "upper_winner37 = np.asarray(winner37_results[14:15][0])[0]"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVsY1buDxAzx"
      },
      "source": [
        "# Iteration47 :\n",
        "\n",
        "slice47 = 46\n",
        "\n",
        "loser47 = [train_regret_loser_1[slice47],\n",
        "       train_regret_loser_2[slice47],\n",
        "       train_regret_loser_3[slice47],\n",
        "       train_regret_loser_4[slice47],\n",
        "       train_regret_loser_5[slice47],\n",
        "       train_regret_loser_6[slice47],\n",
        "       train_regret_loser_7[slice47],\n",
        "       train_regret_loser_8[slice47],\n",
        "       train_regret_loser_9[slice47],\n",
        "       train_regret_loser_10[slice47],\n",
        "       train_regret_loser_11[slice47],\n",
        "       train_regret_loser_12[slice47],\n",
        "       train_regret_loser_13[slice47],\n",
        "       train_regret_loser_14[slice47],\n",
        "       train_regret_loser_15[slice47],\n",
        "       train_regret_loser_16[slice47],\n",
        "       train_regret_loser_17[slice47],\n",
        "       train_regret_loser_18[slice47],\n",
        "       train_regret_loser_19[slice47],\n",
        "       train_regret_loser_20[slice47]]\n",
        "\n",
        "winner47 = [train_regret_winner_1[slice47],\n",
        "       train_regret_winner_2[slice47],\n",
        "       train_regret_winner_3[slice47],\n",
        "       train_regret_winner_4[slice47],\n",
        "       train_regret_winner_5[slice47],\n",
        "       train_regret_winner_6[slice47],\n",
        "       train_regret_winner_7[slice47],\n",
        "       train_regret_winner_8[slice47],\n",
        "       train_regret_winner_9[slice47],\n",
        "       train_regret_winner_10[slice47],\n",
        "       train_regret_winner_11[slice47],\n",
        "       train_regret_winner_12[slice47],\n",
        "       train_regret_winner_13[slice47],\n",
        "       train_regret_winner_14[slice47],\n",
        "       train_regret_winner_15[slice47],\n",
        "       train_regret_winner_16[slice47],\n",
        "       train_regret_winner_17[slice47],\n",
        "       train_regret_winner_18[slice47],\n",
        "       train_regret_winner_19[slice47],\n",
        "       train_regret_winner_20[slice47]]\n",
        "\n",
        "loser47_results = pd.DataFrame(loser47).sort_values(by=[0], ascending=False)\n",
        "winner47_results = pd.DataFrame(winner47).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser47 = np.asarray(loser47_results[4:5][0])[0]\n",
        "median_loser47 = np.asarray(loser47_results[9:10][0])[0]\n",
        "upper_loser47 = np.asarray(loser47_results[14:15][0])[0]\n",
        "\n",
        "lower_winner47 = np.asarray(winner47_results[4:5][0])[0]\n",
        "median_winner47 = np.asarray(winner47_results[9:10][0])[0]\n",
        "upper_winner47 = np.asarray(winner47_results[14:15][0])[0]"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fIy_EyTxA20"
      },
      "source": [
        "# Iteration57 :\n",
        "\n",
        "slice57 = 56\n",
        "\n",
        "loser57 = [train_regret_loser_1[slice57],\n",
        "       train_regret_loser_2[slice57],\n",
        "       train_regret_loser_3[slice57],\n",
        "       train_regret_loser_4[slice57],\n",
        "       train_regret_loser_5[slice57],\n",
        "       train_regret_loser_6[slice57],\n",
        "       train_regret_loser_7[slice57],\n",
        "       train_regret_loser_8[slice57],\n",
        "       train_regret_loser_9[slice57],\n",
        "       train_regret_loser_10[slice57],\n",
        "       train_regret_loser_11[slice57],\n",
        "       train_regret_loser_12[slice57],\n",
        "       train_regret_loser_13[slice57],\n",
        "       train_regret_loser_14[slice57],\n",
        "       train_regret_loser_15[slice57],\n",
        "       train_regret_loser_16[slice57],\n",
        "       train_regret_loser_17[slice57],\n",
        "       train_regret_loser_18[slice57],\n",
        "       train_regret_loser_19[slice57],\n",
        "       train_regret_loser_20[slice57]]\n",
        "\n",
        "winner57 = [train_regret_winner_1[slice57],\n",
        "       train_regret_winner_2[slice57],\n",
        "       train_regret_winner_3[slice57],\n",
        "       train_regret_winner_4[slice57],\n",
        "       train_regret_winner_5[slice57],\n",
        "       train_regret_winner_6[slice57],\n",
        "       train_regret_winner_7[slice57],\n",
        "       train_regret_winner_8[slice57],\n",
        "       train_regret_winner_9[slice57],\n",
        "       train_regret_winner_10[slice57],\n",
        "       train_regret_winner_11[slice57],\n",
        "       train_regret_winner_12[slice57],\n",
        "       train_regret_winner_13[slice57],\n",
        "       train_regret_winner_14[slice57],\n",
        "       train_regret_winner_15[slice57],\n",
        "       train_regret_winner_16[slice57],\n",
        "       train_regret_winner_17[slice57],\n",
        "       train_regret_winner_18[slice57],\n",
        "       train_regret_winner_19[slice57],\n",
        "       train_regret_winner_20[slice57]]\n",
        "\n",
        "loser57_results = pd.DataFrame(loser57).sort_values(by=[0], ascending=False)\n",
        "winner57_results = pd.DataFrame(winner57).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser57 = np.asarray(loser57_results[4:5][0])[0]\n",
        "median_loser57 = np.asarray(loser57_results[9:10][0])[0]\n",
        "upper_loser57 = np.asarray(loser57_results[14:15][0])[0]\n",
        "\n",
        "lower_winner57 = np.asarray(winner57_results[4:5][0])[0]\n",
        "median_winner57 = np.asarray(winner57_results[9:10][0])[0]\n",
        "upper_winner57 = np.asarray(winner57_results[14:15][0])[0]"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umwdBl8XxA5r"
      },
      "source": [
        "# Iteration67 :\n",
        "\n",
        "slice67 = 66\n",
        "\n",
        "loser67 = [train_regret_loser_1[slice67],\n",
        "       train_regret_loser_2[slice67],\n",
        "       train_regret_loser_3[slice67],\n",
        "       train_regret_loser_4[slice67],\n",
        "       train_regret_loser_5[slice67],\n",
        "       train_regret_loser_6[slice67],\n",
        "       train_regret_loser_7[slice67],\n",
        "       train_regret_loser_8[slice67],\n",
        "       train_regret_loser_9[slice67],\n",
        "       train_regret_loser_10[slice67],\n",
        "       train_regret_loser_11[slice67],\n",
        "       train_regret_loser_12[slice67],\n",
        "       train_regret_loser_13[slice67],\n",
        "       train_regret_loser_14[slice67],\n",
        "       train_regret_loser_15[slice67],\n",
        "       train_regret_loser_16[slice67],\n",
        "       train_regret_loser_17[slice67],\n",
        "       train_regret_loser_18[slice67],\n",
        "       train_regret_loser_19[slice67],\n",
        "       train_regret_loser_20[slice67]]\n",
        "\n",
        "winner67 = [train_regret_winner_1[slice67],\n",
        "       train_regret_winner_2[slice67],\n",
        "       train_regret_winner_3[slice67],\n",
        "       train_regret_winner_4[slice67],\n",
        "       train_regret_winner_5[slice67],\n",
        "       train_regret_winner_6[slice67],\n",
        "       train_regret_winner_7[slice67],\n",
        "       train_regret_winner_8[slice67],\n",
        "       train_regret_winner_9[slice67],\n",
        "       train_regret_winner_10[slice67],\n",
        "       train_regret_winner_11[slice67],\n",
        "       train_regret_winner_12[slice67],\n",
        "       train_regret_winner_13[slice67],\n",
        "       train_regret_winner_14[slice67],\n",
        "       train_regret_winner_15[slice67],\n",
        "       train_regret_winner_16[slice67],\n",
        "       train_regret_winner_17[slice67],\n",
        "       train_regret_winner_18[slice67],\n",
        "       train_regret_winner_19[slice67],\n",
        "       train_regret_winner_20[slice67]]\n",
        "\n",
        "loser67_results = pd.DataFrame(loser67).sort_values(by=[0], ascending=False)\n",
        "winner67_results = pd.DataFrame(winner67).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser67 = np.asarray(loser67_results[4:5][0])[0]\n",
        "median_loser67 = np.asarray(loser67_results[9:10][0])[0]\n",
        "upper_loser67 = np.asarray(loser67_results[14:15][0])[0]\n",
        "\n",
        "lower_winner67 = np.asarray(winner67_results[4:5][0])[0]\n",
        "median_winner67 = np.asarray(winner67_results[9:10][0])[0]\n",
        "upper_winner67 = np.asarray(winner67_results[14:15][0])[0]"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF3KFX-ZxA8q"
      },
      "source": [
        "# Iteration77 :\n",
        "\n",
        "slice77 = 76\n",
        "\n",
        "loser77 = [train_regret_loser_1[slice77],\n",
        "       train_regret_loser_2[slice77],\n",
        "       train_regret_loser_3[slice77],\n",
        "       train_regret_loser_4[slice77],\n",
        "       train_regret_loser_5[slice77],\n",
        "       train_regret_loser_6[slice77],\n",
        "       train_regret_loser_7[slice77],\n",
        "       train_regret_loser_8[slice77],\n",
        "       train_regret_loser_9[slice77],\n",
        "       train_regret_loser_10[slice77],\n",
        "       train_regret_loser_11[slice77],\n",
        "       train_regret_loser_12[slice77],\n",
        "       train_regret_loser_13[slice77],\n",
        "       train_regret_loser_14[slice77],\n",
        "       train_regret_loser_15[slice77],\n",
        "       train_regret_loser_16[slice77],\n",
        "       train_regret_loser_17[slice77],\n",
        "       train_regret_loser_18[slice77],\n",
        "       train_regret_loser_19[slice77],\n",
        "       train_regret_loser_20[slice77]]\n",
        "\n",
        "winner77 = [train_regret_winner_1[slice77],\n",
        "       train_regret_winner_2[slice77],\n",
        "       train_regret_winner_3[slice77],\n",
        "       train_regret_winner_4[slice77],\n",
        "       train_regret_winner_5[slice77],\n",
        "       train_regret_winner_6[slice77],\n",
        "       train_regret_winner_7[slice77],\n",
        "       train_regret_winner_8[slice77],\n",
        "       train_regret_winner_9[slice77],\n",
        "       train_regret_winner_10[slice77],\n",
        "       train_regret_winner_11[slice77],\n",
        "       train_regret_winner_12[slice77],\n",
        "       train_regret_winner_13[slice77],\n",
        "       train_regret_winner_14[slice77],\n",
        "       train_regret_winner_15[slice77],\n",
        "       train_regret_winner_16[slice77],\n",
        "       train_regret_winner_17[slice77],\n",
        "       train_regret_winner_18[slice77],\n",
        "       train_regret_winner_19[slice77],\n",
        "       train_regret_winner_20[slice77]]\n",
        "\n",
        "loser77_results = pd.DataFrame(loser77).sort_values(by=[0], ascending=False)\n",
        "winner77_results = pd.DataFrame(winner77).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser77 = np.asarray(loser77_results[4:5][0])[0]\n",
        "median_loser77 = np.asarray(loser77_results[9:10][0])[0]\n",
        "upper_loser77 = np.asarray(loser77_results[14:15][0])[0]\n",
        "\n",
        "lower_winner77 = np.asarray(winner77_results[4:5][0])[0]\n",
        "median_winner77 = np.asarray(winner77_results[9:10][0])[0]\n",
        "upper_winner77 = np.asarray(winner77_results[14:15][0])[0]"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVYft39xA_t"
      },
      "source": [
        "# Iteration87 :\n",
        "\n",
        "slice87 = 86\n",
        "\n",
        "loser87 = [train_regret_loser_1[slice87],\n",
        "       train_regret_loser_2[slice87],\n",
        "       train_regret_loser_3[slice87],\n",
        "       train_regret_loser_4[slice87],\n",
        "       train_regret_loser_5[slice87],\n",
        "       train_regret_loser_6[slice87],\n",
        "       train_regret_loser_7[slice87],\n",
        "       train_regret_loser_8[slice87],\n",
        "       train_regret_loser_9[slice87],\n",
        "       train_regret_loser_10[slice87],\n",
        "       train_regret_loser_11[slice87],\n",
        "       train_regret_loser_12[slice87],\n",
        "       train_regret_loser_13[slice87],\n",
        "       train_regret_loser_14[slice87],\n",
        "       train_regret_loser_15[slice87],\n",
        "       train_regret_loser_16[slice87],\n",
        "       train_regret_loser_17[slice87],\n",
        "       train_regret_loser_18[slice87],\n",
        "       train_regret_loser_19[slice87],\n",
        "       train_regret_loser_20[slice87]]\n",
        "\n",
        "winner87 = [train_regret_winner_1[slice87],\n",
        "       train_regret_winner_2[slice87],\n",
        "       train_regret_winner_3[slice87],\n",
        "       train_regret_winner_4[slice87],\n",
        "       train_regret_winner_5[slice87],\n",
        "       train_regret_winner_6[slice87],\n",
        "       train_regret_winner_7[slice87],\n",
        "       train_regret_winner_8[slice87],\n",
        "       train_regret_winner_9[slice87],\n",
        "       train_regret_winner_10[slice87],\n",
        "       train_regret_winner_11[slice87],\n",
        "       train_regret_winner_12[slice87],\n",
        "       train_regret_winner_13[slice87],\n",
        "       train_regret_winner_14[slice87],\n",
        "       train_regret_winner_15[slice87],\n",
        "       train_regret_winner_16[slice87],\n",
        "       train_regret_winner_17[slice87],\n",
        "       train_regret_winner_18[slice87],\n",
        "       train_regret_winner_19[slice87],\n",
        "       train_regret_winner_20[slice87]]\n",
        "\n",
        "loser87_results = pd.DataFrame(loser87).sort_values(by=[0], ascending=False)\n",
        "winner87_results = pd.DataFrame(winner87).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser87 = np.asarray(loser87_results[4:5][0])[0]\n",
        "median_loser87 = np.asarray(loser87_results[9:10][0])[0]\n",
        "upper_loser87 = np.asarray(loser87_results[14:15][0])[0]\n",
        "\n",
        "lower_winner87 = np.asarray(winner87_results[4:5][0])[0]\n",
        "median_winner87 = np.asarray(winner87_results[9:10][0])[0]\n",
        "upper_winner87 = np.asarray(winner87_results[14:15][0])[0]"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gPkLC0yxBCs"
      },
      "source": [
        "# Iteration97 :\n",
        "\n",
        "slice97 = 96\n",
        "\n",
        "loser97 = [train_regret_loser_1[slice97],\n",
        "       train_regret_loser_2[slice97],\n",
        "       train_regret_loser_3[slice97],\n",
        "       train_regret_loser_4[slice97],\n",
        "       train_regret_loser_5[slice97],\n",
        "       train_regret_loser_6[slice97],\n",
        "       train_regret_loser_7[slice97],\n",
        "       train_regret_loser_8[slice97],\n",
        "       train_regret_loser_9[slice97],\n",
        "       train_regret_loser_10[slice97],\n",
        "       train_regret_loser_11[slice97],\n",
        "       train_regret_loser_12[slice97],\n",
        "       train_regret_loser_13[slice97],\n",
        "       train_regret_loser_14[slice97],\n",
        "       train_regret_loser_15[slice97],\n",
        "       train_regret_loser_16[slice97],\n",
        "       train_regret_loser_17[slice97],\n",
        "       train_regret_loser_18[slice97],\n",
        "       train_regret_loser_19[slice97],\n",
        "       train_regret_loser_20[slice97]]\n",
        "\n",
        "winner97 = [train_regret_winner_1[slice97],\n",
        "       train_regret_winner_2[slice97],\n",
        "       train_regret_winner_3[slice97],\n",
        "       train_regret_winner_4[slice97],\n",
        "       train_regret_winner_5[slice97],\n",
        "       train_regret_winner_6[slice97],\n",
        "       train_regret_winner_7[slice97],\n",
        "       train_regret_winner_8[slice97],\n",
        "       train_regret_winner_9[slice97],\n",
        "       train_regret_winner_10[slice97],\n",
        "       train_regret_winner_11[slice97],\n",
        "       train_regret_winner_12[slice97],\n",
        "       train_regret_winner_13[slice97],\n",
        "       train_regret_winner_14[slice97],\n",
        "       train_regret_winner_15[slice97],\n",
        "       train_regret_winner_16[slice97],\n",
        "       train_regret_winner_17[slice97],\n",
        "       train_regret_winner_18[slice97],\n",
        "       train_regret_winner_19[slice97],\n",
        "       train_regret_winner_20[slice97]]\n",
        "\n",
        "loser97_results = pd.DataFrame(loser97).sort_values(by=[0], ascending=False)\n",
        "winner97_results = pd.DataFrame(winner97).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser97 = np.asarray(loser97_results[4:5][0])[0]\n",
        "median_loser97 = np.asarray(loser97_results[9:10][0])[0]\n",
        "upper_loser97 = np.asarray(loser97_results[14:15][0])[0]\n",
        "\n",
        "lower_winner97 = np.asarray(winner97_results[4:5][0])[0]\n",
        "median_winner97 = np.asarray(winner97_results[9:10][0])[0]\n",
        "upper_winner97 = np.asarray(winner97_results[14:15][0])[0]"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbgYEpYUxBFr"
      },
      "source": [
        "# Iteration8 :\n",
        "\n",
        "slice8 = 7\n",
        "\n",
        "loser8 = [train_regret_loser_1[slice8],\n",
        "       train_regret_loser_2[slice8],\n",
        "       train_regret_loser_3[slice8],\n",
        "       train_regret_loser_4[slice8],\n",
        "       train_regret_loser_5[slice8],\n",
        "       train_regret_loser_6[slice8],\n",
        "       train_regret_loser_7[slice8],\n",
        "       train_regret_loser_8[slice8],\n",
        "       train_regret_loser_9[slice8],\n",
        "       train_regret_loser_10[slice8],\n",
        "       train_regret_loser_11[slice8],\n",
        "       train_regret_loser_12[slice8],\n",
        "       train_regret_loser_13[slice8],\n",
        "       train_regret_loser_14[slice8],\n",
        "       train_regret_loser_15[slice8],\n",
        "       train_regret_loser_16[slice8],\n",
        "       train_regret_loser_17[slice8],\n",
        "       train_regret_loser_18[slice8],\n",
        "       train_regret_loser_19[slice8],\n",
        "       train_regret_loser_20[slice8]]\n",
        "\n",
        "winner8 = [train_regret_winner_1[slice8],\n",
        "       train_regret_winner_2[slice8],\n",
        "       train_regret_winner_3[slice8],\n",
        "       train_regret_winner_4[slice8],\n",
        "       train_regret_winner_5[slice8],\n",
        "       train_regret_winner_6[slice8],\n",
        "       train_regret_winner_7[slice8],\n",
        "       train_regret_winner_8[slice8],\n",
        "       train_regret_winner_9[slice8],\n",
        "       train_regret_winner_10[slice8],\n",
        "       train_regret_winner_11[slice8],\n",
        "       train_regret_winner_12[slice8],\n",
        "       train_regret_winner_13[slice8],\n",
        "       train_regret_winner_14[slice8],\n",
        "       train_regret_winner_15[slice8],\n",
        "       train_regret_winner_16[slice8],\n",
        "       train_regret_winner_17[slice8],\n",
        "       train_regret_winner_18[slice8],\n",
        "       train_regret_winner_19[slice8],\n",
        "       train_regret_winner_20[slice8]]\n",
        "\n",
        "loser8_results = pd.DataFrame(loser8).sort_values(by=[0], ascending=False)\n",
        "winner8_results = pd.DataFrame(winner8).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser8 = np.asarray(loser8_results[4:5][0])[0]\n",
        "median_loser8 = np.asarray(loser8_results[9:10][0])[0]\n",
        "upper_loser8 = np.asarray(loser8_results[14:15][0])[0]\n",
        "\n",
        "lower_winner8 = np.asarray(winner8_results[4:5][0])[0]\n",
        "median_winner8 = np.asarray(winner8_results[9:10][0])[0]\n",
        "upper_winner8 = np.asarray(winner8_results[14:15][0])[0]"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im9dHUqvxBH9"
      },
      "source": [
        "# Iteration18 :\n",
        "\n",
        "slice18 = 17\n",
        "\n",
        "loser18 = [train_regret_loser_1[slice18],\n",
        "       train_regret_loser_2[slice18],\n",
        "       train_regret_loser_3[slice18],\n",
        "       train_regret_loser_4[slice18],\n",
        "       train_regret_loser_5[slice18],\n",
        "       train_regret_loser_6[slice18],\n",
        "       train_regret_loser_7[slice18],\n",
        "       train_regret_loser_8[slice18],\n",
        "       train_regret_loser_9[slice18],\n",
        "       train_regret_loser_10[slice18],\n",
        "       train_regret_loser_11[slice18],\n",
        "       train_regret_loser_12[slice18],\n",
        "       train_regret_loser_13[slice18],\n",
        "       train_regret_loser_14[slice18],\n",
        "       train_regret_loser_15[slice18],\n",
        "       train_regret_loser_16[slice18],\n",
        "       train_regret_loser_17[slice18],\n",
        "       train_regret_loser_18[slice18],\n",
        "       train_regret_loser_19[slice18],\n",
        "       train_regret_loser_20[slice18]]\n",
        "\n",
        "winner18 = [train_regret_winner_1[slice18],\n",
        "       train_regret_winner_2[slice18],\n",
        "       train_regret_winner_3[slice18],\n",
        "       train_regret_winner_4[slice18],\n",
        "       train_regret_winner_5[slice18],\n",
        "       train_regret_winner_6[slice18],\n",
        "       train_regret_winner_7[slice18],\n",
        "       train_regret_winner_8[slice18],\n",
        "       train_regret_winner_9[slice18],\n",
        "       train_regret_winner_10[slice18],\n",
        "       train_regret_winner_11[slice18],\n",
        "       train_regret_winner_12[slice18],\n",
        "       train_regret_winner_13[slice18],\n",
        "       train_regret_winner_14[slice18],\n",
        "       train_regret_winner_15[slice18],\n",
        "       train_regret_winner_16[slice18],\n",
        "       train_regret_winner_17[slice18],\n",
        "       train_regret_winner_18[slice18],\n",
        "       train_regret_winner_19[slice18],\n",
        "       train_regret_winner_20[slice18]]\n",
        "\n",
        "loser18_results = pd.DataFrame(loser18).sort_values(by=[0], ascending=False)\n",
        "winner18_results = pd.DataFrame(winner18).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser18 = np.asarray(loser18_results[4:5][0])[0]\n",
        "median_loser18 = np.asarray(loser18_results[9:10][0])[0]\n",
        "upper_loser18 = np.asarray(loser18_results[14:15][0])[0]\n",
        "\n",
        "lower_winner18 = np.asarray(winner18_results[4:5][0])[0]\n",
        "median_winner18 = np.asarray(winner18_results[9:10][0])[0]\n",
        "upper_winner18 = np.asarray(winner18_results[14:15][0])[0]"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvqFjlBDxBK4"
      },
      "source": [
        "# Iteration28 :\n",
        "\n",
        "slice28 = 27\n",
        "\n",
        "loser28 = [train_regret_loser_1[slice28],\n",
        "       train_regret_loser_2[slice28],\n",
        "       train_regret_loser_3[slice28],\n",
        "       train_regret_loser_4[slice28],\n",
        "       train_regret_loser_5[slice28],\n",
        "       train_regret_loser_6[slice28],\n",
        "       train_regret_loser_7[slice28],\n",
        "       train_regret_loser_8[slice28],\n",
        "       train_regret_loser_9[slice28],\n",
        "       train_regret_loser_10[slice28],\n",
        "       train_regret_loser_11[slice28],\n",
        "       train_regret_loser_12[slice28],\n",
        "       train_regret_loser_13[slice28],\n",
        "       train_regret_loser_14[slice28],\n",
        "       train_regret_loser_15[slice28],\n",
        "       train_regret_loser_16[slice28],\n",
        "       train_regret_loser_17[slice28],\n",
        "       train_regret_loser_18[slice28],\n",
        "       train_regret_loser_19[slice28],\n",
        "       train_regret_loser_20[slice28]]\n",
        "\n",
        "winner28 = [train_regret_winner_1[slice28],\n",
        "       train_regret_winner_2[slice28],\n",
        "       train_regret_winner_3[slice28],\n",
        "       train_regret_winner_4[slice28],\n",
        "       train_regret_winner_5[slice28],\n",
        "       train_regret_winner_6[slice28],\n",
        "       train_regret_winner_7[slice28],\n",
        "       train_regret_winner_8[slice28],\n",
        "       train_regret_winner_9[slice28],\n",
        "       train_regret_winner_10[slice28],\n",
        "       train_regret_winner_11[slice28],\n",
        "       train_regret_winner_12[slice28],\n",
        "       train_regret_winner_13[slice28],\n",
        "       train_regret_winner_14[slice28],\n",
        "       train_regret_winner_15[slice28],\n",
        "       train_regret_winner_16[slice28],\n",
        "       train_regret_winner_17[slice28],\n",
        "       train_regret_winner_18[slice28],\n",
        "       train_regret_winner_19[slice28],\n",
        "       train_regret_winner_20[slice28]]\n",
        "\n",
        "loser28_results = pd.DataFrame(loser28).sort_values(by=[0], ascending=False)\n",
        "winner28_results = pd.DataFrame(winner28).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser28 = np.asarray(loser28_results[4:5][0])[0]\n",
        "median_loser28 = np.asarray(loser28_results[9:10][0])[0]\n",
        "upper_loser28 = np.asarray(loser28_results[14:15][0])[0]\n",
        "\n",
        "lower_winner28 = np.asarray(winner28_results[4:5][0])[0]\n",
        "median_winner28 = np.asarray(winner28_results[9:10][0])[0]\n",
        "upper_winner28 = np.asarray(winner28_results[14:15][0])[0]"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It5daJCEted3"
      },
      "source": [
        "# Iteration38 :\n",
        "\n",
        "slice38 = 37\n",
        "\n",
        "loser38 = [train_regret_loser_1[slice38],\n",
        "       train_regret_loser_2[slice38],\n",
        "       train_regret_loser_3[slice38],\n",
        "       train_regret_loser_4[slice38],\n",
        "       train_regret_loser_5[slice38],\n",
        "       train_regret_loser_6[slice38],\n",
        "       train_regret_loser_7[slice38],\n",
        "       train_regret_loser_8[slice38],\n",
        "       train_regret_loser_9[slice38],\n",
        "       train_regret_loser_10[slice38],\n",
        "       train_regret_loser_11[slice38],\n",
        "       train_regret_loser_12[slice38],\n",
        "       train_regret_loser_13[slice38],\n",
        "       train_regret_loser_14[slice38],\n",
        "       train_regret_loser_15[slice38],\n",
        "       train_regret_loser_16[slice38],\n",
        "       train_regret_loser_17[slice38],\n",
        "       train_regret_loser_18[slice38],\n",
        "       train_regret_loser_19[slice38],\n",
        "       train_regret_loser_20[slice38]]\n",
        "\n",
        "winner38 = [train_regret_winner_1[slice38],\n",
        "       train_regret_winner_2[slice38],\n",
        "       train_regret_winner_3[slice38],\n",
        "       train_regret_winner_4[slice38],\n",
        "       train_regret_winner_5[slice38],\n",
        "       train_regret_winner_6[slice38],\n",
        "       train_regret_winner_7[slice38],\n",
        "       train_regret_winner_8[slice38],\n",
        "       train_regret_winner_9[slice38],\n",
        "       train_regret_winner_10[slice38],\n",
        "       train_regret_winner_11[slice38],\n",
        "       train_regret_winner_12[slice38],\n",
        "       train_regret_winner_13[slice38],\n",
        "       train_regret_winner_14[slice38],\n",
        "       train_regret_winner_15[slice38],\n",
        "       train_regret_winner_16[slice38],\n",
        "       train_regret_winner_17[slice38],\n",
        "       train_regret_winner_18[slice38],\n",
        "       train_regret_winner_19[slice38],\n",
        "       train_regret_winner_20[slice38]]\n",
        "\n",
        "loser38_results = pd.DataFrame(loser38).sort_values(by=[0], ascending=False)\n",
        "winner38_results = pd.DataFrame(winner38).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser38 = np.asarray(loser38_results[4:5][0])[0]\n",
        "median_loser38 = np.asarray(loser38_results[9:10][0])[0]\n",
        "upper_loser38 = np.asarray(loser38_results[14:15][0])[0]\n",
        "\n",
        "lower_winner38 = np.asarray(winner38_results[4:5][0])[0]\n",
        "median_winner38 = np.asarray(winner38_results[9:10][0])[0]\n",
        "upper_winner38 = np.asarray(winner38_results[14:15][0])[0]"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GekXOf_gtegw"
      },
      "source": [
        "# Iteration48 :\n",
        "\n",
        "slice48 = 47\n",
        "\n",
        "loser48 = [train_regret_loser_1[slice48],\n",
        "       train_regret_loser_2[slice48],\n",
        "       train_regret_loser_3[slice48],\n",
        "       train_regret_loser_4[slice48],\n",
        "       train_regret_loser_5[slice48],\n",
        "       train_regret_loser_6[slice48],\n",
        "       train_regret_loser_7[slice48],\n",
        "       train_regret_loser_8[slice48],\n",
        "       train_regret_loser_9[slice48],\n",
        "       train_regret_loser_10[slice48],\n",
        "       train_regret_loser_11[slice48],\n",
        "       train_regret_loser_12[slice48],\n",
        "       train_regret_loser_13[slice48],\n",
        "       train_regret_loser_14[slice48],\n",
        "       train_regret_loser_15[slice48],\n",
        "       train_regret_loser_16[slice48],\n",
        "       train_regret_loser_17[slice48],\n",
        "       train_regret_loser_18[slice48],\n",
        "       train_regret_loser_19[slice48],\n",
        "       train_regret_loser_20[slice48]]\n",
        "\n",
        "winner48 = [train_regret_winner_1[slice48],\n",
        "       train_regret_winner_2[slice48],\n",
        "       train_regret_winner_3[slice48],\n",
        "       train_regret_winner_4[slice48],\n",
        "       train_regret_winner_5[slice48],\n",
        "       train_regret_winner_6[slice48],\n",
        "       train_regret_winner_7[slice48],\n",
        "       train_regret_winner_8[slice48],\n",
        "       train_regret_winner_9[slice48],\n",
        "       train_regret_winner_10[slice48],\n",
        "       train_regret_winner_11[slice48],\n",
        "       train_regret_winner_12[slice48],\n",
        "       train_regret_winner_13[slice48],\n",
        "       train_regret_winner_14[slice48],\n",
        "       train_regret_winner_15[slice48],\n",
        "       train_regret_winner_16[slice48],\n",
        "       train_regret_winner_17[slice48],\n",
        "       train_regret_winner_18[slice48],\n",
        "       train_regret_winner_19[slice48],\n",
        "       train_regret_winner_20[slice48]]\n",
        "\n",
        "loser48_results = pd.DataFrame(loser48).sort_values(by=[0], ascending=False)\n",
        "winner48_results = pd.DataFrame(winner48).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser48 = np.asarray(loser48_results[4:5][0])[0]\n",
        "median_loser48 = np.asarray(loser48_results[9:10][0])[0]\n",
        "upper_loser48 = np.asarray(loser48_results[14:15][0])[0]\n",
        "\n",
        "lower_winner48 = np.asarray(winner48_results[4:5][0])[0]\n",
        "median_winner48 = np.asarray(winner48_results[9:10][0])[0]\n",
        "upper_winner48 = np.asarray(winner48_results[14:15][0])[0]"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNpV6knOtejv"
      },
      "source": [
        "# Iteration58 :\n",
        "\n",
        "slice58 = 57\n",
        "\n",
        "loser58 = [train_regret_loser_1[slice58],\n",
        "       train_regret_loser_2[slice58],\n",
        "       train_regret_loser_3[slice58],\n",
        "       train_regret_loser_4[slice58],\n",
        "       train_regret_loser_5[slice58],\n",
        "       train_regret_loser_6[slice58],\n",
        "       train_regret_loser_7[slice58],\n",
        "       train_regret_loser_8[slice58],\n",
        "       train_regret_loser_9[slice58],\n",
        "       train_regret_loser_10[slice58],\n",
        "       train_regret_loser_11[slice58],\n",
        "       train_regret_loser_12[slice58],\n",
        "       train_regret_loser_13[slice58],\n",
        "       train_regret_loser_14[slice58],\n",
        "       train_regret_loser_15[slice58],\n",
        "       train_regret_loser_16[slice58],\n",
        "       train_regret_loser_17[slice58],\n",
        "       train_regret_loser_18[slice58],\n",
        "       train_regret_loser_19[slice58],\n",
        "       train_regret_loser_20[slice58]]\n",
        "\n",
        "winner58 = [train_regret_winner_1[slice58],\n",
        "       train_regret_winner_2[slice58],\n",
        "       train_regret_winner_3[slice58],\n",
        "       train_regret_winner_4[slice58],\n",
        "       train_regret_winner_5[slice58],\n",
        "       train_regret_winner_6[slice58],\n",
        "       train_regret_winner_7[slice58],\n",
        "       train_regret_winner_8[slice58],\n",
        "       train_regret_winner_9[slice58],\n",
        "       train_regret_winner_10[slice58],\n",
        "       train_regret_winner_11[slice58],\n",
        "       train_regret_winner_12[slice58],\n",
        "       train_regret_winner_13[slice58],\n",
        "       train_regret_winner_14[slice58],\n",
        "       train_regret_winner_15[slice58],\n",
        "       train_regret_winner_16[slice58],\n",
        "       train_regret_winner_17[slice58],\n",
        "       train_regret_winner_18[slice58],\n",
        "       train_regret_winner_19[slice58],\n",
        "       train_regret_winner_20[slice58]]\n",
        "\n",
        "loser58_results = pd.DataFrame(loser58).sort_values(by=[0], ascending=False)\n",
        "winner58_results = pd.DataFrame(winner58).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser58 = np.asarray(loser58_results[4:5][0])[0]\n",
        "median_loser58 = np.asarray(loser58_results[9:10][0])[0]\n",
        "upper_loser58 = np.asarray(loser58_results[14:15][0])[0]\n",
        "\n",
        "lower_winner58 = np.asarray(winner58_results[4:5][0])[0]\n",
        "median_winner58 = np.asarray(winner58_results[9:10][0])[0]\n",
        "upper_winner58 = np.asarray(winner58_results[14:15][0])[0]"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VFsqaBqtemn"
      },
      "source": [
        "# Iteration68 :\n",
        "\n",
        "slice68 = 67\n",
        "\n",
        "loser68 = [train_regret_loser_1[slice68],\n",
        "       train_regret_loser_2[slice68],\n",
        "       train_regret_loser_3[slice68],\n",
        "       train_regret_loser_4[slice68],\n",
        "       train_regret_loser_5[slice68],\n",
        "       train_regret_loser_6[slice68],\n",
        "       train_regret_loser_7[slice68],\n",
        "       train_regret_loser_8[slice68],\n",
        "       train_regret_loser_9[slice68],\n",
        "       train_regret_loser_10[slice68],\n",
        "       train_regret_loser_11[slice68],\n",
        "       train_regret_loser_12[slice68],\n",
        "       train_regret_loser_13[slice68],\n",
        "       train_regret_loser_14[slice68],\n",
        "       train_regret_loser_15[slice68],\n",
        "       train_regret_loser_16[slice68],\n",
        "       train_regret_loser_17[slice68],\n",
        "       train_regret_loser_18[slice68],\n",
        "       train_regret_loser_19[slice68],\n",
        "       train_regret_loser_20[slice68]]\n",
        "\n",
        "winner68 = [train_regret_winner_1[slice68],\n",
        "       train_regret_winner_2[slice68],\n",
        "       train_regret_winner_3[slice68],\n",
        "       train_regret_winner_4[slice68],\n",
        "       train_regret_winner_5[slice68],\n",
        "       train_regret_winner_6[slice68],\n",
        "       train_regret_winner_7[slice68],\n",
        "       train_regret_winner_8[slice68],\n",
        "       train_regret_winner_9[slice68],\n",
        "       train_regret_winner_10[slice68],\n",
        "       train_regret_winner_11[slice68],\n",
        "       train_regret_winner_12[slice68],\n",
        "       train_regret_winner_13[slice68],\n",
        "       train_regret_winner_14[slice68],\n",
        "       train_regret_winner_15[slice68],\n",
        "       train_regret_winner_16[slice68],\n",
        "       train_regret_winner_17[slice68],\n",
        "       train_regret_winner_18[slice68],\n",
        "       train_regret_winner_19[slice68],\n",
        "       train_regret_winner_20[slice68]]\n",
        "\n",
        "loser68_results = pd.DataFrame(loser68).sort_values(by=[0], ascending=False)\n",
        "winner68_results = pd.DataFrame(winner68).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser68 = np.asarray(loser68_results[4:5][0])[0]\n",
        "median_loser68 = np.asarray(loser68_results[9:10][0])[0]\n",
        "upper_loser68 = np.asarray(loser68_results[14:15][0])[0]\n",
        "\n",
        "lower_winner68 = np.asarray(winner68_results[4:5][0])[0]\n",
        "median_winner68 = np.asarray(winner68_results[9:10][0])[0]\n",
        "upper_winner68 = np.asarray(winner68_results[14:15][0])[0]"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XlFH0Wxtepo"
      },
      "source": [
        "# Iteration78 :\n",
        "\n",
        "slice78 = 77\n",
        "\n",
        "loser78 = [train_regret_loser_1[slice78],\n",
        "       train_regret_loser_2[slice78],\n",
        "       train_regret_loser_3[slice78],\n",
        "       train_regret_loser_4[slice78],\n",
        "       train_regret_loser_5[slice78],\n",
        "       train_regret_loser_6[slice78],\n",
        "       train_regret_loser_7[slice78],\n",
        "       train_regret_loser_8[slice78],\n",
        "       train_regret_loser_9[slice78],\n",
        "       train_regret_loser_10[slice78],\n",
        "       train_regret_loser_11[slice78],\n",
        "       train_regret_loser_12[slice78],\n",
        "       train_regret_loser_13[slice78],\n",
        "       train_regret_loser_14[slice78],\n",
        "       train_regret_loser_15[slice78],\n",
        "       train_regret_loser_16[slice78],\n",
        "       train_regret_loser_17[slice78],\n",
        "       train_regret_loser_18[slice78],\n",
        "       train_regret_loser_19[slice78],\n",
        "       train_regret_loser_20[slice78]]\n",
        "\n",
        "winner78 = [train_regret_winner_1[slice78],\n",
        "       train_regret_winner_2[slice78],\n",
        "       train_regret_winner_3[slice78],\n",
        "       train_regret_winner_4[slice78],\n",
        "       train_regret_winner_5[slice78],\n",
        "       train_regret_winner_6[slice78],\n",
        "       train_regret_winner_7[slice78],\n",
        "       train_regret_winner_8[slice78],\n",
        "       train_regret_winner_9[slice78],\n",
        "       train_regret_winner_10[slice78],\n",
        "       train_regret_winner_11[slice78],\n",
        "       train_regret_winner_12[slice78],\n",
        "       train_regret_winner_13[slice78],\n",
        "       train_regret_winner_14[slice78],\n",
        "       train_regret_winner_15[slice78],\n",
        "       train_regret_winner_16[slice78],\n",
        "       train_regret_winner_17[slice78],\n",
        "       train_regret_winner_18[slice78],\n",
        "       train_regret_winner_19[slice78],\n",
        "       train_regret_winner_20[slice78]]\n",
        "\n",
        "loser78_results = pd.DataFrame(loser78).sort_values(by=[0], ascending=False)\n",
        "winner78_results = pd.DataFrame(winner78).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser78 = np.asarray(loser78_results[4:5][0])[0]\n",
        "median_loser78 = np.asarray(loser78_results[9:10][0])[0]\n",
        "upper_loser78 = np.asarray(loser78_results[14:15][0])[0]\n",
        "\n",
        "lower_winner78 = np.asarray(winner78_results[4:5][0])[0]\n",
        "median_winner78 = np.asarray(winner78_results[9:10][0])[0]\n",
        "upper_winner78 = np.asarray(winner78_results[14:15][0])[0]"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsL0PJVetesC"
      },
      "source": [
        "# Iteration88 :\n",
        "\n",
        "slice88 = 87\n",
        "\n",
        "loser88 = [train_regret_loser_1[slice88],\n",
        "       train_regret_loser_2[slice88],\n",
        "       train_regret_loser_3[slice88],\n",
        "       train_regret_loser_4[slice88],\n",
        "       train_regret_loser_5[slice88],\n",
        "       train_regret_loser_6[slice88],\n",
        "       train_regret_loser_7[slice88],\n",
        "       train_regret_loser_8[slice88],\n",
        "       train_regret_loser_9[slice88],\n",
        "       train_regret_loser_10[slice88],\n",
        "       train_regret_loser_11[slice88],\n",
        "       train_regret_loser_12[slice88],\n",
        "       train_regret_loser_13[slice88],\n",
        "       train_regret_loser_14[slice88],\n",
        "       train_regret_loser_15[slice88],\n",
        "       train_regret_loser_16[slice88],\n",
        "       train_regret_loser_17[slice88],\n",
        "       train_regret_loser_18[slice88],\n",
        "       train_regret_loser_19[slice88],\n",
        "       train_regret_loser_20[slice88]]\n",
        "\n",
        "winner88 = [train_regret_winner_1[slice88],\n",
        "       train_regret_winner_2[slice88],\n",
        "       train_regret_winner_3[slice88],\n",
        "       train_regret_winner_4[slice88],\n",
        "       train_regret_winner_5[slice88],\n",
        "       train_regret_winner_6[slice88],\n",
        "       train_regret_winner_7[slice88],\n",
        "       train_regret_winner_8[slice88],\n",
        "       train_regret_winner_9[slice88],\n",
        "       train_regret_winner_10[slice88],\n",
        "       train_regret_winner_11[slice88],\n",
        "       train_regret_winner_12[slice88],\n",
        "       train_regret_winner_13[slice88],\n",
        "       train_regret_winner_14[slice88],\n",
        "       train_regret_winner_15[slice88],\n",
        "       train_regret_winner_16[slice88],\n",
        "       train_regret_winner_17[slice88],\n",
        "       train_regret_winner_18[slice88],\n",
        "       train_regret_winner_19[slice88],\n",
        "       train_regret_winner_20[slice88]]\n",
        "\n",
        "loser88_results = pd.DataFrame(loser88).sort_values(by=[0], ascending=False)\n",
        "winner88_results = pd.DataFrame(winner88).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser88 = np.asarray(loser88_results[4:5][0])[0]\n",
        "median_loser88 = np.asarray(loser88_results[9:10][0])[0]\n",
        "upper_loser88 = np.asarray(loser88_results[14:15][0])[0]\n",
        "\n",
        "lower_winner88 = np.asarray(winner88_results[4:5][0])[0]\n",
        "median_winner88 = np.asarray(winner88_results[9:10][0])[0]\n",
        "upper_winner88 = np.asarray(winner88_results[14:15][0])[0]"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYWEWGku1o_9"
      },
      "source": [
        "# Iteration98 :\n",
        "\n",
        "slice98 = 97\n",
        "\n",
        "loser98 = [train_regret_loser_1[slice98],\n",
        "       train_regret_loser_2[slice98],\n",
        "       train_regret_loser_3[slice98],\n",
        "       train_regret_loser_4[slice98],\n",
        "       train_regret_loser_5[slice98],\n",
        "       train_regret_loser_6[slice98],\n",
        "       train_regret_loser_7[slice98],\n",
        "       train_regret_loser_8[slice98],\n",
        "       train_regret_loser_9[slice98],\n",
        "       train_regret_loser_10[slice98],\n",
        "       train_regret_loser_11[slice98],\n",
        "       train_regret_loser_12[slice98],\n",
        "       train_regret_loser_13[slice98],\n",
        "       train_regret_loser_14[slice98],\n",
        "       train_regret_loser_15[slice98],\n",
        "       train_regret_loser_16[slice98],\n",
        "       train_regret_loser_17[slice98],\n",
        "       train_regret_loser_18[slice98],\n",
        "       train_regret_loser_19[slice98],\n",
        "       train_regret_loser_20[slice98]]\n",
        "\n",
        "winner98 = [train_regret_winner_1[slice98],\n",
        "       train_regret_winner_2[slice98],\n",
        "       train_regret_winner_3[slice98],\n",
        "       train_regret_winner_4[slice98],\n",
        "       train_regret_winner_5[slice98],\n",
        "       train_regret_winner_6[slice98],\n",
        "       train_regret_winner_7[slice98],\n",
        "       train_regret_winner_8[slice98],\n",
        "       train_regret_winner_9[slice98],\n",
        "       train_regret_winner_10[slice98],\n",
        "       train_regret_winner_11[slice98],\n",
        "       train_regret_winner_12[slice98],\n",
        "       train_regret_winner_13[slice98],\n",
        "       train_regret_winner_14[slice98],\n",
        "       train_regret_winner_15[slice98],\n",
        "       train_regret_winner_16[slice98],\n",
        "       train_regret_winner_17[slice98],\n",
        "       train_regret_winner_18[slice98],\n",
        "       train_regret_winner_19[slice98],\n",
        "       train_regret_winner_20[slice98]]\n",
        "\n",
        "loser98_results = pd.DataFrame(loser98).sort_values(by=[0], ascending=False)\n",
        "winner98_results = pd.DataFrame(winner98).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser98 = np.asarray(loser98_results[4:5][0])[0]\n",
        "median_loser98 = np.asarray(loser98_results[9:10][0])[0]\n",
        "upper_loser98 = np.asarray(loser98_results[14:15][0])[0]\n",
        "\n",
        "lower_winner98 = np.asarray(winner98_results[4:5][0])[0]\n",
        "median_winner98 = np.asarray(winner98_results[9:10][0])[0]\n",
        "upper_winner98 = np.asarray(winner98_results[14:15][0])[0]"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guLGgcX91pDK"
      },
      "source": [
        "# Iteration9 :\n",
        "\n",
        "slice9 = 8\n",
        "\n",
        "loser9 = [train_regret_loser_1[slice9],\n",
        "       train_regret_loser_2[slice9],\n",
        "       train_regret_loser_3[slice9],\n",
        "       train_regret_loser_4[slice9],\n",
        "       train_regret_loser_5[slice9],\n",
        "       train_regret_loser_6[slice9],\n",
        "       train_regret_loser_7[slice9],\n",
        "       train_regret_loser_8[slice9],\n",
        "       train_regret_loser_9[slice9],\n",
        "       train_regret_loser_10[slice9],\n",
        "       train_regret_loser_11[slice9],\n",
        "       train_regret_loser_12[slice9],\n",
        "       train_regret_loser_13[slice9],\n",
        "       train_regret_loser_14[slice9],\n",
        "       train_regret_loser_15[slice9],\n",
        "       train_regret_loser_16[slice9],\n",
        "       train_regret_loser_17[slice9],\n",
        "       train_regret_loser_18[slice9],\n",
        "       train_regret_loser_19[slice9],\n",
        "       train_regret_loser_20[slice9]]\n",
        "\n",
        "winner9 = [train_regret_winner_1[slice9],\n",
        "       train_regret_winner_2[slice9],\n",
        "       train_regret_winner_3[slice9],\n",
        "       train_regret_winner_4[slice9],\n",
        "       train_regret_winner_5[slice9],\n",
        "       train_regret_winner_6[slice9],\n",
        "       train_regret_winner_7[slice9],\n",
        "       train_regret_winner_8[slice9],\n",
        "       train_regret_winner_9[slice9],\n",
        "       train_regret_winner_10[slice9],\n",
        "       train_regret_winner_11[slice9],\n",
        "       train_regret_winner_12[slice9],\n",
        "       train_regret_winner_13[slice9],\n",
        "       train_regret_winner_14[slice9],\n",
        "       train_regret_winner_15[slice9],\n",
        "       train_regret_winner_16[slice9],\n",
        "       train_regret_winner_17[slice9],\n",
        "       train_regret_winner_18[slice9],\n",
        "       train_regret_winner_19[slice9],\n",
        "       train_regret_winner_20[slice9]]\n",
        "\n",
        "loser9_results = pd.DataFrame(loser9).sort_values(by=[0], ascending=False)\n",
        "winner9_results = pd.DataFrame(winner9).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser9 = np.asarray(loser9_results[4:5][0])[0]\n",
        "median_loser9 = np.asarray(loser9_results[9:10][0])[0]\n",
        "upper_loser9 = np.asarray(loser9_results[14:15][0])[0]\n",
        "\n",
        "lower_winner9 = np.asarray(winner9_results[4:5][0])[0]\n",
        "median_winner9 = np.asarray(winner9_results[9:10][0])[0]\n",
        "upper_winner9 = np.asarray(winner9_results[14:15][0])[0]"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3_9-eoT1pGd"
      },
      "source": [
        "# Iteration19 :\n",
        "\n",
        "slice19 = 18\n",
        "\n",
        "loser19 = [train_regret_loser_1[slice19],\n",
        "       train_regret_loser_2[slice19],\n",
        "       train_regret_loser_3[slice19],\n",
        "       train_regret_loser_4[slice19],\n",
        "       train_regret_loser_5[slice19],\n",
        "       train_regret_loser_6[slice19],\n",
        "       train_regret_loser_7[slice19],\n",
        "       train_regret_loser_8[slice19],\n",
        "       train_regret_loser_9[slice19],\n",
        "       train_regret_loser_10[slice19],\n",
        "       train_regret_loser_11[slice19],\n",
        "       train_regret_loser_12[slice19],\n",
        "       train_regret_loser_13[slice19],\n",
        "       train_regret_loser_14[slice19],\n",
        "       train_regret_loser_15[slice19],\n",
        "       train_regret_loser_16[slice19],\n",
        "       train_regret_loser_17[slice19],\n",
        "       train_regret_loser_18[slice19],\n",
        "       train_regret_loser_19[slice19],\n",
        "       train_regret_loser_20[slice19]]\n",
        "\n",
        "winner19 = [train_regret_winner_1[slice19],\n",
        "       train_regret_winner_2[slice19],\n",
        "       train_regret_winner_3[slice19],\n",
        "       train_regret_winner_4[slice19],\n",
        "       train_regret_winner_5[slice19],\n",
        "       train_regret_winner_6[slice19],\n",
        "       train_regret_winner_7[slice19],\n",
        "       train_regret_winner_8[slice19],\n",
        "       train_regret_winner_9[slice19],\n",
        "       train_regret_winner_10[slice19],\n",
        "       train_regret_winner_11[slice19],\n",
        "       train_regret_winner_12[slice19],\n",
        "       train_regret_winner_13[slice19],\n",
        "       train_regret_winner_14[slice19],\n",
        "       train_regret_winner_15[slice19],\n",
        "       train_regret_winner_16[slice19],\n",
        "       train_regret_winner_17[slice19],\n",
        "       train_regret_winner_18[slice19],\n",
        "       train_regret_winner_19[slice19],\n",
        "       train_regret_winner_20[slice19]]\n",
        "\n",
        "loser19_results = pd.DataFrame(loser19).sort_values(by=[0], ascending=False)\n",
        "winner19_results = pd.DataFrame(winner19).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser19 = np.asarray(loser19_results[4:5][0])[0]\n",
        "median_loser19 = np.asarray(loser19_results[9:10][0])[0]\n",
        "upper_loser19 = np.asarray(loser19_results[14:15][0])[0]\n",
        "\n",
        "lower_winner19 = np.asarray(winner19_results[4:5][0])[0]\n",
        "median_winner19 = np.asarray(winner19_results[9:10][0])[0]\n",
        "upper_winner19 = np.asarray(winner19_results[14:15][0])[0]"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ae5x13M1pRp"
      },
      "source": [
        "# Iteration29 :\n",
        "\n",
        "slice29 = 28\n",
        "\n",
        "loser29 = [train_regret_loser_1[slice29],\n",
        "       train_regret_loser_2[slice29],\n",
        "       train_regret_loser_3[slice29],\n",
        "       train_regret_loser_4[slice29],\n",
        "       train_regret_loser_5[slice29],\n",
        "       train_regret_loser_6[slice29],\n",
        "       train_regret_loser_7[slice29],\n",
        "       train_regret_loser_8[slice29],\n",
        "       train_regret_loser_9[slice29],\n",
        "       train_regret_loser_10[slice29],\n",
        "       train_regret_loser_11[slice29],\n",
        "       train_regret_loser_12[slice29],\n",
        "       train_regret_loser_13[slice29],\n",
        "       train_regret_loser_14[slice29],\n",
        "       train_regret_loser_15[slice29],\n",
        "       train_regret_loser_16[slice29],\n",
        "       train_regret_loser_17[slice29],\n",
        "       train_regret_loser_18[slice29],\n",
        "       train_regret_loser_19[slice29],\n",
        "       train_regret_loser_20[slice29]]\n",
        "\n",
        "winner29 = [train_regret_winner_1[slice29],\n",
        "       train_regret_winner_2[slice29],\n",
        "       train_regret_winner_3[slice29],\n",
        "       train_regret_winner_4[slice29],\n",
        "       train_regret_winner_5[slice29],\n",
        "       train_regret_winner_6[slice29],\n",
        "       train_regret_winner_7[slice29],\n",
        "       train_regret_winner_8[slice29],\n",
        "       train_regret_winner_9[slice29],\n",
        "       train_regret_winner_10[slice29],\n",
        "       train_regret_winner_11[slice29],\n",
        "       train_regret_winner_12[slice29],\n",
        "       train_regret_winner_13[slice29],\n",
        "       train_regret_winner_14[slice29],\n",
        "       train_regret_winner_15[slice29],\n",
        "       train_regret_winner_16[slice29],\n",
        "       train_regret_winner_17[slice29],\n",
        "       train_regret_winner_18[slice29],\n",
        "       train_regret_winner_19[slice29],\n",
        "       train_regret_winner_20[slice29]]\n",
        "\n",
        "loser29_results = pd.DataFrame(loser29).sort_values(by=[0], ascending=False)\n",
        "winner29_results = pd.DataFrame(winner29).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser29 = np.asarray(loser29_results[4:5][0])[0]\n",
        "median_loser29 = np.asarray(loser29_results[9:10][0])[0]\n",
        "upper_loser29 = np.asarray(loser29_results[14:15][0])[0]\n",
        "\n",
        "lower_winner29 = np.asarray(winner29_results[4:5][0])[0]\n",
        "median_winner29 = np.asarray(winner29_results[9:10][0])[0]\n",
        "upper_winner29 = np.asarray(winner29_results[14:15][0])[0]"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR9aPvBy1pUc"
      },
      "source": [
        "# Iteration39 :\n",
        "\n",
        "slice39 = 38\n",
        "\n",
        "loser39 = [train_regret_loser_1[slice39],\n",
        "       train_regret_loser_2[slice39],\n",
        "       train_regret_loser_3[slice39],\n",
        "       train_regret_loser_4[slice39],\n",
        "       train_regret_loser_5[slice39],\n",
        "       train_regret_loser_6[slice39],\n",
        "       train_regret_loser_7[slice39],\n",
        "       train_regret_loser_8[slice39],\n",
        "       train_regret_loser_9[slice39],\n",
        "       train_regret_loser_10[slice39],\n",
        "       train_regret_loser_11[slice39],\n",
        "       train_regret_loser_12[slice39],\n",
        "       train_regret_loser_13[slice39],\n",
        "       train_regret_loser_14[slice39],\n",
        "       train_regret_loser_15[slice39],\n",
        "       train_regret_loser_16[slice39],\n",
        "       train_regret_loser_17[slice39],\n",
        "       train_regret_loser_18[slice39],\n",
        "       train_regret_loser_19[slice39],\n",
        "       train_regret_loser_20[slice39]]\n",
        "\n",
        "winner39 = [train_regret_winner_1[slice39],\n",
        "       train_regret_winner_2[slice39],\n",
        "       train_regret_winner_3[slice39],\n",
        "       train_regret_winner_4[slice39],\n",
        "       train_regret_winner_5[slice39],\n",
        "       train_regret_winner_6[slice39],\n",
        "       train_regret_winner_7[slice39],\n",
        "       train_regret_winner_8[slice39],\n",
        "       train_regret_winner_9[slice39],\n",
        "       train_regret_winner_10[slice39],\n",
        "       train_regret_winner_11[slice39],\n",
        "       train_regret_winner_12[slice39],\n",
        "       train_regret_winner_13[slice39],\n",
        "       train_regret_winner_14[slice39],\n",
        "       train_regret_winner_15[slice39],\n",
        "       train_regret_winner_16[slice39],\n",
        "       train_regret_winner_17[slice39],\n",
        "       train_regret_winner_18[slice39],\n",
        "       train_regret_winner_19[slice39],\n",
        "       train_regret_winner_20[slice39]]\n",
        "\n",
        "loser39_results = pd.DataFrame(loser39).sort_values(by=[0], ascending=False)\n",
        "winner39_results = pd.DataFrame(winner39).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser39 = np.asarray(loser39_results[4:5][0])[0]\n",
        "median_loser39 = np.asarray(loser39_results[9:10][0])[0]\n",
        "upper_loser39 = np.asarray(loser39_results[14:15][0])[0]\n",
        "\n",
        "lower_winner39 = np.asarray(winner39_results[4:5][0])[0]\n",
        "median_winner39 = np.asarray(winner39_results[9:10][0])[0]\n",
        "upper_winner39 = np.asarray(winner39_results[14:15][0])[0]"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vb7vh2K1pXp"
      },
      "source": [
        "# Iteration49 :\n",
        "\n",
        "slice49 = 48\n",
        "\n",
        "loser49 = [train_regret_loser_1[slice49],\n",
        "       train_regret_loser_2[slice49],\n",
        "       train_regret_loser_3[slice49],\n",
        "       train_regret_loser_4[slice49],\n",
        "       train_regret_loser_5[slice49],\n",
        "       train_regret_loser_6[slice49],\n",
        "       train_regret_loser_7[slice49],\n",
        "       train_regret_loser_8[slice49],\n",
        "       train_regret_loser_9[slice49],\n",
        "       train_regret_loser_10[slice49],\n",
        "       train_regret_loser_11[slice49],\n",
        "       train_regret_loser_12[slice49],\n",
        "       train_regret_loser_13[slice49],\n",
        "       train_regret_loser_14[slice49],\n",
        "       train_regret_loser_15[slice49],\n",
        "       train_regret_loser_16[slice49],\n",
        "       train_regret_loser_17[slice49],\n",
        "       train_regret_loser_18[slice49],\n",
        "       train_regret_loser_19[slice49],\n",
        "       train_regret_loser_20[slice49]]\n",
        "\n",
        "winner49 = [train_regret_winner_1[slice49],\n",
        "       train_regret_winner_2[slice49],\n",
        "       train_regret_winner_3[slice49],\n",
        "       train_regret_winner_4[slice49],\n",
        "       train_regret_winner_5[slice49],\n",
        "       train_regret_winner_6[slice49],\n",
        "       train_regret_winner_7[slice49],\n",
        "       train_regret_winner_8[slice49],\n",
        "       train_regret_winner_9[slice49],\n",
        "       train_regret_winner_10[slice49],\n",
        "       train_regret_winner_11[slice49],\n",
        "       train_regret_winner_12[slice49],\n",
        "       train_regret_winner_13[slice49],\n",
        "       train_regret_winner_14[slice49],\n",
        "       train_regret_winner_15[slice49],\n",
        "       train_regret_winner_16[slice49],\n",
        "       train_regret_winner_17[slice49],\n",
        "       train_regret_winner_18[slice49],\n",
        "       train_regret_winner_19[slice49],\n",
        "       train_regret_winner_20[slice49]]\n",
        "\n",
        "loser49_results = pd.DataFrame(loser49).sort_values(by=[0], ascending=False)\n",
        "winner49_results = pd.DataFrame(winner49).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser49 = np.asarray(loser49_results[4:5][0])[0]\n",
        "median_loser49 = np.asarray(loser49_results[9:10][0])[0]\n",
        "upper_loser49 = np.asarray(loser49_results[14:15][0])[0]\n",
        "\n",
        "lower_winner49 = np.asarray(winner49_results[4:5][0])[0]\n",
        "median_winner49 = np.asarray(winner49_results[9:10][0])[0]\n",
        "upper_winner49 = np.asarray(winner49_results[14:15][0])[0]"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wN7DWwt1paM"
      },
      "source": [
        "# Iteration59 :\n",
        "\n",
        "slice59 = 58\n",
        "\n",
        "loser59 = [train_regret_loser_1[slice59],\n",
        "       train_regret_loser_2[slice59],\n",
        "       train_regret_loser_3[slice59],\n",
        "       train_regret_loser_4[slice59],\n",
        "       train_regret_loser_5[slice59],\n",
        "       train_regret_loser_6[slice59],\n",
        "       train_regret_loser_7[slice59],\n",
        "       train_regret_loser_8[slice59],\n",
        "       train_regret_loser_9[slice59],\n",
        "       train_regret_loser_10[slice59],\n",
        "       train_regret_loser_11[slice59],\n",
        "       train_regret_loser_12[slice59],\n",
        "       train_regret_loser_13[slice59],\n",
        "       train_regret_loser_14[slice59],\n",
        "       train_regret_loser_15[slice59],\n",
        "       train_regret_loser_16[slice59],\n",
        "       train_regret_loser_17[slice59],\n",
        "       train_regret_loser_18[slice59],\n",
        "       train_regret_loser_19[slice59],\n",
        "       train_regret_loser_20[slice59]]\n",
        "\n",
        "winner59 = [train_regret_winner_1[slice59],\n",
        "       train_regret_winner_2[slice59],\n",
        "       train_regret_winner_3[slice59],\n",
        "       train_regret_winner_4[slice59],\n",
        "       train_regret_winner_5[slice59],\n",
        "       train_regret_winner_6[slice59],\n",
        "       train_regret_winner_7[slice59],\n",
        "       train_regret_winner_8[slice59],\n",
        "       train_regret_winner_9[slice59],\n",
        "       train_regret_winner_10[slice59],\n",
        "       train_regret_winner_11[slice59],\n",
        "       train_regret_winner_12[slice59],\n",
        "       train_regret_winner_13[slice59],\n",
        "       train_regret_winner_14[slice59],\n",
        "       train_regret_winner_15[slice59],\n",
        "       train_regret_winner_16[slice59],\n",
        "       train_regret_winner_17[slice59],\n",
        "       train_regret_winner_18[slice59],\n",
        "       train_regret_winner_19[slice59],\n",
        "       train_regret_winner_20[slice59]]\n",
        "\n",
        "loser59_results = pd.DataFrame(loser59).sort_values(by=[0], ascending=False)\n",
        "winner59_results = pd.DataFrame(winner59).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser59 = np.asarray(loser59_results[4:5][0])[0]\n",
        "median_loser59 = np.asarray(loser59_results[9:10][0])[0]\n",
        "upper_loser59 = np.asarray(loser59_results[14:15][0])[0]\n",
        "\n",
        "lower_winner59 = np.asarray(winner59_results[4:5][0])[0]\n",
        "median_winner59 = np.asarray(winner59_results[9:10][0])[0]\n",
        "upper_winner59 = np.asarray(winner59_results[14:15][0])[0]"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqtgekml1pde"
      },
      "source": [
        "# Iteration69 :\n",
        "\n",
        "slice69 = 68\n",
        "\n",
        "loser69 = [train_regret_loser_1[slice69],\n",
        "       train_regret_loser_2[slice69],\n",
        "       train_regret_loser_3[slice69],\n",
        "       train_regret_loser_4[slice69],\n",
        "       train_regret_loser_5[slice69],\n",
        "       train_regret_loser_6[slice69],\n",
        "       train_regret_loser_7[slice69],\n",
        "       train_regret_loser_8[slice69],\n",
        "       train_regret_loser_9[slice69],\n",
        "       train_regret_loser_10[slice69],\n",
        "       train_regret_loser_11[slice69],\n",
        "       train_regret_loser_12[slice69],\n",
        "       train_regret_loser_13[slice69],\n",
        "       train_regret_loser_14[slice69],\n",
        "       train_regret_loser_15[slice69],\n",
        "       train_regret_loser_16[slice69],\n",
        "       train_regret_loser_17[slice69],\n",
        "       train_regret_loser_18[slice69],\n",
        "       train_regret_loser_19[slice69],\n",
        "       train_regret_loser_20[slice69]]\n",
        "\n",
        "winner69 = [train_regret_winner_1[slice69],\n",
        "       train_regret_winner_2[slice69],\n",
        "       train_regret_winner_3[slice69],\n",
        "       train_regret_winner_4[slice69],\n",
        "       train_regret_winner_5[slice69],\n",
        "       train_regret_winner_6[slice69],\n",
        "       train_regret_winner_7[slice69],\n",
        "       train_regret_winner_8[slice69],\n",
        "       train_regret_winner_9[slice69],\n",
        "       train_regret_winner_10[slice69],\n",
        "       train_regret_winner_11[slice69],\n",
        "       train_regret_winner_12[slice69],\n",
        "       train_regret_winner_13[slice69],\n",
        "       train_regret_winner_14[slice69],\n",
        "       train_regret_winner_15[slice69],\n",
        "       train_regret_winner_16[slice69],\n",
        "       train_regret_winner_17[slice69],\n",
        "       train_regret_winner_18[slice69],\n",
        "       train_regret_winner_19[slice69],\n",
        "       train_regret_winner_20[slice69]]\n",
        "\n",
        "loser69_results = pd.DataFrame(loser69).sort_values(by=[0], ascending=False)\n",
        "winner69_results = pd.DataFrame(winner69).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser69 = np.asarray(loser69_results[4:5][0])[0]\n",
        "median_loser69 = np.asarray(loser69_results[9:10][0])[0]\n",
        "upper_loser69 = np.asarray(loser69_results[14:15][0])[0]\n",
        "\n",
        "lower_winner69 = np.asarray(winner69_results[4:5][0])[0]\n",
        "median_winner69 = np.asarray(winner69_results[9:10][0])[0]\n",
        "upper_winner69 = np.asarray(winner69_results[14:15][0])[0]"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFTa1171pgF"
      },
      "source": [
        "# Iteration79 :\n",
        "\n",
        "slice79 = 78\n",
        "\n",
        "loser79 = [train_regret_loser_1[slice79],\n",
        "       train_regret_loser_2[slice79],\n",
        "       train_regret_loser_3[slice79],\n",
        "       train_regret_loser_4[slice79],\n",
        "       train_regret_loser_5[slice79],\n",
        "       train_regret_loser_6[slice79],\n",
        "       train_regret_loser_7[slice79],\n",
        "       train_regret_loser_8[slice79],\n",
        "       train_regret_loser_9[slice79],\n",
        "       train_regret_loser_10[slice79],\n",
        "       train_regret_loser_11[slice79],\n",
        "       train_regret_loser_12[slice79],\n",
        "       train_regret_loser_13[slice79],\n",
        "       train_regret_loser_14[slice79],\n",
        "       train_regret_loser_15[slice79],\n",
        "       train_regret_loser_16[slice79],\n",
        "       train_regret_loser_17[slice79],\n",
        "       train_regret_loser_18[slice79],\n",
        "       train_regret_loser_19[slice79],\n",
        "       train_regret_loser_20[slice79]]\n",
        "\n",
        "winner79 = [train_regret_winner_1[slice79],\n",
        "       train_regret_winner_2[slice79],\n",
        "       train_regret_winner_3[slice79],\n",
        "       train_regret_winner_4[slice79],\n",
        "       train_regret_winner_5[slice79],\n",
        "       train_regret_winner_6[slice79],\n",
        "       train_regret_winner_7[slice79],\n",
        "       train_regret_winner_8[slice79],\n",
        "       train_regret_winner_9[slice79],\n",
        "       train_regret_winner_10[slice79],\n",
        "       train_regret_winner_11[slice79],\n",
        "       train_regret_winner_12[slice79],\n",
        "       train_regret_winner_13[slice79],\n",
        "       train_regret_winner_14[slice79],\n",
        "       train_regret_winner_15[slice79],\n",
        "       train_regret_winner_16[slice79],\n",
        "       train_regret_winner_17[slice79],\n",
        "       train_regret_winner_18[slice79],\n",
        "       train_regret_winner_19[slice79],\n",
        "       train_regret_winner_20[slice79]]\n",
        "\n",
        "loser79_results = pd.DataFrame(loser79).sort_values(by=[0], ascending=False)\n",
        "winner79_results = pd.DataFrame(winner79).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser79 = np.asarray(loser79_results[4:5][0])[0]\n",
        "median_loser79 = np.asarray(loser79_results[9:10][0])[0]\n",
        "upper_loser79 = np.asarray(loser79_results[14:15][0])[0]\n",
        "\n",
        "lower_winner79 = np.asarray(winner79_results[4:5][0])[0]\n",
        "median_winner79 = np.asarray(winner79_results[9:10][0])[0]\n",
        "upper_winner79 = np.asarray(winner79_results[14:15][0])[0]"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTnRF4lx1pio"
      },
      "source": [
        "# Iteration89 :\n",
        "\n",
        "slice89 = 88\n",
        "\n",
        "loser89 = [train_regret_loser_1[slice89],\n",
        "       train_regret_loser_2[slice89],\n",
        "       train_regret_loser_3[slice89],\n",
        "       train_regret_loser_4[slice89],\n",
        "       train_regret_loser_5[slice89],\n",
        "       train_regret_loser_6[slice89],\n",
        "       train_regret_loser_7[slice89],\n",
        "       train_regret_loser_8[slice89],\n",
        "       train_regret_loser_9[slice89],\n",
        "       train_regret_loser_10[slice89],\n",
        "       train_regret_loser_11[slice89],\n",
        "       train_regret_loser_12[slice89],\n",
        "       train_regret_loser_13[slice89],\n",
        "       train_regret_loser_14[slice89],\n",
        "       train_regret_loser_15[slice89],\n",
        "       train_regret_loser_16[slice89],\n",
        "       train_regret_loser_17[slice89],\n",
        "       train_regret_loser_18[slice89],\n",
        "       train_regret_loser_19[slice89],\n",
        "       train_regret_loser_20[slice89]]\n",
        "\n",
        "winner89 = [train_regret_winner_1[slice89],\n",
        "       train_regret_winner_2[slice89],\n",
        "       train_regret_winner_3[slice89],\n",
        "       train_regret_winner_4[slice89],\n",
        "       train_regret_winner_5[slice89],\n",
        "       train_regret_winner_6[slice89],\n",
        "       train_regret_winner_7[slice89],\n",
        "       train_regret_winner_8[slice89],\n",
        "       train_regret_winner_9[slice89],\n",
        "       train_regret_winner_10[slice89],\n",
        "       train_regret_winner_11[slice89],\n",
        "       train_regret_winner_12[slice89],\n",
        "       train_regret_winner_13[slice89],\n",
        "       train_regret_winner_14[slice89],\n",
        "       train_regret_winner_15[slice89],\n",
        "       train_regret_winner_16[slice89],\n",
        "       train_regret_winner_17[slice89],\n",
        "       train_regret_winner_18[slice89],\n",
        "       train_regret_winner_19[slice89],\n",
        "       train_regret_winner_20[slice89]]\n",
        "\n",
        "loser89_results = pd.DataFrame(loser89).sort_values(by=[0], ascending=False)\n",
        "winner89_results = pd.DataFrame(winner89).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser89 = np.asarray(loser89_results[4:5][0])[0]\n",
        "median_loser89 = np.asarray(loser89_results[9:10][0])[0]\n",
        "upper_loser89 = np.asarray(loser89_results[14:15][0])[0]\n",
        "\n",
        "lower_winner89 = np.asarray(winner89_results[4:5][0])[0]\n",
        "median_winner89 = np.asarray(winner89_results[9:10][0])[0]\n",
        "upper_winner89 = np.asarray(winner89_results[14:15][0])[0]"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiLAF38i1plO"
      },
      "source": [
        "# Iteration99 :\n",
        "\n",
        "slice99 = 98\n",
        "\n",
        "loser99 = [train_regret_loser_1[slice99],\n",
        "       train_regret_loser_2[slice99],\n",
        "       train_regret_loser_3[slice99],\n",
        "       train_regret_loser_4[slice99],\n",
        "       train_regret_loser_5[slice99],\n",
        "       train_regret_loser_6[slice99],\n",
        "       train_regret_loser_7[slice99],\n",
        "       train_regret_loser_8[slice99],\n",
        "       train_regret_loser_9[slice99],\n",
        "       train_regret_loser_10[slice99],\n",
        "       train_regret_loser_11[slice99],\n",
        "       train_regret_loser_12[slice99],\n",
        "       train_regret_loser_13[slice99],\n",
        "       train_regret_loser_14[slice99],\n",
        "       train_regret_loser_15[slice99],\n",
        "       train_regret_loser_16[slice99],\n",
        "       train_regret_loser_17[slice99],\n",
        "       train_regret_loser_18[slice99],\n",
        "       train_regret_loser_19[slice99],\n",
        "       train_regret_loser_20[slice99]]\n",
        "\n",
        "winner99 = [train_regret_winner_1[slice99],\n",
        "       train_regret_winner_2[slice99],\n",
        "       train_regret_winner_3[slice99],\n",
        "       train_regret_winner_4[slice99],\n",
        "       train_regret_winner_5[slice99],\n",
        "       train_regret_winner_6[slice99],\n",
        "       train_regret_winner_7[slice99],\n",
        "       train_regret_winner_8[slice99],\n",
        "       train_regret_winner_9[slice99],\n",
        "       train_regret_winner_10[slice99],\n",
        "       train_regret_winner_11[slice99],\n",
        "       train_regret_winner_12[slice99],\n",
        "       train_regret_winner_13[slice99],\n",
        "       train_regret_winner_14[slice99],\n",
        "       train_regret_winner_15[slice99],\n",
        "       train_regret_winner_16[slice99],\n",
        "       train_regret_winner_17[slice99],\n",
        "       train_regret_winner_18[slice99],\n",
        "       train_regret_winner_19[slice99],\n",
        "       train_regret_winner_20[slice99]]\n",
        "\n",
        "loser99_results = pd.DataFrame(loser99).sort_values(by=[0], ascending=False)\n",
        "winner99_results = pd.DataFrame(winner99).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser99 = np.asarray(loser99_results[4:5][0])[0]\n",
        "median_loser99 = np.asarray(loser99_results[9:10][0])[0]\n",
        "upper_loser99 = np.asarray(loser99_results[14:15][0])[0]\n",
        "\n",
        "lower_winner99 = np.asarray(winner99_results[4:5][0])[0]\n",
        "median_winner99 = np.asarray(winner99_results[9:10][0])[0]\n",
        "upper_winner99 = np.asarray(winner99_results[14:15][0])[0]"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBd_N0F21pn0"
      },
      "source": [
        "# Iteration10 :\n",
        "\n",
        "slice10 = 9\n",
        "\n",
        "loser10 = [train_regret_loser_1[slice10],\n",
        "       train_regret_loser_2[slice10],\n",
        "       train_regret_loser_3[slice10],\n",
        "       train_regret_loser_4[slice10],\n",
        "       train_regret_loser_5[slice10],\n",
        "       train_regret_loser_6[slice10],\n",
        "       train_regret_loser_7[slice10],\n",
        "       train_regret_loser_8[slice10],\n",
        "       train_regret_loser_9[slice10],\n",
        "       train_regret_loser_10[slice10],\n",
        "       train_regret_loser_11[slice10],\n",
        "       train_regret_loser_12[slice10],\n",
        "       train_regret_loser_13[slice10],\n",
        "       train_regret_loser_14[slice10],\n",
        "       train_regret_loser_15[slice10],\n",
        "       train_regret_loser_16[slice10],\n",
        "       train_regret_loser_17[slice10],\n",
        "       train_regret_loser_18[slice10],\n",
        "       train_regret_loser_19[slice10],\n",
        "       train_regret_loser_20[slice10]]\n",
        "\n",
        "winner10 = [train_regret_winner_1[slice10],\n",
        "       train_regret_winner_2[slice10],\n",
        "       train_regret_winner_3[slice10],\n",
        "       train_regret_winner_4[slice10],\n",
        "       train_regret_winner_5[slice10],\n",
        "       train_regret_winner_6[slice10],\n",
        "       train_regret_winner_7[slice10],\n",
        "       train_regret_winner_8[slice10],\n",
        "       train_regret_winner_9[slice10],\n",
        "       train_regret_winner_10[slice10],\n",
        "       train_regret_winner_11[slice10],\n",
        "       train_regret_winner_12[slice10],\n",
        "       train_regret_winner_13[slice10],\n",
        "       train_regret_winner_14[slice10],\n",
        "       train_regret_winner_15[slice10],\n",
        "       train_regret_winner_16[slice10],\n",
        "       train_regret_winner_17[slice10],\n",
        "       train_regret_winner_18[slice10],\n",
        "       train_regret_winner_19[slice10],\n",
        "       train_regret_winner_20[slice10]]\n",
        "\n",
        "loser10_results = pd.DataFrame(loser10).sort_values(by=[0], ascending=False)\n",
        "winner10_results = pd.DataFrame(winner10).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser10 = np.asarray(loser10_results[4:5][0])[0]\n",
        "median_loser10 = np.asarray(loser10_results[9:10][0])[0]\n",
        "upper_loser10 = np.asarray(loser10_results[14:15][0])[0]\n",
        "\n",
        "lower_winner10 = np.asarray(winner10_results[4:5][0])[0]\n",
        "median_winner10 = np.asarray(winner10_results[9:10][0])[0]\n",
        "upper_winner10 = np.asarray(winner10_results[14:15][0])[0]"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXjdqc4s1pqb"
      },
      "source": [
        "# Iteration20 :\n",
        "\n",
        "slice20 = 19\n",
        "\n",
        "loser20 = [train_regret_loser_1[slice20],\n",
        "       train_regret_loser_2[slice20],\n",
        "       train_regret_loser_3[slice20],\n",
        "       train_regret_loser_4[slice20],\n",
        "       train_regret_loser_5[slice20],\n",
        "       train_regret_loser_6[slice20],\n",
        "       train_regret_loser_7[slice20],\n",
        "       train_regret_loser_8[slice20],\n",
        "       train_regret_loser_9[slice20],\n",
        "       train_regret_loser_10[slice20],\n",
        "       train_regret_loser_11[slice20],\n",
        "       train_regret_loser_12[slice20],\n",
        "       train_regret_loser_13[slice20],\n",
        "       train_regret_loser_14[slice20],\n",
        "       train_regret_loser_15[slice20],\n",
        "       train_regret_loser_16[slice20],\n",
        "       train_regret_loser_17[slice20],\n",
        "       train_regret_loser_18[slice20],\n",
        "       train_regret_loser_19[slice20],\n",
        "       train_regret_loser_20[slice20]]\n",
        "\n",
        "winner20 = [train_regret_winner_1[slice20],\n",
        "       train_regret_winner_2[slice20],\n",
        "       train_regret_winner_3[slice20],\n",
        "       train_regret_winner_4[slice20],\n",
        "       train_regret_winner_5[slice20],\n",
        "       train_regret_winner_6[slice20],\n",
        "       train_regret_winner_7[slice20],\n",
        "       train_regret_winner_8[slice20],\n",
        "       train_regret_winner_9[slice20],\n",
        "       train_regret_winner_10[slice20],\n",
        "       train_regret_winner_11[slice20],\n",
        "       train_regret_winner_12[slice20],\n",
        "       train_regret_winner_13[slice20],\n",
        "       train_regret_winner_14[slice20],\n",
        "       train_regret_winner_15[slice20],\n",
        "       train_regret_winner_16[slice20],\n",
        "       train_regret_winner_17[slice20],\n",
        "       train_regret_winner_18[slice20],\n",
        "       train_regret_winner_19[slice20],\n",
        "       train_regret_winner_20[slice20]]\n",
        "\n",
        "loser20_results = pd.DataFrame(loser20).sort_values(by=[0], ascending=False)\n",
        "winner20_results = pd.DataFrame(winner20).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser20 = np.asarray(loser20_results[4:5][0])[0]\n",
        "median_loser20 = np.asarray(loser20_results[9:10][0])[0]\n",
        "upper_loser20 = np.asarray(loser20_results[14:15][0])[0]\n",
        "\n",
        "lower_winner20 = np.asarray(winner20_results[4:5][0])[0]\n",
        "median_winner20 = np.asarray(winner20_results[9:10][0])[0]\n",
        "upper_winner20 = np.asarray(winner20_results[14:15][0])[0]"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQBVS6dx1ptB"
      },
      "source": [
        "# Iteration30 :\n",
        "\n",
        "slice30 = 29\n",
        "\n",
        "loser30 = [train_regret_loser_1[slice30],\n",
        "       train_regret_loser_2[slice30],\n",
        "       train_regret_loser_3[slice30],\n",
        "       train_regret_loser_4[slice30],\n",
        "       train_regret_loser_5[slice30],\n",
        "       train_regret_loser_6[slice30],\n",
        "       train_regret_loser_7[slice30],\n",
        "       train_regret_loser_8[slice30],\n",
        "       train_regret_loser_9[slice30],\n",
        "       train_regret_loser_10[slice30],\n",
        "       train_regret_loser_11[slice30],\n",
        "       train_regret_loser_12[slice30],\n",
        "       train_regret_loser_13[slice30],\n",
        "       train_regret_loser_14[slice30],\n",
        "       train_regret_loser_15[slice30],\n",
        "       train_regret_loser_16[slice30],\n",
        "       train_regret_loser_17[slice30],\n",
        "       train_regret_loser_18[slice30],\n",
        "       train_regret_loser_19[slice30],\n",
        "       train_regret_loser_20[slice30]]\n",
        "\n",
        "winner30 = [train_regret_winner_1[slice30],\n",
        "       train_regret_winner_2[slice30],\n",
        "       train_regret_winner_3[slice30],\n",
        "       train_regret_winner_4[slice30],\n",
        "       train_regret_winner_5[slice30],\n",
        "       train_regret_winner_6[slice30],\n",
        "       train_regret_winner_7[slice30],\n",
        "       train_regret_winner_8[slice30],\n",
        "       train_regret_winner_9[slice30],\n",
        "       train_regret_winner_10[slice30],\n",
        "       train_regret_winner_11[slice30],\n",
        "       train_regret_winner_12[slice30],\n",
        "       train_regret_winner_13[slice30],\n",
        "       train_regret_winner_14[slice30],\n",
        "       train_regret_winner_15[slice30],\n",
        "       train_regret_winner_16[slice30],\n",
        "       train_regret_winner_17[slice30],\n",
        "       train_regret_winner_18[slice30],\n",
        "       train_regret_winner_19[slice30],\n",
        "       train_regret_winner_20[slice30]]\n",
        "\n",
        "loser30_results = pd.DataFrame(loser30).sort_values(by=[0], ascending=False)\n",
        "winner30_results = pd.DataFrame(winner30).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser30 = np.asarray(loser30_results[4:5][0])[0]\n",
        "median_loser30 = np.asarray(loser30_results[9:10][0])[0]\n",
        "upper_loser30 = np.asarray(loser30_results[14:15][0])[0]\n",
        "\n",
        "lower_winner30 = np.asarray(winner30_results[4:5][0])[0]\n",
        "median_winner30 = np.asarray(winner30_results[9:10][0])[0]\n",
        "upper_winner30 = np.asarray(winner30_results[14:15][0])[0]"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-iWfLkj1pvn"
      },
      "source": [
        "# Iteration40 :\n",
        "\n",
        "slice40 = 39\n",
        "\n",
        "loser40 = [train_regret_loser_1[slice40],\n",
        "       train_regret_loser_2[slice40],\n",
        "       train_regret_loser_3[slice40],\n",
        "       train_regret_loser_4[slice40],\n",
        "       train_regret_loser_5[slice40],\n",
        "       train_regret_loser_6[slice40],\n",
        "       train_regret_loser_7[slice40],\n",
        "       train_regret_loser_8[slice40],\n",
        "       train_regret_loser_9[slice40],\n",
        "       train_regret_loser_10[slice40],\n",
        "       train_regret_loser_11[slice40],\n",
        "       train_regret_loser_12[slice40],\n",
        "       train_regret_loser_13[slice40],\n",
        "       train_regret_loser_14[slice40],\n",
        "       train_regret_loser_15[slice40],\n",
        "       train_regret_loser_16[slice40],\n",
        "       train_regret_loser_17[slice40],\n",
        "       train_regret_loser_18[slice40],\n",
        "       train_regret_loser_19[slice40],\n",
        "       train_regret_loser_20[slice40]]\n",
        "\n",
        "winner40 = [train_regret_winner_1[slice40],\n",
        "       train_regret_winner_2[slice40],\n",
        "       train_regret_winner_3[slice40],\n",
        "       train_regret_winner_4[slice40],\n",
        "       train_regret_winner_5[slice40],\n",
        "       train_regret_winner_6[slice40],\n",
        "       train_regret_winner_7[slice40],\n",
        "       train_regret_winner_8[slice40],\n",
        "       train_regret_winner_9[slice40],\n",
        "       train_regret_winner_10[slice40],\n",
        "       train_regret_winner_11[slice40],\n",
        "       train_regret_winner_12[slice40],\n",
        "       train_regret_winner_13[slice40],\n",
        "       train_regret_winner_14[slice40],\n",
        "       train_regret_winner_15[slice40],\n",
        "       train_regret_winner_16[slice40],\n",
        "       train_regret_winner_17[slice40],\n",
        "       train_regret_winner_18[slice40],\n",
        "       train_regret_winner_19[slice40],\n",
        "       train_regret_winner_20[slice40]]\n",
        "\n",
        "loser40_results = pd.DataFrame(loser40).sort_values(by=[0], ascending=False)\n",
        "winner40_results = pd.DataFrame(winner40).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser40 = np.asarray(loser40_results[4:5][0])[0]\n",
        "median_loser40 = np.asarray(loser40_results[9:10][0])[0]\n",
        "upper_loser40 = np.asarray(loser40_results[14:15][0])[0]\n",
        "\n",
        "lower_winner40 = np.asarray(winner40_results[4:5][0])[0]\n",
        "median_winner40 = np.asarray(winner40_results[9:10][0])[0]\n",
        "upper_winner40 = np.asarray(winner40_results[14:15][0])[0]"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G5i-Cjw2U7K"
      },
      "source": [
        "# Iteration50 :\n",
        "\n",
        "slice50 = 49\n",
        "\n",
        "loser50 = [train_regret_loser_1[slice50],\n",
        "       train_regret_loser_2[slice50],\n",
        "       train_regret_loser_3[slice50],\n",
        "       train_regret_loser_4[slice50],\n",
        "       train_regret_loser_5[slice50],\n",
        "       train_regret_loser_6[slice50],\n",
        "       train_regret_loser_7[slice50],\n",
        "       train_regret_loser_8[slice50],\n",
        "       train_regret_loser_9[slice50],\n",
        "       train_regret_loser_10[slice50],\n",
        "       train_regret_loser_11[slice50],\n",
        "       train_regret_loser_12[slice50],\n",
        "       train_regret_loser_13[slice50],\n",
        "       train_regret_loser_14[slice50],\n",
        "       train_regret_loser_15[slice50],\n",
        "       train_regret_loser_16[slice50],\n",
        "       train_regret_loser_17[slice50],\n",
        "       train_regret_loser_18[slice50],\n",
        "       train_regret_loser_19[slice50],\n",
        "       train_regret_loser_20[slice50]]\n",
        "\n",
        "winner50 = [train_regret_winner_1[slice50],\n",
        "       train_regret_winner_2[slice50],\n",
        "       train_regret_winner_3[slice50],\n",
        "       train_regret_winner_4[slice50],\n",
        "       train_regret_winner_5[slice50],\n",
        "       train_regret_winner_6[slice50],\n",
        "       train_regret_winner_7[slice50],\n",
        "       train_regret_winner_8[slice50],\n",
        "       train_regret_winner_9[slice50],\n",
        "       train_regret_winner_10[slice50],\n",
        "       train_regret_winner_11[slice50],\n",
        "       train_regret_winner_12[slice50],\n",
        "       train_regret_winner_13[slice50],\n",
        "       train_regret_winner_14[slice50],\n",
        "       train_regret_winner_15[slice50],\n",
        "       train_regret_winner_16[slice50],\n",
        "       train_regret_winner_17[slice50],\n",
        "       train_regret_winner_18[slice50],\n",
        "       train_regret_winner_19[slice50],\n",
        "       train_regret_winner_20[slice50]]\n",
        "\n",
        "loser50_results = pd.DataFrame(loser50).sort_values(by=[0], ascending=False)\n",
        "winner50_results = pd.DataFrame(winner50).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser50 = np.asarray(loser50_results[4:5][0])[0]\n",
        "median_loser50 = np.asarray(loser50_results[9:10][0])[0]\n",
        "upper_loser50 = np.asarray(loser50_results[14:15][0])[0]\n",
        "\n",
        "lower_winner50 = np.asarray(winner50_results[4:5][0])[0]\n",
        "median_winner50 = np.asarray(winner50_results[9:10][0])[0]\n",
        "upper_winner50 = np.asarray(winner50_results[14:15][0])[0]"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY6qxZQA2U-r"
      },
      "source": [
        "# Iteration60 :\n",
        "\n",
        "slice60 = 59\n",
        "\n",
        "loser60 = [train_regret_loser_1[slice60],\n",
        "       train_regret_loser_2[slice60],\n",
        "       train_regret_loser_3[slice60],\n",
        "       train_regret_loser_4[slice60],\n",
        "       train_regret_loser_5[slice60],\n",
        "       train_regret_loser_6[slice60],\n",
        "       train_regret_loser_7[slice60],\n",
        "       train_regret_loser_8[slice60],\n",
        "       train_regret_loser_9[slice60],\n",
        "       train_regret_loser_10[slice60],\n",
        "       train_regret_loser_11[slice60],\n",
        "       train_regret_loser_12[slice60],\n",
        "       train_regret_loser_13[slice60],\n",
        "       train_regret_loser_14[slice60],\n",
        "       train_regret_loser_15[slice60],\n",
        "       train_regret_loser_16[slice60],\n",
        "       train_regret_loser_17[slice60],\n",
        "       train_regret_loser_18[slice60],\n",
        "       train_regret_loser_19[slice60],\n",
        "       train_regret_loser_20[slice60]]\n",
        "\n",
        "winner60 = [train_regret_winner_1[slice60],\n",
        "       train_regret_winner_2[slice60],\n",
        "       train_regret_winner_3[slice60],\n",
        "       train_regret_winner_4[slice60],\n",
        "       train_regret_winner_5[slice60],\n",
        "       train_regret_winner_6[slice60],\n",
        "       train_regret_winner_7[slice60],\n",
        "       train_regret_winner_8[slice60],\n",
        "       train_regret_winner_9[slice60],\n",
        "       train_regret_winner_10[slice60],\n",
        "       train_regret_winner_11[slice60],\n",
        "       train_regret_winner_12[slice60],\n",
        "       train_regret_winner_13[slice60],\n",
        "       train_regret_winner_14[slice60],\n",
        "       train_regret_winner_15[slice60],\n",
        "       train_regret_winner_16[slice60],\n",
        "       train_regret_winner_17[slice60],\n",
        "       train_regret_winner_18[slice60],\n",
        "       train_regret_winner_19[slice60],\n",
        "       train_regret_winner_20[slice60]]\n",
        "\n",
        "loser60_results = pd.DataFrame(loser60).sort_values(by=[0], ascending=False)\n",
        "winner60_results = pd.DataFrame(winner60).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser60 = np.asarray(loser60_results[4:5][0])[0]\n",
        "median_loser60 = np.asarray(loser60_results[9:10][0])[0]\n",
        "upper_loser60 = np.asarray(loser60_results[14:15][0])[0]\n",
        "\n",
        "lower_winner60 = np.asarray(winner60_results[4:5][0])[0]\n",
        "median_winner60 = np.asarray(winner60_results[9:10][0])[0]\n",
        "upper_winner60 = np.asarray(winner60_results[14:15][0])[0]"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBqgVxVH2VCU"
      },
      "source": [
        "# Iteration70 :\n",
        "\n",
        "slice70 = 69\n",
        "\n",
        "loser70 = [train_regret_loser_1[slice70],\n",
        "       train_regret_loser_2[slice70],\n",
        "       train_regret_loser_3[slice70],\n",
        "       train_regret_loser_4[slice70],\n",
        "       train_regret_loser_5[slice70],\n",
        "       train_regret_loser_6[slice70],\n",
        "       train_regret_loser_7[slice70],\n",
        "       train_regret_loser_8[slice70],\n",
        "       train_regret_loser_9[slice70],\n",
        "       train_regret_loser_10[slice70],\n",
        "       train_regret_loser_11[slice70],\n",
        "       train_regret_loser_12[slice70],\n",
        "       train_regret_loser_13[slice70],\n",
        "       train_regret_loser_14[slice70],\n",
        "       train_regret_loser_15[slice70],\n",
        "       train_regret_loser_16[slice70],\n",
        "       train_regret_loser_17[slice70],\n",
        "       train_regret_loser_18[slice70],\n",
        "       train_regret_loser_19[slice70],\n",
        "       train_regret_loser_20[slice70]]\n",
        "\n",
        "winner70 = [train_regret_winner_1[slice70],\n",
        "       train_regret_winner_2[slice70],\n",
        "       train_regret_winner_3[slice70],\n",
        "       train_regret_winner_4[slice70],\n",
        "       train_regret_winner_5[slice70],\n",
        "       train_regret_winner_6[slice70],\n",
        "       train_regret_winner_7[slice70],\n",
        "       train_regret_winner_8[slice70],\n",
        "       train_regret_winner_9[slice70],\n",
        "       train_regret_winner_10[slice70],\n",
        "       train_regret_winner_11[slice70],\n",
        "       train_regret_winner_12[slice70],\n",
        "       train_regret_winner_13[slice70],\n",
        "       train_regret_winner_14[slice70],\n",
        "       train_regret_winner_15[slice70],\n",
        "       train_regret_winner_16[slice70],\n",
        "       train_regret_winner_17[slice70],\n",
        "       train_regret_winner_18[slice70],\n",
        "       train_regret_winner_19[slice70],\n",
        "       train_regret_winner_20[slice70]]\n",
        "\n",
        "loser70_results = pd.DataFrame(loser70).sort_values(by=[0], ascending=False)\n",
        "winner70_results = pd.DataFrame(winner70).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser70 = np.asarray(loser70_results[4:5][0])[0]\n",
        "median_loser70 = np.asarray(loser70_results[9:10][0])[0]\n",
        "upper_loser70 = np.asarray(loser70_results[14:15][0])[0]\n",
        "\n",
        "lower_winner70 = np.asarray(winner70_results[4:5][0])[0]\n",
        "median_winner70 = np.asarray(winner70_results[9:10][0])[0]\n",
        "upper_winner70 = np.asarray(winner70_results[14:15][0])[0]"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF7mlDZL1pyN"
      },
      "source": [
        "# Iteration80 :\n",
        "\n",
        "slice80 = 79\n",
        "\n",
        "loser80 = [train_regret_loser_1[slice80],\n",
        "       train_regret_loser_2[slice80],\n",
        "       train_regret_loser_3[slice80],\n",
        "       train_regret_loser_4[slice80],\n",
        "       train_regret_loser_5[slice80],\n",
        "       train_regret_loser_6[slice80],\n",
        "       train_regret_loser_7[slice80],\n",
        "       train_regret_loser_8[slice80],\n",
        "       train_regret_loser_9[slice80],\n",
        "       train_regret_loser_10[slice80],\n",
        "       train_regret_loser_11[slice80],\n",
        "       train_regret_loser_12[slice80],\n",
        "       train_regret_loser_13[slice80],\n",
        "       train_regret_loser_14[slice80],\n",
        "       train_regret_loser_15[slice80],\n",
        "       train_regret_loser_16[slice80],\n",
        "       train_regret_loser_17[slice80],\n",
        "       train_regret_loser_18[slice80],\n",
        "       train_regret_loser_19[slice80],\n",
        "       train_regret_loser_20[slice80]]\n",
        "\n",
        "winner80 = [train_regret_winner_1[slice80],\n",
        "       train_regret_winner_2[slice80],\n",
        "       train_regret_winner_3[slice80],\n",
        "       train_regret_winner_4[slice80],\n",
        "       train_regret_winner_5[slice80],\n",
        "       train_regret_winner_6[slice80],\n",
        "       train_regret_winner_7[slice80],\n",
        "       train_regret_winner_8[slice80],\n",
        "       train_regret_winner_9[slice80],\n",
        "       train_regret_winner_10[slice80],\n",
        "       train_regret_winner_11[slice80],\n",
        "       train_regret_winner_12[slice80],\n",
        "       train_regret_winner_13[slice80],\n",
        "       train_regret_winner_14[slice80],\n",
        "       train_regret_winner_15[slice80],\n",
        "       train_regret_winner_16[slice80],\n",
        "       train_regret_winner_17[slice80],\n",
        "       train_regret_winner_18[slice80],\n",
        "       train_regret_winner_19[slice80],\n",
        "       train_regret_winner_20[slice80]]\n",
        "\n",
        "loser80_results = pd.DataFrame(loser80).sort_values(by=[0], ascending=False)\n",
        "winner80_results = pd.DataFrame(winner80).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser80 = np.asarray(loser80_results[4:5][0])[0]\n",
        "median_loser80 = np.asarray(loser80_results[9:10][0])[0]\n",
        "upper_loser80 = np.asarray(loser80_results[14:15][0])[0]\n",
        "\n",
        "lower_winner80 = np.asarray(winner80_results[4:5][0])[0]\n",
        "median_winner80 = np.asarray(winner80_results[9:10][0])[0]\n",
        "upper_winner80 = np.asarray(winner80_results[14:15][0])[0]"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Rw8IkD1p0z"
      },
      "source": [
        "# Iteration90 :\n",
        "\n",
        "slice90 = 89\n",
        "\n",
        "loser90 = [train_regret_loser_1[slice90],\n",
        "       train_regret_loser_2[slice90],\n",
        "       train_regret_loser_3[slice90],\n",
        "       train_regret_loser_4[slice90],\n",
        "       train_regret_loser_5[slice90],\n",
        "       train_regret_loser_6[slice90],\n",
        "       train_regret_loser_7[slice90],\n",
        "       train_regret_loser_8[slice90],\n",
        "       train_regret_loser_9[slice90],\n",
        "       train_regret_loser_10[slice90],\n",
        "       train_regret_loser_11[slice90],\n",
        "       train_regret_loser_12[slice90],\n",
        "       train_regret_loser_13[slice90],\n",
        "       train_regret_loser_14[slice90],\n",
        "       train_regret_loser_15[slice90],\n",
        "       train_regret_loser_16[slice90],\n",
        "       train_regret_loser_17[slice90],\n",
        "       train_regret_loser_18[slice90],\n",
        "       train_regret_loser_19[slice90],\n",
        "       train_regret_loser_20[slice90]]\n",
        "\n",
        "winner90 = [train_regret_winner_1[slice90],\n",
        "       train_regret_winner_2[slice90],\n",
        "       train_regret_winner_3[slice90],\n",
        "       train_regret_winner_4[slice90],\n",
        "       train_regret_winner_5[slice90],\n",
        "       train_regret_winner_6[slice90],\n",
        "       train_regret_winner_7[slice90],\n",
        "       train_regret_winner_8[slice90],\n",
        "       train_regret_winner_9[slice90],\n",
        "       train_regret_winner_10[slice90],\n",
        "       train_regret_winner_11[slice90],\n",
        "       train_regret_winner_12[slice90],\n",
        "       train_regret_winner_13[slice90],\n",
        "       train_regret_winner_14[slice90],\n",
        "       train_regret_winner_15[slice90],\n",
        "       train_regret_winner_16[slice90],\n",
        "       train_regret_winner_17[slice90],\n",
        "       train_regret_winner_18[slice90],\n",
        "       train_regret_winner_19[slice90],\n",
        "       train_regret_winner_20[slice90]]\n",
        "\n",
        "loser90_results = pd.DataFrame(loser90).sort_values(by=[0], ascending=False)\n",
        "winner90_results = pd.DataFrame(winner90).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser90 = np.asarray(loser90_results[4:5][0])[0]\n",
        "median_loser90 = np.asarray(loser90_results[9:10][0])[0]\n",
        "upper_loser90 = np.asarray(loser90_results[14:15][0])[0]\n",
        "\n",
        "lower_winner90 = np.asarray(winner90_results[4:5][0])[0]\n",
        "median_winner90 = np.asarray(winner90_results[9:10][0])[0]\n",
        "upper_winner90 = np.asarray(winner90_results[14:15][0])[0]"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiljCrq21p3a"
      },
      "source": [
        "# Iteration100 :\n",
        "\n",
        "slice100 = 99\n",
        "\n",
        "loser100 = [train_regret_loser_1[slice100],\n",
        "       train_regret_loser_2[slice100],\n",
        "       train_regret_loser_3[slice100],\n",
        "       train_regret_loser_4[slice100],\n",
        "       train_regret_loser_5[slice100],\n",
        "       train_regret_loser_6[slice100],\n",
        "       train_regret_loser_7[slice100],\n",
        "       train_regret_loser_8[slice100],\n",
        "       train_regret_loser_9[slice100],\n",
        "       train_regret_loser_10[slice100],\n",
        "       train_regret_loser_11[slice100],\n",
        "       train_regret_loser_12[slice100],\n",
        "       train_regret_loser_13[slice100],\n",
        "       train_regret_loser_14[slice100],\n",
        "       train_regret_loser_15[slice100],\n",
        "       train_regret_loser_16[slice100],\n",
        "       train_regret_loser_17[slice100],\n",
        "       train_regret_loser_18[slice100],\n",
        "       train_regret_loser_19[slice100],\n",
        "       train_regret_loser_20[slice100]]\n",
        "\n",
        "winner100 = [train_regret_winner_1[slice100],\n",
        "       train_regret_winner_2[slice100],\n",
        "       train_regret_winner_3[slice100],\n",
        "       train_regret_winner_4[slice100],\n",
        "       train_regret_winner_5[slice100],\n",
        "       train_regret_winner_6[slice100],\n",
        "       train_regret_winner_7[slice100],\n",
        "       train_regret_winner_8[slice100],\n",
        "       train_regret_winner_9[slice100],\n",
        "       train_regret_winner_10[slice100],\n",
        "       train_regret_winner_11[slice100],\n",
        "       train_regret_winner_12[slice100],\n",
        "       train_regret_winner_13[slice100],\n",
        "       train_regret_winner_14[slice100],\n",
        "       train_regret_winner_15[slice100],\n",
        "       train_regret_winner_16[slice100],\n",
        "       train_regret_winner_17[slice100],\n",
        "       train_regret_winner_18[slice100],\n",
        "       train_regret_winner_19[slice100],\n",
        "       train_regret_winner_20[slice100]]\n",
        "\n",
        "loser100_results = pd.DataFrame(loser100).sort_values(by=[0], ascending=False)\n",
        "winner100_results = pd.DataFrame(winner100).sort_values(by=[0], ascending=False)\n",
        "\n",
        "### Best training regret minimization IQR - loser:\n",
        "lower_loser100 = np.asarray(loser100_results[4:5][0])[0]\n",
        "median_loser100 = np.asarray(loser100_results[9:10][0])[0]\n",
        "upper_loser100 = np.asarray(loser100_results[14:15][0])[0]\n",
        "\n",
        "lower_winner100 = np.asarray(winner100_results[4:5][0])[0]\n",
        "median_winner100 = np.asarray(winner100_results[9:10][0])[0]\n",
        "upper_winner100 = np.asarray(winner100_results[14:15][0])[0]"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OItJgqUT2oNb"
      },
      "source": [
        "### Summarize arrays: 'Loser'\n",
        "\n",
        "lower_loser = [lower_loser1,\n",
        "            lower_loser2,\n",
        "            lower_loser3,\n",
        "            lower_loser4,\n",
        "            lower_loser5,\n",
        "            lower_loser6,\n",
        "            lower_loser7,\n",
        "            lower_loser8,\n",
        "            lower_loser9,\n",
        "            lower_loser10,\n",
        "            lower_loser11,\n",
        "            lower_loser12,\n",
        "            lower_loser13,\n",
        "            lower_loser14,\n",
        "            lower_loser15,\n",
        "            lower_loser16,\n",
        "            lower_loser17,\n",
        "            lower_loser18,\n",
        "            lower_loser19,\n",
        "            lower_loser20,\n",
        "            lower_loser21,\n",
        "            lower_loser22,\n",
        "            lower_loser23,\n",
        "            lower_loser24,\n",
        "            lower_loser25,\n",
        "            lower_loser26,\n",
        "            lower_loser27,\n",
        "            lower_loser28,\n",
        "            lower_loser29,\n",
        "            lower_loser30,\n",
        "            lower_loser31,\n",
        "            lower_loser32,\n",
        "            lower_loser33,\n",
        "            lower_loser34,\n",
        "            lower_loser35,\n",
        "            lower_loser36,\n",
        "            lower_loser37,\n",
        "            lower_loser38,\n",
        "            lower_loser39,\n",
        "            lower_loser40,\n",
        "            lower_loser41,\n",
        "            lower_loser42,\n",
        "            lower_loser43,\n",
        "            lower_loser44,\n",
        "            lower_loser45,\n",
        "            lower_loser46,\n",
        "            lower_loser47,\n",
        "            lower_loser48,\n",
        "            lower_loser49,\n",
        "            lower_loser50,\n",
        "            lower_loser51,\n",
        "            lower_loser52,\n",
        "            lower_loser53,\n",
        "            lower_loser54,\n",
        "            lower_loser55,\n",
        "            lower_loser56,\n",
        "            lower_loser57,\n",
        "            lower_loser58,\n",
        "            lower_loser59,\n",
        "            lower_loser60,\n",
        "            lower_loser61,\n",
        "            lower_loser62,\n",
        "            lower_loser63,\n",
        "            lower_loser64,\n",
        "            lower_loser65,\n",
        "            lower_loser66,\n",
        "            lower_loser67,\n",
        "            lower_loser68,\n",
        "            lower_loser69,\n",
        "            lower_loser70,\n",
        "            lower_loser71,\n",
        "            lower_loser72,\n",
        "            lower_loser73,\n",
        "            lower_loser74,\n",
        "            lower_loser75,\n",
        "            lower_loser76,\n",
        "            lower_loser77,\n",
        "            lower_loser78,\n",
        "            lower_loser79,\n",
        "            lower_loser80,\n",
        "            lower_loser81,\n",
        "            lower_loser82,\n",
        "            lower_loser83,\n",
        "            lower_loser84,\n",
        "            lower_loser85,\n",
        "            lower_loser86,\n",
        "            lower_loser87,\n",
        "            lower_loser88,\n",
        "            lower_loser89,\n",
        "            lower_loser90,\n",
        "            lower_loser91,\n",
        "            lower_loser92,\n",
        "            lower_loser93,\n",
        "            lower_loser94,\n",
        "            lower_loser95,\n",
        "            lower_loser96,\n",
        "            lower_loser97,\n",
        "            lower_loser98,\n",
        "            lower_loser99,\n",
        "            lower_loser100,\n",
        "            lower_loser101]\n",
        "\n",
        "median_loser = [median_loser1,\n",
        "            median_loser2,\n",
        "            median_loser3,\n",
        "            median_loser4,\n",
        "            median_loser5,\n",
        "            median_loser6,\n",
        "            median_loser7,\n",
        "            median_loser8,\n",
        "            median_loser9,\n",
        "            median_loser10,\n",
        "            median_loser11,\n",
        "            median_loser12,\n",
        "            median_loser13,\n",
        "            median_loser14,\n",
        "            median_loser15,\n",
        "            median_loser16,\n",
        "            median_loser17,\n",
        "            median_loser18,\n",
        "            median_loser19,\n",
        "            median_loser20,\n",
        "            median_loser21,\n",
        "            median_loser22,\n",
        "            median_loser23,\n",
        "            median_loser24,\n",
        "            median_loser25,\n",
        "            median_loser26,\n",
        "            median_loser27,\n",
        "            median_loser28,\n",
        "            median_loser29,\n",
        "            median_loser30,\n",
        "            median_loser31,\n",
        "            median_loser32,\n",
        "            median_loser33,\n",
        "            median_loser34,\n",
        "            median_loser35,\n",
        "            median_loser36,\n",
        "            median_loser37,\n",
        "            median_loser38,\n",
        "            median_loser39,\n",
        "            median_loser40,\n",
        "            median_loser41,\n",
        "            median_loser42,\n",
        "            median_loser43,\n",
        "            median_loser44,\n",
        "            median_loser45,\n",
        "            median_loser46,\n",
        "            median_loser47,\n",
        "            median_loser48,\n",
        "            median_loser49,\n",
        "            median_loser50,\n",
        "            median_loser51,\n",
        "            median_loser52,\n",
        "            median_loser53,\n",
        "            median_loser54,\n",
        "            median_loser55,\n",
        "            median_loser56,\n",
        "            median_loser57,\n",
        "            median_loser58,\n",
        "            median_loser59,\n",
        "            median_loser60,\n",
        "            median_loser61,\n",
        "            median_loser62,\n",
        "            median_loser63,\n",
        "            median_loser64,\n",
        "            median_loser65,\n",
        "            median_loser66,\n",
        "            median_loser67,\n",
        "            median_loser68,\n",
        "            median_loser69,\n",
        "            median_loser70,\n",
        "            median_loser71,\n",
        "            median_loser72,\n",
        "            median_loser73,\n",
        "            median_loser74,\n",
        "            median_loser75,\n",
        "            median_loser76,\n",
        "            median_loser77,\n",
        "            median_loser78,\n",
        "            median_loser79,\n",
        "            median_loser80,\n",
        "            median_loser81,\n",
        "            median_loser82,\n",
        "            median_loser83,\n",
        "            median_loser84,\n",
        "            median_loser85,\n",
        "            median_loser86,\n",
        "            median_loser87,\n",
        "            median_loser88,\n",
        "            median_loser89,\n",
        "            median_loser90,\n",
        "            median_loser91,\n",
        "            median_loser92,\n",
        "            median_loser93,\n",
        "            median_loser94,\n",
        "            median_loser95,\n",
        "            median_loser96,\n",
        "            median_loser97,\n",
        "            median_loser98,\n",
        "            median_loser99,\n",
        "            median_loser100,\n",
        "            median_loser101]\n",
        "\n",
        "upper_loser = [upper_loser1,\n",
        "            upper_loser2,\n",
        "            upper_loser3,\n",
        "            upper_loser4,\n",
        "            upper_loser5,\n",
        "            upper_loser6,\n",
        "            upper_loser7,\n",
        "            upper_loser8,\n",
        "            upper_loser9,\n",
        "            upper_loser10,\n",
        "            upper_loser11,\n",
        "            upper_loser12,\n",
        "            upper_loser13,\n",
        "            upper_loser14,\n",
        "            upper_loser15,\n",
        "            upper_loser16,\n",
        "            upper_loser17,\n",
        "            upper_loser18,\n",
        "            upper_loser19,\n",
        "            upper_loser20,\n",
        "            upper_loser21,\n",
        "            upper_loser22,\n",
        "            upper_loser23,\n",
        "            upper_loser24,\n",
        "            upper_loser25,\n",
        "            upper_loser26,\n",
        "            upper_loser27,\n",
        "            upper_loser28,\n",
        "            upper_loser29,\n",
        "            upper_loser30,\n",
        "            upper_loser31,\n",
        "            upper_loser32,\n",
        "            upper_loser33,\n",
        "            upper_loser34,\n",
        "            upper_loser35,\n",
        "            upper_loser36,\n",
        "            upper_loser37,\n",
        "            upper_loser38,\n",
        "            upper_loser39,\n",
        "            upper_loser40,\n",
        "            upper_loser41,\n",
        "            upper_loser42,\n",
        "            upper_loser43,\n",
        "            upper_loser44,\n",
        "            upper_loser45,\n",
        "            upper_loser46,\n",
        "            upper_loser47,\n",
        "            upper_loser48,\n",
        "            upper_loser49,\n",
        "            upper_loser50,\n",
        "            upper_loser51,\n",
        "            upper_loser52,\n",
        "            upper_loser53,\n",
        "            upper_loser54,\n",
        "            upper_loser55,\n",
        "            upper_loser56,\n",
        "            upper_loser57,\n",
        "            upper_loser58,\n",
        "            upper_loser59,\n",
        "            upper_loser60,\n",
        "            upper_loser61,\n",
        "            upper_loser62,\n",
        "            upper_loser63,\n",
        "            upper_loser64,\n",
        "            upper_loser65,\n",
        "            upper_loser66,\n",
        "            upper_loser67,\n",
        "            upper_loser68,\n",
        "            upper_loser69,\n",
        "            upper_loser70,\n",
        "            upper_loser71,\n",
        "            upper_loser72,\n",
        "            upper_loser73,\n",
        "            upper_loser74,\n",
        "            upper_loser75,\n",
        "            upper_loser76,\n",
        "            upper_loser77,\n",
        "            upper_loser78,\n",
        "            upper_loser79,\n",
        "            upper_loser80,\n",
        "            upper_loser81,\n",
        "            upper_loser82,\n",
        "            upper_loser83,\n",
        "            upper_loser84,\n",
        "            upper_loser85,\n",
        "            upper_loser86,\n",
        "            upper_loser87,\n",
        "            upper_loser88,\n",
        "            upper_loser89,\n",
        "            upper_loser90,\n",
        "            upper_loser91,\n",
        "            upper_loser92,\n",
        "            upper_loser93,\n",
        "            upper_loser94,\n",
        "            upper_loser95,\n",
        "            upper_loser96,\n",
        "            upper_loser97,\n",
        "            upper_loser98,\n",
        "            upper_loser99,\n",
        "            upper_loser100,\n",
        "            upper_loser101]"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u19FndLT2oU3"
      },
      "source": [
        "### Summarize arrays: 'Winner'\n",
        "\n",
        "lower_winner = [lower_winner1,\n",
        "            lower_winner2,\n",
        "            lower_winner3,\n",
        "            lower_winner4,\n",
        "            lower_winner5,\n",
        "            lower_winner6,\n",
        "            lower_winner7,\n",
        "            lower_winner8,\n",
        "            lower_winner9,\n",
        "            lower_winner10,\n",
        "            lower_winner11,\n",
        "            lower_winner12,\n",
        "            lower_winner13,\n",
        "            lower_winner14,\n",
        "            lower_winner15,\n",
        "            lower_winner16,\n",
        "            lower_winner17,\n",
        "            lower_winner18,\n",
        "            lower_winner19,\n",
        "            lower_winner20,\n",
        "            lower_winner21,\n",
        "            lower_winner22,\n",
        "            lower_winner23,\n",
        "            lower_winner24,\n",
        "            lower_winner25,\n",
        "            lower_winner26,\n",
        "            lower_winner27,\n",
        "            lower_winner28,\n",
        "            lower_winner29,\n",
        "            lower_winner30,\n",
        "            lower_winner31,\n",
        "            lower_winner32,\n",
        "            lower_winner33,\n",
        "            lower_winner34,\n",
        "            lower_winner35,\n",
        "            lower_winner36,\n",
        "            lower_winner37,\n",
        "            lower_winner38,\n",
        "            lower_winner39,\n",
        "            lower_winner40,\n",
        "            lower_winner41,\n",
        "            lower_winner42,\n",
        "            lower_winner43,\n",
        "            lower_winner44,\n",
        "            lower_winner45,\n",
        "            lower_winner46,\n",
        "            lower_winner47,\n",
        "            lower_winner48,\n",
        "            lower_winner49,\n",
        "            lower_winner50,\n",
        "            lower_winner51,\n",
        "            lower_winner52,\n",
        "            lower_winner53,\n",
        "            lower_winner54,\n",
        "            lower_winner55,\n",
        "            lower_winner56,\n",
        "            lower_winner57,\n",
        "            lower_winner58,\n",
        "            lower_winner59,\n",
        "            lower_winner60,\n",
        "            lower_winner61,\n",
        "            lower_winner62,\n",
        "            lower_winner63,\n",
        "            lower_winner64,\n",
        "            lower_winner65,\n",
        "            lower_winner66,\n",
        "            lower_winner67,\n",
        "            lower_winner68,\n",
        "            lower_winner69,\n",
        "            lower_winner70,\n",
        "            lower_winner71,\n",
        "            lower_winner72,\n",
        "            lower_winner73,\n",
        "            lower_winner74,\n",
        "            lower_winner75,\n",
        "            lower_winner76,\n",
        "            lower_winner77,\n",
        "            lower_winner78,\n",
        "            lower_winner79,\n",
        "            lower_winner80,\n",
        "            lower_winner81,\n",
        "            lower_winner82,\n",
        "            lower_winner83,\n",
        "            lower_winner84,\n",
        "            lower_winner85,\n",
        "            lower_winner86,\n",
        "            lower_winner87,\n",
        "            lower_winner88,\n",
        "            lower_winner89,\n",
        "            lower_winner90,\n",
        "            lower_winner91,\n",
        "            lower_winner92,\n",
        "            lower_winner93,\n",
        "            lower_winner94,\n",
        "            lower_winner95,\n",
        "            lower_winner96,\n",
        "            lower_winner97,\n",
        "            lower_winner98,\n",
        "            lower_winner99,\n",
        "            lower_winner100,\n",
        "            lower_winner101]\n",
        "\n",
        "median_winner = [median_winner1,\n",
        "            median_winner2,\n",
        "            median_winner3,\n",
        "            median_winner4,\n",
        "            median_winner5,\n",
        "            median_winner6,\n",
        "            median_winner7,\n",
        "            median_winner8,\n",
        "            median_winner9,\n",
        "            median_winner10,\n",
        "            median_winner11,\n",
        "            median_winner12,\n",
        "            median_winner13,\n",
        "            median_winner14,\n",
        "            median_winner15,\n",
        "            median_winner16,\n",
        "            median_winner17,\n",
        "            median_winner18,\n",
        "            median_winner19,\n",
        "            median_winner20,\n",
        "            median_winner21,\n",
        "            median_winner22,\n",
        "            median_winner23,\n",
        "            median_winner24,\n",
        "            median_winner25,\n",
        "            median_winner26,\n",
        "            median_winner27,\n",
        "            median_winner28,\n",
        "            median_winner29,\n",
        "            median_winner30,\n",
        "            median_winner31,\n",
        "            median_winner32,\n",
        "            median_winner33,\n",
        "            median_winner34,\n",
        "            median_winner35,\n",
        "            median_winner36,\n",
        "            median_winner37,\n",
        "            median_winner38,\n",
        "            median_winner39,\n",
        "            median_winner40,\n",
        "            median_winner41,\n",
        "            median_winner42,\n",
        "            median_winner43,\n",
        "            median_winner44,\n",
        "            median_winner45,\n",
        "            median_winner46,\n",
        "            median_winner47,\n",
        "            median_winner48,\n",
        "            median_winner49,\n",
        "            median_winner50,\n",
        "            median_winner51,\n",
        "            median_winner52,\n",
        "            median_winner53,\n",
        "            median_winner54,\n",
        "            median_winner55,\n",
        "            median_winner56,\n",
        "            median_winner57,\n",
        "            median_winner58,\n",
        "            median_winner59,\n",
        "            median_winner60,\n",
        "            median_winner61,\n",
        "            median_winner62,\n",
        "            median_winner63,\n",
        "            median_winner64,\n",
        "            median_winner65,\n",
        "            median_winner66,\n",
        "            median_winner67,\n",
        "            median_winner68,\n",
        "            median_winner69,\n",
        "            median_winner70,\n",
        "            median_winner71,\n",
        "            median_winner72,\n",
        "            median_winner73,\n",
        "            median_winner74,\n",
        "            median_winner75,\n",
        "            median_winner76,\n",
        "            median_winner77,\n",
        "            median_winner78,\n",
        "            median_winner79,\n",
        "            median_winner80,\n",
        "            median_winner81,\n",
        "            median_winner82,\n",
        "            median_winner83,\n",
        "            median_winner84,\n",
        "            median_winner85,\n",
        "            median_winner86,\n",
        "            median_winner87,\n",
        "            median_winner88,\n",
        "            median_winner89,\n",
        "            median_winner90,\n",
        "            median_winner91,\n",
        "            median_winner92,\n",
        "            median_winner93,\n",
        "            median_winner94,\n",
        "            median_winner95,\n",
        "            median_winner96,\n",
        "            median_winner97,\n",
        "            median_winner98,\n",
        "            median_winner99,\n",
        "            median_winner100,\n",
        "            median_winner101]\n",
        "\n",
        "upper_winner = [upper_winner1,\n",
        "            upper_winner2,\n",
        "            upper_winner3,\n",
        "            upper_winner4,\n",
        "            upper_winner5,\n",
        "            upper_winner6,\n",
        "            upper_winner7,\n",
        "            upper_winner8,\n",
        "            upper_winner9,\n",
        "            upper_winner10,\n",
        "            upper_winner11,\n",
        "            upper_winner12,\n",
        "            upper_winner13,\n",
        "            upper_winner14,\n",
        "            upper_winner15,\n",
        "            upper_winner16,\n",
        "            upper_winner17,\n",
        "            upper_winner18,\n",
        "            upper_winner19,\n",
        "            upper_winner20,\n",
        "            upper_winner21,\n",
        "            upper_winner22,\n",
        "            upper_winner23,\n",
        "            upper_winner24,\n",
        "            upper_winner25,\n",
        "            upper_winner26,\n",
        "            upper_winner27,\n",
        "            upper_winner28,\n",
        "            upper_winner29,\n",
        "            upper_winner30,\n",
        "            upper_winner31,\n",
        "            upper_winner32,\n",
        "            upper_winner33,\n",
        "            upper_winner34,\n",
        "            upper_winner35,\n",
        "            upper_winner36,\n",
        "            upper_winner37,\n",
        "            upper_winner38,\n",
        "            upper_winner39,\n",
        "            upper_winner40,\n",
        "            upper_winner41,\n",
        "            upper_winner42,\n",
        "            upper_winner43,\n",
        "            upper_winner44,\n",
        "            upper_winner45,\n",
        "            upper_winner46,\n",
        "            upper_winner47,\n",
        "            upper_winner48,\n",
        "            upper_winner49,\n",
        "            upper_winner50,\n",
        "            upper_winner51,\n",
        "            upper_winner52,\n",
        "            upper_winner53,\n",
        "            upper_winner54,\n",
        "            upper_winner55,\n",
        "            upper_winner56,\n",
        "            upper_winner57,\n",
        "            upper_winner58,\n",
        "            upper_winner59,\n",
        "            upper_winner60,\n",
        "            upper_winner61,\n",
        "            upper_winner62,\n",
        "            upper_winner63,\n",
        "            upper_winner64,\n",
        "            upper_winner65,\n",
        "            upper_winner66,\n",
        "            upper_winner67,\n",
        "            upper_winner68,\n",
        "            upper_winner69,\n",
        "            upper_winner70,\n",
        "            upper_winner71,\n",
        "            upper_winner72,\n",
        "            upper_winner73,\n",
        "            upper_winner74,\n",
        "            upper_winner75,\n",
        "            upper_winner76,\n",
        "            upper_winner77,\n",
        "            upper_winner78,\n",
        "            upper_winner79,\n",
        "            upper_winner80,\n",
        "            upper_winner81,\n",
        "            upper_winner82,\n",
        "            upper_winner83,\n",
        "            upper_winner84,\n",
        "            upper_winner85,\n",
        "            upper_winner86,\n",
        "            upper_winner87,\n",
        "            upper_winner88,\n",
        "            upper_winner89,\n",
        "            upper_winner90,\n",
        "            upper_winner91,\n",
        "            upper_winner92,\n",
        "            upper_winner93,\n",
        "            upper_winner94,\n",
        "            upper_winner95,\n",
        "            upper_winner96,\n",
        "            upper_winner97,\n",
        "            upper_winner98,\n",
        "            upper_winner99,\n",
        "            upper_winner100,\n",
        "            upper_winner101]"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84XIzmWD2oba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "84cf55da-98a0-4cea-e19b-93abea791985"
      },
      "source": [
        "### Visualize!\n",
        "\n",
        "title = obj_func\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(median_loser, color = 'Green')\n",
        "plt.plot(median_winner, color = 'Purple')\n",
        "\n",
        "xstar = np.arange(0, max_iter+1, step=1)\n",
        "plt.fill_between(xstar, lower_loser, upper_loser, facecolor = 'Green', alpha=0.4, label='GP EI Regret IQR: dEI')\n",
        "plt.fill_between(xstar, lower_winner, upper_winner, facecolor = 'Purple', alpha=0.4, label='STP CBM Regret IQR: dCBM')\n",
        "\n",
        "plt.title(title, weight = 'bold', family = 'Arial')\n",
        "plt.xlabel('(Post-initialization) iteration $\\it{k}$', weight = 'bold', family = 'Arial') \n",
        "plt.ylabel('log(Regret)', weight = 'bold', family = 'Arial') \n",
        "plt.legend(loc=1) # add plot legend\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n",
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5dkR2Id2oiu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb583d2-b8fa-410c-9d42-a9ca18d4e2a6"
      },
      "source": [
        "time_lose, time_win"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12746.943955421448, 9119.067081928253)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNLBF57p2opi"
      },
      "source": [
        ""
      ],
      "execution_count": 198,
      "outputs": []
    }
  ]
}